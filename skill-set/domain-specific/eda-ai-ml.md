#	EDA: Electronic Design Automation Job Opportunities

+ skill set:
	- Required Machine Learning Experts for EDA Products, we need people who are passionate about technology, constantly seeking to learn and improve the skill set with good communication and interpersonal skills.
	- Should be proficient in Python and applying ML Algorithms.
	- Good knowledge of machine learning algorithms like Neural network, CNN, Logistic regression, KNN, Random forest, decision tree, clustering etc.
	- knowledge of C with good programming skills & logical interpretation.
	- Decent depth in understanding ML algorithm concepts like supervised/unsupervised, regression/classification, time series algorithms
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.











###	Hardware Security

hardware security topics from Trust-Hub website Trust-Hub.org:
+ System-on-chip (SoC) Attacks and Security
+ Intellectual Property (IP) Trust and Assurance
+ Reverse Engineering
+ Invasive and Semi-invasive Physical Attacks
+ Computer-aided design (CAD) for Security
+ Side Channel Attacks and Mitigation
+ Hardware Security Primitives (PUFs, TRNGs, etc.)
+ Hardware Obfuscation
+ Hardware Trojans and Backdoors
+ Counterfeit Electronics
+ FPGA/eFPGA Security
+ IoT and Cyber-physical System Security
+ Emerging and Nanoscale Device Security

Denis Gray, Ph.D.: dogray@ncsu.edu








##	VLSI Deep Learning & Embedded Deep Learning





+ skill set:
	- R&D Director - ML Systems
	- We are a Cambridge-based startup developing a revolutionary B2B SaaS product for automated synthesis of ultra-efficient Intelligent Systems. Our product will empower Edge AI & Robotics companies to achieve supreme efficiency and flexibility, while slash the development time and costs tenfold.
	- To perform advanced R&D critical for the success of our product, we are looking for a passionate and impactful leader to direct our growing activities in designing and optimizing Computer Systems for Machine Learning (ML Systems).
	- Perform critical R&D for a revolutionary neuralware/middleware/hardware co-design product.
	- Lead a team of ninja-class engineers (many at PhD-level) with glorious achievements in performance analysis and optimization.
	- Collaborate with high-profile ML Hardware customers to create highly competitive and fully compliant submissions to MLPerf.
	- Collaborate with Robotics and Edge AI customers to apply the hard-earned optimization knowledge to real-world use cases.
	- Represent KRAI in the most active working groups of MLCommons, including Inference and Power, and contribute to the roadmap.
	- Push the number of automated KRAI submissions in each round from hundreds to hundreds of thousands!
	- A PhD or MSc in Computing or Natural Sciences, with 5+ years of post-graduate experience.
	- Deep understanding of the full software/hardware stack, including algorithms, compilers, libraries, computer architecture.
	- Expertise in domain-specific accelerators (e.g. NPUs, GPUs, DSPs).
	- Hands-on experience with ML frameworks (e.g. Torch, TensorFlow) and inference engines (e.g. OpenVINO, TensorRT, TFLite, ArmNN).
	- Familiarity with ML optimization techniques (e.g. quantization, pruning).
	- If you're a systems person, you can play to your strengths and keep growing your expertise in any of the above areas, or instead jump outside your comfort zone and learn more about Edge AI & Robotics applications. Two things are certain: a) you'll be constantly learning and pushing the boundaries of your skills and knowledge; b) it'll be fun!
	- It is a unique opportunity to advance the state-of-the-art in ML Systems by considering all critical elements of the stack: from hardware to middleware to neuralware, akin to the amazing Nand-to-Tetris approach. (In fact, we hope to write our own book about our learnings one day!)
	- Please send your CV and short covering letter to info@krai.ai - we will be happy to arrange a friendly chat! What we ask for is evidence supporting your abilities and motivation: it's up to you to decide what that evidence might be.
	- Our team at KRAI (formerly, dividiti) has come a long way from co-organizing the ReQuEST tournament at ASPLOS'18 to becoming leading contributors to MLCommons/MLPerf™, the industry-leading forum for benchmarking Computer Systems for Machine Learning (ML). As part of our journey, we have collaborated with Arm, Dell, Intel, VMware, Qualcomm and leading ML hardware startups. In particular, in our public collaboration with Qualcomm we have produced some of the fastest and most energy-efficient Inference results, both in the Datacenter and Edge category. Over the three year history of MLPerf Inference, we submitted over 50% of all results, that is, more than other 40+ submitters combined.
+ skill set:
	- Ultra-efficient Computer Systems for Edge AI and Robotics
	- Krai is a Cambridge-based startup focusing on creating ultra-efficient computer systems for Edge AI and Robotics applications. We are looking for curious and motivated R&D engineers to join us on our exciting journey!
	- Automating software/hardware co-design
	- We are building an automated platform for software/hardware (SW/HW) co-design. We envision our customers will provide their requirements such as training and validation datasets, quality targets, performance and energy efficiency constraints, etc. Then, our platform will design several candidate AI/SW/HW stacks composed of neural networks, libraries, inference engines, etc., for running on one or more HW platforms. The platform will integrate many state-of-the-art and emerging techniques such as network architecture search, network optimisation, graph compilers, etc. - all wrapped up in an intelligent meta-technology for searching through myriads of combinations and configuration options. Our automated platform will produce superior designs and slash development time and cost by 10-100 times, opening up unprecedented opportunities for Edge AI and Robotics applications.
	- Collaborating with a broad computer systems community
	- As part of our strategy, we collaborate with many leading organisations ranging from stealth-mode AI HW startups to global corporations. Our core expertise and responsibilities include compilers, runtime systems, architecture definition, performance modelling, optimization, workload mapping and benchmarking. For example, we implemented, validated and optimized the MLPerf Inference benchmarks for Qualcomm's impressive entrance with their Cloud AI 100 accelerators, achieving up to 6x energy efficiency over the entrenched competition.
	- If you're a systems person, you can play to your strengths and keep growing your expertise in any of the above areas, or instead jump outside your comfort zone and learn more about AI applications. Two things are certain: a) you'll be constantly learning and pushing the boundaries of your skills and knowledge; b) it'll be fun! What we ask for is evidence supporting your abilities and motivation: it's up to you to decide what that evidence might be.
	- If that sounds like your cup of tea, please send us your CV and covering letter to info@krai.ai - we will be happy to arrange a friendly chat.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.















###	Start-ups related to VLSI Deep Learning & Embedded Deep Learning

+ 
















##	Companies in the Semiconductor Industry



+ FPGA companies
	- AMD/Xilinx
	- Intel Altera
	- [Lattice Semiconductor](https://www.latticesemi.com/)
	- [QuickLogic Corporation](https://www.quicklogic.com/company/careers/)
		* Not friendly to non- U.S. citizens.
	- [Menta S.A.S, Sophia Antipolis](https://www.menta-efpga.com/careers)
	- [Achronix Semiconductor Corporation](https://www.achronix.com/company/careers)
	- [Flex Logix Technologies, Inc.](https://flex-logix.com/)
	- [Microchip Technology](https://www.microchip.com/)
+ machine learning hardware accelerators (including coarse-grained reconfigurable architctures, CGRA), machine learning acceleration via domain-specific computing, heterogeneous computing systems for machine learning, VLSI deep learning, and embedded deep learning
	- [SimpleMachines, Inc.](https://www.simplemachines.ai/company)
	- [Codeplay Software Ltd.](https://www.codeplay.com/company/careers/#career-list)
	- [Thirdwayv](https://www.thirdwayv.com/careers/)
	- [NAME](URL)
	- [NAME](URL)
	- [NAME](URL)
	- [NAME](URL)
	- [NAME](URL)
	- [Qualcomm Technologies, Inc.](https://www.qualcomm.com/research/artificial-intelligence/ai-research): https://www.qualcomm.com/company/careers
	- [Cornami, Inc.](https://cornami.com/)
+ companies selling RISC-V -based products
	- [SiFive, Inc.](https://www.sifive.com/careers)
+ edge computing
	- [EdgeImpulse Inc.](https://edgeimpulse.com/careers)















##	Additional Information about EDA

+ [IP-XACT is an XML format that defines and describes individual, re-usable electronic circuit designs (individual pieces of intellectual property, or IPs) to facilitate their use in creating integrated circuits (i.e. microchips). IP-XACT was created by the SPIRIT Consortium as a standard to enable automated configuration and integration through tools.](https://en.wikipedia.org/wiki/IP-XACT)
+ [The SystemRDL language, supported by the SPIRIT Consortium, was specifically designed to describe and implement a wide variety of control status registers. Using SystemRDL, developers can automatically generate and synchronize register views for specification, hardware design, software development, verification, and documentation.](https://en.wikipedia.org/wiki/SystemRDL)
	- [SystemRDL Compiler](https://github.com/SystemRDL/systemrdl-compilerSystemRDL Compiler)
	- [open-register-design-tool, Ordt](https://github.com/Juniper/open-register-design-tool)
	- https://www.eda.org/images/downloads/standards/systemrdl/SystemRDL_2.0_Jan2018.pdf
+ Automatic Register Verification (ARV)
+ synthesizable RTL, UVM, c-header, RALF eRM, SystemRDL, IP-XACT
+ UVM, Universal Verification Methodology, SystemVerilog based
+ VMM, Verification Methodology Manual
+ OVM, Open Verification Methodology
+ URM, Universal Reuse Methodology
+ eRM, e Reuse Methodology, e Verification Language








##	Application engineers of different EDA products

Skill sets for application engineers of different EDA products:
+ Bus protocols such as AMBA-AXI, AHB, APB, I2C, SPI
+ Expert in coding SV Testbench, drivers, monitors, scoreboards, checkers
+ Experience in C/C++,Shell/Perl scripting.
+ Understanding of AHB, AXI and other bus protocols and system architecture is a plus.
+ Expert in System Verilog and OVM/UVM based verification.
+ Preferred Expertise in MIPI UniPro/UFS Protocol and UVM.
+ To help the team to verify the existing design (UFS/UniPro)
+ Preferable: Experience in one/more of the following areas PCI_Express, USB, SATA, SDIO, MIPI and /or AMBA standards (OCP, AXI, AHB etc.)
+ Experience with verification methodology like OVM/VMM/UVM
+ Experience in constrained-random verification is a strong plus




+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.










#	Artificial Intelligence + Machine Learning










##	Machine Learning, ML





+ ML/AI compiler design
	- Poplar framework for IPU architecture compiler.
+ ML/AI compilers:
	- MLIR
	- TVM
	- Glow
+ ML/AI frameworks
	- JAX:
		* JAX = Autograd + XLA
		* for high-performance machine learning research
		* https://github.com/google/jax





***Machine Learning Scientist*** and ***Deep Learning Scientist*** roles:
+ BLAH




















***Machine Learning Engineer*** roles:
+ You will be expected to have a good understanding of a broad range of traditional supervised and unsupervised techniques (e.g. logistic regression, SVMs, GBDTs, Random Forests, k-means and other clustering techniques, matrix factorization, LDA . . .) as well as be up to date with latest ML advances (e.g. Deep Neural Networks, or non-parametric Bayesian methods).
+ tech stack:
	- Experience with Deep Learning frameworks, e.g., PyTorch, DeepLearning4J, TensorFlow
	- Experience in SPARK (using Python or Scala). Knowledge of AWS services will be appreciated.
+ skill set:
	- 3+ years of experience in machine learning, data mining, natural language processing, information retrieval, or statistical analysis
	- Experience working with large data sets using open source technologies such as Spark, Hadoop, and NoSQL
	- Experience developing and productizing real-world AI/ML applications such as prediction, personalization, recommendation, content understanding and NLP
	- Experience working with at least 3 of the following popular machine learning frameworks/libraries: sklearn, tensorflow, pytorch, caffe, keras, theano, cntk, mxnet, spark mllib
	- Experience developing and deploying deep learning NLP models is a plus
	- Experience working with a knowledge graph is a plus
+ skill set:
	- 7+ years of industry/academic experience in Machine Learning or related field
	- You will be expected to have a good understanding of a broad range of traditional supervised and unsupervised techniques (e.g. logistic regression, SVMs, GBDTs, Random Forests, k-means and other clustering techniques, matrix factorization, LDA . . .) as well as be up to date with latest ML advances (e.g. Deep Neural Networks, or non-parametric Bayesian methods).
	- Previous experience building end to end scalable Machine Learning systems
	- Software engineering skills. Knowledge of Python and C++ is a plus.
	- Knowledge of existing open source frameworks such as scikit-learn, Torch, Caffe, or Theano is a plus
+ skill set:
	- Individuals in this role should be experts in machine learning and NLP and have experience working on problems such as language models, discourse analysis, question-answering, word-sense disambiguation, automatic summarization etc.
	- Improve our existing NLP and Machine Learning systems using your expertise
	- Identify new opportunities to apply NLP and Machine Learning to different parts of the Quora product
	- Work with other engineers to implement algorithms, abstractions and systems in an efficient way, with strong positive impact on our user-facing products
	- Take end to end ownership of Machine Learning systems - from data pipelines and training to realtime prediction engines
	- Good mathematical understanding of popular NLP and Machine Learning algorithms
	- Experience building production-ready NLP or information retrieval systems
	- Hands-on experience with NLP tools, libraries and corpora (e.g. NLTK, Stanford CoreNLP, Wikipedia corpus, etc)
	- Knowledge of Python or C++, or the ability to learn them quickly
+ skill set:
	- At Quora, we use Machine Learning in almost every part of the product - feed ranking, answer ranking, search, topic and user recommendations, spam detection etc.
	- Take end to end ownership of Machine Learning systems - from data pipelines and training, to realtime prediction engines.
	- Previous experience building internet applications and large systems
	- General understanding of Machine Learning at the level of a semester-long ML class (college or multiple MOOCs)
	- Passion for learning
+ skill set:
	- We use a variety of algorithms — everything from linear models to decision trees and deep neural networks.
	- To that end, we are looking for engineers to help us build our company-wide ML development platform. In this role, you will be the part of a small team solving very interesting technical problems at the intersection of various exciting domains like Machine Learning, Distributed Systems and High Performance Computing.
	- Build and maintain large scale distributed systems to support the whole pipeline from data collection and training to deployment
	- Write efficient implementations of ML algorithms over CPUs & GPUs
	- Integrate our in-house systems with open source libraries like Spark and Tensorflow
	- Build abstractions to automate various steps in different ML workflows
	- Build tools to debug, visualize and inspect various features and models
	- Work with the engineers who use the platform, and help them be more impactful by improving the platform
	- Experience with designing large-scale distributed systems
	- Experience with building end-to-end machine learning systems
	- Take end to end ownership of Machine Learning systems - from data pipelines and training, to realtime prediction engines.
	- Previous experience building end to end Machine Learning systems
+ skill set:
	- 









































+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.














##	Applied Machine Learning, Applied ML



For applications of machine learning, or ML, in the following fields, see the *Markdown* document for [](bio-biochem-biotech-pharma.md)
+ bioinformatics
+ bio design automation, BDA
+ bio manufacturing automation
+ biology
+ biochemistry
+ biotechnology
+ medicinal chemistry
+ pharmacy
+ pharmaceutical science








For applications of machine learning, or ML, in finance, see the *Markdown* document for [](financial-engr-n-finance-x.md)











###	Computer Vision

















###	Natural Language Processing





+ Experience with Natural Language Processing
	- Topic Modeling
	- Document Classification
	- Document Summarization
	- Sentiment Analysis
+ skill set:
	- experience with ML deployment frameworks
	- work with highly imbalanced data sets to improve detection performance of our existing NLP models and algorithms
	- work closely with product and platform teams, participate in design reviews, and demo your work
	- apply the latest cutting-edge advancements in AI/ML research to our current solutions in a scalable manner for online detection
	- take full ownership of ML models, including:
		* collecting training data
		* evaluating and deploying models to production with ongoing quality monitoring
+ skill set:
	- build and operate high volume distributed systems
	- design and build systems in a microservice-based architecture
	- experience with ML deployment frameworks
	- design, implement, and deploy NLP models
	- experience working with high growth venture-backed start-ups



















###	Legal Informatics & Computational Law



This subsubsection includes skill sets for applied machine learning roles in legal services, including:
+ legal informatics
+ computational law











###	MLOps, or ML Ops, ModelOps, & AIOps 





####	MLOps, or ML Ops



MLOps is the set of practices at the intersection of Machine Learning, DevOps and Data Engineering.

MLOps or ML Ops is a set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently.

Machine learning models are tested and developed in isolated experimental systems. When an algorithm is ready to be launched, MLOps is practiced between Data Scientists, DevOps, and Machine Learning engineers to transition the algorithm to production systems.

Similar to DevOps or DataOps approaches, MLOps seeks to increase automation and improve the quality of production models, while also focusing on business and regulatory requirements. While MLOps started as a set of best practices, it is slowly evolving into an independent approach to ML lifecycle management.

MLOps applies to the entire lifecycle:
+ integrating with model generation
	- software development lifecycle
	- continuous integration/continuous delivery, CI/CD
+ orchestration
+ deployment
+ health
+ diagnostics
+ governance
+ business metrics

MLOps is a subset of ModelOps
+ MLOps is focused on the operationalization of ML models, while ModelOps covers the operationalization of all types of AI models.
+ MLOps is the intersection of:
	- machine learning engineering
	- DevOps
	- data engineering



Steps in a machine learning lifecycle:
+ data collection
+ data processing
+ feature engineering
+ data labelling
+ model design
+ model training
+ optimization
+ endpoint deployment
+ endpoint monitoring




Goals of enterprise machine learning that can be achieved through MLOps systems:
+ Deployment and automation
+ Reproducibility of models and predictions
+ Diagnostics
+ Governance and regulatory compliance
+ Scalability
+ Collaboration
+ Business uses
+ Monitoring and management


A common architecture of an MLOps system would include data science platforms where models are constructed and the analytical engines where computations are performed, with the MLOps tool orchestrating the movement of machine learning models, data and outcomes between the systems.



Need to address:
+ model effectiveness
+ model compliance
+ model life cycle (MLC) management as a cross-functional process




+ skill set:
	- develop distributed traning infrastructure for faster training of ML models
	- efficiently deploy ML models into production
	- create automation pipelines for continuous training, evaluation, and deployment of models
	- improve tracking of models, data, and experiments
	- create the interfaces, infrastructure, and clusters to process data efficiently
	- advance monitoring to identify model drift and active learning opportunities
	- establish scalable, efficient, automated processes for data analyses, model deployment, model validation, and model implementation
	- create and deploy new product features via collaboration with data scientists and software developers
	- ***champion engineering excellence and culture, establish metrics for regular improvement***
	- automate ML pipelines and deploy ML models in production environments
	- design and build systems in a microservices-based architecture
	- experience with ML deployment frameworks
	- experience with containerized applications, databases, and distributed computing
	- experience with deploying ML models as a Web service, and building scalable machine learning systems spanning multiple teams and organizations
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






















####	ModelOps



MLOps is a subset of ModelOps
+ MLOps is focused on the operationalization of ML models, while ModelOps covers the operationalization of all types of AI models.


ModelOps (model operations), as defined by Gartner, "is focused primarily on the governance and life cycle management of a wide range of operationalized"
+ artificial intelligence (AI) models
+ decision models
	- machine learning models
	- knowledge graphs models
	- rules
	- optimization
	- linguistic models
	- agent-based models
	- decision optimization models
+ optimization models
+ transformational models



ModelOps has overlaps wothin:
+ DataOps
+ DevOps


ModelOps is a programming model for reusable, platform-independent, and composable AI workflows.
+ Mitigate the accumulation of AI and machine learning models that are:
	- undeployed
	- unused
	- unrefreshed
	- manually deployed
+ Support model management of AI and machine learning models
+ address the gap between model deployment and model governance
+ ensure that all models are running in production with strong governance, and aligned with technical and business KPIs while managing the risk
+ programmatic solution for AI-aware staged deployment and reusable components that would enable model versions to match business apps, and which would include AI model concepts such as:
	- model monitoring
	- drift detection
	- active learning
+ cloud-based framework and platform for end-to-end development and lifecycle management of artificial intelligence (AI) applications
+ extend the principles of software lifecycle management to enable the following for AI model pipelines:
	- automation
	- trust
	- reliability
	- traceability
	- quality control
	- reproducibility
+ includes:
	- routine deployment of machine learning models
	- continuous retraining
	- automated updating
	- synchronized development
	- deployment of more complex machine learning models




References:
+ Hummer, Waldemar; Muthusamy, Vinod. ModelOps: Cloud-based Lifecycle Management for Reliable and Trusted AI. IEEE International Conference on Cloud Engineering. Parijat Dube, Kaoutar El Maghraoui. p. 1.


The ModelOps process focuses on:
+ automating the governance, management and monitoring of models in production across the enterprise
+ enabling AI and application developers to easily plug in life cycle capabilities
	- bias-detection
	- robustness and reliability
	- drift detection
	- technical, business and compliance KPIs
	+ regulatory constraints and approval flows for putting AI models into production as business applications



The ModelOps process starts with a standard representation of candidate models for production that includes a metamodel (the model specification) with all of the component and dependent pieces that go into building the model such as:
+ data
+ hardware and software environments
+ classifiers
+ code plug-ins
+ business and compliance/risk KPIs





+ Spring Boot, Spring Data Rest, and Microservice Development experience
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.












####	AIOps

AIOps, a similarly named, but different concept - using AI (ML) in IT and Operations.
























##	Logical AI + Other AI




















##	Differential Machine Learning











##	Differential Privacy





+ Hestia - Differential Privacy - Data Anonymization Challenge, https://www.topcoder.com/challenges/30082341
	- https://github.com/uber/sql-differential-privacy
	- https://github.com/arx-deidentifier/arx




























##	Data Science + Data Engineering + DataOps


This section provides information about data science roles and skills set regarding:
+ [Generic data science positions]()
+ [Business analytics]()
+ [Sports Analytics]()
+ [Data Science for public health]()
+ [Data Science for Advocacy, Lobbying, Think Tanks]()
+ []()
+ []()
+ []()
+ []()
+ []()




For skill sets in data science roles regarding finance, see the *Markdown* document [](financial-engr-n-finance-x.md).





For skill sets in data science roles regarding the following fields, see the *Markdown* document [](bio-biochem-biotech-pharma.md).
+ bioinformatics
+ bio design automation, BDA
+ bio manufacturing automation
+ biology
+ biochemistry
+ biotechnology
+ medicinal chemistry
+ pharmacy
+ pharmaceutical science






Notes:
+ In database normalization, unnormalized form (UNF), also known as an unnormalized relation or non first normal form (N1NF or NF^2),[1] is a database data model (organization of data in a database) which does not meet any of the conditions of database normalization defined by the relational model. Database systems which support unnormalized data are sometimes called non-relational or NoSQL databases. In the relational model, unnormalized relations can be considered the starting point for a process of normalization. It should not be confused with denormalization, where normalization is deliberately compromised for selected tables in a relational database.







###	Generic Data Science Roles




+ skill set:
	- Understand data landscape i.e tooling, tech stack, source systems etc. and work closely with the data Engineering team to improve the data collection and quality.
	- Ability to define and spot macro and micro levels trends with statistical significance on a regular basis and understand key drivers driving those trends.
	- 8+ years of data analyst experience with 4+ years of proven industry experience in a large scale environment(PBs scale, globally distributed teams).
	- Strong experience in Python, R, SQL, Tableau, Google Analytics, Hive and BigQuery (or any other Big data/Cloud equivalent) etc.
+ skill set:
	- Partner and align with business leaders, stakeholders, product managers and internal teams to understand the business and product challenges and goals and address them using predictive analytics in a globally distributed environment.
	- Understand data landscape i.e tooling, tech stack, source systems etc. and work closely with the data Engineering team to improve the data collection and quality.
	- Understand business/product strategy and high-level roadmap and align analysis efforts to enable them with data insights and help achieve their strategic goals.
	- Strong audience focused presentation and storytelling skills focused on key takeaways in a crisp and concise manner.
	- Define hypothesis driven models and best practices to derive and publish model scores/insights/learnings at scale within the company.
	- Ability to define and spot macro and micro levels trends with statistical significance on a regular basis and understand key drivers driving those trends.
	- 8+ years of data scientist experience with 4+ years of proven industry experience in a large scale environment (PBs scale, globally distributed teams).
	- Proven lead in driving multi-million dollar revenue generator models for the company and setting up data science related best practices at a company.
	- 2+ years experience with a fast-growing SaaS business based company is preferred.
	- Strong experience in Python, R, Spark, SQL, Tableau, Google Analytics, Hive and BigQuery (or any other Big data/Cloud equivalent) etc.
+ Experience with data analytics platforms, such as Semantic Pro, Semantic Cortex, IBM i2
+ tech stack:
	- 2+ years of analytical work experience (experience working with product organizations a plus)
	- Strong critical thinking and problem solving skills
	- Experience  communicating effectively with non-technical audiences
	- Strong ability to devise data-driven solutions to business problems
	- Strong competency with SQL
	- Experience with or exposure to a scripting language (Python preferred)
+ tech stack:
	- 5+ years of relevant analytical experience working with data or MS in a relevant technical field and 2+ years of analytical work experience (experience working with product organizations a plus)
	- Strong critical thinking and problem solving skills
	- Comfort and expertise communicating effectively with a wide-range of audiences (including product managers, engineers, business development managers, occasionally executives)
	- Strong ability to devise data-driven solutions to business problems
	- Ability to drive impact by thoughtfully tackling open-ended problems
	- Strong data intuition and deep understanding of and experience with statistical and/or ML modeling techniques
	- Strong competency with SQL
	- Fluency in a scripting language (Python preferred)
	- A plus: Experience with large scale data processing tools (Apache Spark) or implementing systems in production at scale
+ skill set:
	- Strong proficiency in Python a necessity, especially the Python data science stack
	- Experience developing data science models, workflows, and software for real world applications and working with imperfect data
	- Exploratory analysis, modeling, and visualization in Jupyter notebooks
	- Integrating data sources, creating subsets (ex. train/test) for modeling, and assessing potential datasets, tools, and approaches
	- Translating the results of analysis into implications for people and problems
	- Developing well-organized code that can be collaboratively reviewed, reproduced, and integrated into applications
	- Quickly assessing and becoming productive in relevant new technologies and methods
	- Experience with core data science tools (ex. pandas, scikit-learn, numpy, jupyter)
	- Experience working with messy data and real-world applications
	- Experience using IaaS like Amazon AWS
	- Working on a small team means doing a little bit of a lot of things. We're looking for somebody who can ask the right questions to figure out what is important, iterate between brainstorming together, working independently, and managing other data scientists, scope new data science projects, and exercise sound judgment to make reasonable decisions under conditions of ambiguity.
	- Communication is a core data science skill at DrivenData. Doing client-facing work involves articulating concepts, interpreting results, and selecting the method that satisfies the constraints of the project.
	- Working familiarity with the tools and practices used in software engineering and deployment (including test-driven deployment, containerization (ex. Docker), platform as a service (ex. Heroku), and infrastructure as a service (ex. AWS, Azure)
+ skill set:
	- Use Python and SQL to draw insights from data at scale
	- Extract actionable insights from broad, open-ended questions
	- Create dashboards and develop metrics to track the success and growth of the product
	- Design and evaluate experiments to measure the impact of product changes
	- Analyze data from across the product to uncover the root causes of metric movements
	- Communicate results to cross-functional stakeholders to inform product decisions
	- Develop tools to scale and automate analyses, improving productivity across the company
	- Improve the work of other data scientists through mentorship and by bringing industry best practices to the team
	- Experience generating insights using statistical techniques (e.g. regression, hypothesis testing)
	- Demonstrated ability to clearly explain data results to cross-functional teams
	- Experience using a procedural programming language (e.g. Python, R) to manipulate, clean, and analyze data
	- Ability to exercise judgment and combine quantitative skills with intuition and common sense
	- Experience evangelizing best practices and process improvements on your team
	- Experience working with large data sets and distributed computing tools (e.g. Redshift, Presto)
	- Experience pushing code and navigating a complex codebase
+ skill set:
	- Identify new methods to test product changes where traditional A/B testing is not possible
	- Drive adoption of good experimental and statistical practices across the company
	- Apply statistical techniques to increase the efficiency and rigor of our experimental analyses
	- Proactively identify ways to optimize and scale up the way we run experiments, and to increase data scientists' impact in general, and create processes and tools to meet these needs
	- Mentor other data scientists in experimental design and causal inference techniques
	- Coursework in experimental design, causal inference, and/or econometrics
	- Experience running and analyzing behavioral experiments
	- Statistical intuition and knowledge of various hypothesis testing and regression approaches, e.g. hierarchical modeling, difference-in-differences
	- Demonstrated ability working effectively with cross-functional teams
	- Experience using git and pushing to a codebase
	- Experience with software engineering projects or coursework
	- Develop tools to scale and automate analyses, improving productivity across the company
	- Experience working with large data sets and distributed computing tools (e.g. Redshift, Presto)
	- Experience pushing code and navigating a complex codebase
+ skill set:
	- Experience in data store design (data lakes; relational, columnar, NoSQL databases, analytics/OLAP cubes)
	- AWS and DevOps experience with AI/ML pipelines
	- Create the vision to build and evolve the team’s data infrastructure and tools. Technically lead for the design, building, and launching of new data models and data pipelines
	- Ensure production quality methods to retrieve, condition, validate, synthesize, and manipulate data
	- Full-stack build custom integrations between cloud-based systems using APIs
	- Continuously refine and improve the data architecture and delivery as new requirements surface
	- Experience ensuring data integrity, security, and encryption
+ skill set:
	- Associate Data Scientist (Internship):
	- VMware Tanzu Labs partners with organizations worldwide to accelerate innovation, while reducing operating costs and risk.  The data science team at VMware Tanzu Labs is primarily a consulting practice; we work with our customers to solve real world problems.  Our customers, like us, are cross-disciplinary. We service engagements with use cases running from customer churn to optimization to detecting fraud and misconduct.  We are not just doers; we are also educators and enablers. programs.
	- You have a passion for exploring data and connecting the value hidden in data with business outcomes and user needs.  You’re agile and retrospective, and not afraid to identify what we’re doing wrong so we can fix it, and what we're doing right so we can improve on it.  You’ll be working on a wide variety of data problems for a diverse range of clients. You will often be asked to learn new technologies and domains on the fly.   Above all, you judge your success by the success of your team and the happiness of your customers.
	- Be given an opportunity to attend fun and educational events to kickstart your career, meanwhile, you’ll get a better feel for our culture. 
	- Get hands-on exposure with cutting edge technology from managers, mentors, and fellow team members.
	- Acquire the tools and knowledge to contribute on a large scale.
	- Have the ability to advance your career in the direction you choose in the future. 
	- While there is no such thing as a “typical day”, these are activities we frequently find ourselves doing the following:
	- Partnering with clients to uncover and frame new opportunities for data science. Clients often come to us without a clear understanding of what we can do, so this is our chance to open their eyes to new possibilities for their businesses.
	- Pairing and writing code together with clients around engineering features, training models, tuning hyperparameters and evaluating results.  We emphasize rigor, because data science done right at this stage leads to models that shine in production.
	- Taking the models we build into production. This is an exciting stage for anyone who likes collaborating with product teams and seeing their model become real when users interact with it.
	- Helping our clients develop their internal data science practices, through mentoring and pair programming, so that they can be successful when we hand off the project.
	- Continuous learning by building demos and prototypes on new technologies, methodologies, and frameworks.  Presentation of learnings and findings for internal audiences, external conferences, and blog posts.
	- Bachelor’s degree in an analytical or quantitative field, or currently pursuing a master’s or doctorate degree in an analytical or technical field (e.g. applied mathematics, statistics, computer science, operations research, economics, data science, etc.). 
	- Clear and empathetic communicator. You’ll be the one sharing your insights with clients and stakeholders. As such, frequent communication and tireless empathy are essential to succeed in this role.
	- Fluent speaking and writing ability in Chinese and English.
	- Advanced knowledge of statistical modeling and/or machine learning methods. These are the technical skills we need to iterate and improve data science pipelines.
	- Strong exploratory data analysis skills. Every engagement starts with an investigation of the data, and thorough EDA saves us a lot of headaches in the long run.
	- Strong programming skills in SQL and Python/R
	- Hands-on experience working in a distributed computing environment
































####	Data Visualization


+ data visualization with:
	- Plotly
	- Tableau
	- PowerBI
	- Qlik
	- Google Charts
	


































###	Business Analytics



This subsubsection includes the following topics of business analytics, except financial analytics which is found in the following *Markdown* document for [Financial Engineering, Computational Finance, and Financial Analytics]().
+ [Marketing Analytics]()
+ [Human Resource Analytics]()
+ [Data Science for Logistics, Supply Chain Management, Industrial Distribution, & Retail Sales]()



####	Marketing Analytics





####	Human Resource Analytics









####	Data Science for Logistics, Supply Chain Management, Industrial Distribution, & Retail Sales






















###	Sports Analytics or Data Science for Sports









###	Data Science for Public Health












###	Data Science for Advocacy, Lobbying, Think Tanks












###	Data Science for Legal Informatics & Computational Law


This subsubsection includes skill sets for data science roles in legal services, including:
+ legal informatics
+ computational law











###	Data Science for Semiconductor Manufacturing















###	Data Engineering, DataOps, & Management of Information Systems



####	Data Engineering


Data engineering roles involve creating *Big Data* extract, transform, load (ETL) pipelines, and provide infrastructure support to help data scientists obtain insights from processing huge amounts of data.

They address:
+ readiness of data (sets)
+ format of data sets
+ resilience of infrastructure support for information systems
+ scaling of infrastructure support for information systems
+ security of infrastructure support for information systems

They support databases for:
+ operational data stores
+ data marts
+ data lakes
+ (enterprise) data warehouses, DW, DWH, or EDW







+ skill set:
	- Build and Support scalable and reliable data solutions that can enable self-service reporting and advanced analytics at Cloudflare using modern data lake and EDW technologies (Hadoop, Spark, Cloud, NoSQL etc.) in a agile manner.
	- 3+ years of development experience in Big data space working with Petabytes of data and building large scale data solutions.
	- Solid understanding of Google Cloud Platform, Hadoop, Python, Spark, Hive, and Kafka.
	- Experience in all aspects of data systems(both Big data and traditional) including data schema design, ETL, aggregation strategy, and performance optimization.
	- Capable of working closely with business and product teams to ensure data solutions are aligned with business initiatives and are of high quality.
+ Experience in working with large data sets and distributed computing tools (Hive, Redshift) is a plus
+ skill set:
	- Our data infrastructure team is responsible for all things data — our data warehouse, Hadoop, Redshift, Spark, Kafka, Airflow and so on.
	- Deep experience with MySQL, NoSQL data stores like HBase or similar.
	- Strong understanding of Unix/Linux variants, web network protocols, persistence solutions
+ skill set:
	- Python/Java Developer (Datagens)
	- LAB  SYSTEM & DATA ENGINEER
	- Are you interested in being part of a small, diverse team passionate about building technologies that change the way people learn?  Splunk Education is looking for a Lab and Data Engineer to join our Education Technologies Team. Our team is focused on building systems that help users learn to use our products in innovative ways.
	- Do you love tackling interesting problems and coming up with clean, stable solutions that delight users? We need to talk.
	- Opportunity to grow as an engineer. This role will provide a constant stream of new things to learn, providing the opportunity to expand your current knowledge and deep dive into new technologies.
	- Growth. We strongly believe in growing team members through ownership and leadership opportunities.
	- We pride ourselves on a collaborative, open and supported work environment.
	- The ability to work from home, or one of our many offices across the globe.
	- Participate in design and development of projects, either independently or in a team.
	- Be self-sufficient and take ownership of seeing projects through to successful conclusions.
	- Work with a diverse team of experts in education, video production, security and IT infrastructure.
	- Tasks include creating Terraform and Ansible playbooks to provision lab instances, along with building data generators that mock machine data across many technologies. 
	- B.S. degree in Computer Science or related field.
	- 8 years of experience
	- Deep knowledge of Python, Ansible, Terraform, Java, and AWS technologies.
	- Ability to read, understand and reproduce machine logs.
	- Experience with Docker, Kubernetes, GIT, and Splunk.























###	DataOps



DataOps is a set of practices, processes and technologies that combines an integrated and process-oriented perspective on data with automation and methods from agile software engineering to improve quality, speed, and collaboration and promote a culture of continuous improvement in the area of data analytics.

DataOps incorporates the Agile methodology to shorten the cycle time of analytics development in alignment with business goals.

DevOps focuses on continuous delivery by leveraging on-demand IT resources and by automating test and deployment of software. This merging of software development and IT operations has improved velocity, quality, predictability and scale of software engineering and deployment. Borrowing methods from DevOps, DataOps seeks to bring these same improvements to data analytics.

DataOps utilizes statistical process control (SPC) to monitor and control the data analytics pipeline. With SPC in place, the data flowing through an operational system is constantly monitored and verified to be working. If an anomaly occurs, the data analytics team can be notified through an automated alert.

DataOps is not tied to a particular technology, architecture, tool, language or framework.

Tools that support DataOps promote:
+ collaboration
+ orchestration
+ quality
+ security
+ access
+ ease of use



The volume of data is forecast to grow at a rate of 32% CAGR to 180 Zettabytes by the year 2025. 

DataOps seeks to provide the ***tools, processes, and organizational structures*** to cope with this significant increase in data. ***Automation streamlines the daily demands of managing large integrated databases,*** freeing the data team to develop new analytics in a more efficient and effective way. ***DataOps seeks to increase velocity, reliability, and quality of data analytics. It emphasizes communication, collaboration, integration, automation, measurement and cooperation between data scientists, analysts, data/ETL (extract, transform, load) engineers, information technology (IT), and quality assurance/governance.***




DataOps leadership principles:
+ Establish progress and performance measurements at every stage of the data flow. Where possible, benchmark data-flow cycle times.
+ Define rules for an abstracted semantic layer. Ensure everyone is "speaking the same language" and agrees upon what the data (and metadata) is and is not.
+ Validate with the "eyeball test":
	- Include continuous-improvement -oriented human feedback loops.
	- Consumers must be able to trust the data, and that can only come with incremental validation.
+ Automate as many stages of the data flow as possible, including:
	- BI
	- data science
	- data analytics
+ Using benchmarked performance information, identify bottlenecks and then optimize for them. This may require investment in commodity hardware, or automation of a formerly-human-delivered data-science step in the process.
+ Establish governance discipline, with a particular focus on two-way data control, data ownership, transparency, and comprehensive data lineage tracking through the entire workflow.
+ ***Design process for growth and extensibility. The data flow model must be designed to accommodate volume and variety of data.*** Ensure enabling technologies are priced affordably to scale with that enterprise data growth.”
























###	Management of Information Systems, MIS



Goals of MIS:
+ facilitate decision making
+ coordination, control, analysis, and visualization of information in an organization


Types of MIS include:
+ decision support systems, DSSs
+ executive information systems, EIS
+ marketing information systems
+ accounting information systems
+ human resource information systems
+ office automation systems, OAS
+ school information management systems, SIMS
+ enterprise resource planning, ERP
+ local databases
	- primal or base-level version of MIS




Enterprise applications of MIS:
+ enterprise resource planning, ERP
	- or, enterprise systems
+ supply chain management, SCM
+ customer relationship management, CRM
+ knowledge management system, KMS








+ Interact with MySQL data stores and NSQ messaging queues.
+ Senior Data Integration Solution Architect
	- Join us as we pursue our disruptive new vision to make machine data accessible, usable, and valuable to everyone. We are a company filled with people who are passionate about our product and seek to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most importantly, to each other’s success. Learn more about Splunk careers and how you can become a part of our journey!
	- As a Senior Solution Architect within the Enterprise Architecture group, you will play an important role in the success of our data integration strategy that directly impacts critical internal business processes that run our $3B+ and growing business. You will be responsible for defining the overall solution and technical architecture for our data integration platform that meets our vision for a Programmable Enterprise, while providing data integration solutions and expertise for a variety of complex internal business scenarios across the enterprise. You will need to apply your deep knowledge of ​data integration technologies, expertise with integration design patterns, and business application integration experience. To be successful you will have to balance priorities, collaborate with senior leaders, and present to executives while delivering within an agile delivery framework to meet key performance indicators.
	- This position requires you to be a self-starter with the ability to take ownership, prioritize, and handle various tasks simultaneously while maintaining a positive demeanor. In addition, strong verbal communication and written documentation skills are a must for this role for promoting ideas throughout the business to both technical and non-technical audiences.
	- Lead the overall technical strategy and solution design for a robust and scalable data integration and API platform
	- Facilitate the evaluation and selection of integration tools and technologies to meet business needs and demands
	- Define merger and acquisition data integration and migration strategies
	- Perform proof-of-concepts (POC) to prove out solutions and establish a core codebase ready for implementation
	- Deliver as-is and to-be application integration solution architecture for a variety of scenarios to meet business requirements and scale the company
	- Document data flows in relevant segments and ratify data ownership and retention policy with appropriate partners
	- Deliver high-quality deployment architecture diagrams that describe the solution and implementation
	- Participate in organization-wide project planning activities with project and product managers to guide on integration implementation strategies and cross-team dependencies
	- Partner closely with project managers, product managers, and engineering managers to define roadmaps and sprint planning objectives to meet solution designs
	- Represent the IT organization as the expert for data integration and API reference architecture and ensure alignment across partners
	- Collaborate with the broader architecture community, such as Architectural Review Board (ARB) and Enterprise Architects Council (EAC), to establish strategies and standard practices
	- Create executive presentations and present simple solutions to sophisticated problems to diverse partners across the company
	- 10+ years of demonstrable technical integration experience within IT application development environments
	- 8+ years of solution and technical architecture experience within the middleware industry to meet strict security and compliance requirements
	- Experience designing technical integration solutions for Salesforce, SAP S4/HANA, and Workday
	- Deep experience with a variety of middleware and data integration technology solutions, such as TIBCO, Boomi, Jitterbit, Oracle SOA, IBM WebSphere, Informatica, and/or Matillion
	- Familiarity with enterprise architecture frameworks such as Zachman and/or TOGAF
	- Demonstrated knowledge of Service Oriented Architecture (SOA) concepts and practices
	- Deep understanding of data integration and API concepts, patterns, and technologies
	- Demonstrable experience working in an Agile software development environment
	- Excellent both verbal and written communication skills to convey abstract and complex concepts
	- Travel up to 25% between Splunk offices locations
	- TOGAF 9 certification
	- Experience crafting high availability, publish and subscribe systems
	- Experience with AWS Application Integration and Compute products
	- BA, BS, or MS in Computer Science/Information Systems/Business or equivalent experience required
	- (Colorado only\*) Minimum base salary of $135,000.00. You may also be eligible for incentive pay + equity + benefits. \*Note: Disclosure per sb19-085 (8-5-201 et seq).
+ Experience in operations or cloud service environments and related partner platforms
	- EDR, endpoint detection and response, or endpoint threat detection and response
	- XDR, extended detection and response
		* NTA, network traffic analysis
	- CSPM
		* cloud security posture management
	- SEIM
		* security event and incident management
			+ Or, SIEM, security incident and event management
		* SEIM = security information management + security event management
			+ SEIM = SIM + SEM
		* log management
		* MSS, managed security service
		* MSSP, managed security service provider
		* SECaaS, security as a service
+ DLP, data loss prevention software
	- ILDP, information leak detection and prevention
	- ILP, information leak prevention
	- CMF, content monitoring and filtering
	- IPC, information protection and control
	- EPS, extrusion prevention system
	- IPS, intrusion prevention system
	- IDS, intrusion detection system
		* NIDS, network intrusion detection system
		* HIDS, host-based intrusion detection system




















##	Applied Machine Learning & Data Science Roles in Other Domains




For the transportation industry, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.










For the management consulting market, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.











For the K-12 (kindergarten to grade 12) education market, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.














For the higher education market, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.








For the real estate market, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.









For the waste management market, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.











For the health care industry, including health care informatics, health care analytics, health care management and hospital management, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.







For the media industry, including mass media and social media, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.








For the hospitality industry, including the tourism market, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






For the telecommunication industry, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.










For the electric power industry, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
















For the construction industry, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.







For the fashion industry, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.









For the entertainment industry, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.









For the music industry, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.









For the manufacturing industry, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.










For the regulatory compliance market, and regulatory enforcement and inspection/auditing market, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.




























#	Corporate Research Labs







##	EDA Research







###	EDA + Related Research with Alibaba Group


+ Using HW/SW Mechanisms to Improve Performance of remote Heterogeneous Systems
	- Alibaba is an e-commerce and AI company. We generate enormous data and consume huge amount of computation and storage resources every day. It is critical for Alibaba to keep on improving data center design given the emerging of powerful accelerator computation clusters.
	- We would focus on:
		* 1. Analyze different AI workloads in distributed GPU clusters, study their computation and network requirement
		* 2. Based on current remote accelerator technique, improve its efficiency via hardware/software solutions
		* 3. Apply the technique to real workload
	- Requirement:
		* 1. PHD candidate, experienced with distributed heterogeneous systems
		* 2. It's a plus if candidate worked with deep learning algorithms
		* 3. it's a plus if candidate has top conference publications
+ Last mile of datacenter as a computer -- local protocol and semantics based ASIC/FPGA cloud
	- Developers and customers prefer to use heterogeneous compute resources with a set of local server access protocol and semantics. We need to find talents to do research and prototyping with a specific local API on an ASIC or FPGA chip.
+ Emerging Accelerator Architecture, Programming Model, and Optimizations
	- The emerging hardware accelerator architectures, such as process-in-memory (PIM) and neuromorphic computing,  have shown great potential to speed up AI/ML and data-heavy applications. This research aims to investigate these non-traditional architecture designs and their performance implications for domain-specific applications in Alibaba datacenters and ecosystem. It will study the emerging architecture's programming model for usability and explore the software-hardware co-design strategies (e.g. reinforcement learning based architecture space exploration, architecture-aware compression and sparsity exploitation) and optimization trade-offs to maximize the performance.
+ Execution engine optimization based on GPUs and other modern hardware
	- Targeting Maxcompute SQL engine, we'd like to import modern hardware technology (such as GPU, FPGA etc) to model and improve the core operators of the distributed execution engine, optimize the system performance on specific scenes at last.
+ Performance/Power/Area (PPA) Modeling & Analysis
	- The ***Computing Technology Lab of Alibaba Damo Academy*** focuses on advanced research topics in computing, memory/storage, and interconnect technologies that can revolutionize today's computing systems with holistic innovations ranging from system architectures to VLSI designs, to enable new computing capabilities for improving energy efficiency and performance across multiple application domains, including both high-performance and embedded computing.
+ Research on Domain Specific Architecture
	- As the end of Dennard's scaling and Moore's Law running out of steam, the traditional architecture for general-purpose processors can no longer meet the requirements of high performance and low energy consumption for various emerging applications. To allow the computing to have higher performance/energy efficiency, Domain Specific Architecture (DSA) has become a popular solution. However, there are many challenges in the DSA design. For example, the definition of the scope of Domain, trade-off between specialization and general-purpose, instruction set design, compiler design and optimization, memory wall, ultra-low-power design, micro-structure design and optimization, etc. This internship Project is a thorough and detailed study of the DSA to address these challenges.
	- The Computing Technology Lab focuses on advanced research topics in computing, memory/storage, and interconnect technologies that can revolutionize today's computing systems with holistic innovations ranging from system architectures to VLSI designs, to enable new computing capabilities for improving energy efficiency and performance across multiple application domains, including both high-performance and embedded computing.
+ Research on Cloud Server Architecture
	- Perform profiling/modeling and evaluation of workloads for our cloud server, design and optimize server architecture including but not limited to: CPU, cache/memory, storage and accelerators.
+ Research on algorithms/architectures of the next-generation AliNPU for training
	- AliNPU targeting for neural network training is a key component of Alibaba's AI Chip strategy. To design an architecture surpassing the best of the AI training chips, such as GPU and TPU, we must look into all aspects from algorithms to HW architecture, for the potential computational efficiency improvements.
	- The works may focus on one or a few of the following directions：
		* 1. Algorithm innovations that may improve the system efficiency, and the experiments.
		* 2. The analysis of the theoretic bounds and/or the proof with regards to the algorithm innovations.
		* 3. Experimental HW architecture designs, simulations and their PPA analysis.
+ Hyper-scale cloud datacenter's compute resource pool and management platform prototype
	- Compute pools will be widely deployed in hyper-scale cloud datacenter. Alibaba Infrastructure AI Ops Platform (TIANJI) team is now actively seeking talents to work on research in this area.
+ Research on optimization of AI accelerator
	- Nowadays high performance computing has become one of the hot topics of AI research. The research aims on optimizing power dissipation and energy efficiency of AI accelerators targeting various of AI applications, providing high quality computation support for AI applications.
	- The research topics include:
		* 1. Research on computation pattern of various AI applications to look for bottleneck
		* 2. Research on AI accelerator architectures, implementations to improve performance and energy efficiency
		* 3. Codesign AI accelerator (SW/HW) and application to maximize the performance of accelerator)
+ Accelerating Machine Learning Applications on Heterogeneous Computing Architectures
	- This research aims to optimize ML applications on heterogeneous accelerators such as GPUs, FPGAs, and/or ASICs. S/he will conduct analysis and exploration on various performance bottlenecks in the full software/hardware stack, including ML algorithm improvement, model level transformation (e.g. compression, sparsity, data parallelization), and domain-specific architecture innovations, in order to dramatically boost the ML application's performance.






##	Computer Architecture Research




***Resources***
+ [HiPEAC](https://www.hipeac.net/)
	- For computer architecture, compiler design, and related areas.
	- [HiPEAC Jobs](https://www.hipeac.net/jobs/#/)





































##	Hardware Security Research














##	Formal Verification Research & Logical AI Research


***Resources***:
+ [SAT Live!](https://www.satlive.org/)















##	Machine Learning Research & Deep Learning Research







###	Machine Learning Research with Alibaba Group

+ Building an innovative and systematic AI benchmarks platform
	- Currently in Alibaba Group, deep learning and related applications have been employed in various business departments. Tmall, Alitrip, Taobao, Ant Financial and other departments are making extensive use of emerging deep learning technologies to continuously improve application and algorithms and enhance the consumer experience. On the one hand, Alibaba's engineering teams design, experiment and deploy different deep learning algorithms and applications every day. On the other hand, deep learning requires a lot of computational power, which also puts higher requirements on the computational power of the hardware and their adaptability to the application. How to balance the demand and supply relationship between these two and integrate the solution into a systematic platform product? How to automatically and systematically evaluate the computional power of an AI hardware? How to evaluate the advantages and disadvantages of a hardware for usage in an application and give customer recommendations through a systematic platform? These are the challenges we are currently dealing with and we need to solve. Recently we have launched the AI Matrix product (through aimatrix.ai website), but it is still in the early stage of the product. In the future, we need more people who have the same understanding as us and are willing to involve in solving these problems. Let's contribute our own strength and make the AI Matrix as an effective systematic platform and an impactful technical brand.
	- [AI Matrix](https://aimatrix.ai/en-us/)
	- https://github.com/alibaba/ai-matrix









##	Computer Vision Research









##	Compiler Design & Program Analysis (or Software Analysis) Research














##	Quantum Computing Research





###	Quantum Computing Research with Alibaba Group

+ Quantum Algorithm for Near-term Quantum Devices
	- A general-purpose fault-tolerant quantum computer will require millions of physical qubits and millions of quantum gate operations. With quantum computers of significant size now on the horizon, we should understand how to best exploit the initially limited abilities and how to develop and run useful quantum algorithms within the limited circuit depth of intermediate size quantum devices with limited error correction.
+ Research in Practical Applications of Quantum-Safe Communication
	- Quantum communication may refer to quantum cryptography, quantum teleportation, and quantum entanglement. Among those, quantum key distribution (QKD) is one of the most practical applications in recent years. Quantum cryptography takes the advantage of the laws of quantum physics to protect data,
	- Currently, the most significant problems in practical quantum cryptography systems include: high-speed quantum random number generation, long-distance fiber quantum key distribution with high key generation speed, co-fiber transmission of classical and quantum optical signals, as well as practical commercialization and stabilization.
	- Our project aims to study these critical issues in quantum cryptography system for practical applications. Due to the transmission loss and dark count, the bottleneck for its practical application lies in the trade-off between high speed key generation rate and long transmission distance. In order to solve these problems, one potential solution is to design more efficient telecommunication protocol to exceed the theoretical up bound of the generation rate. Meanwhile, the project will also focus on the study and practical solutions for quantum random number generation, post-quantum cryptography algorithm, the migration of classical and quantum networks, etc





















