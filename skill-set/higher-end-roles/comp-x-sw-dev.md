#	Computational *X* Software Development Roles


## Notes about Computational *X* Software Development Roles



This set of skill sets is for computational *X* software development roles, which includes the following (especially topics that involved computer simulation).
+ computational science, scientific computing, or scientific computation
	- computational biology
		* molecular bionetworks
	- computational physics
		* computational particle physics
			+ automatic calculation of particle interaction or decay
		* plasma modeling
	- computational astrophysics
		* numerical weather prediction
	- computational chemistry
		* cheminformatics
		* computational chemical methods in solid-state physics
		* for chemical pollution transport
	- computational geophysics
		* seismic processing
		* modeling of natural disasters
	- computational neuroscience
	- neuroinformatics
	- computational sustainability
		* computational environmental science
			+ climate research
	- computational forensics
	- ***scientific visualization***
	- molecular modeling
		* involves:
			+ computational chemistry
			+ computational physics
			+ molecular mechanics
+ computational engineering
	- except the following:
		* electronic design automation
		* design automation of cyber-physical systems
		* design automation of MEMS, NEMS, and related technologies.
		* bio design automation
	- includes:
		* finite element method, FEM
			+ finite element analysis, FEA
		* computational fluid dynamics, CFD
		* computational electromagnetics, CEM, computational electrodynamics, electromagnetic modeling
			+ RF simulation
			+ antenna CAD
				- antenna performance
				- radar cross section
				- computation of radiation pattern
				- electrical properties of radio antennas
				- waveguide modeling
			+ electromagnetic compatibility, EMC
				- electromagnetic interference, EMI
				- electromagnetic radiation
				- electromagnetic scattering
			+ electromagnetic wave propagation
		* computational mechanics
			+ structural dynamics
			+ computational solid mechanics
			+ vehicle crash simulations
			+ computational biomechanics
		* combustion simulations
		* computational thermodynamics
		* computational thermofluids
		* computational material science
			+ for:
				- polymers
				- crystals
		* computational industrial engineering (for logistics and manufacturing systems)
			+ discrete event simulation
			+ Monte-Carlo simulation
			+ queueing networks
			+ mathematical optimization
			+ simulation for ["methods engineering"](https://en.wikipedia.org/wiki/Methods_engineering)
		* for:
			+ structural engineering, or construction engineering
				- includes the following:
					* arcology
						arcology = architecture + ecology
			+ water supply systems
			+ transport modeling,r transportation o
				- vehicle modeling
			+ energy infrastructure, electrical power grids - including smart grids
			+ building information modeling, BIM
			+ model-based design approach
				- verification approaches
					* X-in-the-loop simulation, X-in-loop simulation, XIL simulation, X-based testing
					* model-in-the-loop simulation, model-in-loop simulation, MIL simulation, model-based testing
					* software-in-the-loop simulation, software-in-loop simulation, SIL simulation
						+ for control logic, controller, control plant, or controller subsystem
						+ closed-loop simulation with simulated plant
					* processor-in-the-loop simulation, processor-in-loop simulation, PIL simulation, PIL testing
					* FPGA-in-the-loop simulation, FPGA-in-loop simulation, FIL simulation, FIL testing, FPGA-in-the-loop testing, FPGA-in-loop testing
					* hardware-in-the-loop simulation, hardware-in-loop simulation, HIL simulation, HIL testing, hardware-in-the-loop testing, hardware-in-loop testing
						+ hardware for HILS
					* rapid control prototyping, RCP
+ computational mathematics
	- computer algebra
	- numerical computing
	- graph computing
	- stchastic methods
	- computational algebraic geometry
	- computational group theory
	- computational number theory
	- computational geometry
	- computational topology
	- algorithmic information theory
	- algorithmic game theory
	- experimental mathematics
+ computational statistics
+ high-performance computing, HPC
	- parallel computing
	- distributed computing
+ computational intelligence
+ computational network science, computational complex systems, or computational complex networks
	- computational public health
		* computational epidemiology
+ computational finance
	- derivative pricing
	- risk management
+ computational law
+ computational social science
	- computational economics
		* mathematical economics
		* econometrics
			+ semi-parametric approaches
			+ non-parametric approaches
		* dynamical systems modeling and optimization
			+ dynamic stochastic general equilibrium modeling, DSGE modeling
			+ agent-based modeling
	- computational sociology
+ computational linguistics
+ computational humanities
	- computational history
+ computational urban planning and architectural design
	- multi-objective optimization
		* generative design
	- parametric design of buildings and other structures
		* automatic shape generation algorithms
			+ based on reasonable rules
			+ using the tools:
				- *Digital Twins*
				- Revit-Dynamo
				- Rhinoceros-Grasshopper
	- quantification of evaluation indices for judging the merits of designs, produced from computational urban planning and architectural design
+ computational informatics
+ computational creativity, artificial creativity, mechanical creativity, creative computing, or creative computation
	- computational musicology
		* cognitive musicology
			+ compare with: cognitive neuroscience of music.
			+ part of: music psychology.
		* computer music
			+ application of computing technology in music composition, to help human composers create new music or to have computers independently create music, such as with algorithmic composition programs
			+ computer audition, CA, or machine listening
				- auditory cognition
					* modeling of emotions
					* anticipation and familiarity
					* auditory surprise
					* analysis of musical structure
				- multi-modal analysis
					* finding correspondences between textual, visual, and audio signals
				- feature extraction
					* sound descriptors
					* segmentation
					* onset
					* pitch and envelope detection
					* chroma
					* auditory representations
				- musical knowledge structures
					* analysis of tonality, rhythm, and harmonies
				- representation
					* signal and symbolic
					* time-frequency representations
					* both in terms of notes and spectral models
						+ pattern playback
						+ audio texture
				- sequence modeling
					* matching and alignment between signals and note sequences
				- source separation
					* methods of grouping of simultaneous sounds
						+ multiple pitch detection
						+ time-frequency clustering methods
				- sound similarity
					* methods for comparison between sounds, sound identification, novelty detection, segmentation, and clustering.
			+ machine improvisation
				- statistical style modeling
			+ sound synthesis
			+ sound design
			+ sonic diffusion
			+ acoustics
			+ psychoacoustics
		* digital musicology
		* mathematical music theory
		* music informatics
		* music information retrieval
		* sound and music computing
		* systematic musicology
	- computer art
		* AI art
		* algorithmic art, or algorithm art
			+ evolutionary art
		* digital art
		+ fractal art
		* generative art
			+ generative music
			+ visual art
		+ information art, informatism, or data art
		* systems art
			+ anti-form movement
			+ cybernetic art
			+ generative systems
			+ process art
			+ systemic art
				-systemic paintaing
				-systemic sculpture
	- sound and music computing
		* AI and music, AIM
			+ interactive scores
			+ music accompaniment
			+ music composition
		* assisted sound and music creation
			+ computer tools for assisting:
				- algorithmic composition
					* computer-aided algorithmic composition, CAAC
					* computer-generated scores for performance by human players
					* evolutionary music
					* generative music
				- music composition
				- sound design
		* interfaces for sound and music
			+ design and implementation of computer interfaces for sound and music
				- related to Human Computer Interaction.
		* processing of sound and music signals
			+ audio signal processing techniques
				- for the analysis, transformation, and resynthesis of sound and music signals
			+ auditory scene analysis
				- understanding and description of audio sources and events
		* understanding and modeling sound and music
			+ computational musicology
			+ music information retrieval
			+ (computational) music cognition
		* applications:
			+ auditory interfaces
				- applications where non-verbal sound is employed in the communication channel between the user and the computing device
				- Auditory displays are used in applications and objects that require monitoring of some type of information.
				- Sonification is used as a method for data display in a wide range of application domains where auditory inspection, analysis and summarisation can be more efficient than traditional visual display.
				- Sonic interaction design emphasizes the role of sound in interactive contexts.
			+ augmented action and perception:
				- tools that increase the normal action and perception capabilities of humans
					* systems adds virtual information to a user's sensory perception by merging real images, sounds, and haptic sensation with virtual ones
						+ This has the effect of augmenting the user's sense of presence, and of making possible a symbiosis between her view of the world and the computer interface.
						+ Possible applications are in the:
							- medical domain
							- manufacturing and repair
							- entertainment
							- annotation and visualization
							- robot tele-operation
			+ digital music instruments
				- musical sound generation and processing devices
					* simulation of traditional instruments
					* transformation of sound in recording studios or at live performances
					* musical interfaces for augmented or collaborative instruments
			+ digital music libraries:
				- preservation, conservation and archiving and the integration of musical audio content and meta-data descriptions, with a focus on flexible access
				- applications range from large distributed libraries to mobile access platforms
			+ interactive multimedia systems:
				- for use in:
					* everyday appliances
					* artistic and entertainment applications
				- aim to facilitate music-related human-machine interaction involving various modalities of action and perception
					* auditory
					* visual
					* olfactory
					* tactile
					* haptic
					* all kinds of body movements
				 	* music-related human-machine interaction can be captured through the use of the following categories of devices:
				 		+ audio/visual
				 		+ kinematic and bioparametric
				 			- skin conduction
				 			- temperature
				- machine musicianship
					* audition driven interactive music systems
			+ music information retrieval:
				- methods for search and analysis of similarity between music signals
				- retrieval technologies for music
					* both audio and symbolic data
					* applications include:
						+ music audio-identification
						+ broadcast monitoring
						+ higher-level semantic descriptions
						+ all associated tools for search and retrieval
			+ music production: This application domain focuses on technologies and tools for music composition. Applications range from music modeling and generation to tools for music post–production and audio editing.








Where possible, exploit [incremental computing](https://en.wikipedia.org/wiki/Incremental_computing), to speed up the performance of the computational *X* tool.






###	Application Domains of Computational *X*: Emerging Technologies


Emerging technologies that would be interesting application domains of computational *X*, especially computational engineering:
+ [***atomtronic circuit***](https://en.wikipedia.org/wiki/Atomtronics)
	- gravimetry
	- quantum computing
	- rotational sensing via the Sagnac effect
+ ***4-dimensional printing***, ***4-D printing***, 4-D bioprinting, ***active origami***, or ***shape-morphing systems***
	- uses ***programmable matter***
		* ["Programmable matter is matter which has the ability to change its physical properties (shape, density, moduli, conductivity, optical properties, etc.) in a programmable fashion, based upon user input or autonomous sensing. Programmable matter is thus linked to the concept of a material which inherently has the ability to perform information processing."](https://en.wikipedia.org/wiki/Programmable_matter)
			+ Robotics-based approaches
				- ***self-reconfiguring modular robotics***
					* Or, ***modular reconfigurable robotics***
					* Or, ***modular reconfigurable robot systems, MRRs***
					* Or, ***modular self-reconfiguring robotic systems***
					* ["are autonomous kinematic machines with variable morphology"](https://en.wikipedia.org/wiki/Self-reconfiguring_modular_robot)
					* stochastic reconfiguration
					* deterministic reconfiguration
				- claytronics
				- cellular automata
			+ ***Metamaterials*** are examples of programmable matter.
				- ["Metamaterials are artificial composites that can be controlled to react in ways that do not occur in nature."](https://en.wikipedia.org/wiki/Programmable_matter)
				- ["A metamaterial (from the Greek word μετά meta, meaning "beyond" and the Latin word materia, meaning "matter" or "material") is any material engineered to have a property that is not found in naturally occurring materials. They are made from assemblies of multiple elements fashioned from composite materials such as metals and plastics. The materials are usually arranged in repeating patterns, at scales that are smaller than the wavelengths of the phenomena they influence. Metamaterials derive their properties not from the properties of the base materials, but from their newly designed structures. Their precise shape, geometry, size, orientation and arrangement gives them their smart properties capable of manipulating electromagnetic waves: by blocking, absorbing, enhancing, or bending waves, to achieve benefits that go beyond what is possible with conventional materials."](https://en.wikipedia.org/wiki/Metamaterial)
				- ["Metamaterial research is interdisciplinary and involves such fields as electrical engineering, electromagnetics, classical optics, solid state physics, microwave and antenna engineering, optoelectronics, material sciences, nanoscience and semiconductor engineering"](https://en.wikipedia.org/wiki/Metamaterial)
				- optical filters
				- medical devices
				- sensor detection and infrastructure monitoring
				- smart solar power management
				- crowd control
				- high-frequency battlefield communication
				- lenses for high-gain antennas
				- improving ultrasonic sensors
				- shielding structures from earthquakes
	- "the resulting 3D shape is able to morph into different forms in response to environmental stimulus"
	- "4th dimension being the time-dependent shape change after the printing"
	- 4-D product, four-dimensional product
		* ["A four-dimensional product (4D product) considers a physical product as a life-like entity capable of changing form and physical properties autonomously over time. It is an evolving field of product design practice and research linked to similar concepts at the material scale (programmable matter and four-dimensional printing), however, typically utilizes sensors and actuators in order to respond to environmental and human conditions, modifying the shape, color, character and other physical properties of the product. In this way 4D products share similarities with responsive architecture, at the more human scale associated with products."](https://en.wikipedia.org/wiki/Four-dimensional_product)
+ ***Responsive computer-aided design, responsive CAD, responsive design***
	- ["Responsive computer-aided design (also simplified to responsive design) is an approach to computer-aided design (CAD) that utilizes real-world sensors and data to modify a three-dimensional (3D) computer model. The concept is related to cyber-physical systems through blurring of the virtual and physical worlds, however, applies specifically to the initial digital design of an object prior to production. ... The process begins with a designer creating a basic design of an object using CAD software with parametric or algorithmic relationships. These relationships are then linked to physical sensors, allowing them to drive changes to the CAD model within the established parameters. Reasons to allow sensors to modify a CAD model include customizing a design to fit a user's anthropometry, assisting people without CAD skills to personalize a design, or automating part of an iterative design process in similar fashion to generative design. Once the sensors have affected the design it may then be manufactured as a one-off piece using a digital fabrication technology, or go through further development by a designer."](https://en.wikipedia.org/wiki/Responsive_computer-aided_design)
		* ["Participatory design (originally co-operative design, now often co-design) is an approach to design attempting to actively involve all stakeholders (e.g. employees, partners, customers, citizens, end users) in the design process to help ensure the result meets their needs and is usable. Participatory design is an approach which is focused on processes and procedures of design and is not a design style. The term is used in a variety of fields e.g. software design, urban design, architecture, landscape architecture, product design, sustainability, graphic design, planning, and even medicine as a way of creating environments that are more responsive and appropriate to their inhabitants' and users' cultural, emotional, spiritual and practical needs. It is one approach to placemaking."](https://en.wikipedia.org/wiki/Participatory_design)
			+ ["Participatory design has been used in many settings and at various scales. For some, this approach has a political dimension of user empowerment and democratization. [3] For others, it is seen as a way of abrogating design responsibility and innovation by designers."](https://en.wikipedia.org/wiki/Participatory_design)
			+ ["Public interest design is a human-centered and participatory design practice that places emphasis on the 'triple bottom line' of sustainable design that includes ecological, economic, and social issues and on designing products, structures, and systems that address issues such as economic development and the preservation of the environment. Projects incorporating public interest design focus on the general good of the local citizens with a fundamentally collaborative perspective."](https://en.wikipedia.org/wiki/Public_interest_design)
	- ["Responsive computer-aided design is enabled by ubiquitous computing and the Internet of Things, concepts which describe the capacity for everyday objects to contain computing and sensing technologies. It is also enabled by the ability to directly manufacture one-off objects from digital data, using technologies such as 3D printing and computer numerical control (CNC) machines. Such digital fabrication technologies allow for customization, and are drivers of the mass-customization phenomenon. They also provide new opportunities for consumers to participate in the design process, known as co-design (or participatory design). ... As these concepts mature, responsive design is emerging as an opportunity to reduce reliance on graphical user interfaces (GUIs) as the only method for designers and consumers to design products,[3] aligning with claims by Golden Krishna that "the best design reduces work. The best computer is unseen. The best interaction is natural. The best interface is no interface."[4] Calls to reduce reliance on GUIs and automate some of the design process connects with Mark Weiser's original vision of ubiquitous computing."](https://en.wikipedia.org/wiki/Responsive_computer-aided_design)
+ design computing, design and computation, and computational design
	- ["The terms design computing and other relevant terms including design and computation and computational design refer to the study and practice of design activities through the application and development of novel ideas and techniques in computing."](https://en.wikipedia.org/wiki/Design_computing)
		* Artificial Intelligence in Design
		* Artificial Architecture
		* Expert and Knowledge-based Systems
		* Computational creativity
		* Computer-Aided Design
		* Responsive computer-aided design
		* Digital morphogenesis
		* Visual and Spatial Modelling
		* Computational Analogy
		* Automated Design Systems
		* Design Support Systems
		* Computer Supported Cooperative Work (CSCW)
		* Building Information Modeling (BIM)
		* Extended Reality (XR) and Hybrid Space
		* Digital Place-making
+ Responsive architecture
	- ["Responsive architecture is an evolving field of architectural practice and research. Responsive architectures are those that measure actual environmental conditions (via sensors) to enable buildings to adapt their form, shape, color or character responsively (via actuators). ... Responsive architectures aim to refine and extend the discipline of architecture by improving the energy performance of buildings with responsive technologies (sensors / control systems / actuators) while also producing buildings that reflect the technological and cultural conditions of our time. ... Responsive architectures distinguish themselves from other forms of interactive design by incorporating intelligent and responsive technologies into the core elements of a building's fabric. For example: by incorporating responsive technologies into the structural systems of buildings architects have the ability to tie the shape of a building directly to its environment. This enables architects to reconsider the way they design and construct space while striving to advance the discipline rather than applying patchworks of intelligent technologies to an existing vision of 'building'."](https://en.wikipedia.org/wiki/Responsive_architecture)
+ active structure
	- ["An active structure (also known as a smart or adaptive structure) is a mechanical structure with the ability to alter its configuration, form or properties in response to changes in the environment."](https://en.wikipedia.org/wiki/Active_structure)
+ ***semiconductor device engineering***, semiconductor device physics, solid-state physics
	- magnonics
	- spinmechatronics
		* spin mechatronics
			+ integration of nano- and micro- mechatronic systems with spin physics and spintronics
	- spinplasmonics
		* spinplasmonics = spintronics + plasmonics (or nanoplasmonics)
+ materials for new electronic and computer systems
	- electronic textiles, e-textiles
		* different from wearable computing
	- for storage systems:
		* [holographic data storage](https://en.wikipedia.org/wiki/Holographic_data_storage)
	- [Magnonics](https://en.wikipedia.org/wiki/Magnonics)
		* for integrating storage and logic together, in the same device.
	- multiferroics
		* ferroelasticity
		* ferroelectricity
		* ferromagnetism
	- [spintronics](https://en.wikipedia.org/wiki/Spintronics)
		* semiconductor-based spintronic devices
			+ antiferromagnetic storage media
			+ magnetic-tunnel transistor
		* spintronic-logic devices
			+ non-volatile spintronic-logic devices, non-volatile spin-logic devices
	- stereoelectronic effect
	- [Straintronics](https://en.wikipedia.org/wiki/Straintronics)
	- thin film
	- [Twistronics](https://en.wikipedia.org/wiki/Twistronics)
		* for flexible electronics
+ wearable computing
+ batteries
	- flexible batteries
		* flexible primary batteries
		* flexible secondary batteries, flexible rechargeable batteries
+ civic technology, or civic tech
	- ["Civic technology, or civic tech, enhances the relationship between the people and government with software for communications, decision-making, service delivery, and political process. It includes information and communications technology supporting government with software built by community-led teams of volunteers, nonprofits, consultants, and private companies as well as embedded tech teams working within government."](https://en.wikipedia.org/wiki/Civic_technology)
		* ["civic tech companies"](https://en.wikipedia.org/wiki/Civic_technology_companies)





















##	Software Development for Numerical Computing




+ [Numerical Library](https://en.wikipedia.org/wiki/List_of_numerical_libraries)
	- [Blaze C++ math library](https://bitbucket.org/blaze-lib/blaze/src/master/)
		* https://github.com/parsa/blaze
		* https://swmath.org/software/33224
		* https://www.cct.lsu.edu/~pdiehl/teaching/2019/4977/lecture9.pdf
		* https://www.cct.lsu.edu/~pdiehl/teaching/2019/4977/
			+ "Math 4997-3 Parallel computational mathematics"
		* https://isocpp.org/blog/2017/08/cppcon-2016-the-blaze-high-performance-math-library-klaus-iglberger
+ skill set:
	- We are looking for software engineering interns for our cuSPARSE and cuSOLVER team which are a key part of high-performance computing and deep learning software stacks. The main purpose of these libraries is to provide the fastest computing primitives for sparse and dense linear algebra, like Cholesky decomposition and sparse matrix products among many others. We see strong interest in optimization of such key functionalities from various industrial and research organizations - from Gaming and Machine Learning to autonomous driving and chip modeling. Some of these kernels spend several milliseconds while others involve hundreds of GPUs and spend hours. All of them need to be optimized for current and future GPUs that involve mathematical changes of algorithms. Does the idea of being at the heart of these projects and apply your knowledge to develop and optimize algorithms which make an impact around world excite you? If yes, then come and join our team!
	- During your internship, you will work with senior software engineers in the libraries team who will provide mentorship and guide you in developing highly optimized algorithms. Projects will involve implementing new numerical algorithms, defining APIs, analyzing performance, finding appropriate solutions for difficult numerical corner cases, and other general software engineering work.
	- Prototype and develop numerical algorithms for high-performance math libraries in the areas of dense and sparse linear algebra for single node and multi GPU clusters
	- Analyze the performance of GPU or CPU implementations and find opportunities for improvements.
	- Collaborate with team members to understand software use cases and requirements
	- Studying towards a degree in Computer Science, Applied Math, Engineering, or related field.
	- Strong C++ programming, debugging, performance analysis, and test design skills.
	- Strong algorithms and numerical methods fundamentals.
	- Ability to work independently.
	- Good teamwork, communication, and documentation habits.
	- Parallel programming experience using multi-threading or MPI.
	- GPU programming experience (CUDA or OpenCL).
	- Experience developing and optimizing numerical software.
	- Experience with sparse or dense algebra optimizations.
	- Exposure to floating-point arithmetic and numerical error analysis.
	- A scripting language, preferably Python.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.











##	Software Development for Graph Computing




+ skill set:
	- Experience with parallel programming, especially pthreads, OpenMP, and MPI
	- Strong mathematical fundamentals, including linear algebra and numerical methods
	- Experience in implementing direct and iterative solvers for the solution of large sparse linear systems
	- Experience with CUDA or OpenACC
+ skill set:
	- Katana Graph is an enterprise graph computing system and storage engine. Our technology is the world’s fastest graph processing engine, providing compelling scalability and programmability advantages... Building on decades of experience in developing state-of-the-art distributed systems, Katana Graph is bringing together experts in hardware acceleration, cloud computing, storage systems, and high-performance computing to help create the platform of the future for data processing and analysis in this new world of specialized hardware and revitalized algorithms... Katana Graph recently completed a $28.5 million Series A financing round led by Intel Capital with participation from existing and new investors including WRVI Capital, Nepenthe Capital, Dell Technologies Capital, and Redline Capital.
	- Are you a talented software engineer that is interested in developing solutions for difficult problems? Do you love to code and be actively engaged in the work you do?
	- Roles:
		* Graph Engine GPU - Software Engineer
		* Graph Query Engine - Software Engineer
		* Graph Transaction Engine - Software Engineer
		* Evolving Graph Engine - Software Engineer
		* Graph Storage Engine - Software Engineer
	- Successful engineers at Katana Graph are familiar with GRAPH ALGORITHMS, comfortable working in C/C++, and are proficient PARALLEL PROGRAMMERS, in addition to experience in one of the following areas::
		* Compiler, runtime or query engine development
		* Relational and/or graph databases
		* Distributed systems and/or high-performance computing
		* CUDA or OpenCL
		* Python
+ ***topological data analysis and graph network***
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






##	Software Development for Other Computational Mathematics Roles




+ skill set:
	- Digital Design Technologies is a software development group inside the Tesla design studio. The team creates state-of-the-art tools which improve the way Tesla conceives its products.
	- Although the main focus point will be surface-centered math, successful applicants will also be involved in key software development.
	- Implement techniques and formulas into usable algorithms
	- Create new mathematical formulas to solve complex surface-related problems
	- Thorough understanding of ***computational surface mathematics***
		* Surface mathematics uses:
			+ differential goemetry
			+ algebraic geometry
			+ topology
	- Knowledge of the mathematics inherent to ***NURBS and Subdivision surfaces***
		* NURBS: non-uniform rational basis spline. Or, non-uniform rational B-spline.
	- Experience with real time technologies preferred but not required
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.














##	Software Development for Computational Optimization



###	Notes for Computational Optimization


+ https://en.wikipedia.org/wiki/Multi-objective_optimization
	- Mathematical programming-based a posteriori methods, where an algorithm is repeated and each run of the algorithm produces one Pareto optimal solution;
		* Well-known examples of mathematical programming-based a posteriori methods are the Normal Boundary Intersection (NBI),[43] Modified Normal Boundary Intersection (NBIm)[44] Normal Constraint (NC),[45][46] Successive Pareto Optimization (SPO),[47] and Directed Search Domain (DSD)[citation needed] methods, which solve the multi-objective optimization problem by constructing several scalarizations. The solution to each scalarization yields a Pareto optimal solution, whether locally or globally. The scalarizations of the NBI, NBIm, NC and DSD methods are constructed with the target of obtaining evenly distributed Pareto points that give a good evenly distributed approximation of the real set of Pareto points.
	- Evolutionary algorithms where one run of the algorithm produces a set of Pareto optimal solutions.
		* Evolutionary algorithms are popular approaches to generating Pareto optimal solutions to a multi-objective optimization problem. Currently, most evolutionary multi-objective optimization (EMO) algorithms apply Pareto-based ranking schemes. Evolutionary algorithms such as the Non-dominated Sorting Genetic Algorithm-II (NSGA-II)[48] or its extended version NSGA-III[49][50] and Strength Pareto Evolutionary Algorithm 2 (SPEA-2)[51] have become standard approaches, although some schemes based on particle swarm optimization and simulated annealing[52] are significant. The main advantage of evolutionary algorithms, when applied to solve multi-objective optimization problems, is the fact that they typically generate sets of solutions, allowing computation of an approximation of the entire Pareto front. The main disadvantage of evolutionary algorithms is their lower speed and the Pareto optimality of the solutions cannot be guaranteed. It is only known that none of the generated solutions is dominated by another.
		* Another paradigm for multi-objective optimization based on novelty using evolutionary algorithms was recently improved upon.[53] This paradigm searches for novel solutions in objective space (i.e., novelty search[54] on objective space) in addition to the search for non-dominated solutions. Novelty search is like stepping stones guiding the search to previously unexplored places. It is especially useful in overcoming bias and plateaus as well as guiding the search in many-objective optimization problems.
	- Deep learning methods, where a model is first trained on a subset of solutions, and then queried to provide other solutions on the Pareto front.
		* Deep learning conditional methods are new approaches to generating several Pareto optimal solutions. The idea is to use the generalization capacity of deep neural networks to learn a model of the entire Pareto front, from a limited number of example trade-offs along that front, a task called Pareto Front Learning.[55] Several approaches address this setup, including using hypernetworks,[55] and using Stein variational gradient descent.[56]
	- ε-constraints method[57][58]
	- Pareto-Hypernetworks [55]
	- Multiple-objective Branch-and-Bound[59][60][61]
	- Normal Boundary Intersection (NBI)[43]
	- Modified Normal Boundary Intersection (NBIm)[44] Normal Constraint (NC),[45][46]
	- Successive Pareto Optimization (SPO)[47]
	- Directed Search Domain (DSD)[citation needed]
	- NSGA-II[48]
	- PGEN (Pareto surface generation for convex multi-objective instances)[62]
	- IOSO (Indirect Optimization on the basis of Self-Organization)
	- SMS-EMOA (S-metric selection evolutionary multi-objective algorithm)[63]
	- Approximation-Guided Evolution (first algorithm to directly implement and optimise the formal concept of approximation from theoretical computer science)[64]
	- Reactive Search Optimization (using machine learning for adapting strategies and objectives),[65][66] implemented in LIONsolver
	- Benson's algorithm for multiple objective linear programs and for multiple objective convex programs
	- Multi-objective particle swarm optimization
	- Subpopulation Algorithm based on Novelty
	- Types of preference information
		* There are different interactive methods involving different types of preference information. Three of those types can be identified based on
			+ trade-off information,
			+ reference points and
			+ classification of objective functions.[67]
		* On the other hand, a fourth type of generating a small sample of solutions is included:[68][69] An example of interactive method utilizing trade-off information is the Zionts-Wallenius method,[70] where the decision maker is shown several objective trade-offs at each iteration, and (s)he is expected to say whether (s)he likes, dislikes or is indifferent with respect to each trade-off. In reference point based methods (see e.g.[71][72]), the decision maker is expected at each iteration to specify a reference point consisting of desired values for each objective and a corresponding Pareto optimal solution(s) is then computed and shown to him/her for analysis. In classification based interactive methods, the decision maker is assumed to give preferences in the form of classifying objectives at the current Pareto optimal solution into different classes indicating how the values of the objectives should be changed to get a more preferred solution. Then, the classification information given is taken into account when new (more preferred) Pareto optimal solution(s) are computed. In the satisficing trade-off method (STOM)[73] three classes are used: objectives whose values 1) should be improved, 2) can be relaxed, and 3) are acceptable as such. In the NIMBUS method,[74][75] two additional classes are also used: objectives whose values 4) should be improved until a given bound and 5) can be relaxed until a given bound.
	- Hybrid methods
		* Different hybrid methods exist, but here we consider hybridizing MCDM (multi-criteria decision making) and EMO (evolutionary multi-objective optimization). A hybrid algorithm in the context of multi-objective optimization is a combination of algorithms/approaches from these two fields (see e.g.[67]). Hybrid algorithms of EMO and MCDM are mainly used to overcome shortcomings by utilizing strengths. Several types of hybrid algorithms have been proposed in the literature, e.g. incorporating MCDM approaches into EMO algorithms as a local search operator and to lead a DM to the most preferred solution(s) etc. A local search operator is mainly used to enhance the rate of convergence of EMO algorithms.
		* The roots for hybrid multi-objective optimization can be traced to the first Dagstuhl seminar organized in November 2004 (see, here). Here some of the best minds[citation needed] in EMO (Professor Kalyanmoy Deb, Professor Jürgen Branke etc.) and MCDM (Professor Kaisa Miettinen, Professor Ralph E. Steuer etc.) realized the potential in combining ideas and approaches of MCDM and EMO fields to prepare hybrids of them. Subsequently many more Dagstuhl seminars have been arranged to foster collaboration. Recently, hybrid multi-objective optimization has become an important theme in several international conferences in the area of EMO and MCDM (see e.g.[76][77]).
	- Visualization of the Pareto front
	- https://en.wikipedia.org/wiki/Multidisciplinary_design_optimization
		* multi-disciplinary design optimization (MDO)
	- https://en.wikipedia.org/wiki/List_of_optimization_software
		* https://en.wikipedia.org/wiki/Satisfiability_modulo_theories#SMT_solvers
		* https://ascend4.org/Publications







###	Skill Sets for Computational Optimization


+ advanced optimization algorithms:
	- Evolutionary Algorithms
	- surrogate model optimization
	- particle swarm optimization
	- Bayesian optimization
+ skill set:
	- ***Google OR-Tools***.
		* linear programming
		* mixed integer programming
		* constraint programming
			+ CP-SAT problem
		* vehicle routing
		* also has implementations of:
			+ graph algorithms
+ skill set:
	- Experience with C++11 and ***modern C++ style and idioms***
	- Optimize existing and new C++ code to ***reduce memory consumption*** and to ***increase performance and scalability***
	- Design and implement algorithms and solvers in C++ for ***transportation routing problems***
	- Work with product engineers to ***diagnose root causes for incorrect software behavior and failures***
	- Fix bugs in the existing C++ codebase
+ skill set:
	- Sr. Scientist with Applied Math (Ph.D. Required)
	- MemComputing Inc. is developing disruptive, next generation and unconventional computing platforms. We are looking for an exceptional and talented scientist with strong skills in applied math, physics, combinatorics, scientific programming, and high-performance computing. Join our team and help develop a software-based solution for our customers needing faster computation for their A.I., M.L., Operations Research, and Big Data Analytics problems. This Scientist role will participate in the architecture, design, development, test, and deployment of an advanced computational engine, as well as helping with professional services for high-profile customers. Successful candidates will find rewarding work in a diverse set of math, physics, and computer science specialties, including parallel and distributed computing (on GPU, FPGA, etc.), combinatorial optimization, numerical analysis, and simulation of differential equations. Applications include transportation & logistics, aerospace, satellites, robotics, autonomous vehicles, computational chemistry, and more. Excellent communication and collaborative skills, attention to detail, and strong technical and problem-solving skills are essential aspects of this role. All efforts will be performed in-house at our San Diego Headquarters.
	- Ph.D. in physics, applied math, computer science, computer engineering, data science, electrical engineering, or similar disciplines
	- High Performance Computing or scientific programming
	- Familiarity with modern software development practices and tools.
	- Experience with C++, CUDA, Python
	- Experience in combinatorial optimization and numerical analysis.
	- Demonstrated ability to develop and present ideas and results in oral and written form.
	- Demonstrated ability to work effectively and collaboratively in a team environment.
	- 3+ years of experience.
	- MATLAB skills and experience
	- Experience with FPGA implementation
	- Experience with algorithms used for optimization, machine learning, and A.I.
	- Experience with large, complex scientific and technical software systems.
	- Knowledge of distributed machine learning and unsupervised deep learning/neural networks.
	- Experience/education in a subset of the following: system engineering, distributed system design, numerical analysis, modeling and simulation, relational/object/geographic database technologies, user interfaces, scientific data visualization, web services technologies, and software development for multi-core/GPU/parallel computing.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.








##	Software Development for Computational Statistics



+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.












##	Software Development for Simulations


+ simulation technologies and software packages:
	- Bullet
	- Drake
	- Unity
	- Blender








###	Software Development for Modeling (only)


+ **Expertise and experience in Revit, Dynamo and/or other Revit scripting languages**... Strong background in computational design and design analysis... Fluency in a technical programming language (python, javascript, C#) is highly desired.
	- Autodesk Revit, for building information modeling
+ skill set:
	- At Toyota Research Institute (TRI), we’re working to build a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We’re dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life. Through innovations in AI, we’ll help...
		* Develop vehicles incapable of causing a crash, regardless of the actions of the driver.
		* Develop technology for vehicles and robots to help people enjoy new levels of independence, access, and mobility.
		* Bring advanced mobility technology to market faster.
		* Discover new materials that will make batteries and hydrogen fuel cells smaller, lighter, less expensive and more powerful.
		* Develop human-centered AI systems to augment (not replace) human decision making to increase the quality of decisions (e.g. mitigate cognitive biases) and/or to facilitate faster innovation cycles.
	- Our work is guided by a dedication to safety – in both what we research and how we perform our research our goal is to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies. Over half of our technical team carries PhD degrees. We’re continually searching for the world’s best talent ‒ people who are ready to define the new world of mobility with us!
	- We strive to build a company that helps our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve our goals. Come work with TRI if you’re interested in transforming mobility through designing technology for safer cars, enabling the elderly to age in place, or designing alternative fuel sources. Start your impossible with us.
	- TRI’s Machine Assisted Cognition (MAC) team is developing AI systems to augment (not replace) human decision making. In particular, MAC is advancing the intersection between behavioral science, machine learning, human-computer interaction, and causal inference to enhance human decision making. MAC will achieve this through simultaneously:
		* 1) Conducting experiments on the mechanisms underlying decision making to build predictive models of human behavior, and
		* 2) Conducting research on understanding those decisions, including new ways to engage and interact with those models, and investigating the nature of understanding information uncovered in our models.
	- Responsibilities:
		* Collaborate cross-functionally with specialists in multiple fields, as well as university partners to research and develop novel ways to demonstrate AI to augment human decision making. Some potential research and development areas may include:
		* Increasing quality of predictions, judgments, and decisions by creating new behavioral insights and computational models
		* Speeding up predictions, judgments, and decisions
		* Scaling up to more complex cognitive tasks and larger groups while countering the tendency of groups to be risk-averse.
		* Insights or tooling into how people can better understand human decision making (driven by models) and explainable AI (XAI)
		* Applying machine learning or reinforcement learning to model human behavioral data in ways consistent with human cognition
		* Conduct groundbreaking research at the intersection of behavioral science, AI, HCI as it relates to decision making resulting in peer-reviewed publications and/or patents
		* Co-define research projects and inform the strategy behind the research agenda of the Machine Assisted Cognition team
	- Qualifications:
		* Degree in Psychology, Behavioral Economics, Computer Science, Engineering, Information Sciences, or equivalent. Ph.D. preferred.
		* Experience in interdisciplinary research in these areas
		* Strong research background, including top-tier peer-reviewed publications.
		* Experience in use-inspired basic research and/or applying academic research in an industry setting
		* Strong interpersonal skills. Great teammate.
		* Appetite to learn across functions.
		* Ability to lead cross-functional projects.
	- Please add a link to Google Scholar and include a full list of publications when submitting your CV to this position.
+ skill set:
	- At Toyota Research Institute (TRI), we’re working to build a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We’re dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life. Through innovations in AI, we’ll help...
		* Develop vehicles incapable of causing a crash, regardless of the actions of the driver.
		* Develop technology for vehicles and robots to help people enjoy new levels of independence, access, and mobility.
		* Bring advanced mobility technology to market faster.
		* Discover new materials that will make batteries and hydrogen fuel cells smaller, lighter, less expensive and more powerful.
		* Develop human-centered AI systems to augment (not replace) human decision making to increase the quality of decisions (e.g. mitigate cognitive biases) and/or to facilitate faster innovation cycles.
	- Our work is guided by a dedication to safety – in both what we research and how we perform our research our goal is to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies. Over half of our technical team carries PhD degrees. We’re continually searching for the world’s best talent ‒ people who are ready to define the new world of mobility with us!
	- We strive to build a company that helps our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve our goals. Come work with TRI if you’re interested in transforming mobility through designing technology for safer cars, enabling the elderly to age in place, or designing alternative fuel sources. Start your impossible with us.
	- TRI’s Machine Assisted Cognition team is developing AI systems to augment (not replace) human decision making. In particular, we are interested in advancing the intersection between behavioral science, machine learning and causal inference to increase the quality of human decisions (e.g. mitigate cognitive biases) and / or to facilitate faster innovation cycles. We are looking for a Staff Behavioral Scientist to join this exciting new endeavor to collaborate cross-functionally with software engineers, machine learning and causal inference experts, designers and user researchers. 
	- Responsibilities:
		* Collaborate cross-functionally with software engineers, machine learning and causal inference experts, designers, user researchers and university partners to develop and build novel AIs to augment human decision making. Some potential research and development areas may include:
		* Increasing quality of predictions, judgments, and decisions by (a) reducing/neutralizing cognitive biases, (b) ensuring fitness, (c) ensuring ethics
		* Speeding up predictions, judgments, and decisions
		* Scaling up to more complex cognitive tasks and larger groups while countering the tendency of groups to be risk-averse.
		* Co-define the vision and strategy of the branch of the behavioral science of the machine-assisted cognition team with the organization's Sr. Director. 
	- Qualifications:
		* Degree in Psychology, Behavioral Economics or equivalent. PhD preferred.
		* Experience applying behavioral science principles in an industry setting.
		* Advanced knowledge of statistics, preferably passionate about causality.
		* Strong interpersonal skills. Great teammate.
		* Appetite to learn across functions.
		* Production-level coding and machine learning capabilities is a plus.
		* Ability to lead cross-functional projects
	- Please add a link to Google Scholar and include a full list of publications when submitting your CV to this position.
+ skill set:
	- At Toyota Research Institute (TRI), we’re working to build a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We’re dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life. Through innovations in AI, we’ll help...
		* Develop vehicles incapable of causing a crash, regardless of the actions of the driver.
		* Develop technology for vehicles and robots to help people enjoy new levels of independence, access, and mobility.
		* Bring advanced mobility technology to market faster.
		* Discover new materials that will make batteries and hydrogen fuel cells smaller, lighter, less expensive and more powerful.
		* Develop human-centered AI systems to augment (not replace) human decision making to increase the quality of decisions (e.g. mitigate cognitive biases) and/or to facilitate faster innovation cycles.
	- Our work is guided by a dedication to safety – in both what we research and how we perform our research our goal is to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies. Over half of our technical team carries PhD degrees. We’re continually searching for the world’s best talent ‒ people who are ready to define the new world of mobility with us!
	- We strive to build a company that helps our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve our goals. Come work with TRI if you’re interested in transforming mobility through designing technology for safer cars, enabling the elderly to age in place, or designing alternative fuel sources. Start your impossible with us.
	- TRI’s Machine Assisted Cognition team is developing AI systems to augment (not replace) human decision making. In particular, we are interested in advancing the intersection between machine learning, causal inference, and behavioral science to increase the quality of human decisions and / or to facilitate faster innovation cycles. We are looking for a Senior or Staff Machine Learning Engineer / Data Scientist to join this exciting new endeavor to collaborate cross-functionally with machine learning and causal inference experts, behavioral scientists, designers, and user researchers. 
	- Responsibilities:
		* Collaborate cross-functionally with machine learning and causal inference experts, designers, behavioral scientists, user researchers, and university partners to design and build novel AIs to augment human decision making. Some potential research and development areas may include:
		* Pushing the boundaries of AIs that can reason (causally informed AI)
		* Increasing quality of predictions, judgments, and decisions by (a) reducing/neutralizing cognitive biases, (b) ensuring fitness, (c) ensuring ethics
		* Scaling up to more complex cognitive tasks and larger groups while countering the tendency of groups to be risk-averse.
		* Mentor and advise others. 
	- Qualifications:
		* Bachelor’s or Master’s degree in a quantitative field (e.g. Computer Science, Mathematics, Physics, Engineering, Chemistry). Ph.D. preferred.
		* Deep expertise in machine learning and deep learning.
		* Proficiency in causal inference and advanced statistics.
		* Experience architecting and deploying machine learning systems in an industry setting.
		* Experience in providing technical leadership and mentorship.
		* Strong track record of driving and executing complex, open-ended, cross-functional projects.
		* Strong interpersonal skills. Great teammate.
		* Appetite to learn across functions.
	- Please add a link to Google Scholar and include a full list of publications when submitting your CV to this position.



















##	Software Development for Computational Science, or Scientific Computing





+ Experience with CUDA, VTK/ITK, and/or physics based simulation
+ skill set:
	- Experience in developing and debugging multi-threaded/parallel applications.
	- Experience in image processing, computational geometry, large data application, high performance computing and scientific simulation is a good plus.
+ tech stack:
	- Write C++ code to tackle ***scientific algorithmic problems*** such as: ***transforming 3D coordinates, Metropolis Monte Carlo simulation, Gradient Descent minimization***, and others.
	- Implement highly optimized multi-threaded C++ or CUDA code that scales well on cloud infrastructure.
	- Work closely with other software engineers via code reviews and testing to foster high-quality software and systems.
	- Solid computer science fundamentals, with strong competencies in data structures, algorithms, and compilers.   
	- Experience profiling C/C++ code to find and fix performance bottlenecks.
	- Comfort with the Linux command-line environment.
	- Background in Biology, Chemistry or Physics.
	- Familiarity working with Docker and Kubernetes.
	- Knowledge of parallel computing paradigms and demonstrated proficiency in some of the following: openMP, CUDA, or openCL.
	- https://www.atomwise.com/jobs/senior-software-engineer-scientific-computing/
+ tech stack:
	- Interact with customers to understand their project requirements.
	- Generate and analyze predictive results, and deliver these to our clients.
	- Communicate our results and capabilities through scientific publications.
	- Analyze, curate, and automate the processing of our biochemical databases.
	- Help to develop our modeling software.
	- Ph.D. in chemistry, biology or a related field.
	- Extensive knowledge of medicinal chemistry.
	- Minimum 3 years of experience in lead optimization at a pharmaceutical company.
	- Experience in Computer-Aided Drug Design: structure/ligand-based drug design, molecular docking, virtual screening, QSAR, pharmacophore modeling, PK/PD data analysis and modeling.
	- Comfortable on the Linux command-line.
	- Undergraduate knowledge of statistics.
	- Good knowledge of Python, Perl, Bash, or related scripting languages.
	- Statistical modeling.
	- Experience with cloud computing environments (AWS/Azure/GCE).
	- https://www.atomwise.com/jobs/senior-computational-chemist/
+ skill set:
	- large-scale compute platform
	- quantum chemistry methods for drug-design
	- experience with quantum chemistry software:
		* Psi4
		* Gaussian
	- experience with small-molecule crystallography and formulation
	- experience with:
		* computational chemistry methods
			+ development
			+ implementation
			+ validation
			+ massively parallel relative binding free energy (RBFE) tools
		* molecular modeling
			+ predict crystal structures of drug molecules and accelerate drug development
			+ molecular dynamics
				- free energy calculations
				- molecular dynamics simulation
					* enhanced sampling molecular dynamics simulations
		* cloud computing
			+ cloud-based CADD, computer-aided drug design (CADD) pipeline
		* statistical mechanics
		* computational molecular design
			+ scientific approach to deliver rapid, robust, and scalable software, toolkits, and technology and design services for the advancements of pharmaceuticals, biologics, agrochemicals, and flavors and fragrances
		* cheminformatics
		* cryoEM 3-D map reconstruction or protein structure refinement
			+ cryoEM 3-D density map reconstruction and refinement, image process, ab initio all-atom model building
			+ 3-D (protein) structure refinement
			+ biomolecular simulation
	- software tools
		* conda
		* pip
		* git
		* pandas
		* flask
		* AWS services
+ skill set:
	- make actionable decisions based on multiple levels of data
	data visualizations of:
		* 3-D protein structures
		* molecular simulation data
	- predict properties of small molecular drug candidates
		* validate with measured data of these properties
	- (bio)molecular modeling and simulation
	- work under a development schedule, balancing features with delivery
	- experience with:
		* Qt
		* PySide
		* 3-D graphics
		* event-driven programming
+ skill set:
	- Software Developer - Scientific Computing
	- Are you looking for an opportunity to contribute to the next revolution in computing technology? Do you want to take part in an exciting and rapidly growing new industry? Do you want to put your skills to use at the forefront of a cutting-edge field?
	- In this role you will develop highly optimized numerical code for simulating and benchmarking a variety of quantum computing devices. You will help translate high-level algorithms to run on a variety of computing architectures. You will help develop and optimize new parallelization techniques for simulating large quantum systems and algorithms designed for Xanadu's quantum computing platform and participate in the design and development of new simulation algorithms.
	- Required Skills and Experience:
		* To succeed in this role, you should have the following:
		* Strong experience programming in low-level languages (e.g., C, C++, Fortran)
		* Knowledge of CPU instruction sets, GPU programming, and compilation  
		* Experience with high-level scientific programming frameworks in Python
		* Ability to convert high-level language scripts to optimized low-level implementations  (e.g., C, C++, Fortran) with optimization (SIMD vectorization) and parallelization (OpenMP, threading)
		* Experience working with multiprocessing and parallelized code
		* Experience with development of numerical / approximation techniques
		* Experience with binding high-level scripting languages to low-level implementations
		* Ability to convert abstract descriptions of algorithms into efficient code implementations
		* Ability to aggressively optimize algorithm efficiency at every part of the computational stack
		* Ability to determine sensible tradeoffs between code being optimal, user-friendly, and easy to install
		* Experience with software engineering best practices: testing, continuous integration, version control, documentation, and code review
		* Familiarity with and experience working in a fast-growing technology start-up environment
		* Great communication skills; can express complex technical concepts in a clear and easy to understand way
	- Preferred Skills and Experience:
		* Familiarity with distributed computation
		* Experience with scientific computing on HPC, supercomputer, and cluster-grade hardware
		* Experience with scientific computing on commodity / cloud hardware (e.g., AWS)
		* Understanding of quantum computing and quantum simulation algorithms, including experience with tensor networks
		* PhD in Computer Science, Physics, Mathematics, or Engineering an asset
	- Qualifications:
		* 5+ years of experience working in related fields
		* BSc or MSc  in Computer Science, Physics, Mathematics, or Engineering with relevant industry experience preferred, or equivalent combination of education and experience
		* Proven track record delivering highly optimized numerical algorithms
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.












###	Software Development for Molecular Modeling, Molecular Dynamics, Molecular Simulation, & Computational Chemistry






+ OpenMM experience for molecular dynamics simulations
+ skill set:
	- We are now looking for Sr. Research Scientist, Computational Chemistry!
	- NVIDIA is using the power of GPU computing and computational chemistry to accelerate digital biology. We are seeking hardworking individuals to help us realize our mission. As a Sr. Computational Chemistry Researcher, you will join a team passionate about research and development using molecular simulation and machine learning. Together, we will advance NVIDIA's capacity to build digital biology solutions.
	- You’ll build large scale molecular dynamics simulations
	- Collaborate with multiple AI research, high performance computing, and digital biology teams
	- Drive the testing and maintenance of the algorithms and software modules
	- Develop tools to assist data processing, data quality control, algorithm development, and algorithm testing
	- 8+ years of relevant experience
	- Advanced degree in a quantitative field such as Computational Chemistry, Computational Biophysics, Physics, Computer Science, Mathematics, or equivalent work experience
	- Experience with molecular dynamics-based modeling, enhanced sampling or free-energy calculations, or statistical approaches for analyzing large datasets
	- Background with C++ and/or python
	- Recognized for technical leadership contributions, capable of self-direction, and ability to learn from and teach others
	- You should display strong communication skills, be organized and self-motivated, and play well with others (be a phenomenal teammate)
	- Ways To Stand Out From The Crowd
		* Ability to use structural biology and experimental data to inform computational approaches
		* Experience applying molecular dynamics or machine learning to drug discovery, biochemical and biophysical assay development, or target analysis and selection
		* Background with CUDA programming
		* Experience with deep learning
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.












###	Skill Sets for Computational Biology




Skill sets for computational biology:
+ skill set:
	- Post-Doctoral Research Fellow, Computational Biology and Precision Oncology in Lung Cancer
	- The laboratories of Dr. Gavin Ha and Dr. David MacPherson have a joint postdoctoral research position open in the Computational Biology Program of the Public Health Sciences and Human Biology Divisions. We are seeking a highly motivated individual who is interested in developing and implementing innovative computational and analytical approaches to study the genetics and epigenetics of lung cancer from tumor and liquid biopsies. Candidates who are excited about large/complex ‘omics’ data analysis of cancer genomes, computational methods development, and liquid biopsy research are encouraged to apply. Projects can be completely computational or could also involve wet-lab components, depending on the interests and experience of the applicant.  The position has a competitive salary and great benefits. 
	- The successful candidate will have the opportunity to work on transformative and leading-edge research study in lung cancer research using circulating tumor DNA (ctDNA) from liquid biopsies. This project will involve analysis of ctDNA and methods development to exploit liquid biopsies for detecting and studying small cell lung cancer (SCLC) and non-small cell lung cancer (NSCLC), discovering new ctDNA biomarkers of treatment response, and to advance precision oncology. For examples of recent studies, see PMID:29109393, PMID: 36399432, PMID: 36463275.
	- Dr. Ha’s laboratory develops computational approaches to study cancer genomes from tumors and liquid biopsies, such as circulating tumor DNA. He is a recipient of an NIH Director’s New Innovator Award, an NCI Transition Career Development Award, a Prostate Cancer Foundation Young Investigator Award, and a V Foundation Scholar Grant.
	- The goals of this collaboration are to uncover mechanisms of treatment resistance, to identify blood-based genetic biomarkers, and to translate these findings to help improve clinical applications. We aim to develop novel liquid biopsy assays to apply to SCLC patients and allow us to identify biological correlates of treatment responses.  We work in an interdisciplinary team environment with many local and external experts. All of our projects involve partnering with investigators who have diverse expertise in molecular and experimental biology, cancer biology, and clinical research.
	- Computational biology, bioinformatics, computer science, data science, statistics, computer/electrical engineering, physics, or other related fields.
	- Machine learning and interpretable/explainable artificial intelligence (AI)
	- Work well in team environments, have strong communication/organization skills and is detail-oriented
	- Highly motivated individual who think independently but also enjoy working in a dynamic, collaborative, multidisciplinary team
	- Strong programming experience (R, Python, Matlab, Java, C/C++, Perl or other languages for research)
	- Experience with cancer data analysis is preferred
	- A background in cancer biology is considered a strong asset
	- For candidates interested in wet-lab work, experience in molecular biology is expected
	- Experience with analyzing sequencing data is considered a strong asset
	- Experience with high performance computing environments and cloud computing environments is a plus
	- Applicants must have a demonstrated publication track record
	- Candidates with strong interest and/or expertise in any of these research areas are highly encouraged to apply: 
		* Cancer genomics and epigenetics, liquid biopsies, tumor evolution/heterogeneity
		* Application of explainable AI, statistical modeling, algorithm design, machine learning to study cancer and genetics
		* Analysis of large, complex genome, epigenome, and transcriptome data
+ skill set:
	- computational science, especially computational physics/chemistry/biology for statistical mechanics, biophysics, fluid mechanics, and molecular dynamics.
	- statistical methodology, modeling, and inference
	- numerical methods for solving PDEs, PDE solvers
	- high-performance computing and software libraries
	- signal and image processing for ***neurophysiology and structural biology***
	- machine learning for scientific applications
	- mathematics, algorithms, and optimization for deep neural networks
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.







###	Skill Sets for Computational Neuroscience




+ The Computational Neuroscientist's primary job function is to work with the CTO to identify innovative technologies, and to research and develop practical Spiking Neural Network based products by using BrainChip's spiking neural model and previous research.  This involves the development of an architecture that is flexible in its application. The resulting SNN architecture will have a wide application range in areas such as Computer Vision, Olfactory, Auditory and Tactile feature learning and extraction.  Will also work on a development kit and API which will form the foundation for products for the in-house product development team and will also be made available to external research and development facilities. The computational Neuroscientist will work with associated educational facilities such as the Cerco, UCI and UCSD and evaluate technologies that are relevant to BrainChip's SNN technology.
















##	Software Development for Computational Engineering (except EDA)



Skill set for software development for computational engineering (except EDA):
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.





###	Software Development for Computational Fluid Dynamics



Skill set for software development for computational fluid dynamics, CFD:
+ skill set:
	- The Principal Fluidics Engineer will be responsible for driving the fluidic architecture including pumps, valves, manifolds, consumables/cartridges and chips etc. through the development process to take the Roboflow system to new heights. As part of the Fluidics team at ONI, this person will work closely with the engineering, chemistry, and biology teams to develop and deliver customer-centric fluidic products for our customers. Our microfluidics platform is universal and can support almost all applications, this role will be responsible for carrying on that spirit and create a great opportunity to be involved in the applications of single molecule microscopy. 
	- Fluidics systems design, integration and development
	- Lead consumable and manifold development projects
	- Consumable/cartridge design and injection moulding 
	- Manage technology transfer and manufacturing processes 
	- Reliability and lifetime testing
	- Liaising with external vendors
	- PhD in engineering or sciences
	- Excellent track record in product development and contributing to successful products on the market
	- Demonstrated the expertise in automation, control systems, fluidic and pneumatic components and systems
	- Strong foundation in physics, esp. hydrodynamics to understand micro- and macro-scale regime fluid flow
	- Strong experience in design and manufacturing of consumables incl. cartridges (injection moulding, draft angles, piercing, foils, sealing etc.)
	- Experience with finite-element analysis software for CFD simulation, e.g. COMSOL, Ansys CFD, etc.
	- Modelling experience in: overall systems, instrument and consumable COGS, error budget
	- 3D CAD experience
	- Proficiency with electronics PCB design and microcontrollers programming
	- Experience with fast prototyping techniques and statistical data analysis (JMP, R, Matlab)
	- Track record of publications in high impact journals.	
	- Programming experience in Python, C/C++
	- Practical knowledge of biology with the ability and desire to work alongside life scientists
	- Microfabrication techniques experience (photolithography, micromachining, bonding processes, etc.)
+ skill set:
	- The Staff Fluidics Platform Engineer will be responsible for supporting the transition of the fluidic architecture including pumps, valves, manifolds etc. through the development process to take the Roboflow system to new heights. As part of the Fluidics team at ONI, this person will work closely with the engineering, chemistry, and biology teams to develop and deliver customer-centric fluidic products for our customers. Our microfluidics platform is universal and can support almost all applications, this role will be responsible for carrying on that spirit and create a great opportunity to be involved in the applications of single molecule microscopy. 
	- Fluidics systems (incl. manifolds) design, integration and development
	- Fluidics system modelling
	- CFD simulations
	- Reliability and lifetime testing
	- PhD in engineering or sciences
	- Excellent experience in the lab environment incl. reagent delivery and detection of biomolecules to produce scientific results
	- Track record of contributing to development of successful products on the market
	- Demonstrated the expertise in automation, control systems, fluidic and pneumatic components and systems
	- Strong foundation in physics, esp. hydrodynamics to understand micro- and macro-scale regime fluid flow
	- Experience with overall system modelling and finite-element analysis software for CFD simulation, e.g. COMSOL, Ansys CFD, etc.
	- 3D CAD experience
	- Proficiency with electronics PCB design and microcontrollers programming
	- Experience with fast prototyping techniques and statistical data analysis (JMP, R, Matlab)
	- Track record of publications in high impact journals.
	- Capabilities for Success (nice to haves)
	- Strong track record in product development
	- Programming experience in Python, C/C++
	- Practical knowledge of biology with the ability and desire to work alongside life scientists
	- Microfabrication techniques experience (photolithography, micromachining, bonding processes, etc.)
+ Experience in CFD combustion or other reacting-flow simulations.
+ skill set:
	- Reservoir Labs is seeking talented engineering, computer science, and mathematics interns to join our team. We are working on some of the most interesting and challenging problems related to high-performance computing and compilers, cybersecurity, advanced algorithms, and high-performance data analytics.
	- As a member of our team, you will participate directly in our research, learn new skills at the cutting edge of computer science, and gain visibility with our customers. You will work with engineers across diverse areas and will be mentored by a Ph.D. researcher. You will have the opportunity to share your fresh perspective and make strong contributions to our research and engineering team.
	- The concrete research and deep systems experience that you will gain working on projects at Reservoir will be especially beneficial to your application to graduate schools or search of full-time industry jobs.
	- Some examples of recent intern projects include developing parallel hypergraph analytic visualization for cybersecurity, developing parallel SAT solvers, developing advanced systems software testing infrastructure, developing advanced optimizations for LQCD physics computations.
		* LQCD physics computations
		* Lattice QCD, lattice quantum chromodynamics
			+ Monte-Carlo simulations
			+ fermions on the lattice
	- An ideal candidate will have exceptional intellectual ability, motivation, and a strong history of achievement. Solid foundation in computer science and/or software engineering and strong math background (Linear Algebra, Algorithms, Numerical Analysis) are desired. Serious consideration will be given to candidates with strong programming skills (C, C++, and Java) and knowledge of computer systems and architectures. LLVM or other compiler development experience would be particularly valuable. Genuine interest in the spectrum of Reservoir’s projects is key, and the flexibility to move among them is essential.
	- Currently Reservoir Labs is operating remotely. Should on-site work resume by Summer 2022, this role will be based in Reservoir Labs' New York City offices.
	- Candidates seeking work in Reservoir's offices in Portland, OR or Denver, CO may be considered as well on a case-by-case basis.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






###	Software Development for Finite Element Method, FEM




+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.







###	Software Development for Computational Electromagnetics, CEM, Computational Electrodynamics, Electromagnetic Modeling




+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.









###	Software Development for Computational Mechanics




+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.













###	Software Development for Computational Thermodynamics




+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






###	Software Development for Computational Thermofluids



+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.











###	Software Development for Computational Material Science




+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.












###	Software Development Roles for Parallel Programming



Skill set for software development for parallel programming, especially on heterogeneous computing platforms (e.g., heterogeneous computer system architectures that support multiple instruction set architectures, ISAs, including ISAs for domain-specific computing) and high-performance computing (HPC):
+ Published papers (e.g. in Supercomputing, IPDPS, or PPOPP) and/or open-source code that demonstrate your skills in writing fast code.
+ Familiarity with GPU computing (CUDA, OpenCL) is preferred
+ After CUDA, learn OpenACC before OpenCL.
+ Proficient with parallel programming and performance optimization techniques such as NEON, OpenCL, OpenGL ES, Metal and Vulkan;
+ skill set:
	- Multi-GPU software development engineer
	- Design, develop and debug multi-GPU drivers and software
	- Work with other software engineers to design and develop drivers and support software, providing support for multiple GPUs (same node and multiple nodes across the network)
	- Coordinate with other software and hardware engineers to provide solutions to problems arising in multi-GPU platforms. And optimize system performance tuning
	- Assist the multi-GPU solution of the customer platform, and improve the end-to-end software solution of the overall platform according to the needs of users 
	- Proficient in C/C++ programming, familiar with Linux programming
	- Familiar with computer architecture, and have an overall understanding of distributed parallel computing and heterogeneous computing frameworks
	- Knowledge of OpenMPI, OpenSHEM, MPICH, etc. and support libraries (NCCL, UCX, etc.) and experience are preferred
	- Knowledge related to chip interconnection and network transmission programming, such as RDMA, PCIE Peer2Peer, GPU Direct, etc., and software development experience is preferred
	- Familiar with Linux kernel, Linux file system, distributed file system is preferred
	- Familiar with CUDA kernel programming is preferred
+ Familiarity with heterogeneous programming languages such as ***CUDA/OpenCL/OpenGL*** is preferred
+ skill set:
	- GPUs, CPUs, and TPUs
	- High-Performance Networking (InfiniBand, HSE and RoCE)
	- MPI, CUDA-Aware MPI, NCCL
	- DGX-1, DGX-2, IBM Power-AI
+ skill set:
	- NVIDIA is seeking an outstanding researcher to join our programming systems research team. If you would like to help build the future of computing by equipping programmers with the tools they need to use parallel computing systems, this team will be a great fit for you! We seek to invent innovative parallel algorithm techniques, expressive parallel programming models/languages, powerful code analysis & generation tools, and scalable runtime environments that can help accelerate a broad range of real-world applications. After developing novel solutions and building prototype software that demonstrates their promise, you will work with product teams to help integrate your ideas into NVIDIA's accelerated computing platform.
	- Develop innovative parallel computing technologies and craft these technologies into prototype implementations.
	- Collaborate with other researchers and engineers at NVIDIA to deliver your innovations in high-quality software systems.
	- Engage with the research community by publishing work that advances the state of the art.
	- A Doctoral degree (Ph.D.) or equivalent experience in a computational subject area such as computer science, computer engineering, or scientific computing. 3+ years of relevant research experience.
	- Expertise in parallel programming and algorithmic techniques.
	- Creativity in developing innovative solutions to the problems faced by parallel programmers and the skill to implement them in software.
	- Experience developing software in languages, such as C++ and Python, commonly used by the developer community.
	- An existing track record of research excellence and publications that demonstrate your body of work.
	- Expertise in applying programming system insights and techniques to problems in machine learning, data science, and/or distributed computing.
	- Ability to implement ideas in the CUDA programming model
	- Experience building software systems used by other developers to solve their own problems.
+ skill set:
	- We're looking for outstanding interns to apply their parallel programming skills to accelerate NVIDIA's open source software suite for data science, RAPIDS. RAPIDS combines the performance of modern GPUs with the ease of use of Python and Scala APIs. It builds on a highly-optimized computational core, written in C++ and CUDA, that leverages the parallel nature of GPUs to accelerate fundamental data operations from load and parsing, to joins, aggregations, and more. Previous interns have made significant contributions to these core libraries, and we hope you’ll be the next major contributor!
	- Developing novel, parallel algorithms to accelerate core problems in data processing
	- Implementing solutions in C++ and CUDA
	- Contributing to open source RAPIDS projects, such as cuDF
	- Benchmarking, profiling, and optimizing code
	- Working closely with mentors and some of the world’s top experts in GPU optimization
	- Pursuing a PhD, MS, or BS in computer science, engineering, or a related field
	- You have strong Modern C++ programming skills
	- Familiar with at least one parallel programming framework, such as CUDA, OpenACC, OpenMP, etc.
	- You care deeply about robust, readable, high-performance code
	- Excited to learn, explore new problem areas, and apply your creativity to some of the most challenging and rewarding problems we have
+ skill set:
	- Developing high quality, scalable and innovative heterogeneous parallel computing runtime.
	- Developing software that meets certain quality and real time requirements for applications in multiple domains such as Machine Learning and AI.
	- Designing scalable and maintainable solutions from the ground up.
	- 3+ proven years of experience in developing high quality production software.
	- Experience in developing runtimes for parallel systems or accelerators.
+ skill set:
	- 3+ years of experience in algorithm optimization to target parallel hardware such as GPUs, SIMD, or similar.
	- Proven experience working close to and understanding the hardware, and optimizing algorithms for specific hardware implementations.
+ skill set:
	- Non-blocking Operations in GraphBLAS
	- In our Computing Systems Lab, we shape the next generations of computing systems from programming models to parallel computing, computer architectures of CPUs and specialized hardware accelerators, and engineering productivity tools to handle the every growing complexity of these systems.
	- We are currently looking for an outstanding intern who will work on GraphBLAS that defines standard building blocks for the expression of graph algorithms in the language of linear algebra. The goal of this project is to provide a GraphBLAS implementation that supports non-blocking operations by exploiting dynamic parallelism and lazy evaluation. The API of GraphBLAS will remain the same, and the non-blocking implementation will be achieved in the library level, i.e., without compiler support.
	- Investigate parallelization opportunities in the GraphBLAS library
	- Provide a non-blocking implementation of GraphBLAS
	- Evaluate the performance of the parallel implementation for a set of different benchmarks
	- Strong mathematical/algorithmic problem-solving and software development skills in C/C++
	- Experience in parallel programming
	- Experience in parallel programming models (e.g. OpenMP) is a plus
	- Excellent communication and writing skills in English
+ Demonstrated expertise with C++ with at least one of std::thread / OpenCL / CUDA
+ Experience with Hadoop/Hbase/Pig or MapReduce/Sawzall/Bigtable
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.

















###	Software Development Roles for Distributed Programming



Skill set for software development for distributed programming (or distributed computing), especially on heterogeneous computing platforms (e.g., heterogeneous computer system architectures that support multiple instruction set architectures, ISAs, including ISAs for domain-specific computing) and high-performance computing (HPC):
+ Knowledge in Hadoop (HDFS, YARN), its programming models (MapReduce, Spark), and its services such as Hive, HBase etc.
+ Hadoop data platform is capable of supporting a growing list of downstream platforms like Tableau, Zeppelin etc.
+ Experience working with distributed systems and streaming / queuing platforms (e.g. Kafka, Celery)
+ Experience working with either a Map Reduce or a MPP system on any size/scale
+ skill set:
	- a Master’s degree in CS or equivalent,
	- experience with Functional Programming (e.g. OCaml, Erlang),
	- has worked on 2+ large scale commercial projects taken from inception to production,
	- experience with dynamically typed systems (e.g. Javascript, Erlang; Python is a must),
	- experience with C/C++ or other low-level languages with manual memory management,
	- experience with scalable microservice architecture,
	- the ability to work on any system, from code running in the browser to big data analytics dealing with terabytes of data,
	- excellent communications skills in English,
	- the opportunity to obtain a valid EU work permit.
	- Other things you should know are
		* we're currently working on Issuu’s Story Cloud both on web and mobile apps, machine learning for better understanding of our content, internal analytics and our famous reading experience to mention a few examples,
		* we currently use Python, OCaml, Javascript, Erlang and a bit of C++, and we’re extremely open to using new languages and/or technologies,
		* our architecture is microservice-oriented using AMQP,
		* we deploy multiple times a day on AWS and use Docker Swarm, MySQL, Redis, Node, etc.,
		* we strive to be agile (who doesn’t?), but we're not religious about Scrum, Kanban or any other methodology.
	- We believe you can help us succeed by
		* delivering results that create value for the end users, while we ensure a high-performance,  high-availability, robust product that scale with our traffic (10.000++ requests/second) and data-heavy platforms (100++ terabytes),
		* working across disciplines, and take a holistic, end-2-end approach to software development,
		* being at the forefront of development practices, Agile, Continuous Delivery, Software as Service, Cloud-based, Docker, React,
		* working equally well creating back-end and front-end solutions that can run in production at the scale of our traffic,
		* solving problems from just about every area of computer science, including search, information retrieval, artificial intelligence, natural language processing, distributed computing, large-scale system design, networking, security, data compression, big data and so on.
	- We are the right company for you, if you
		* want to work on a product that matters to a lot of people – We receive hundreds of visits per second and host over 50M+ documents,
		* consider yourself one of the best at what you do and you're looking for equally talented colleagues,
		* are self-driven and would never just want to take the next ticket,
		* are curious and never stopped learning and exploring new languages, technologies and solutions,
		* seek a culture where all voices matter when it comes to shaping the future of the product,
		* want to work with colleagues who have ‘here to help’ attitude, and absolutely want to help you succeed.
+ skill set:
	- Experience in building and owning critical user-facing API systems, and solving scaling, latency, and performance problems in high-volume low-latency distributed systems
	- 8+ years of industry experience with distributed systems, transactional data stores, and systems programming
+ Experience with MapReduce/Hadoop and/or distributed systems.
+ skill set:
	- Proficient programmer that can code efficient algorithms (like map-reduce, preferably in Java) that traverse data partitioned in a distributed architecture
	- Design, build, and deploy distributed querying strategy to achieve highly scalable and resilient transactional processing and reporting for different size and shape workloads
	- Perform analysis on data access patterns to uncover opportunities to improve query throughput and drive decision making on new architectures. Recommend best practices.
	- Design efficiently distributed query service for low latency access and traversal for transactional and reporting use cases
	- Influence and collaborate cross functional teams in coming together towards a common, data architecture
	- Learn and fundamentally understand the Workday technology stack including a home-grown meta-data driven application development environment
	- Be responsible for system stability by proactively identifying and diagnosing issues and rapidly deploying code to address production issues
	- Strong coding experience in any language
	- Good working experience of distributed systems gossip protocols and consensus algorithms
	- Experience implementing distributed computing frameworks and architectures
	- Good knowledge of network protocols, routing and handshaking
	- Good experience performance tuning/ garbage collection / JVM internals
	- Proficient knowledge of maintaining and debugging live, business critical software systems
	- Good understanding and hands on experience with SQL, especially in the area of data aggregation and query performance tuning
	- Communicates clearly to engineering peers including ability to identify and communicate data-driven insights
+ Experience working with distributed computing tools like Spark or Hadoop
+ designing high availability systems
+ Experience with distributed messages systems ( Apache Kafka)
+ tech stack:
	- Expertise in Go preferred, but not required. If you're new to Go, then proficiency in a mainstream language such as Java, Python, C++, Scala, etc.., and a willingness to learn Go required.
	- You've got experience writing, deploying and monitoring microservices.
	- Working knowledge of SQL and relational databases(we use Postgres)
	- You've used an RPC framework like gRPC or Thrift.
		* remote procedure call, RPC
	- You have high level experience working in a containerized infrastructure deployed in the cloud(AWS, GCP, Azure)
+ Celery, for distributed message passing via asynchronous task queue or job queue
+ skill set:
	- Understanding of high-level network protocols (HTTPS, protobuf, JSON)
	- Understanding of distributed computing (load balancing, RPC, Map/Reduce, databases)
+ Exposure to various high-performance networking technologies including MPI, NCCL, RDMA, Infiniband and RoCE
+ ***If composable abstractions, distributed systems, security, reliability, containers, microVMs, filesystems, networking, Go, or Rust fascinate you, we want to hear from you!***
	- ***To achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.***
+ skill set:
	- We are looking for enthusiastic software engineers that can make a significant contribution to the development of next generation Load Balancers with high availability and scalable distribution of traffic. The software you write will drive and enable functionality on thousands of load balancers deployed by our customers.  Reporting to the Engineering Manager, the Software Engineer will participate in the design, development and deployment of new services and products.
	- Use technologies and tools such as: Go, SQL, Consul, Kafka, Chef, Git, Jira, Prometheus, Lightstep, Docker, Kubernetes and what not?
	- Participate in design, implementation, tests and optimization of new services that run at scale and solve challenging distributed coordination problems.
	- Work with other teams within the vertical and across the company to build the next generation of products and services for our developers community.
	- Support existing products and contribute creative solutions to the pain points.
	- Help improve our toolings and process to ship robust and mission-critical parts of the ecosystem.
	- Experience as a software engineer, developer, or programmer in building software used by external users
	- Experience with a typed or OOP language (like C, C++, Java, Go) and unit tests
	- Experience developing full-stack applications with databases and API
	- Understanding of large scale distributed systems programming
	- Understanding of Continuous Integration and Delivery (CI/CD)
	- Knowledge of application networking fundamentals
	- You understand and seek to automate the steps necessary to deliver high-quality, well-tested, and production-ready software from initial development to ongoing, scalable, production operation.
	- Bonus: Exposure to containerization and virtualization
	- Bonus: You have used gRPC to build robust distributed and high-demand systems
+ skill set for Blockchain Research Engineer:
	- Lead key blockchain technology innovation, system design and development, and key application model and algorithm development of HUAWEI CLOUD Blockchain Service. Build a blockchain system featuring high fault tolerance and performance.
	- Continuously gain insights into the industry's cutting-edge technical issues and develop products based on customer requirements to improve service competitiveness.
	- Information security, computer science, data communications, or related major. Solid security expertise and project research experience. Ability to independently engage in research
	- Extensive technical knowledge of distributed system architectures and the SOA architecture. Deep understanding of cloud computing technologies, such as Kubernetes and Docker. Experience with related product security development preferred
+ skill set - Bonus points if you have experience with any of the following:
	- distributed systems
	- batch data processing
	- stream processing
	- database internals
	- query optimizers
	- query processing
	- data integration
	- recommender systems
	- information theory
	- knowledge graphs