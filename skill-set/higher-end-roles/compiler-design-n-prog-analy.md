#	Compiler Design and Program Analysis




List of companies in compiler design:
+ AdaCore: https://www.adacore.com/company/careers
+ Kestrel Institute: https://www.kestrel.edu/research/
+ Supermicro: https://jobs.supermicro.com/







##	Skill Set for Compiler Design




Notes:
+ Compiler design involves code optimization (with the intermediate representation, and during code generation - such as instruction scheduling and register allocation), rather than merely than implementing interpreters that translate source code to binaries/executables.
	- Other steps in code generation do not need optimization, such as debug data generation.
	- Instruction selection can involve optimization to select the set/sequence of instructions that would allow the software, or computer program, to execute with the fastest time.
+ This set of positions target parallel compiler design (e.g., sequential source code to parallel source code), and standard/traditional/classic compiler design.
	- For compiler design positions related to domain-specific languages, in the context of domain-specific computing, see the list for [EDA, Machine Learning, and AI]()
+ Checking for compiler correctness, including translation validation, can involve formal verification.












Skill set for compiler design:
+ Open64 is a free, open-source, optimizing compiler for the Itanium and x86-64 microprocessor architectures.
+ skill set:
	- LLVM compiler internals.
	- Polyhedral models.
	- Familiarity with HPC kernels and their optimization.
+ Because compilers, interpreters, JIT, pre-processors, grammars, register allocation, term rewriting, LLVM and more are what brought us to computer science in the first place, Raincode Labs forms the largest independent compilation technology company in the world.
+ skill set:
	- Research in Compilers and Architecture
	- Conduct fundamental research on new directions in compilers and architecture
	- Develop academic research partnerships and cooperation with leading universities and professors in the area
	- Work with internal research colleagues and academic research partners to achieve new breakthroughs in research and innovation
	- Produce and present research papers at internationally leading conferences and events
	- Produce white papers on current developments and future directions in computing systems
	- Where appropriate, contribute insight and research expertise to committees and other organizations that are looking to establish new industry standards and platforms
	- Contribute to the research and academic community through service such as conference program committee membership, membership of journal editorial boards etc.
	- PhD in an area related to computing systems, or equivalent research experience in industry
	- Record of publishing research papers in the area of computing systems
	- Candidates should have research experience in computing systems, and be familiar with at least one of the following areas:
		* CPU Compilers
		* Just-In-Time Compilation
		* Compilers and Microarchitecture
		* ***Compiler/Architecture Co-Design***
		* ***Hardware/Software Co-Optimization***
		* Static/Dynamic Analysis
		* Static/Dynamic Compiler and Runtime Systems
		* ***Static/Dynamic and Machine Learning-Based Optimization***
		* Compile-time and Runtime Analysis
		* Code Generation and Optimization
		* ***Software Profiling for Hardware Optimization***
	- Strong interpersonal skills and ability to work productively in a research environment
+ skill set:
	- If you're interested in really neat computer architectures and the compiler challenges associated with them, then you really want to be talking to us! We work at the cutting edge of compilers and computer architecture. These are real machines and they are doing important work.
	- Reservoir Labs is looking for a Compiler Developer to join our growing business. We are tackling some of the most interesting and challenging problems in high performance computing, including designing compilers for high performance embedded computing systems, compiler algorithms for machine learning, and simulators and software for advanced supercomputers. This is a great opportunity for a rewarding career in applied computer science research.
	- Work on a wide range of projects within small teams of engineers
	- Frequently interact with clients and effectively identify and meet client needs
	- Represent the company in conferences and industry forums
	- Opportunity to lead and manage projects
	- An ideal candidate will have solid intellectual ability, motivation, and a strong history of achievement. Strong software engineering and development skills, as well as excellent oral and written communication skills, are desired. Serious consideration will be given to candidates with knowledge of and previous experience in compilers. Experience with LLVM is a plus. Interest in the spectrum of Reservoir’s projects is key, and the flexibility to move among them is essential.
+ skill set:
	- We at SiFive are proud to take a software first approach to develop tools and frameworks that achieve cutting edge performance without compromising quality for the SiFive Intelligence processor family. The SiFive Intelligence processors deliver AI acceleration for the edge and beyond. SiFive intelligence builds on RISC-V Vectors (RVV) allowing SiFive to design Core IPs that deliver performance, are optimized for power and area, but do not sacrifice flexibility or programmability. Our software stack is codesigned with the hardware and developed with scalability and quality in mind. Join us to develop revolutionary software from the ground up!
	- Our LLVM-based, world class compiler technology is the backbone of the SiFive software stack that enables SiFive high-performance Linux-capable cores and SiFive Intelligence processors. The compiler team's mission is to deliver cutting-edge performance in SiFive products while working with the community to advance RISC-V architecture and ISA extensions. SiFive is an active participant in the RISC-V ecosystem that opens a vast opportunity to develop the next generation of computer architecture and compiler technology. SiFive engineers are active members and maintainers in many open source projects, and our mission is to work with and drive the RSIC-V ecosystem.
	- We are looking for a new college graduate to join our LLVM compiler team, and to learn techniques for tuning and optimizing the RISC-V LLVM compiler for the SiFive Intelligence processor family.
	- Working with SiFive’s LLVM compiler team on improving performance for the SiFive Intelligence processor family.
	- Working with SiFive’s benchmarking teams in analyzing performance results and suggesting new compiler optimizations.
	- Working with SiFive’s compiler and release teams in releasing timely compiler toolchains for use by SiFive software and hardware teams.
	- A degree in Computer Science or equivalent technical field of study.
	- Have completed coursework, projects, internships, and/or research in data structures/algorithms and compilers.
	- Have completed at least one internship, research assistantship, teaching assistantship, or equivalent practical experience in compilers.
	- Strong C++ programming skills.
+ skill set:
	- If you’re interested in advancing and applying mathematics to program optimization for cutting-edge computer architectures, then you really want to be talking to us! We work on developing new and innovative compilers that break the mold of current computing.
	- Reservoir Labs is looking for Automatic Parallelization and Compiler Engineers and Researchers to join our growing business. We are tackling some of the most interesting and challenging problems in high performance computing, including designing compilers for high performance embedded computing systems, for machine learning, and for advanced supercomputers.
	- We have a great platform, R-Stream, for applying and advancing the polyhedral model of optimization for these challenges. This is an opportunity for a rewarding career in applied computer science research.
	- Job Responsibilities
		* Develop and apply polyhedral optimization for new architecture and applications
		* Work on a wide range of projects within small teams of engineers
		* Frequently interact with clients and effectively identify and meet client needs
		* Represent the company in conferences and industry forums
		* Opportunity to lead and manage projects
	- Desired Skills
		* An advanced degree in the field of computer science or applied mathematics
		* Experience with compiler development, the polyhedral model, and computer architecture
		* Experience with software engineering
		* Solid intellectual ability, motivation, and a strong history of achievement
		* Excellent oral and written communication skills
	- We are particularly interested in candidates with knowledge of the polyhedral model. Genuine interest in the spectrum of Reservoir’s projects is key, and the flexibility to move among them is essential.
+ skill set:
	- 5+ years of experience in SSA-based optimizations for high performance architectures.
	- Experience with hardware specific optimizations such as SIMD or other specialized accelerators.
+ skill set:
	- Target-independent optimization techniques
	- Optimized code-generation for scalar and vector DSPs
	- Definition and implementation of dedicated C/C++ language extensions
	- Architecture definition and enhancements
	- Benchmark and performance optimization
	- B.Sc Computer science, or similar degree from a known University.
	- Experience and knowledge of C/C++ – An advantage
	- Team player with excellent communication skills.
	- Experience in Python scripting – advantage
+ skill set:
	- Target-independent optimization techniques
	- Optimized code-generation for scalar and vector DSPs
	- Definition and implementation of dedicated C/C++ language extensions
	- Architecture definition and enhancements
	- Benchmark and performance optimizations
	- B.Sc Computer science, or similar degree that provides strong knowledge of computer science theory along with practical software devolvement skills
	- 3+ years software development experience with excellent knowledge of C/C++.
	- Team player with excellent communication skills.
	- Experience with LLVM Compilers – advantage
	- Experience in Python scripting – advantage
+ skill set:
	- Retargeting of a C/C++ compiler towards specific microcontroller architectures
	- Activities comprise participation in the development, maintenance, build, test, and release of compiler and run-time libraries for existing and forthcoming processor architectures, including competitive performance analysis, root cause analysis, and bug resolution
	- 6+ years of experience with SQL databases (we use Postgres) and data manipulation
+ skill set:
	- Interest/experience in compilers, parsers, LLDB
		* LLDB is the default debugger in Xcode on macOS and supports debugging C, Objective-C and C++ on the desktop and iOS devices and simulator.
		* The LLDB Debugger (LLDB) is the debugger component of the LLVM project. It is built as a set of reusable components which extensively use existing libraries from LLVM, such as the Clang expression parser and LLVM disassembler.
	- compiler of our proprietary CodAL language to IR XML
	- LLDB-based software debugger and profiler
+ skill set:
	- Our LLVM-based, world-class compiler technology is the backbone of the SiFive software stack that enables SiFive high-performance Linux-capable cores and SiFive Intelligence processors. The compiler team's mission is to deliver cutting-edge performance in SiFive products while working with the community to advance RISC-V architecture and ISA extensions.  SiFive is an active participant in the RISC-V ecosystem that opens a vast opportunity to develop the next generation of computer architecture and compiler technology. SiFive engineers are active members and maintainers in many open-source projects, and our mission is to work with and drive the RSIC-V ecosystem.
	- We are looking for a solid experienced LLVM compiler team member with proven experience in compiler technology such as ***SSA-based global optimizations, auto-vectorization, ISA extensions***, and high-performance computing. The candidate should demonstrate a track record in cross-team collaboration and in delivering high-quality compiler products. 
	- Work with SiFive’s LLVM compiler team in improving performance for the SiFive Intelligence processor family.
	- Work with SiFive’s benchmarking teams in analyzing performance results and suggesting new compiler optimizations.
	- Work with SiFive’s compiler and release teams in releasing timely compiler toolchains for use by SiFive software and hardware teams.
	- Degree in computer science or engineering.
	- 3+ years of experience in compiler technology.
	- Experience with open-source contributions. 
	- Experience with ***hardware-specific optimizations such as SIMD or other specialized accelerators***.
	- Have completed coursework, projects, internships, and/or research in data structures/algorithms and compilers.
	- Strong C++ programming skills.
	- If you want to do incredible work and be challenged by exciting, truly innovative projects that will test the boundaries of your skills and creativity, then SiFive is the place for you!  Be proud of your work.  Do things better.  Join SiFive.  
+ skill set:
	- The Esperanto LLVM compiler team is searching for software engineers to bring our AI platform out to the world.  You will participate in a focused effort to design, develop, and deliver ground-breaking solutions. You will work in a team that directly impacts our products and you will collaborate with other engineering teams in achieving this goal.
	- Working with Esperanto's LLVM and GLOW compiler teams in improving performance for the Esperanto processor family.
	- Working with benchmarking teams in analyzing performance results and suggesting new compiler optimizations.
	- 3+ years of experience in compiler technology.
	- Degree in computer science or engineering.
	- Experience with open source contributions. 
	- Experience with hardware specific optimizations such as SIMD or other specialized accelerators.
	- RISC-V experience a plus.
+ skill set:
	- Programming Language Engineer
	- LOCATION: New York
	- DEPARTMENT: Technology
	- TEAM: Software Engineering
	- We're looking to hire an experienced Software Engineer with a background working on programming languages to join us. Jane Street's OCaml Language team focuses on improving OCaml as a foundation for our ever-growing technology stack, in collaboration with the greater OCaml community. We work on many different aspects of the language, aiming to make it easier for developers to express their ideas in OCaml, to improve the performance of the generated code, and to make the OCaml compiler itself faster and easier to use. 
	- Over the years, we’ve extended the type system with support for novel language features, re-engineered the optimizer ground-up, and added feedback-directed optimization. We also extend and enhance the surrounding toolchain, working on tools for profiling, debugging and generating documentation. The vast majority of our work is open-source, and we upstream as much as we can to the mainstream OCaml compiler.
	- For this specialized role within the OCaml Language team, we are seeking candidates with multiple years of experience in practical language design and implementation in an industrial-strength implementation. Research experience and publications in programming languages is a plus, but not a requirement. No previous experience with OCaml or functional programming languages is required.
	- Base salary is $250,000 - $300,000. Base salary is only one part of Jane Street total compensation, which includes an annual discretionary bonus.
+ skill set:
	- Programming Language Engineer
	- We're looking to hire a Software Engineer with experience working on programming languages to join us. Jane Street's Compilers team focuses on improving OCaml as a foundation for our ever-growing technology stack, in collaboration with the greater OCaml community. We work on many different aspects of the language, aiming to make it easier for developers to express their ideas in OCaml, to improve the performance of the generated code, and to make the OCaml compiler itself faster and easier to use. 
	- Over the years, we’ve extended the type system with support for novel language features, re-engineered the optimizer ground-up, and added feedback-directed optimization. We also extend and enhance the surrounding toolchain, working on tools for profiling, debugging and generating documentation. The vast majority of our work is open-source, and we upstream as much as we can to the mainstream OCaml compiler.
	- If you’ve worked on a production compiler in industry or on research compilers in an academic setting, you might have a strong foundation for this role. No previous experience with OCaml or functional programming languages is required. Fluency in English is required.
	- Base salary is $250,000 - $300,000. Base salary is only one part of Jane Street total compensation, which includes an annual discretionary bonus.
+ skill set:
	- Tools & Compilers Researcher
	- We are excited to announce research internships in our Tools and Compilers group, which will be available to complete from Summer 2022. We’re looking for PhD and masters students with outstanding research experience in programming languages, compilers, verification, and related areas. 
	- Jane Street's Compilers team focuses on improving OCaml as a foundation for Jane Street's ever-growing technology stack, in collaboration with the greater OCaml community. We work on many different aspects of the compiler, aiming to make it easier for developers to express their ideas in OCaml, to improve the performance of the generated code, and to make the OCaml compiler itself faster and easier to use. 
	- Over the years, we extended the type system with support for novel language features, re-engineered the optimizer ground-up, and added feedback-directed optimization. We also extend and enhance the surrounding toolchain, working on tools for profiling, debugging, documenting, and building automation. The vast majority of our work is open-source, and we upstream as much as we can to the mainstream OCaml compiler.
	- During the application process, we will work with you to identify a project that aligns with your research expertise and interests. Examples of areas we are interested in exploring include:
		* Verifying C bindings with respect to OCaml’s garbage collector
		* Superoptimization 
		* Type systems that track locality and uniqueness
	- During the internship, you will work in collaboration with your mentors on one project for about 10-12 weeks. You’ll learn how we use OCaml in our day-to-day work, and gain exposure to the libraries and tools that are foundational to our internal systems. You’ll gain a better understanding of the wide range of problems we solve every day. You’ll try out new ideas and apply state-of-the art research to a large actively-developed production codebase.
	- You’ll also be able to access our physical and virtual educational resources, attend guest speakers and social events, and hopefully get a real sense of what it would be like to work here full time.
	- We’re looking for PhD and masters students with outstanding research experience in programming languages, compilers, verification, and related areas. We don’t expect you to have a background in finance, OCaml, or functional programming. Fluency in English required.
+ skill set:
	- Tools & Compilers Researcher Internship, Flexible
	- LOCATION: New York
	- DEPARTMENT: Technology
	- TEAM: Software Engineering
	- We are excited to announce research internships in our Tools and Compilers group, which will be available to complete from Summer 2022. We’re looking for PhD and masters students with outstanding research experience in programming languages, compilers, verification, and related areas.
	- Jane Street's Compilers team focuses on improving OCaml as a foundation for Jane Street's ever-growing technology stack, in collaboration with the greater OCaml community. We work on many different aspects of the compiler, aiming to make it easier for developers to express their ideas in OCaml, to improve the performance of the generated code, and to make the OCaml compiler itself faster and easier to use. 
	- Over the years, we extended the type system with support for novel language features, re-engineered the optimizer ground-up, and added feedback-directed optimization. We also extend and enhance the surrounding toolchain, working on tools for profiling, debugging, documenting, and building automation. The vast majority of our work is open-source, and we upstream as much as we can to the mainstream OCaml compiler.
	- During the application process, we will work with you to identify a project that aligns with your research expertise and interests. Examples of areas we are interested in exploring include:
		* Verifying C bindings with respect to OCaml’s garbage collector
		* Superoptimization 
		* Type systems that track locality and uniqueness
	- During the internship, you will work in collaboration with your mentors on one project for about 10-12 weeks. You’ll learn how we use OCaml in our day-to-day work, and gain exposure to the libraries and tools that are foundational to our internal systems. You’ll gain a better understanding of the wide range of problems we solve every day. You’ll try out new ideas and apply state-of-the art research to a large actively-developed production codebase.
	- You’ll also be able to access our physical and virtual educational resources, attend guest speakers and social events, and hopefully get a real sense of what it would be like to work here full time.
	- We’re looking for PhD and masters students with outstanding research experience in programming languages, compilers, verification, and related areas. We don’t expect you to have a background in finance, OCaml, or functional programming. Fluency in English required. Please include the list of your peer-reviewed publications in your resume.
+ skill set:
	- Tools & Compilers Research and Development Internship, Flexible
	- LOCATION: New York
	- DEPARTMENT: Technology
	- TEAM: Software Engineering
	- We are excited to announce research internships in our Tools and Compilers group. We’re looking for PhD and masters students with outstanding research experience in programming languages, compilers, verification, and related areas. 
	- Jane Street's Compilers team focuses on improving OCaml as a foundation for Jane Street's ever-growing technology stack, in collaboration with the greater OCaml community. We work on many different aspects of the compiler, aiming to make it easier for developers to express their ideas in OCaml, to improve the performance of the generated code, and to make the OCaml compiler itself faster and easier to use. 
	- Over the years, we extended the type system with support for novel language features, re-engineered the optimizer ground-up, and added feedback-directed optimization. We also extend and enhance the surrounding toolchain, working on tools for profiling, debugging, documenting, and building automation. The vast majority of our work is open-source, and we upstream as much as we can to the mainstream OCaml compiler.
	- During the application process, we will work with you to identify a project that aligns with your research expertise and interests. Examples of areas we are interested in exploring include:
		* Type systems that track locality and uniqueness
		* Superoptimization 
		* Compiler testing and validation
	- During the internship, you will work in collaboration with your mentors on one project for about 10-12 weeks. You’ll learn how we use OCaml in our day-to-day work, and gain exposure to the libraries and tools that are foundational to our internal systems. You’ll gain a better understanding of the wide range of problems we solve every day. You’ll try out new ideas and apply state-of-the art research to a large actively-developed production codebase.
	- You’ll also be able to access our physical and virtual educational resources, attend guest speakers and social events, and hopefully get a real sense of what it would be like to work here full time.
	- We’re looking for PhD and masters students with outstanding research experience in programming languages, compilers, verification, and related areas. We don’t expect you to have a background in finance, OCaml, or functional programming. Please include the list of your peer-reviewed publications in your resume.
	- Base salary is $250,000.
+ skill set:
	- GNU toolchain developer
	- AdaCore is seeking a talented and highly motivated GNU toolchain developer. 
	- Everything we do at AdaCore is centered around helping developers build safe, secure and reliable software. For over 20 years, we've worked with global leaders across avionics, aerospace and defense industries, building tools and providing services that ease the complex and difficult process of developing high-integrity software. As the need for truly secure and reliable applications expands into industries such as automotive, medical, energy, and IOT, we’re advancing our time-tested technologies to bring expertise and services to help a whole new generation of developers.
	- Our 120 experts worldwide in the US (New York, Lexington), France (Paris, Toulouse, Grenoble and Vannes), the UK and Estonia all play a role in developing bleeding edge technologies to meet the highest grade of open-source software development.
	- Joining AdaCore is about joining a culture of innovation, openness, collaboration and dependability, which defines how we work together, with our customers and partners.
	- AdaCore maintains GNU GCC based Ada and C/C++ compilation tool suites for a wide range of customers and operational environments. We currently support native toolchains for x86/x86_64-Linux/Windows, cross ports to a variety of target architectures such as Leon, PowerPC, Arm or Aarch64, bare metal or on top of RTOSes such as VxWorks or LynxOS.
	- Our toolchains are all based on a branched version of GCC/Binutils, which we evolve on a very regular basis to anticipate our customers needs for better performance, particular features or new architectures.
	- To grow our compiler team, we are looking for a software engineer with experience in GCC middle-end/back-end development for a variety of purposes - maintenance, expert customer support, new ports, feature extensions, compiler performance improvements, optimization improvements, ...
	- Familiarity with the contribution process to upstream GCC would be a significant plus, as well as experience in the Binutils domain or willingness to develop expertise on this front.
	- This position is a great opportunity to get in touch with a large base of users developing industrial grade software, often safety critical, in very diverse areas. It also gets you to strengthen the GNU toolchains overall, providing solid grounds for numerous contributions upstream.
+ skill set:
	- We at SiFive are proud to take a software first approach to develop tools and frameworks that achieve cutting edge performance without compromising quality for the SiFive Intelligence processor family. The SiFive Intelligence processors deliver AI acceleration for the edge and beyond. SiFive intelligence builds on RISC-V Vectors (RVV) allowing SiFive to design Core IPs that deliver performance, are optimized for power and area, but do not sacrifice flexibility or programmability. Our software stack is codesigned with the hardware and developed with scalability and quality in mind. Join us to develop revolutionary software from the ground up.
	- Our LLVM based, world class compiler technology is the backbone of the SiFive software stack that enables SiFive high-performance Linux-capable cores and SiFive Intelligence processors. The compiler team's mission is to deliver cutting-edge performance in SiFive products while working with the community to advance RISC-V architecture and ISA extensions.  SiFive is an active participant in the RISC-V ecosystem that opens a vast opportunity to develop the next generation of computer architecture and compiler technology. SiFive engineers are active members and maintainers in many open source projects, and our mission is to work with and drive the RSIC-V ecosystem.
	- We are looking for a solid senior LLVM compiler team member with proven experience in compiler technology such as SSA-based global optimizations, auto-vectorization, ISA extensions, and high-performance computing. The candidate should demonstrate a track record in cross-team collaboration and in delivering high quality compiler products. 
	- Working with SiFive’s LLVM compiler team in improving performance for the SiFive Intelligence processor family.
	- Working with SiFive’s benchmarking teams in analyzing performance results and suggesting new compiler optimizations.
	- Working with SiFive’s compiler and release teams in releasing timely compiler toolchains for use by SiFive software and hardware teams.
	- 3+ years of experience in compiler technology.
	- Degree in computer science or engineering.
	- Experience with open source contributions. 
	- Experience with hardware specific optimizations such as SIMD or other specialized accelerators.
+ skill set:
	- As a Software Engineer in the Platform Engineering team, you will architect and implement features and compiler internals for the language that drives our sandboxing, verification and delivery workflows. You will use your understanding of functional programming to architect and maintain the systems that allow SiFive to design and deliver our primary product to our customers.
	- Architecting and implementing language features and compiler internals that drive a functional language to enable development and delivery of SiFive’s RISC-V core IP products.
	- Developing tools required by a language ecosystem such as a language server protocol for interacting with IDEs.
	- Owning architecture and code quality to facilitate meeting expanding requirements for business processes, efficiency and usability.
	- Collaborating with design, verification and other teams within SiFive to define the next generation of flow automation.
	- Proficiency in C++11.
	- Previous experience in compiler development.
	- Familiarity with functional programming languages such as ML, Scala, Haskell, Lisp, or F#.
	- Experience with Linux operating systems.
	- Experience defining build rules in a build system.
	- Ability to work and learn independently.
+ skill set:
	- Our LLVM-based, world class compiler technology is the backbone of the SiFive software stack that enables SiFive high-performance Linux-capable cores and SiFive Intelligence processors. The compiler team's mission is to deliver cutting-edge performance in SiFive products while working with the community to advance RISC-V architecture and ISA extensions. SiFive is an active participant in the RISC-V ecosystem that opens a vast opportunity to develop the next generation of computer architecture and compiler technology. SiFive engineers are active members and maintainers in many open source projects, and our mission is to work with and drive the RSIC-V ecosystem.
	- We are looking for a new college graduate to join our LLVM compiler team, and to learn techniques for tuning and optimizing the RISC-V LLVM compiler for the SiFive Intelligence processor family.
	- Working with SiFive’s LLVM compiler team on improving performance for the SiFive Intelligence processor family.
	- Working with SiFive’s benchmarking teams in analyzing performance results and suggesting new compiler optimizations.
	- Working with SiFive’s compiler and release teams in releasing timely compiler toolchains for use by SiFive software and hardware teams.
	- A degree in Computer Science or equivalent technical field of study.
	- Have completed coursework, projects, internships, and/or research in data structures/algorithms and compilers.
	- Have completed at least one internship, research assistantship, teaching assistantship, or equivalent practical experience in compilers.
	- Strong C++ programming skills.
+ skill set:
	- We are looking for a solid LLVM compiler team leader with proven experience in compiler technology such as SSA-based global optimizations, auto-vectorization, ISA extensions, and high-performance computing. The candidate should demonstrate a track record in leadership, cross-team collaboration, planning, and delivering high quality compiler products.
	- Leading a geographically distributed LLVM-based compiler team in developing a LLVM based compiler for SiFive processors..
	- Closely collaborating with SiFive’s Algorithms, Frameworks and Hardware teams in implementing optimized vertical solutions for AI and other domains.
	- Planning the development alongside hardware, software, and product organizations to deliver a combined hardware and software quality products.
	- Collaborating with RISC-V open source projects, upstreaming changes and coordinating internally and externally with cross geographical and distributed ecosystems.
	- Building, leading, inspiring and growing the software organization alongside other software leaders.
	- 3+ years of experience in technical leadership of a compiler team.
	- 5+ years of experience in compiler technology.
	- 5+ years of experience in SSA-based optimizations for high performance architectures.
	- Experience with open source contributions.
	- Experience with hardware specific optimizations such as SIMD or other specialized accelerators.
+ skill set:
	- We at SiFive are proud to take a software first approach to develop tools and frameworks that achieve cutting edge performance without compromising quality for the SiFive Intelligence processor family. The SiFive Intelligence processors deliver AI acceleration for the edge and beyond. SiFive intelligence builds on RISC-V Vectors (RVV) allowing SiFive to design Core IPs that deliver performance, are optimized for power and area, but do not sacrifice flexibility or programmability. Our software stack is codesigned with the hardware and developed with scalability and quality in mind. Join us to develop revolutionary software from the ground up.
	- Our LLVM based, world class compiler technology is the backbone of the SiFive software stack that enables SiFive high-performance Linux-capable cores and SiFive Intelligence processors. The compiler team's mission is to deliver cutting-edge performance in SiFive products while working with the community to advance RISC-V architecture and ISA extensions.  SiFive is an active participant in the RISC-V ecosystem that opens a vast opportunity to develop the next generation of computer architecture and compiler technology. SiFive engineers are active members and maintainers in many open source projects, and our mission is to work with and drive the RSIC-V ecosystem.
	- We are looking for a solid senior LLVM compiler team member with proven experience in compiler technology such as SSA-based global optimizations, auto-vectorization, ISA extensions, and high-performance computing. The candidate should demonstrate a track record in cross-team collaboration and in delivering high quality compiler products. 
	- Working with SiFive’s LLVM compiler team in improving performance for the SiFive Intelligence processor family.
	- Working with SiFive’s benchmarking teams in analyzing performance results and suggesting new compiler optimizations.
	- Working with SiFive’s compiler and release teams in releasing timely compiler toolchains for use by SiFive software and hardware teams.
	- 3+ years of experience in compiler technology.
	- Degree in computer science or engineering.
	- Experience with open source contributions. 
	- Experience with hardware specific optimizations such as SIMD or other specialized accelerators.
+ skill set:
	- Reservoir Labs is a private technology research and development company headquartered in New York City. Our mission is to make the world safer, cleaner, more secure, and more efficient through the application of radical high-performance computing technologies. Our engineers and computer scientists work on projects related to high-performance computing and compilers, cybersecurity, advanced algorithms, and high-performance data analytics. Reservoir has a proven track record of delivering cutting-edge solutions to both government and commercial clients.
	- Reservoir Labs is seeking talented entry level Research Engineers to join our team. We are working on some of the most interesting and challenging problems related to high-performance computing and compilers, cybersecurity, advanced algorithms, and high-performance data analytics.
	- As a Research Engineer, you will work on a range of projects within small technical teams. You will be closely guided and mentored by one of our experienced researchers, providing you with an unparalleled learning experience. You will have the opportunity to publish your own research papers, attend client meetings and academic conferences.
	- Some examples of projects our Research Engineers have contributed to include:
		* Cybersecurity behavioral analytics using hypergraph decomposition
		* Advanced radar tracker algorithms for ballistic missile defense
		* Parallelizing compilers for next generation processors (exascale, low power, accelerators)
		* Software verification systems for software radios
		* Parallel SAT solvers and their application
		* Parallel hypergraph decomposition for analysis of intelligence data
	- An ideal candidate will have solid intellectual ability, motivation, and a strong history of achievement. Strong math, programming and engineering skills, as well as excellent oral and written communication skills, are desired. Serious consideration will be given to candidates with a firm math background, knowledge of network security, and/or knowledge of compilers. Passion for Computer Science research and application is a huge plus. Genuine interest in the spectrum of Reservoir’s projects is key, and the flexibility to move among them is essential.
+ skill set:
	- Intel Architecture, Graphics, and Software (IAGS) brings Intel's technical strategy to life. We have embraced the new reality of competing at a product and solution level—not just a transistor one. We take pride in reshaping the status quo and thinking exponentially to achieve what's never been done before. We've also built a culture of continuous learning and persistent leadership that provides opportunities to practice until perfection and filter ambitious ideas into execution.
	- In this position, you will develop compiler technology as the primary job function;  You will Design, develop, debug & test compiler software and programming languages e.g. advanced compiler optimizations and features specific for Intel Architectures, parallelization and vectorization through compilers, new programming languages support. May work directly with hardware design team, companies and communities developing compilers, participate in language and standard groups.
	- Master's Degree in Computer science or Computer Engineering or Electrical Engineering with 4+ years of experience or PhD in Computer Science, Computer Engineering or Electrical Engineering or a related field with 2+ years of experience.
	- 5+ years of experience with:
		* Experience in C/C++
		* object-oriented programming
		* data structures
		* compiler theory
	- 2+ years of experience with compiler development
	- 1+ years of experience with LLVM compiler development
	- Knowledge of x86 instruction set architecture and Advanced Vector Extensions (AVX)
	- Experience with vectorization and parallel programming models such as OpenMP and/or SYCL and/or GPU programming
+ skill set:
	- The Data Center Group (DCG) is at the heart of Intel’s transformation from a PC company to a company that runs the cloud and billions of smart, connected computing devices. The data center is the underpinning for every data-driven service, from artificial intelligence to 5G to high-performance computing, and DCG delivers the products and technologies—spanning software, processors, storage, I/O, and networking solutions—that fuel cloud, communications, enterprise, and government data centers around the world.
	- In this position, you will develop compiler technology as the primary job function. You will design, develop, debug & test compiler software, e.g. advanced compiler optimizations and features specific for Intel Architectures, parallelization and vectorization through compilers, new programming language support. You might work directly with hardware design teams, companies and communities developing compilers and, participate in language and standard groups.
	- Bachelor’s degree in Computer Science, Computer Engineering,  Electrical Engineering or a related discipline with 8+ years of experience or a Master's Degree in Computer science, Computer Engineering or Electrical Engineering with 6+ years of experience or a PhD in Computer Science, Computer Engineering, Electrical Engineering or a related field with 4+ years of experience.
	- 5+ years of experience with:
		* C/C++
		* object-oriented programming
		* data structures
		* compiler theory
	- 3+ years of experience with compiler development
	- 3+ years of experience with LLVM compiler development
	- Knowledge of x86 instruction set architecture and Advanced Vector Extensions (AVX)
	- Experience with vectorization and parallel programming models such as OpenMP and/or SYCL and/or GPU programming
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






















##	Compiler Design for Domain-Specific Languages


Companies that hire compiler designers for domain-specific languages (DSLs):
+ DataPelago, Inc.: https://datapelago.io/careers/





Skill sets for developing compilers for domain-specific languages (DSLs):
+ ***Experienced with Glow/TVM/NVM/TensorRT/Tensorflow compiler portion is plus***
+ [CUDA LLVM Compiler](https://developer.nvidia.com/cuda-llvm-compiler)
+ skill set:
	- passion for developing and optimizing compilers for modern architectures
	- experience in either or both of the following:
		* LLVM architecture, polyhedral optimization, auto vectorization, back-end code generation
		* deep learning compilers
			+ TVM
			+ XLA
			+ Glow
	- experience with neural network inference on dedicated SoC or GPU
	- high-level C++ programming expertise
	- excellent problem solving and debugging skills
+ skill set:
	- LLVM/MLIR compiler, compiler frameworks, compiler architecture, compiler infrastructure
	- ability to deliver production quality code in modern C++
	- Torch-MLIR
	- ONNX-MLIR
	- Caffe
	- TVM
	- MLIR
	- LLVM
	- TVM
	- Glow
+ experience with modern compiler frameworks:
	- TVM
	- LLVM
	- MLIR
	- GLOW
	- XLA
+ Design and implement a set of compiler tools to translate from ML-oriented domain-specific languages (TensorFlow, Caffe, Theano) to proprietary binary format
+ Working on the IPU architecture compiler. Understanding code generation & optimization of C / C++ code to the instruction set of the machine. The architecture compiler and its ability to target the IPU for maximum performance and flexibility, is a fundamental component of the Poplar framework.
+ skill set:
	- Software Engineer, Programming Languages
	- Lamini AI is at the forefront of bringing LLMs to production.  We are on a mission to help every company unlock the power of generative AI, by putting their own data to work. Our team is made up of highly experienced ML engineers and tech industry veterans and we’re backed by leading computing and technology companies.
	- We are currently looking for exceptionally talented Software Engineers to join our small team. 
	- You will be responsible for developing and designing DSLs (Domain Specific Languages) for LLMs. 
	- You will build the language software development toolkits (SDKs) that allow external developers to access Lamini AI System from all supported languages. 
	- You will own the component of the generated software runtime (backend, frontend) as well as code generators.
	- Bachelor’s degree in Computer Science, Electrical Engineering, or related field.
	- Passion for programming languages.
	- Proficiency in Python
	- Enjoy learning language internals and advanced language features.
	- Strong competency in object-oriented programming, data structures, and algorithms.
	- Enjoy working with abstract concepts and finding elegant, rigorous solutions to complex problems.
	- Understanding of software development principles and design patterns.
	- Understanding of software development lifecycle, tools, and standard methodologies.
	- Excellent communication and collaboration skills.
	- Intellectually curious and open to challenges.
	- Thrive in a fast-paced, dynamic environment, and value end-to-end ownership of projects.
	- Experience creating Domain-Specific Languages.
	- Experience with end-to-end development of Python packages.
	- Understand how compilers work, e.g. AST, IR, optimizations, code generation
+ Staff AI Compiler Engineer
	- We believe that AI is a net positive force in the world. Our vision and mission are to help rebuild AI infrastructure to advance humanity and our environment. We will do whatever it takes to empower our customers, team, and company to benefit from that pursuit. You can read about our culture and careers here to understand how we work and what we value.
	- We are owners and advocates for the underlying technologies, developer platforms, product components, and infrastructure. These essential building blocks form the high-quality and coherent experiences our users expect. We aim to drive the pace of innovation for every AI/ML developer.
	- Modular is looking for Staff AI Compiler engineers to work on multi-framework, multi-hardware and user-extensible compiler infrastructure. We are looking for candidates with strong communication and teamwork skills who excel in collaborating across team boundaries. In this role you will own the design and implementation of compiler types, operations and passes related to machine learning models, and work across teams to integrate them with the rest of Modular’s product.
	- Build an MLIR-based machine learning compiler with scalable and high quality infrastructure
	- Implement generic and extensible optimizations for machine learning models from multiple frameworks and on multiple devices
	- Work with other teams to provide a balanced stack that fully utilizes today’s complex server and mobile systems.
	- Collaborate with machine learning researchers and engineers to guide compiler development for future ML trends.
	- 8+ years of compiler engineering experience.
	- Experience working with compilers for machine learning, such as XLA, Glow, TVM, nGraph, TensorRT, IREE, etc.
	- Experience with machine learning graph optimizations
	- Creativity and curiosity for solving complex problems, a team-oriented attitude that enables you to work well with others, and alignment with our culture.
	- Strong knowledge of core compiler algorithms and data structures.
	- In-depth knowledge of C++, as well as, knowledge of basic GitHub workflows like pull requests.
	- Strong knowledge of and experience working with MLIR and LLVM.
	- Experience with 8 bit and lower model quantization
	- Advanced degree in Computer Science or a related area
	- The estimated base salary range for this role to be performed in the US, regardless of the state, is $207,000.00 - $286,000.00 USD. The salary for the successful applicant will depend on a variety of permissible, non-discriminatory job-related factors, which include but are not limited to education, training, work experience, business needs, or market demands. This range may be modified in the future. The total compensation for a candidate will also include annual target bonus, equity, and benefits, with equity making up a significant portion of your total compensation.
	- For candidates who fall outside of the listed requirements, we nevertheless encourage you to apply as we may have openings that are lower/higher level than the ones advertised. 
	- What Modular brings to the table:
	- Amazing Team. We are a progressive and agile team with some of the industry’s best engineering and product leaders.
	- Flexible Location. We want you to work where you are most productive and we are a remote-first company. We have offices in Palo Alto, CA and Seattle, WA for collaboration, and will open more next year.
	- World-class Benefits. In order to attract the best, we need to offer the best. Premier insurance plans, up to 5% 401k matching, very generous WFH setup stipends, flexible paid time off, and more are available to you! Please note that specific benefit packages may vary based on your location.
	- Competitive Compensation. We offer very strong compensation packages, including stock options. We want people to be focused on their best work and believe in tailoring compensation plans to meet the needs of our workforce. 
	- Team Building Events. We organize regular team onsites and local meetups in different cities.
	- Working at Modular will enable you to grow quickly as you work alongside incredibly motivated and talented people who have high standards, possess a growth mindset, and a purpose to truly change the world.
+ Mojo Compiler Engineering Manager
	- We believe that AI is a net positive force in the world. Our vision and mission are to help rebuild AI infrastructure to advance humanity and our environment. We will do whatever it takes to empower our customers, team, and company to benefit from that pursuit. You can read about our culture and careers here to understand how we work and what we value.
	- We are owners and advocates for the underlying technologies, developer platforms, product components, and infrastructure. These essential building blocks form the high-quality and coherent experiences our users expect. We aim to drive the pace of innovation for every AI/ML developer.
	- Modular is building a next-generation AI infrastructure platform that unifies the many application frameworks and hardware backends, simplifying deployment for AI production teams and accelerating innovation for AI researchers and hardware developers. We are looking for a technical Software Engineering Manager to lead the development of the compiler for our Mojo 🔥programming language. In this role you will own the definition and design of Mojo 🔥language features and the compiler infrastructure that implements them. You will work to align the team on product deliverables, set team execution strategy and engineering practices, collaborate across teams to deliver Mojo 🔥to internal and external customers, and work closely with a growing community of Mojo developers (aka Mojicians 🔥). We are looking for candidates with compiler background and strong communication and teamwork skills who excel in collaborating across team boundaries. Join our world-leading team and help us redefine how AI systems are built.
	- Lead Mojo 🔥Compiler team in building high-quality compiler infrastructure with state-of-the-art optimizations.
	- Drive development of Mojo 🔥language features based on requirements of internal and external customers.
	- Engage with the Mojo 🔥developer community and, in collaboration with other teams, drive adoption and evolution of Mojo 🔥.
	- Provide technical leadership and career guidance to the team engineers helping them to realize their full potential and set and achieve career goals.
	- Collaborate with engineering and cross-functional teams to build a balanced technology stack that fully utilizes today’s complex hardware systems.
	- 5+ years’ experience in compiler development, including 2+ years in a management role.
	- Strong understanding of programming language and compiler development.
	- Experience working with MLIR or LLVM.
	- Proven experience in managing and developing a high-performance engineering team.
	- Ability to work in a fast-paced, dynamic environment and manage multiple priorities.
	- Creativity and passion for building high-quality user-facing products. 
	- Strong understanding of modern programming languages, such as Python, C++, Rust, Swift and Julia.
	- Experience working with the open source developer community.
	- The estimated base salary range for this role to be performed in the US, regardless of the state, is $207,000.00 - $286,000.00 USD. The salary for the successful applicant will depend on a variety of permissible, non-discriminatory job-related factors, which include but are not limited to education, training, work experience, business needs, or market demands. This range may be modified in the future. The total compensation for a candidate will also include annual target bonus, equity, and benefits, with equity making up a significant portion of your total compensation.
+ AI Compiler Engineering Manager
	- We believe that AI is a net positive force in the world. Our vision and mission are to help rebuild AI infrastructure to advance humanity and our environment. We will do whatever it takes to empower our customers, team, and company to benefit from that pursuit. You can read about our culture and careers here to understand how we work and what we value.
	- We are owners and advocates for the underlying technologies, developer platforms, product components, and infrastructure. These essential building blocks form the high-quality and coherent experiences our users expect. We aim to drive the pace of innovation for every AI/ML developer.
	- Modular is looking for a technical Software Engineering Manager to lead and drive our internal multi-framework, multi-hardware and user-extensible compiler infrastructure. We are looking for candidates with strong communication and teamwork skills who excel in collaborating across team boundaries. In this role you will own the design and implementation of compiler types, operations and passes related to machine learning models, work to align the team on product deliverables, code quality, and software architecture, driving hiring and team growth, and work across teams to provide an excellent experience for customers and other teams.
	- Build an MLIR-based machine learning compiler with scalable and high quality infrastructure.
	- Implement generic and extensible optimizations for machine learning models from multiple frameworks and on multiple devices.
	- Work with other teams to provide a balanced stack that fully utilizes today’s complex server and mobile systems.
	- Collaborate with machine learning researchers and engineers to guide compiler development for future ML trends.
	- 6+ years of compiler engineering experience and 2+ years of software engineering management experience.
	- Proven experience in technical leadership, management, and growth of high performance teams.
	- Creativity and curiosity for solving complex problems, a team-oriented attitude that enables you to work well with others, and alignment with our culture.
	- In-depth knowledge of C++, as well as, knowledge of basic GitHub workflows like pull requests.
	- Experience working with compilers for machine learning, such as XLA, Glow, TVM, nGraph, TensorRT, IREE, etc.
	- Strong knowledge of and experience working with MLIR and LLVM.
	- Experience with 8 bit and lower model quantization.
	- Advanced degree in Computer Science or a related area.
	- The estimated base salary range for this role to be performed in the US, regardless of the state, is $207,000.00 - $286,000.00 USD. The salary for the successful applicant will depend on a variety of permissible, non-discriminatory job-related factors, which include but are not limited to education, training, work experience, business needs, or market demands. This range may be modified in the future. The total compensation for a candidate will also include annual target bonus, equity, and benefits, with equity making up a significant portion of your total compensation.
+ skill set:
	- As an intern on our Compiler team, you will work with leaders from industry and academia to develop entirely new solutions for the toughest problems in AI compute.
	- As deep neural network architectures evolve, they are becoming enormously parallel, and distributed.  Compilers are needed to optimize the mappings of computation graphs to compute nodes. In this position, you will build the tools that generate distributed memory code from evolving intermediate representations.
	- Design and devise graph semantics, intermediate representations, and abstraction layers between high-level definitions (like TensorFlow's XLA) and low-level distributed code.
	- Use state-of-the-art parallelization and partitioning techniques to automate generation, exploiting hand-written distributed kernels.
	- Identify and implement novel program analysis and optimization techniques.
	- Employ and extend state of the art program analysis methods such as the Integer Set Library.
	- Graduate and undergraduate students in Computer Science with a background in compilers and parallel programming.
	- Two or more years of related work experience on compilers and distributed systems.
	- Compiler experience; experience generating and optimizing code.
	- Familiarity with high-level parallel program analysis and optimization
	- LLVM compiler internals.
	- Polyhedral models.
	- Familiarity with HPC kernels and their optimization.
+ skill set:
	- We’re looking for an experienced Compiler Architect to help drive compiler improvements and hardware requirements.  
	- Analyze deep learning networks and develop compiler optimization algorithms for our hardware 
	- Performance tuning and analysis on different levels of the compiler  
	- Architect and implement compiler and optimization techniques for various neural networks  
	- Work closely with chip design team on hardware architecture 
	- Develop and maintain compiler tool chains 
	- Bachelors, Masters or Ph.D. or equivalent in Computer Science, Computer Engineering  
	- 3 to 5 years of relevant work in performance analysis and compiler optimization  
	- Experience with modern ML compiler technologies: ***MLIR, LLVM,  XLA, TVM, TensorRT***
	- Experience with graph algorithms, combinatorial optimization techniques, quantization of Deep Learning models, compilation for multi-core architectures (GPU, FPGA, or systolic arrays)  
	- Excellent C/C++ programming and Python software design skills  
	- Knowledge of deep learning frameworks (***TensorFlow, PyTorch***)  
	- Experience with developing and analyzing neural network models 
	- Experience with ***CUDA, cuDNN***
+ skill set:
	- The SiFive MLIR team's mission is to create a compiler technology that achieves cutting-edge performance without sacrificing quality and scalability.  SiFive is an active participant in the RISC-V ecosystem that opens a vast opportunity to develop the next generation of computer architecture and compiler technology. SiFive engineers are active members and maintainers in many open source projects, and our mission is to work with and drive the RISC-V ecosystem.
	- We are hiring a Director for our MLIR compiler activities, a person with proven experience in compiler technology targeting end-to-end application optimizations in domains such as Machine Learning and AI. The candidate should demonstrate a track record in leadership, cross-team collaboration, planning, and delivering high-quality compiler products. 
	- Grow and Lead a geographically distributed MLIR compiler team from the ground up  
	- Closely collaborate with SiFive’s Algorithms, Frameworks and hardware teams in implementing optimized vertical solutions for AI and other domains.
	- Plan the development alongside hardware, software, and product organizations to deliver a combined hardware and software quality products. 
	- Collaborate with the MLIR community, upstream changes and coordinate internally and externally with cross geographical and distributed ecosystems. 
	- Build, lead, inspire and grow the software organization alongside other software leaders. 
	- 5+ years of experience in technical leadership of a compiler team.
	- 5+ years of experience in compiler technology.
	- Experience in MLIR or similar multi-level optimizing compilers.
	- Experience with open source contributions. 
	- Experience with hardware specific optimizations such as SIMD, parallel architectures or other specialized accelerators.
+ Software Engineer, Triton Compiler
	- San Francisco, California, United States — Research Acceleration
	- Our mission at OpenAI is to discover and enact the path to safe, beneficial AGI. To do this, we believe that many technical breakthroughs are needed in generative modeling, reinforcement learning, large scale optimization, active learning, among other topics.
	- As a Software Engineer, you will help build AI systems that can perform previously impossible tasks or achieve outstanding levels of performance. This requires good engineering (for example designing, implementing, and optimizing state-of-the-art AI models), writing bug-free machine learning code (surprisingly difficult!), and building the science behind the algorithms employed. In all the projects this role pursues, the ultimate goal is to push the field forward.
	- The Research Acceleration team builds high-quality research tools and frameworks to increase research productivity across OpenAI, with the goal of accelerating progress towards AGI. For example, we develop Triton, a language and compiler for writing custom GPU kernels. The aim of Triton is to provide an open-source environment to write fast code at higher productivity than CUDA. 
	- We frequently collaborate with other teams to speed up the development of new state-of-the-art capabilities. For example, we recently collaborated with our Codegen research team on the Codex model, which can generate code in Python and many other languages.
	- Do you love research tools, compilers, and collaborating on cutting-edge AI models? If so, this role is for you! We are looking for people who are self-directed and enjoy determining the most meaningful problem to solve in order to accelerate our research.
	- 3+ years of relevant engineering experience
	- Owning problems end-to-end, with a willingness to pick up whatever knowledge is missing to get the job done
	- Bonus: contributions to an AI framework such as PyTorch or Tensorflow, or compilers such as GCC, LLVM, or MLIR
	- Annual Salary Range: $200,000—$370,000 USD
+ Graph Compiler Engineer
	- The Platform ML team builds the ML side of our state-of-the-art internal training framework used to train our cutting-edge models.  We work on distributed model execution as well as the interfaces and implementation for model code, training, and inference.  Our priorities are to maximize training throughput (how quickly we can train a new model) and researcher throughput (how quickly we can develop new models) with the goal of accelerating progress towards AGI.  We frequently collaborate with other teams to speed up the development of new capabilities.
	- As a Graph Compiler Engineer you will work on the capture and optimization of model graphs for our training runs.  Seamless graph capture is important for keeping researcher throughput high, while graph-level optimizations will allow us to get state-of-the-art training throughput on current and future accelerators.
	- We’re looking for engineers who are excited to work on our training framework and with researchers at the cutting edge of ML research.  Given the scale of our training, small improvements to hardware utilization for our largest runs can produce large cost savings.  Enabling researchers to iterate quickly on their ideas will produce large improvements in model capabilities and compute efficiency.
	- This role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.
	- Work on our internal training framework to enable easy graph capture of our research experiments
	- Apply advanced optimizations to the graph to maximally utilize hardware resources
	- Have strong software engineering skills and are proficient in Python
	- Have experience running machine learning experiments
	- Have experience working on a machine learning compiler
	- Have deep knowledge of GPU performance and systems-level optimization
	- Annual Salary Range: $245,000—$385,000 USD
	- OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity. 
	- At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.
+ skill set:
	- We are looking for an experienced MLIR compiler engineer, passionate about optimization, compiler technology and parallel compute. The candidate should demonstrate a track record in developing compiler technology in MLIR, LLVM or similar frameworks to achieve optimizations of algorithms in domains such as AI, deep learning, and high performance computing.
	- Developing MLIR and LLVM based compiler technology for the SiFive Intelligence platforms.
	- Developing large-scale production software with testing and continuous integration in mind.
	- Closely collaborating with Algorithm, Frameworks and hardware teams to codesign an end to end optimized vertical solutions for AI and other domains.
	- Collaborating with open source projects, upstream changes and coordinating internally and externally with cross geographical and distributed ecosystems.
	- 5+ years of experience in compiler technology.
	- 5+ years of experience in optimization for parallel algorithms and certain vertical domains such as AI or similar.
	- 5+ years of experience in developing production software.
	- Experience with open source contribution.
	- Experience with hardware specific optimizations such as SIMD and special accelerators.
+ skill set:
	- Experience in MLIR or similar multi-level optimizing compilers.
	- Experience with hardware specific optimizations such as SIMD, parallel architectures or other specialized accelerators.
+ skill set:
	- Deep Learning Compiler Engineer
	- Habana Labs is a young and innovative company focused on developing purpose-built AI processors, disruptive solutions that will shape the future of AI and Deep Learning computing. Habana was founded in 2016 by successful entrepreneurs, launched its first AI Inference processor in 2018, its Training processor in 2019 and was acquired by Intel in December 2019.  The company now operates as an autonomous subsidiary of Intel.  Our vision to take AI processing from its current limits to the peak of its potential continues. We see challenges as opportunities, laser focus on execution and are determined to fulfill our vision to improve the quality of life, work and leisure with our AI solutions. We are looking for exceptionally smart people who believe that AI will change the world and would like to join us on our exciting journey!
	- We are looking for a hands-on compiler engineer to join the R&D Engineering team, with in-depth knowledge in one or more of programming languages, compilers and hardware architecture. Knowledge of ML/DL frameworks and machine learning would be an added bonus but is not required.
	- Roles and Responsibilities:
		* Explore solutions to challenging customer requirements through state-of-the-art compilation techniques
		* Put together, discuss and advocate design proposals for innovative ideas
		* Rapid prototyping and data-driven exploration of new ideas
		* Design and implement next-gen features in our compiler and runtime software stack
		* Tackle large scale optimization problems across novel architectures
		* Collaborate with peers in SW, Architecture and HW teams
	- BS with 6+ years of experience or MS with 4+ years of experience in Computer Science, Computer Engineering or similar field
	- 6 + years of experience C++ experience and software design skills
	- 3+ years of compiler engineering experience with one or more of
	- 2+ years of  experience building compilers using LLVM or equivalent
	- 2+ years of  Experience building/designing programming models and languages
	- 2+ years of  experience with loop optimizations (vectorization, unrolling, fusion, parallelization etc.)
+ skill set:
	- We are looking for an experienced AI/ML compiler engineer, passionate about optimization, compiler technology and parallel compute. The candidate should demonstrate a track record in developing compiler technology in MLIR, LLVM, TVM or similar frameworks to achieve optimizations of algorithms in domains such as AI, deep learning, and high performance computing.
	- Develop MLIR and LLVM based compiler technology for the SiFive Intelligence platforms.
	- Develope large-scale production software with testing and continuous integration in mind.
	- Closely collaborate with Algorithm, Frameworks and hardware teams to codesign an end to end optimized vertical solutions for AI and other domains.
	- Collaborate with open source projects, upstream changes and coordinating internally and externally with cross geographical and distributed ecosystems.
	- 3+ years of experience in compiler technology.
	- 3+ years of experience in optimization for parallel algorithms and certain vertical domains such as AI or similar.
	- 3+ years of experience in developing production software.
	- Experience with open source contribution.
	- Experience with hardware specific optimizations such as SIMD and special accelerators.
+ We are looking for a highly motivated compiler engineer to design and develop efficient code-generation and optimization techniques using LLVM infrastructure for the Blaize’s Graph Streaming Processors (Data Flow Processor) and Picasso SDK majorly towards the Machine Learning, Natural Language Processing and Artificial Intelligence workloads. The position offers visibility ranging from the top level AI/ML applications down to its implementation in the SIMD hardware.
+ skill set:
	- We are looking for a highly motivated compiler engineer to design and develop MLIR based graph compiler to achieve peak performance on Blaize’s massively parallel graph streaming processors. The role provides an opportunity to work on cutting edge technologies in AI and to improve performance across Blaize’s software stack with a specific focus on MLIR and LLVM based compilers.
	- Design and develop efficient code-generation and optimization techniques for Blaize’s graph streaming processors using MLIR/LLVM
	- Analyze/Profile various ML workloads and identify/implement optimization techniques for compilers
	- Identify and fix system-level performance bottlenecks
	- Closely work with hardware teams to understand the low-level details and improve the performance of the generated code
	- Follow agile software development methodology, unit testing and continuous integration
	- B.Tech/M.Tech ECE or CS
	- 3 to 12 years of relevant experience in compilers/GPGPU compute
	- Strong programming skills in C/C++
	- Strong knowledge of LLVM infrastructure
	- Prior experience MLIR / Graph Compiler / Optimizations is a plus
	- Knowledge of multi-threaded and distributed programming is a plus
	- Knowledge of ML frameworks like Tensor-Flow and pyTorch for training and inference of network models is a plus
	- Knowledge of low-level hardware architecture of any CPU/GPU is a plus
	- Knowledge of memory and cache hierarchies is a plus
	- Familiarity with GPU device drivers and linux kernel internals is an added advantage but not a requirement.
+ skill set:
	- We are looking for an experienced MLIR compiler engineer, passionate about optimization, compiler technology and parallel compute. The candidate should demonstrate a track record in developing compiler technology in MLIR, LLVM or similar frameworks to achieve optimizations of algorithms in domains such as AI, deep learning, and high performance computing.
	- Developing MLIR and LLVM based compiler technology for the SiFive Intelligence platforms.
	- Developing large-scale production software with testing and continuous integration in mind.
	- Closely collaborating with Algorithm, Frameworks and hardware teams to codesign an end to end optimized vertical solutions for AI and other domains.
	- Collaborating with open source projects, upstream changes and coordinating internally and externally with cross geographical and distributed ecosystems.
	- 5+ years of experience in compiler technology.
	- 5+ years of experience in optimization for parallel algorithms and certain vertical domains such as AI or similar.
	- 5+ years of experience in developing production software.
	- Experience with open source contribution.
	- Experience with hardware specific optimizations such as SIMD and special accelerators.
+ skill set:
	- Familiarity with object oriented and functional programming languages. Experience in ***Scala*** and/or ***Swift*** highly desirable.
	- Collaborating with colleagues to integrate with ***MLIR Compiler*** stack written in ***C++***.
	- Participating in open source communities such as ***Chisel*** and ***LLVM CIRCT***.
	- Developing and enhancing embedded Domain Specific Languages (DSLs) in ***Scala*** and/or ***Swift***, along with associated build tooling, for use by hardware industry professionals.
+ skill set:
	- We at SiFive are proud to take a software first approach to develop tools and frameworks that achieves cutting edge performance without compromising quality for the SiFive Intelligence processor family. The SiFive Intelligence processors deliver AI acceleration for the edge and beyond. SiFive intelligence builds on RISC-V Vectors (RVV) allowing SiFive to design Core IPs that deliver performance, are optimized for power and area, but do not sacrifice flexibility or programmability. Our software stack is codesigned with the hardware and developed with scalability and quality in mind. Join us to develop a revolutionary software from the ground up.
	- We are looking for an experienced AI/ML compiler engineer, passionate about optimization, compiler technology and parallel compute. The candidate should demonstrate a track record in developing compiler technology in MLIR, LLVM, TVM or similar frameworks to achieve optimizations of algorithms in domains such as AI, deep learning, and high performance computing.
	- Develope MLIR and LLVM based compiler technology for the SiFive Intelligence platforms.
	- Develope large-scale production software with testing and continuous integration in mind.
	- Closely collaborate with Algorithm, Frameworks and hardware teams to codesign an end to end optimized vertical solutions for AI and other domains.
	- Collaborate with open source projects, upstream changes and coordinating internally and externally with cross geographical and distributed ecosystems.
	- 3+ years of experience in compiler technology.
	- 3+ years of experience in optimization for parallel algorithms and certain vertical domains such as AI or similar.
	- 3+ years of experience in developing production software.
	- Experience with open source contribution.
	- Experience with hardware specific optimizations such as SIMD and special accelerators.
+ skill set for Frameworks Integration Engineer:
	- Build and maintain SiFive Software CI/CD/CT flow pipelines using build and release orchestration tools (Jenkins, Travis CI, etc.)
	- Conduct SiFive Parallel Compute Frameworks testing and integration for product quality qualification and assurance
	- Build the required automation tools on the basis of past experience in scripting (BASH, Perl, Powershell, Python)
	- Closely collaborate with geographically distributed software and engineering teams.
	- 3+ year experience on large scale software integration
	- 1+ year experience on CI/CD/CT flow development
	- 3+ years Software design and programming experience in C/C++/Python for testing, debugging and problem solving
	- Experience with building tool/system like Make, CMake, Yocto, and Bazel
	- Familiar with gtest, python unittest or other testing frameworks.
	- Familiarity with version control tool with GIT and GitHub
	- Familiarity with software release management tools is plus
	- Strong system administration (Linux/Unix or Windows) at the command-line level is a plus
	- Good understanding of Deep learning, Computer Vision, NLP is plus
	- Familiarity with ML framework (Tensorflow/Tensorflow-Lite/Pytorch) is plus
+ skill set:
	- As a member of our Compiler team, you will work with leaders from industry and academia to develop entirely new solutions for the toughest problems in AI compute. 
	- As deep neural network architectures evolve, they are becoming enormously parallel, and distributed. The Cerebras compiler efficiently maps this computation onto hundreds of thousands of compute nodes, leveraging novel hardware architecture features to maximize performance while maintaining correctness. LLVM is a critical component in the compilation process, not only performing low-level optimization and efficient mapping to hardware instructions, but also ensuring effective use of novel hardware features. 
	- Work with hardware architects to ensure future hardware designs maximize the performance accessible via automatic compilation while minimizing compiler complexity
	- Develop effective representations of Cerebras’ novel architectural features in LLVM IR
	- Extend the LLVM backend to target new hardware architectures, designing and implementing performant and correct mappings from LLVM IR to Cerebras’ novel hardware
	- Design and implement LLVM IR and backend optimizations, maximizing performance on deep learning and HPC workloads
	- Mentor junior engineers on development best practices and LLVM internals
	- Collaborate closely with teams developing related software components to ensure compatibility, robustness, quality, and performance
	- Contribute to the design of higher-level intermediate representations and domain specific languages and their mapping to LLVM IR
	- Maintain our production compiler in use by customers in both the ML and HPC domains
	- Bachelor’s or foreign equivalents in computer science, engineering, or related field 
	- 5+ years of experience developing optimizing compilers using the LLVM tool chain 
	- Strong C++ development skills
	- Excellent verbal and written communication skills
	- Able to collaborate effectively in a distributed team 
	- Master’s, PhD, or foreign equivalents in computer science, engineering, or related field 
	- Production compiler development experience, particularly developing LLVM target backends
	- Experience in the design and implementation of DSLs
	- Familiarity with machine learning frameworks and intermediate representations 
	- Experience with parallel programming techniques and optimizations
+ skill set:
	- As a member of our Compiler team, you will work with leaders from industry and academia to develop entirely new solutions for the toughest problems in AI compute. 
	- As deep neural network architectures evolve, they are becoming enormously parallel, and distributed. Compilers are needed to optimize the mappings of computation graphs to compute nodes. In this position, you will build the tools that generate distributed memory code from evolving intermediate representations. 
	- Design and devise graph semantics, intermediate representations, and abstraction layers between high-level definitions (like TensorFlow and Pytorch) and low-level distributed code 
	- Use state-of-the-art parallelization and partitioning techniques to automate generation, exploiting hand-written distributed kernels
	- Identify and implement novel program analysis and optimization techniques for compilers targeting linear algebra applications on distributed memory architectures 
	- Leverage open-source tools and compiler toolchains such as ***ISL, MLIR and LLVM*** to build domain specific language and compiler for programming Cerebras Wafer Scale Engine
	- Develop and optimize the LLVM backend target for various generations of Cerebras architecture
	- Bachelor’s, Master’s, PhD, or foreign equivalents in computer science, engineering, or related field 
	- Familiarity with high-level parallel program analysis and optimization 
	- Compiler experience; experience in code generation and optimization for distributed systems
	- Strong proficiency in C/C++ or other language for designing large, performant systems
	- Familiarity with Python or other scripting language. 
	- Familiarity with multi-thread and multi-process programming models
	- ***MLIR & LLVM compiler toolchain internals***
	- ***Polyhedral models, Integer Set Library (ISL)***
	- Familiarity with HPC kernels and their optimization 
	- IEEE floating point representations 
	- Familiarity with machine learning frameworks such as TensorFlow and Pytorch 
	- Knowledge of ML application areas and state-of-the-art networks in various application areas
+ skill set for ***Machine Learning Compiler Research Intern***:
	- NVIDIA is hiring software engineer interns for its GPU-accelerated Deep Learning team. Academic and commercial groups around the world are using GPUs to power a revolution in deep learning, enabling breakthroughs in problems from image classification to speech recognition to natural language processing and artificial intelligence. Join NVIDIA's team building software which will be used by the entire deep learning research community.
	- In this role, you will be responsible for developing highly optimized solutions for deep learning algorithms. You’ll collaborate with members of the open source deep learning software engineering community to define and implement the features needed to accelerate the next generation of deep learning software frameworks. The scope of these efforts ranges from defining public APIs, performance tuning and analysis, crafting and implementing compiler and optimization techniques for neural networks, and other general software engineering work.
	- Pursuing Master's (or equivalent experience) or PhD degree in CS or related field or equivalent.
	- Excellent C/C++ programming and software design skills, including debugging, performance analysis, and test design.
	- Knowledge of CPU and/or GPU architecture. CUDA or OpenCL programming experience desired but not required.
	- Experience with the following technologies: deep learning models and algorithms, deep learning framework design, high performance compiler design, or EDA synthesis and optimization algorithms.
	- You have a history of mentoring others.
+ skill set:
	- ***Develop machine learning graph compiler***
	- Participate in the co-design of Tenstorrent's hardware and software stack
	- ***Benchmark, analyze, and optimize performance of key machine learning applications across Tenstorrent's hardware and software stack***
	- ***Develop performance analysis and estimation infrastructure that feeds into Tenstorrent compiler***
	- ***Develop high-performance run-time engine***
	- ***Integrate the Tenstorrent software into leading machine learning frameworks***
	- Work closely with machine learning engineers to discover the hardware and software requirements of current and future machine learning applications
	- BSc, MSc or PhD in Electrical/Computer Engineering or Computer Science;
	- Experience with algorithms, data structures, and software development in C/C++. Python expertise is welcome as well
	- ***Familiarity with and passion for any of the following -- machine learning, compilers, parallel programming, high-performance and massively parallel systems, processor and computer architecture -- is a plus***
+ Familiarity with ***Graph Compilers***
+ Translation of network models in different ML frameworks to MLIR based graphs
+ Experience in or knowledge of MLIR flow, and in any MLIR optimizations.
+ compiler development experience for GPU compilers, dataflow computing compilers, and/or machine learning compilers
+ skill set:
	- Principal Engineer, Compilers
	- In partnership with the leadership team, create and define the product roadmap and co-design of Tenstorrent's hardware and software stack
	- ***Develop machine learning graph compiler***
	- ***Be the subject matter expert across one or more areas: scheduling, parallelization, memory allocation, data flow optimizations, optimizing kernels***
	- ***Define the benchmark, analyze, and optimize performance of key machine learning applications across Tenstorrent's hardware and software stack***
	- ***Develop performance analysis and estimation infrastructure that feeds into Tenstorrent compiler***
	- ***Integrate the Tenstorrent software into leading machine learning frameworks***
	- Provide technical guidance and direction to junior staff member
	- Work closely across teams to discover the hardware and software requirements of current and future machine learning applications
	- ***Deep understanding of IR and machine level compiler optimization techniques.***
	- ***Extensive working experience with one or more: scheduling, parallelization, memory allocation, data flow optimizations, optimizing kernels***
	- 7+ years of experience working with algorithms, data structures, and software development
	- C++, Python
	- Bachelors in Computer Science or Electrical/Computer Engineering or Engineering Science
	- Excellent verbal and written communication skills
	- Ability to work across multiple teams
	- 2+ years of experience as a technical lead, developing and mentoring a team
	- Experience contributing to open-source projects, and demonstrated influence in the open community.
	- Masters/PhD in Computer Science or Electrical/Computer Engineering or Engineering Science
	- Software development in Python
+ skill set:
	- compiler design for data parallel architectures
	- compiler design for machine learning inference models
	- Apache TVM hardware backend codebase and workflow for custom code generators, BYOC
+ skill set:
	- Develop our MLIR compiler flow by writing unit tests or developing optimization passes
	- Find interesting new machine learning workloads and get them running in Centaur’s accelerator flow
	- Contribute to our libraries to produce high-performance assembly for new ML kernels
+ Experience with the deep learning compiler space (ONNC, TVM, XLA, etc) is a huge plus
+ skill set:
	- Support the use of deep learning compilers (graph compilation and operator compilation, etc.); improve the performance of deep learning network training and reasoning on self-developed chips;
	- Lead the design and development of deep learning compiler architecture and algorithm;
	- Participate in the implementation strategy analysis, performance evaluation, and compilation optimization strategy design of typical networks;
	- Participate in future self-developed instruction set and micro-architecture design, and evolve compiler optimization capabilities to support new features.
	- Master's degree or above in computer software, electronic engineering or related majors, and more than seven years of relevant work experience;
	- Proficient in C/C++, familiar with LLVM, MLIR, TVM and other compiler frameworks and technologies;
	- Familiar with typical deep learning frameworks and inference engines such as PyTorch, TensorFloyTensorRT, etc.; have experience in compiling and optimizing large-scale deep learning networks;
	- Familiar with the architecture and compilation principles, and have rich experience in the implementation of compilation optimization;
	- Familiar with heterogeneous programming systems, experience in GPGPU/GPU/NPU heterogeneous compilation is preferred.
+ skill set:
	- AI compiler development engineer/architect
	- Operator generation and optimization for hardware features;
	- Graph compilation for machine learning.
	- Master degree or above in computer software or related majors, proficient in C/C++ programming, familiar with machine learning framework;
	- Have MLIR/TVM/XLA related compilation and optimization experience or strong learning ability;
	- Have good communication skills and code habits; familiar with Linux development and debugging environment, git and other version control tools;
	- Familiar with compilation principles and architecture, experience in compiler development and optimization debugging is preferred;
	- Familiar with deep learning framework and network model.
+ skill set:
	- Staff AI Graph Compiler Engineer
	- Modular is looking for Staff AI Graph Compiler engineers to work on multi-framework, multi-hardware and user-extensible compiler infrastructure. We are looking for candidates with strong communication and teamwork skills who excel in collaborating across team boundaries. In this role you will own the design and implementation of compiler types, operations and passes related to machine learning models, and work across teams to integrate them with the rest of Modular’s product.
	- Build an MLIR-based machine learning compiler with scalable and high quality infrastructure
	- Implement generic and extensible optimizations, such as constant folding, operation fusion, model parallelization, and quantization.
	- Analyze and improve performance across multiple different model architectures and ML frameworks.
	- Work with other teams to provide a balanced stack that fully utilizes today’s complex server and mobile systems.
	- Collaborate with machine learning researchers and engineers to guide compiler development for future ML trends.
	- 8+ years of compiler engineering experience.
	- Experience working with compilers for machine learning, such as XLA, Glow, TVM, nGraph, etc.
	- Experience with ML graph optimizations, 8 bit and lower model quantization, parallel / distributed programming, and/or heterogeneous ML computation.
	- Creativity and curiosity for solving complex problems, a team-oriented attitude that enables you to work well with others, and alignment with our culture.
	- Strong knowledge of core compiler algorithms and data structures.
	- In-depth knowledge of C++, as well as, knowledge of basic GitHub workflows like pull requests.
	- Strong knowledge of and experience working with MLIR and LLVM.
	- Advanced degree in Computer Science or a related area
+ skill set:
	- Computer Vision/Deep Learning Compiler Engineer
	- We are working on developing a modern programming framework designed to facilitate the implementation of high-performance computer vision and machine learning algorithms on Apple hardware. We are looking for an extraordinary compiler engineer to join us on projects that will impact hundreds of millions of users.
	- C++ development experience
	- Writing high performance, memory efficient, and multi-threaded code
	- Differentiable programming
	- Familiarity with domain specific languages such as: Compilers, LLVM, Halide, TVM, Taichi
	- Optimization algorithms
	- Deep Learning applied to computer vision problems
	- Familiarity or experience with Metal and python is a plus
	- We create computer vision algorithms to deliver experiences that are impactful, significant, and influential. We work closely with Apple’s outstanding designers to ensure the products we ship are more than technical demos – they resonate with users at a personal level. In this role you will be working on a wide range of responsibilities: core technology algorithm development in support of future user experiences; communicating with and supporting external teams that use our algorithms; supporting low-level, cross-platform efforts; participating in code reviews; and being a constant advocate within the team for high quality results.
	- PhD in computer vision, robotics or machine learning; alternatively a comparable industry career, with significant experience on delivering products using innovative computer vision, machine learning and robotics technologies
+ skill set:
	- Mojo Compiler Technical Lead Manager
	- Modular is building the next-generation AI infrastructure platform that will radically improve the way developers build and deploy AI models. A key component in our technology stack is the Mojo programming language, which combines usability of Python with the performance of C++ and Rust, unlocking programmability of AI hardware. While Mojo is intentionally designed to look like Python and become a superset of Python over time, it also supports a rich set of system programming features, compile-time metaprogramming and autotuning. We are seeking an engineering leader with strong experience in programming system development to help us drive Mojo language design, implementation and developer tooling. This is a unique opportunity to lead development of a new programming language with a rapidly growing user base and a revolutionary impact on AI software.
	- Drive development of Mojo language features, implementation and development tooling.
	- Lead Mojo engineering team and provide technical guidance and mentoring to the team engineers.
	- Engage with Mojo community and, in collaboration with product, drive adoption and evolution of Mojo.
	- Ensure that the engineering team builds state-of-the-art technology and follows best practices in software development and project management.
	- Provide technical leadership and career guidance to the team engineers helping them to realize their full potential and set and achieve career goals.
	- Collaborate with engineering and cross-functional teams to build a balanced technology stack that fully utilizes today’s complex server and mobile systems.
	- 5+ years experience in building programming systems, including 2+ years in a leadership role.
	- Understanding of the internals of modern programming languages, such as Python, C++, Rust, Swift or Julia.
	- Proven experience in managing and developing a high-performance engineering team.
	- Ability to work in a fast-paced, dynamic environment and manage multiple priorities.
	- Creativity and passion for building high-quality user-facing products. 
	- Experience working with the open source developer community is a strong plus.
	- The estimated base salary range for this role to be performed in the US, regardless of the state, is $207,000.00 - $286,000.00 USD. The salary for the successful applicant will depend on a variety of permissible, non-discriminatory job-related factors, which include but are not limited to education, training, work experience, business needs, or market demands. This range may be modified in the future. The total compensation for a candidate will also include annual target bonus, equity, and benefits, with equity making up a significant portion of your total compensation.
+ skill set:
	- Senior Machine Learning Compiler Engineer
	- We live in a mobile and device driven world, where Deep Learning technology enables a new class of applications.
	- Are you passionate about enabling unique user experience such as Face ID, Animoji, AR games? Imagine the countless possibilities powered by Artificial Intelligence.
	- In the Video Engineering team, we are dedicated in providing hardware acceleration using the new proprietary Apple Neural Engine SOC to enable real time, low power and high performance execution of Deep Learning workloads.
	- Our success is the result of very talented people working in an environment which cultivates creativity, partnership and cross functional collaboration.
	- These elements come together to make Apple an amazing environment for motivated people to do the greatest work of their lives.
	- Will you help us design the next generation of revolutionary Apple Products?
	- Passion for developing and optimizing compilers for modern architectures
	- Working knowledge of compiler architecture, front-end and middle-end optimizations, scheduling, register allocation, back-end code generation
	- Experience with neural networks inference on dedicated SOC or GPU
	- High level C++ programming expertise
	- Excellent problem solving and debugging skills
	- Proven track record of building high quality production software
	- Excellent communication and collaboration skills
	- We develop compiler technology to accelerate deep learning applications for Apple products. 
	- Architect and develop the compiler for Apple proprietary Neural Engine Accelerator architecture, to enable inference of deep learning networks onto this architecture with an emphasis on performance and power.
	- Bring up new hardware silicon and add support in the compiler for these hardware features.
	- Work on bringing the compiler code to production quality and enable a wide range of applications of deep learning technology, for internal clients and 3rd party developers.
	- Evaluate existing hardware blocks and work closely with the platform architecture team on the definition of new hardware features, and hardware specification review.
	- Work with the micro-architecture design team,to understand the functional and performance goals of the design.
	- Masters's degree or higher in Computer Science or equivalent field.
+ skill set:
	- AI Compiler Software Engineer (m/f/d)
	- Axelera AI is a truly European deep-tech Start Up company which is developing a game-changing hardware and software platform for AI at the edge that will make the industry more integrated, efficient and accessible. Our mission is to spread artificial intelligence for a green, fair, trusted and safe world enabling new application of AI in diverse sectors like smart cities, retail and other markets. Our company is a spin-off from a multinational deep-tech group and is backed by a strong syndicate of institutional investors. We have an extraordinary and international team of top talented researchers and developers working in the headquarter in Eindhoven (NL) and in the branch offices in Leuven (BE), Zurich (CH) and Pisa (IT). 
	- At Axelera AI we are building a novel software stack to unlock the power of industry-leading in-memory computing technology. Our software stack enables AI developers to transform their Machine Learning models into highly-optimized machine code for the Axelera hardware platform easily and efficiently and to run DL applications with high efficiency and performance. 
	- We offer a flexible working arrangement, with the option to relocate near an Axelera AI office (currently in the Netherlands, in Belgium and in Switzerland) or work remotely from any European country. 
	- You will be a primary technical contributor to the architecture, design and implementation of Axelera’s Neural Network compiler and SDK.Your tasks will mainly include the following:  
	- Have a leading role in the development of the Axelera NN compiler, including hands-on code contributions in diverse software engineering environments 
	- Work with data scientists and AI experts to develop algorithms for transforming and optimizing Neural Networks for In-Memory Computing 
	- Develop hardware-aware optimizations for the Axelera software stack 
	- Create tools for ensuring high quality in the software development process 
	- Build prototypes to evaluate algorithms and techniques at an exploratory stage before they are implemented in the product 
	- Master’s or PhD in Computer Science or a related technical field 
	- 3-5 years of experience in a Software Engineering role, thereof ideally 2 years of experience with Deep Learning frameworks and AI systems 
	- Background in systems programming, incl. compiler development 
	- Experience with open source compiler frameworks like TVM/MLIR/Glow is a plus 
	- Excellent verbal and communication skills 
	- Proficiency in C++ & Python 
	- You are self-reliant, independent with high sense of ownership of your work and value freedom with responsibility 
+ skill set:
	- Data Flow Compiler Engineer
	- Tel Aviv-Yafo, IL
	- Hailo is a leading start-up developing a first-in-class deep learning inference processor for smart devices in various industries. Hailo offers a breakthrough microprocessor uniquely designed to accelerate embedded AI applications on edge devices.  
	- We combine a fundamental understanding of the way neural networks operate with our team’s expertise in SW and HW architecture, to develop a product that has the potential to be a landmark in computer technology. The company is built from a mixture of experts from various fields, coming from the elite units of the intelligence community and the leading tech companies in Israel, with a track record of executing complex projects from the ground up.  
	- As a team member of the team, you will work on several challenging fronts, implementing different algorithms for resource allocation, mapping, HW-specific features, and optimizations in C++. Help build and develop Hailo's dataflow compiler, an innovative unique toolchain that takes real-world AI models and compiles them to Hailo's breakthrough processors.
	- The role involves a deep understanding of Hailo's architecture and has an extensive direct impact on our products.
	- Design and develop a multidisciplinary system for machine learning.
	- Work in different SW environments: C++, Python, AI frameworks
	- BSc in Computer Science or Electrical Engineering
	- 3+ years of R&D experience in C/C++, Python
	- Hard-working, committed, and self-reliant
	- Great interpersonal skills and a team-player
	- Fluent English
	- Experience in Deep Learning and Deep Learning development frameworks
+ skill set:
	- Compiler Engineer
	- At Groq, we radically simplify compute to accelerate workloads in artificial intelligence, machine learning, and high-performance computing.
	- Why join Groq? You want to be a part of something groundbreaking, where every day you can see the impact of your work on Groq’s technology and customer solutions.  As a Groqstar, you will join a talent-rich group of problem solvers and doers; in a culture that focuses on team, growth, innovation, and creativity. Simply put, at Groq, we defy gravity. 
	- We are changing as the world changes and have evolved into a Geo-agnostic company meaning you work where you are. Exceptional candidates will thrive in asynchronous partnerships and remote collaboration methods. Some roles may require being located near our primary sites, which will be indicated in the job description. We offer a competitive salary & benefits package, numerous quality-of-life perks such as a home office stipend, flexible learning allowance, optional professional coaching and a schedule of fun team activities. 
	- Are you ready to join our crew and help us reimagine machine learning and AI at scale? 
	- As compiler engineer, you will be responsible for developing compiler optimizations for our state-of-the-art spatial compiler - targeting Groq's revolutionary Tensor Streaming Processor.  You will own specific components and compiler passes within Groq's TSP compiler, and be in charge of designing new optimizations, developing innovative scheduling techniques, and developing new front-end language dialects to support the rapidly evolving ML space.  You will also be required to benchmark and monitor key performance metrics to ensure that your components and passes produce efficient mappings of neural network graphs to the Groq TSP.  Experience with LLVM and MLIR preferred, and knowledge with functional programming languages an asset. Also, knowledge with ML frameworks such as TensorFlow and PyTorch, and portable graph models such as ONNX desired.
	- Design, develop, and maintain key components and passes within Groq's TSP compiler
	- Propose and expand Groq IR dialect to reflect the ever changing landscape of ML constructs and models.
	- Benchmark and analyze output produced by optimizing compiler, and quantify quality-of-results when measured on the Groq TSP hardware.
	- Assist in the publication of novel compilation techniques to Groq's TSP at top-tier ML, Compiler, and Computer Architecture conferences.
	- Strong initiative and self starter
	- Keen attention to detail
	- Strong written and oral communication; ability to write clear and concise technical documentation
	- Team first attitude
	- A degree in computer science, computer engineering, or related field
	- 1+ year of experience with C/C++ or Python programming
	- Knowledge of functional programming an asset
	- Experience with distributed systems or spatial compute such as FPGAs
	- Experience with ML frameworks such as TensorFlow or PyTorch desired
	- Knowledge of ML IR representations such as ONNX and Deep Learning
	- Humility - Egos are checked at the door
	- Collaborative and Team Savvy - We make up the smartest person in the room together
	- Growth and Giver Mindset - Learn it all versus know it all, we share knowledge generously
	- Curious and Innovative - Take a creative approach to projects, problems, and design
	- Passion, grit, and boldness - no limit thinking; fueling informed risk taking
+ skill set:
	- AI Compiler and Performance Engineer
	- Stability AI is a community and mission driven, open-source artificial intelligence company that cares deeply about real-world implications and applications. Our most considerable advances grow from our diversity in working across multiple teams and disciplines. We are unafraid to go against established norms and explore creativity. We are motivated to generate breakthrough ideas and convert them into tangible solutions. Our vibrant communities consist of experts, leaders and partners across the globe who are developing cutting-edge open AI models for Image, Language, Audio, Video, 3D and Biology.
	- We are looking for Engineers and Researchers in the machine learning discipline who are passionate about generative models and creative applications of AI. In particular, we are looking for people who share our mission of open-source research; people who do not believe AI models should be controlled by a centralized gatekeeper behind a closed wall, but rather be truly open and in control by all. We want highly creative researchers who are motivated to push the boundaries of generative models research, not just in state-of-the-art performance, but in pushing the efficient frontier between performance and resource usage. You will have access to state-of-the-art high performance computing resources and you will be able to work alongside top researchers and engineers to truly make an impact in the fast growing world of generative AI.
	- As an AI Compiler/Performance Engineer you will work on design and implementation of significant parts of the Stability.ai Compiler and Runtime targeting efficient training and deployment of our models. You will work on performance analysis and design/implementation of new optimizations passes and developing methods targeting new backend targets for custom devices. You will be on the forefront of moving Machine Learning Frameworks from hand written kernels to efficiently generated codegen kernels. You will be responsible for developing the research/engineering agenda, supervising its execution and guiding a group of engineers following it. You will work closely with the key stakeholders within Stability.ai as well as external entities (HW/SW providers) in order to steer the engineering efforts towards more efficient model execution.
	- Analyze and design effective compiler optimizations
	- Implement and/or enhance code generation targeting machine learning accelerators
	- Develop hardware-aware optimization for emerging ML algorithms and across a spectrum of HW platforms (GPU, TPU, CPUs, custom ASICs, edge-devices)
	- Contribute to the development of machine-learning libraries, intermediate representations
	- Employ scientific methods to evaluate performance and to debug, diagnose and drive resolution of cross-disciplinary system issues
	- Work with algorithm research teams to map graphs to hardware implementations, model data-flows, create cost-benefit analysis and estimate cluster or silicon power and performance
	- Work with research team to execute research agenda
	- Work with open-source community on model release and tooling
	- Work with engineering / business teams on model deployment and customized training
	- Develop testing plans
	- Analyze trade offs, risk mitigation strategies and communicate those to internal and external stakeholders
	- Oversee a team of engineers, provide technical direction and engineering leadership
	- 2+ years of experience with an MS or PhD (preferred) in Computer Science, Electrical Engineering or equivalent field
	- ***Experience in deep learning algorithms, frameworks and their Intermediate Representations e.g: Pytorch/GLOW, Jax, Tensorflow XLA, LLVM/MLIR, Apache TVM***
	- Good understanding of benchmarking/profiling, analyzing performance, building performance models for a given task/device
	- Familiar with concepts such as roofline modeling, flop/memory utilization, power consumption, latency
	- Good understanding of language design, compiler optimizers, backend code generators
	- Ability to communicate research/engineering ideas effectively through writing and visualization
+ skill set:
	- Compiler Development Engineer
	- We are building the world’s most advanced, AI edge inference and Learning engine. We have core processor technology that is modular, low power and high performance among peer companies. We are now scaling our engineering team to build products to address various markets’ needs (Automotive, IOT etc.) on AlphaICs home-grown AI Processor.
	- AlphaICs is looking for an accomplished Compiler Engineer to design, implement and test new features for our compiler. In this role, closely with hardware designers and AI experts to identify and deploy support for key hardware capabilities.
	- 1) Design, develop, enhance, optimize AlphaICs a deep learning compiler.
	- 2) Integrate compiler, code generation tools, run time tools to the main SDK.
	- 3) Define and develop compiler optimization for AlphaICs compiler.
	- 4) Collaborate closely with teams developing other related components to ensure compatibility, robustness, and high-quality code generation.
	- 5) Provide design documentation to software and platform teams.
	- 6) Participate in design reviews for software systems.
	- 1) BS, MS or Ph.D. in Computer Science, Computer Engineering, or related fields, or equivalent experience.
	- 2) A minimum of 4+ years of experience in compiler back end/front end, programming language designs, Compilers/Linkers.
	- 3) Hands-on experience in design and development of graph based compilers and experience in LLVM, MLIR, GLOW etc is a plus.
	- 4) Knowledge of CPU/GPU pipeline structure & memory organization.
	- 5) Experience in Deep Learning software stacks and architectures is a big plus.
	- 6) Knowledge and experience in low level programming and CPU or GPU performance optimizations, including parallel/distributed algorithms/DSP is desirable.
	- 7) Familiarity with hardware architectures beyond CPU and GPU (e.g., TPU, VPU, FPGA, etc.)
	- 8) Excellent programming/debugging skills at the Assembly level.
	- 9) Experience with the parallel programming domain OpenMP is a plus.
	- 10) Experience in parallel computing domains like (multi-core, GPGPU, SIMD, MIMD etc) is a plus.
+ skill set:
	- Flex-Logix Inference Software team is looking for Inference Software Compiler Engineers to be a part of its excellent team responsible for the Infer-X Model Compiler. The compiler generates Verilog Code for the Flex-Logix eFPGA platform which controls the nnMAX/TPU computation blocks and memory connections. This is an exceptional opportunity to develop the technology that breathes life into AI inferencing solutions targeting systems in medical, industrial, automotive and other Enterprise edge applications.
	- In this role, you will be responsible for developing highly optimized libraries fundamental to the operation of the AI accelerator.  You'll be working with multiple software teams, deep learning scientists, and hardware designers, to implement the features needed to accelerate the next generation of machine learning algorithms.
	- If you're a collaborative engineer or scientist who has a passion for innovation, solving challenging technical problems and doing impactful work you need to join the team at Flex Logix!
	- Collaborate with the applications, softlogic, architecture, and compiler teams to determine low-latency, high-throughput schemes for executing neural networks on our ML accelerator.
	- Understand low level operator/algorithm implementation and develop APIs to invoke individual operators at the graph level.
	- Make minor modifications to operator/algorithm implementations.
	- Devise unit tests for new deep learning models.
	- Evaluate the performance of the neural network on silicon.
	- Design and develop supporting libraries that run some neural network operators on CPUs.
	- Diagnose and fix performance and integration issues across the software stack using simulators and hardware.
	- BS or higher in computer/software engineering, electrical engineering, or related field.
	- 2+ years commercial development or equivalent hands-on experience.
	- Highly proficient in C/C++.
	- Strong mastery of data structures and algorithms, especially graph data structures.
	- Experience developing and/or analyzing algorithms.
	- Experience with modern C++ (e.g. C++17). 
	- Ability to prototype complex systems with scripting languages such as Python.
	- An ability to learn rapidly in order to solve complex problems.
	- Proficient at using objective oriented programming (OOP) design principles.
	- Experience with design or verification of digital systems using verilog or RTL.
	- Experience writing applications for SIMD processors or accelerators like GPUs or FPGAs.
	- Strong understanding of computer architecture.
	- Familiarity with analyzing machine learning networks using a Deep Learning framework (e.g. Pytorch, Tensorflow, etc.).
+ skill set:
	- Data Processing Unit’s (DPU’s) are the new class of programmable processor’s igniting unprecedented innovation for modern data centers by offloading and accelerating networking, storage, compute and security services. As we work to advance and implement these technologies into our future offerings, our Compiler team is growing and seeking a top-tier Compiler Engineer Intern who wants an exciting and fun role as they help lead the charge to even greater accomplishments within a world-class organization. Come join us and to be part of the team in making a difference!
	- We are hiring a Compiler Engineer Intern for a minimum 12-week, full-time (40 hours/week) internship for the Summer 2022 term!
	- Design and implementation of significant parts of the compiler
	- Work on performance analysis and design/implementation of new optimizations
	- Partnering and collaborating with global compiler and network software teams to coordinate improvements and problem resolutions
	- You are pursuing your BS/MS/PhD in Computer Science or Computer Engineering (MS/PhD strongly preferred) or equivalent
	- Some work or research experience in performance analysis, compiler optimizations, code generation
	- Knowledge of network programming, network protocols and layers
	- Strong C/C++ and Python programming and software design skills, including debugging, performance analysis, and test design
	- Solid interpersonal skills are required along with the ability to work in a dynamic product-oriented team
	- Ability to collaborate well with others in an energizing environment
	- Proven ability to design/architect compiler frameworks
	- Experience with open source compilers and contributions to code base
	- Background with data plane programming or Linux networking stack and hardware packet processing pipelines
+ Hands-on experience design and development of graph-based compilers and experience in LLVM, MLIR, GLOW, etc. is a plus.
+ skill set:
	- Domain specific languages (DSLs) offer great potential in achieving both productivity and performance when implementing tensor based computations that appear in a variety of AI and HPC workloads. However, extending a DSL with new functionalities and porting it to new hardware remain challenging tasks, in part also due to the lack of an accepted standard interface for tensor operations.
	- As a key member of our team, you will support our research focus in this area. In this internship you will:
		* Review current DSL and implementation techniques for high performance matrix and tensor computations.
		* Contribute to the design of a novel mathematical DSL and compiler infrastructure addressing major expressiveness, performance, and portability issues of current solutions.
		* Identify a comprehensive set of AI/HPC benchmarks for validating the effectiveness of your solution.
	- You are currently enrolled in a Bachelor, Master’s degree or PhD in computer science, computer architecture, software engineering or any related fields at a reputable university; or you graduated within the last six months.
	- Strong mathematical/algorithmic problem-solving and software development skills (C/C++, Python, etc.).
	- Solid compiler design background with LLVM experience (knowledge of MLIR is a plus).
	- Solid knowledge of matrix algebra.
	- Understanding of fundamental concepts for high-performance software development, including instruction set architectures, memory hierarchy and locality, and instruction-level parallelism.
	- Proactive in learning and exploring new ideas.
	- Excellent communication and writing skills in English.
+ skill set:
	- several years industry experience designing and developing a core compiler component and strongly prefer at least one of the following:
		* 1. a research record
		* 2. expert knowledge in some compiler or compiler related domain
		* 3. contributions to an open source infrastructure (tensorflow, ...)
		* 4. experience retargeting LLVM, GCC, or some other retargetable compiler infrastructure
		* 5. linear algebra compilers
		* 6. experience with a compiler related technology (profiling, static analysis, ...)
		* 7. compiling to hardware
		* For example, you might have a master's degree with compiler and algorithms course, implemented and you have spent several years at a job developing the IR of custom compiler.
+ skill set:
	- Open-source Platforms:
		* Investigate and determine how to integrate open-source compiler frameworks into Mythic's propriety compiler technology, e.g., LLVM.
		* Investigate how to translate the output of deep learning frameworks such as Keras, Caffe, and Pytorch into programs that execute on Mythic's AI processor.
	- Optimization:
		* Develop Deep Neural Network (DNN) optimization algorithms that target a novel dataflow architecture composed of heterogeneous compute tiles.
		* Investigate analog-aware algorithms that consider reduced precision, new datatypes, linearity, and noise requirements.
		* Consider code generation schemes that tradeoff system latency, throughput, utilization, and power.
	- Programming models:
		* Innovate in a new compiler domain: mixed-signal computing.  Generate code for a heterogeneous processor with a mix of analog and digital compute accelerators.
		* Develop a rapidly retargetable compiler infrastructure that models new custom accelerators for next-generation computer architectures.
		* Investigate AI Domain Specific Languages (DSLs).
	- Product Impact:
		* Coordinate with engineering teams on the successful execution of the release of compiler products.
		* Innovate across the entire product tool chain including parser, optimizer, code generator, linker, assembler, debugger, and related tools.
		* Stay abreast of current industry and university compiler research and communicate key ideas to others at Mythic.
	- ***Specific responsibilities will depend on background and skills.  If working at the intersection of compilers, AI, analog computing, and processor architecture sounds exciting, this is the role for you.***
	- Required:
		* Bachelor's in computer science or related field with 3+ years compiler development.
		* Experience with system software and development tools.
		* Experience with C and C++ programming Languages.
		* Experience implementing, testing and upstreaming optimization and code generation solutions.
		* Previous experience collaborating with others as part of a team.
		* Strong software engineering skills.
	- Nice to have but not required:
		* Master's or PhD in Computer Science or related field with 3+ years compiler research experience.
		* Experience with python.
		* Familiarity with Agile software development processes
		* Experience with embedded systems and instruction set architecture
		* Experience with deep learning graph-compilers and related tools such as Glow, XLA, or TVM.
		* Experience with DNN frameworks such as Pytorch, Tensorflow, or Caffe.
+ skill set:
	- Senior Compiler Engineer.
	- $220,000/yr - $300,000/yr
	- Our mission is to radically reduce the cost of artificial intelligence.
	- We are the world leaders in algorithm/hardware co-design for artificial intelligence. Our roadmap begins with products 100x better than GPUs and will ultimately deliver products that are many orders of magnitude more cost effective than what is available today. We will ultimately be able to put models the size of ChatGPT into chips the size of a thumbnail.
	- As a Senior Compiler Engineer at Rain, you will participate in the design, implementation, and productization of an optimizing ML compiler for Rain’s AI accelerator products. In collaboration with other members of the compiler team, you will deliver software that efficiently maps ML models to Rain’s hardware for inference and training, blending the use of open-source tools, known compiler techniques, and novel algorithm design.
	- This is a remote role – you can work from anywhere in the United States.
	- Develop an optimizing compiler that provides exceptional out-of-the-box performance when mapping ML models to Rain hardware
	- Tackle compilation and performance problems in a boundary-less fashion, contributing to the compiler frontend and backend as needed
	- Work collaboratively with other compiler engineers to ensure high performance and resource efficiency of generated code (while being mindful of compilation time)
	- Write well-documented and tested code, participating in the development of testing infrastructure, debuggers, and performance analysis tools
	- Participate constructively in design and code reviews of your work and the work of others
	- Work closely with the architecture team to codesign Rain’s HW/SW products, including ISA extensions that enable efficient use of Rain’s accelerators for deep learning
	- Work closely with the research and ML applications teams to efficiently map emerging ML algorithms and models to Rain’s hardware
	- Stay up to date with the latest research and trends in compiler design and implementation
	- Mentor and provide technical guidance to junior engineers
	- BS in Computer Science, Computer Engineering, or related fields
	- 7+ years of experience in compilers and programming languages
	- 3+ years of experience developing AI/ML compilers targeting deep learning applications
	- Excellent programming skills in C/C++, Python, or similar high-level languages
	- Familiarity with open-source compiler technologies such as TVM, XLA, Halide, MLIR, and LLVM
	- Strong communication skills, both written and verbal
	- Exhibit a high degree of motivation and independence
	- Ability to work successfully in a distributed and remote environment
	- MS or PhD in Computer Science or Computer Engineering, with a focus on compilers and/or software development for AI accelerators
	- Experience developing software for novel hardware architectures, such as ML accelerators
	- Experience with low-level software, including reading and writing assembly code
	- Familiarity with RISC-V
	- Familiarity with deep learning models and willingness to learn novel algorithms
	- Experience with using generative code techniques (e.g. TableGen, GitHub Copilot, ChatGPT)
+ skill set:
	- ***Software Engineering Manager, AI Compiler***
	- The MTIA (Meta Training & Inference Accelerator) Software team has been developing a comprehensive AI Compiler strategy and optimizing compiler toolchains. This enables training and inference of Meta’s production DL/ML workloads on the specialized MTIA AI accelerator hardware in a highly performant and flexible way.
	- We are looking for a Software Engineering Manager who drives the compiler stack development & high performance compilers optimizations and tuning, specific to the MTIA AI accelerator hardware.
	- Grow a team of domain experts within AI Compiler.
	- Communicate, collaborate, and build relationships with clients and peer teams to facilitate cross-functional projects.
	- Operate strategically and tactically. Develop vision, strategy and help set direction for the team.
	- Remain up-to-date on ongoing software development activities in the team, help work through technical challenges, and be involved in design decisions.
	- Minimum Qualifications
		* Prior experience with Meta can be considered to supplement an applicant’s prior years of experience or types of prior experience to meet the minimum qualifications of the position.
		* Experience with compiler architecture and development, particularly ML compilers or DSLs or static/dynamic languages compilers.
		* 2+ years of experience in managing a team of compiler engineers of varied skill levels.
		* Experience with cross functional collaboration with hardware or AI framework teams.
		* Demonstrated experience recruiting, building, structuring, leading technical organizations, including performance management.
	- Preferred Qualifications
		* Experience with compiler optimizations such as loop optimizations, vectorization, parallelization, HW architecture specific optimizations.
		* Experience in compiling and code generation targeting ML accelerators or custom hardware, GPUs or CPUs.
		* Experience with different programming models for high-performance computations, e.g. ***GPU CUDA programming or OpenCL or OpenMP programming***.
		* Experience with ***MLIR, or LLVM or IREE or XLA or Triton or TVM or Halide***.
		* Knowledge of ***ML frameworks like PyTorch, TensorFlow, ONNX, MXNet***, etc.
	- $173,000/year to $241,000/year + bonus + equity + benefits
+ skill set:
	- Domain-specific compiler designers and interns for "PolyMage Labs"
	- https://www.linkedin.com/company/polymage-labs/about/
	- https://www.linkedin.com/company/polymage-labs/about/
	- Compilers, MLIR, Polyhedral framework, HPC, and AI
	- We look for talented engineers with strong computer science systems and programming skills. Prior compiler engineering experience (two years or more) and familiarity with at least one or more of the following fields are highly desirable: LLVM/MLIR, high-performance computing, and ML/AI programming frameworks. Most of the work done at PolyMage Labs is highly specialized — we thus believe that our engineers will, in most cases, learn additional advanced skills after they are on board with us.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.

















##	Compiler Design for (Dynamic) Just-In-Time Compilers, JITs



+ skill set:
	- The research work of the lab will be carried out not only by Huawei’s internal research staff but also by our academic research partners in universities across Europe. The lab will provide an “open research environment” where academics will be encouraged to visit and work on fundamental long-term research alongside Huawei staff in an environment that, like the best universities and research institutes, is open and conducive to such scientific work.
	- For this new ZRC Laboratory, we are currently looking for an outstanding Research Intern. As a key member in our motivated and multicultural team, you will support to define novel hardware/software interfaces for language runtime systems and dynamic just-in-time compilers (JITs). Just-in time compilers have become very popular due to the wide spread of high-level languages. What make JITs particularly interesting is that they have runtime information about the program execution. Unfortunately, the JITs have no possibility to communicate this information to hardware beyond machine instruction. In this line of research studies additional interfaces besides traditional ISA line to facilitate the communication dynamic program information from the JIT to the hardware.
	- Design hardware/software interface.
	- Prototype in existing JITs (e.g., V8, SpiderMonkey, or JavaScriptCore).
		* V8
		* SpiderMonkey
		* JavaScriptCore
	- Implement hardware interface in architectural simulator (e.g., gem5).
	- Evaluate implementation on standard benchmarks.
	- You are currently enrolled in a Master’s degree or PhD in computer science, computer architecture, software engineering or any related fields at a reputable university; or you graduated within the last six months
	- Strong algorithmic problem-solving and software development skills (in C++)
	- Understanding of compilers and language times
	- Ideally, experience with architectural simulators (e.g., gem5)
	- Excellent communication and writing skills in English
+ Skill set:
	- Psyco, Nukita, Shed skin.
		* Psyco
			+ Psyco is an unmaintained specializing just-in-time compiler for pre-2.7 Python originally developed by Armin Rigo and further maintained and developed by Christian Tismer. Development ceased in December, 2011.
				- run-time algorithm specialization is a methodology for creating efficient algorithms for costly computation tasks of certain kinds
			+ Psyco is a Python extension module which can greatly speed up the execution of any Python code.
		* Nukita
			+ https://pypi.org/project/Nuitka/
			+ Nuitka is the Python compiler. It is written in Python. It is a seamless replacement or extension to the Python interpreter and compiles every construct that CPython 2.6, 2.7, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 3.10, 3.11 have, when itself run with that Python version.
			+ It then executes uncompiled code and compiled code together in an extremely compatible manner.
			+ You can use all Python library modules and all extension modules freely.
		* Shed skin
			+ https://pypi.org/project/shed-skin/
			+ Shed Skin is an experimental compiler, that can translate pure, but implicitly statically typed Python (3.8+) programs into optimized C++. It can generate stand-alone programs or extension modules that can be imported and used in larger Python programs.
			+ Besides the typing restriction, programs cannot freely use the Python standard library (although about 25 common modules, such as random and re, are currently supported). Also, not all Python features, such as nested functions and variable numbers of arguments, are supported (see the documentation for details).
			+ https://github.com/shedskin
			+ An experimental (restricted-)Python-to-C++ compiler
				- An experimental (restricted-Python)-to-C++ compiler
			+ Shed Skin is an experimental compiler, that can translate pure, but implicitly statically typed Python 3 programs into optimized C++. It can generate stand-alone programs or extension modules that can be imported and used in larger Python programs.
			+ Besides the typing restriction, programs cannot freely use the Python standard library (although about 25 common modules, such as random and re, are currently supported). Also, not all Python features, such as nested functions and variable numbers of arguments, are supported (see the documentation for details).
			+ https://shedskin.github.io/
















##	Compiler Design for Heterogeneous Computing & Heterogeneous Computer Architecture



+ skill set:
	- As a part of this team you shall be building the “Blaize C/C++ heterogeneous compiler” which involves a lot of control-and-data-flow analysis, parallelism extraction and instruction vectorization, generic optimizations, backend optimizations and mapping, exposure to SIMD architecture and low-level memory management, insights into debugger; and insights into work-load analysis for performance benchmarking.
	- Compiler basics, Auto-vectorizing techniques and algorithms(LLVM preferable)
+ skill set:
	- Heterogeneous Computing Compilation Optimization Architect
	- Support compilation optimization and performance improvement of self-developed GPGPU applications;
	- Lead the design and development of compiler optimization schemes and algorithms for self-developed GPGPU;
	- ***Responsible for the formulation and implementation of the self-developed GPGPU computing core part benchmark performance and compilation optimization performance evaluation plan;***
	- Participate in the future self-developed GPGPU processor instruction set and micro-architecture design, and evolve compiler optimization capabilities to support new features.
	- Master's degree or above in computer software, electronic engineering or related majors, and more than five years of relevant work experience;
	- Proficient in C/C++, familiar with OpenCL/CUDA/Vulcan and other APIs;
	- Familiar with the architecture and compilation principles, have rich experience in the implementation of compilation optimization, including but not limited to loop optimization, vectorization, etc.;
	- ***Familiar with LLVM, familiar with heterogeneous programming system, experience in GPGPU/GPU/NPU heterogeneous compilation is preferred.***
+ skill set:
	- LLVM compiler development engineer/architect
	- Compiler development and optimized implementation for new hardware and architecture
	- Compiler implementation that supports general computing and heterogeneous programming models
	- Master degree or above in computer software or related majors, proficient in C/C++ programming, familiar with architecture and compilation principles;
	- Have good communication skills and code habits; familiar with Linux development and debugging environment, git and other version control tools;
	- Familiar with compilation frameworks such as LLVM/GCC, and experience in compiler development and optimization debugging is preferred;
	- ***Familiarity with heterogeneous programming languages such as CUDA/OpenCL/OpenGL is preferred.***
+ skill set:
	- AI Compiler and Performance Engineer
	- We are looking for Engineers and Researchers in the machine learning discipline who are passionate about generative models and creative applications of AI. In particular, we are looking for people who share our mission of open-source research; people who do not believe AI models should be controlled by a centralized gatekeeper behind a closed wall, but rather be truly open and in control by all. We want highly creative researchers who are motivated to push the boundaries of generative models research, not just in state-of-the-art performance, but in pushing the efficient frontier between performance and resource usage. You will have access to state-of-the-art high performance computing resources and you will be able to work alongside top researchers and engineers to truly make an impact in the fast growing world of generative AI.
	- As an AI Compiler/Performance Engineer you will work on design and implementation of significant parts of the Stability.ai Compiler and Runtime targeting efficient training and deployment of our models. You will work on performance analysis and design/implementation of new optimizations passes and developing methods targeting new backend targets for custom devices. You will be on the forefront of moving Machine Learning Frameworks from hand written kernels to efficiently generated codegen kernels. You will be responsible for developing the research/engineering agenda, supervising its execution and guiding a group of engineers following it. You will work closely with the key stakeholders within Stability.ai as well as external entities (HW/SW providers) in order to steer the engineering efforts towards more efficient model execution.
	- Analyze and design effective compiler optimizations
	- Implement and/or enhance code generation targeting machine learning accelerators
	- ***Develop hardware-aware optimization for emerging ML algorithms and across a spectrum of HW platforms (GPU, TPU, CPUs, custom ASICs, edge-devices)***
	- Contribute to the development of machine-learning libraries, intermediate representations
	- Employ scientific methods to evaluate performance and to debug, diagnose and drive resolution of cross-disciplinary system issues
	- Work with algorithm research teams to map graphs to hardware implementations, model data-flows, create cost-benefit analysis and estimate cluster or silicon power and performance
	- Work with research team to execute research agenda
	- Work with open-source community on model release and tooling
	- Work with engineering / business teams on model deployment and customized training
	- Develop testing plans
	- Analyze trade offs, risk mitigation strategies and communicate those to internal and external stakeholders
	- Oversee a team of engineers, provide technical direction and engineering leadership
	- 2+ years of experience with an MS or PhD (preferred) in Computer Science, Electrical Engineering or equivalent field
	- Experience in deep learning algorithms, frameworks and their Intermediate Representations e.g: ***Pytorch/GLOW, Jax, Tensorflow XLA, LLVM/MLIR, Apache TVM***
	- Good understanding of benchmarking/profiling, analyzing performance, building performance models for a given task/device
	- Familiar with concepts such as roofline modeling, flop/memory utilization, power consumption, latency
	- Good understanding of language design, compiler optimizers, backend code generators
	- Ability to communicate research/engineering ideas effectively through writing and visualization
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.







##	Compiler Design for Quantum Computing


Skill sets involved with compiler design for quantum computing:
+ skill set:
	- Software Development Manager - Compilation
	- Xanadu is looking for an experienced Software Development Manager to lead the Quantum Compilation team. The team is developing JIT and AOT hybrid compilation pipelines for PennyLane, an open-source library for quantum machine learning, quantum computing, and quantum chemistry. Although quantum software development experience is not required for the role, a strong compilation background is strongly preferred.
	- Manage a team of 7-10 developers to build new features and optimize the PennyLane compiler.
	- Work with Product Managers to define direction and roadmap for the team.
	- Participate in sprints with cross-functional teams, ensuring features are delivered efficiently and on time.
	- Work closely with our community growth team to ensure good feedback loops between external stakeholders and internal teams, and to improve library adoption.
	- Develop and improve processes to ensure developer efficiency and consistent product delivery.
	- Perform team-building activities such as hiring, mentorship, career development and performance management.
	- Advanced Degree in Computer Science, Physics, Math, Engineering, or a related field.
	- 7+ years of compiler development experience.
	- 2+ years of management experience.
	- Understanding of advanced compiler optimization techniques.
	- Experience with MLIR and LLVM core libraries.
	- Experience with benchmarking and performance-oriented optimizations.
	- Familiarity and experience with automatic differentiation methods and frameworks (e.g., Autograd, Torch, TensorFlow, JAX).
	- Comfortable working in a fast-paced environment.
	- Strong communication skills.
	- Expertise in quantum computing, as demonstrated by in-field experience, extensive coursework, thesis, or peer-reviewed publications.
	- Experience with numerical computation and high-performance computing using Python and/or C++.
	- Experience developing open-source software.
+ skill set:
	- New Compiler front-end for a Quantum Computing Software Framework
	- The research work of the lab will be carried out not only by Huawei’s internal research staff but also by our academic research partners in universities across Europe. The lab will provide an “open research environment” where academics will be encouraged to visit and work on fundamental long-term research alongside Huawei staff in an environment that, like the best universities and research institutes, is open and conducive to such scientific work.
	- As we slowly transition our quantum computing software framework to C++ for increased performance and efficiency, we are looking to completely replace the Python front-end by something written in C++.
	- In order to make sure that current code remains compatible with old versions of our quantum computing software framework, we are looking into implementing a new front-end using the libraries from the LLVM project.
	- The objective of this internship is to implement a new compiler front-end in C++ using the LLVM project (or similar). This entails:
		* Research what libraries/project currently exist to achieve this goal
		* Propose, test and implement a prototype in C++ that works on a reduced subset of the quantum computing language
		* Exchanging with other Huawei colleagues in the quantum computing group
		* Finalize the implementation based on those exchanges, write corresponding code tests and code documentation
	- You are currently enrolled in a Master‘s degree or PhD in computer science, software engineering, robotics or any related fields at a reputable university, or graduated within the last six months
	- You are an experienced programmer in C++ (knowledge of latest C++ standard is a plus) and are familiar with Python
	- You have basic knowledge of quantum physics or quantum computing
	- Experience working with LLVM project or similar
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.










#	Program Analysis



##	Companies Involved with Program Analysis



+ Grammatech: https://www.grammatech.com/careers/
+ Perforce, acquired Rogue Wave Software: https://en.wikipedia.org/wiki/Rogue_Wave_Software






##	Skill Sets for Program Analysis


Skill sets for program analysis:
+ Experience with profiling tools like PerfView (CPU, Memory, Garbage collection)
+ DBT experience, for dynamic binary translation in hardware emulators
+ skill set:
	- Are you ready to be challenged, right from the interview process?  Are you looking to work with a highly intelligent but humble team? Do you want to work on cutting-edge cyber security problems and have the background to do it? Well then, this role may be for you.  
	- GrammaTech is looking for a number of software engineers at varying levels of experience to perform advanced software development. Build new components and extend existing tooling to meet project needs. Implement both exploratory research prototypes and high-quality products. Possess significant experience contributing to large projects, developing software, with focus on C++ and Python.
	- GrammaTech employees must be fully vaccinated against COVID-19.
	- Location: Our R&D center is in Ithaca, NY, but we will consider remote employees with a strong match of skills and experience.
	- Responsibilities of a research-oriented software engineer is expected to:
		* Study and implement approaches drawn from academic literature or in-house design
		* Evaluate the resulting prototype implementation to test its value in addressing the research goals
		* Report results to the PI and respond by adapting the prototype to better address research goals
		* Contribute to presentations and written reports to keep research sponsors up to date on project progress
		* Prepare prototypes for demonstrations and evaluations by research sponsors
		* Transition prototypes into deployable products
	- Required Qualifications.
		* BS in Computer Science or equivalent with a minimum of 3+ years demonstrated experience working in software development in C++ and Python. Knowledge of other languages is a plus.
		* Experience in development activities on large code bases with software designed, built, and tested from scratch; familiarity with common software architectures and design patterns
		* Experience with modern software -development life cycle practices including effectively using revision control systems (git), continuous integration and deployment (CI/CD), container and orchestration technology (docker, Kubernetes, etc.)
		* Knowledge of fundamentals of software security and bug/vulnerability finding 
	- Preferred Qualifications.
		* MS or PhD in computer science or closely related field
		* Knowledge of machine code, such as x86, ARM, or MIPS
		* Background in static analysis for binaries and/or source code
		* Experience with fuzzing or symbolic execution
		* Experience with vulnerability research/demonstration or penetration testing (e.g., Metasploit)
		* Compiler design, compiler front-end integration, C/C++ parsers
		* Dynamic analysis, program instrumentation, and profiling
		* System-administration experience, especially related to security
		* Malware-analysis techniques
		* Experience in using Machine Learning Frameworks like scikit-learn, TensorFlow, Keras, etc.
	- Innovation is at the heart of GrammaTech. We are constantly pushing the boundaries of software research and development – from software assurance and software integrity to cyber-security threat mitigation and autonomic computing. 
	- GrammaTech was founded over 30 years ago, with a firmly-grounded purpose to help organizations develop tomorrow’s software.  Given the ever-increasing dependence of software in today’s connected world, our staff is able to focus on the most challenging software issues through a constant stream of highly innovative research and commercial development programs – focused on the evolving cyber-security landscape, software hardening and intelligent systems.  Within these projects, GrammaTech employees have the opportunity to work with industry, academic, and government experts, significantly advancing their skills in engineering, research, marketing, or sales.
+ skill set:
	- GrammaTech’s Common Lisp Software internship program offers students the opportunity to gain real experience in a friendly, open, and supportive environment. We choose projects based on real needs, and interns work closely with engineers to make sure that projects are completed successfully.  Current COMMON LISP IS REQURED FOR THIS ROLE.
	- GrammaTech will conduct a series of programming tests and screening interviews in Common Lisp as part of our process. (Please do not apply if you do not have experience with Lisp, unfortunately, we cannot train for this role.)  
	- GrammaTech employees must be fully vaccinated against COVID-19.
	- Location:  Remote (must be in USA Only) with a possibility of being located in our Ithaca, NY office for the summer.  (COVID Restrictions will be considered as we get closer to the summer.)
	- Responsibilities
		* Research projects at GrammaTech can take on a wide variety of topics and challenges. Projects focus on software assurance, software protection, reverse engineering, and software transformation. We do both static and dynamic analysis on both source and object code, in order to tackle serious problems with practical solutions.
		* Potential projects include:
			+ Apply compiler optimizations to binaries. Develop some classic compiler optimizations on top of our Binary IR (https://grammatech.github.io/gtirb/)
			+ Develop source-code program transformations for refactoring, optimization, and diversification on top of our Software Evolution Library (https://grammatech.github.io/sel)
			+ Design and run large-scale experiments evaluating automated software modification and automated software engineering tools
	- Required Qualifications
		* Currently enrolled in a BS, MS, or PhD program
		* Excellent programming skills with Common LISP (required)
	- Preferred Qualifications
		* Enrollment in a Computer Science PhD program
+ skill set:
	- The primary responsibility is leading efforts to design and implement research prototypes, based on ideas drawn from academic literature and original research. Team size varies from project to project. On small projects, a scientist may implement a significant portion of the prototype, while on larger projects they will lead a team of engineers. Our scientists are expected to:
		* Generate ideas for innovative solutions (original or drawn from the literature) that address needs identified by research sponsors
		* Translate research ideas into working prototypes
		* Manage researchers and engineers implementing research prototypes: identify risks, plan work, monitor progress, review designs and code used in prototypes, as well as adapt plans as we learn more about the sponsor’s needs and the benefits/deficiencies of the prototype
		* Write proposals for research contracts
		* Build and maintain relationships with research sponsors
		* Document research results in written reports. Present results in-person at meetings with research sponsors
		* Work with research sponsors to ensure success of any demonstrations or evaluations of the research prototype
		* Promote research results in blogs, external presentations, and publications
		* Collaborate with product and marketing teams to identify a strategy to turn the research prototype into a marketable product
		* Ph.D. in Computer Science, Computer Engineering, or Software Engineering and a minimum of three years of industry or post-doctoral academic experience
		* Experience leading research projects and managing/supervising a research team, as Principal Investigator (PI) or equivalent
		* Research experience in compilers, static analysis, language-based security, or another field aligned with GrammaTech's research activities. Maybe your area of expertise is reverse engineering, or vulnerability detection, or code transformation. Expertise in machine learning or statistical techniques with applications to software development or security is highly relevant, as well. On the other hand, maybe you will be adding a new area of expertise to our team
		* Lots of languages: C, C++, Java, machine code, etc. It's not just about our own code, it's about taking other people's software apart and showing them what makes it tick
+ skill set:
	- end-to-end workload analysis from low-level assembly instruction code to high-level distributed algorithms
	- experience with performance analysis on:
		* CPUs
		* GPUs
		* TPU
		* parallel architectures or distributed systems
		* dataflow or spatial architctures
		* many-core multi-thread environments.
+ skill set:
	- You will develop new features or extend existing features related to code analysis and transformation in research or commercialized projects
	- You will work in Clang and LLVM versions tailored for our use as well as in Silexica’s compiler infrastructure.
	- You will analyze the effect of your code on the performance and resource usage of your target, which will mostly be FPGAs.
	- You will be responsible for continuous development, debugging and testing of the code you produce
	- Our mission is to provide software development tools reducing time-to-market of innovative software IP and intelligent products. Enabled by deep software analysis, heterogeneous hardware awareness and quick design space exploration, the SLX programming tools significantly accelerate the journey from software to application-specific hardware systems, empowering our customers to win markets.
	- You have excellent C++ programming skills
	- You have solid scripting skills on Windows and Linux (e.g. Python, Bash)
	- You have knowledge of computer architecture
	- You have knowledge about compiler construction and possess knowledge about the LLVM compiler infrastructure
	- Ideally, you have some experience with HLS and/or hardware design.
	- You are fluent in English
	- You have excellent problem-solving capabilities and good communication skills
	- You are a team player, who has a hands-on mentality and a desire to learn
+ skill set:
	- GitHub is seeking a research engineer in the area of code intelligence in the office of the CTO (OCTO), specifically for the experimentation with new and interesting user experiences. OCTO aims to be a meeting place within GitHub for experimentation with new ideas, and for setting the agenda for GitHub’s product several years in advance. OCTO has a small number of permanent research staff, and this position is part of the core OCTO team. The engineer will initially focus on user interfaces for code synthesis.
	- Here is some more detail on that initial project - it’s just an example of similar projects in future. To train machine learning models for program synthesis, we can use existing code bases and their unit tests: find a function that has good test coverage and documentation, mask out the body, synthesize an alternative implementation, and test it. Applied to all Python and JavaScript code on GitHub, this would be a huge training set. Full unit tests can however be slow to execute, and for effectively training machine learning models we need the tests to be as fast as possible. One way might be to distill the unit tests into ‘micro tests’ by recording just enough state and I/O behavior so we can replay previous behaviors.
	- Responsibilities:
		* Design and build a framework for creating fast functional correctness tests of Python and JavaScript code.
		* Collaborate with machine learning experts on applying this framework for reinforcement learning on program synthesis tasks.
		* Participate in all activities of the OCTO at GitHub: organizing webinar series, evaluating project proposals, and disseminating research results.
	- Minimum Qualifications:
		* Ability to do innovative research on one of the following topics: dynamic analysis, instrumentation, or runtime verification.
		* 5+ years experience building developer tools in production
		* Inclination to prototype quickly and make fast decisions on experiment failure.
		* A creative mindset and good practical skills are more important than formal experience.
	- Preferred Qualifications:
		* PhD in computer science or related field, or other evidence of the ability to do independent research.
		* Knowledge of Python or JavaScript and its ecosystem, or the ability to acquire such knowledge quickly.
		* Ability to communicate complex ideas clearly, both in spoken and written form, for expert as well as novice audiences.
		* Interest in modern AI technologies and program synthesis in particular.
+ skill set:
	- Python Developer Tools Engineer
	- Python is a vital part of Jane Street’s research and trading work, acting as the go-to language for data analysis, visualization, and machine learning. Our Python developer tools team is responsible for the tools that support our work in Python, including:
		* CI for running tests and static analysis
		* Automation around the deployment of Python environments and applications
		* Libraries for building hybrid Python/OCaml systems
	- We’re looking for engineers with experience building Python tooling at large scale who want to leverage those skills in a new environment. 
	- The job is wide-ranging, involving both technical and product design challenges — from finding ways to speed up our static analysis and test harnesses to working with users to understand their workflows and requirements and designing solutions that fit their needs.
	- We’re also looking for someone who can contribute to guiding our relatively young Python ecosystem, helping us form and communicate best practices, and make good choices about the tools and libraries we use.
	- Lots of our automation and Python tooling is written in OCaml, but we’re happy to teach you that, and we don’t expect any previous experience with OCaml or any other functional programming language.
	- Base salary is $250,000 - $300,000. Base salary is only one part of Jane Street total compensation, which includes an annual discretionary bonus.
+ skill set:
	- Language and Runtime Engineer
	- LOCATION: New York
	- DEPARTMENT: Technology
	- TEAM: Software Engineering
	- We’re looking to hire a Software Engineer with experience working on language compilers and runtimes. Our team maintains a framework used at Jane Street for a wide variety of purposes, including financial modeling, risk calculation, and custom alerting. Our system evaluates, in real time and in parallel, a large, irregular, and dynamic graph of user-specified computations. We are particularly focused on understanding, quantifying, and improving its performance and scalability. The technical problems we face relate to implementation of programming languages and their runtimes, efficient distribution and scheduling of computation graphs, and effective measurement and communication of resource usage.
	- ***You have a background in compilers, scheduling, dynamic graph systems, parallel runtimes***, or another related field
	- You have strong experience in ***performance analysis and optimization***
	- No previous experience with OCaml or functional programming languages is required
	- Base salary is $250,000 - $300,000. Base salary is only one part of Jane Street total compensation, which includes an annual discretionary bonus.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.










#	Program Synthesis


##	Skill Sets for Program Synthesis


Skill sets for program synthesis:
+ skill set:
	- GitHub is seeking a research engineer in the area of code intelligence in the office of the CTO (OCTO). OCTO aims to be a meeting place within GitHub for experimentation with new ideas, and for setting the agenda for GitHub’s product several years in advance. OCTO has a small number of permanent research staff, and this position is part of the core OCTO team. The engineer will initially focus on exploring synthesis of code from documentation.
	- Here is some more detail on that initial project - it is just an example of more such projects in future. Recent advances in machine learning models for source code indicate that it is possible to synthesize code just from the signature and docstring of a function. Often better synthesis results are possible by also specifying an example to test synthesized candidates. We’d like to explore how to integrate this functionality into CodeSpaces, so that users can browse alternative solutions synthesized by the model. We’d also like to consider other user experiences for the same functionality, for example in an automated assistant for novice developers.
	- Responsibilities:
		* Design and build user interfaces as outlined above, and experiment with new ideas to embody the new ***code synthesis technology***.
		* Collaborate with early adopters and machine learning experts on improving both the underlying technology and the way users interact with the synthesizer.
		* Participate in all activities of the OCTO at GitHub: organizing webinar series, evaluating project proposals, and disseminating research results.
	- Minimum Qualifications:
		* Ability to quickly create innovative ***user interfaces and new user experiences***.
		* 5+ years experience in ***creating frontends in production***
		* Inclination to prototype quickly and make fast decisions on experiment failure.
		* A creative mindset and good practical skills are more important than formal experience.
	- Preferred Qualifications:
		* Experience with ***user interface design, especially for developer tools***.
		* Proven track record of working with early adopters to refine initial designs.
		* Ability to communicate complex ideas clearly, both in spoken and written form, for expert as well as novice audiences.
		* Interest in modern AI technologies and their use in developer tools.










