#	EDA, AI, (Applied) Machine Learning, MLOps, ModelOps, Data Science, Data Engineering, DataOps, MIS, & Corporate Research Labs



##	Important Information about Innovation Management


Important [technology roadmaps](https://en.wikipedia.org/wiki/Technology_roadmap) to pay attention to, so that I can create my own:
+ Semiconductor pathfinding for research and development (R&D) activities
	- References:
		* [Semiconductor Pathfinding and Development](https://www.thermofisher.com/us/en/home/semiconductors/pathfinding.html)
			+ Directed from Thermo Fisher Scientific -> Applications & Techniques -> Industrial & Applied Sciences -> ***Semiconductor Analysis*** -> Applications -> Semiconductor Pathfinding and Development
				- https://www.thermofisher.com/us/en/home/semiconductors.html#applications
			+ Use cases:
				- [NEXS Software, CAD navigation and design debug solutions](https://www.thermofisher.com/us/en/home/electron-microscopy/products/software-em-3d-vis/nexs-software.html) 
				- Circuit edit and nanoprobing
					* [use of high-resolution focused ion beams (FiBs) and advanced chemistry to perform "nanosurgery" on semiconductor devices](https://www.thermofisher.com/us/en/home/semiconductors/circuit-edit.html)
				- defect localization and analysis
				- physical and chemical characterization
+ additional resources for:
	- environmental scanning
		* horizon scanning, horizon scan
			+ trend analysis
			+ issue tree, logic tree
			+ scenario planning, scenario thinking, scenario analysis, scenario prediction, scenario method
			+ morphological analysis, or general morphological analysis, in the context of problem solving
		* analyze the [***market environment*** and ***business environment***](https://en.wikipedia.org/wiki/Market_environment)
	- determine scientific lacuna, or knowledge gaps in science and ***engineering***
	- technological readiness assessment, TRA
		* determine the [technological readiness level, TRL](https://en.wikipedia.org/wiki/Technology_readiness_level)
			+ basic technology research, TRLs 1-2
			+ research to prove feasibility, TRLs 2-4
			+ technology development, TRLs 3-5
			+ technology demonstration, TRLs 5-7
			+ system/subsystem development, TRLs 6-9
				- system test, launch, and operations, TRLs 8-9
	- [technological innovation system](https://en.wikipedia.org/wiki/Technological_innovation_system)
		* Entrepreneurial activities
		* Knowledge development
		* Knowledge diffusion / knowledge exchange through networks
		* Guidance of the search
		* Market formation
		* Resource mobilization
		* Support from advocacy coalitions
	- ethics in EDA and machine learning research
		* [differential technological development](https://en.wikipedia.org/wiki/Differential_technological_development)
		* [proactionary principle](https://en.wikipedia.org/wiki/Proactionary_principle)
		* [precautionary principle, or precautionary approach](https://en.wikipedia.org/wiki/Precautionary_principle)
		* [postcautionary principle](https://en.wikipedia.org/wiki/Postcautionary_principle)
	- list of research labs, such as corporate research labs, research universities, and non-profit research institutes, that perform [***exploratory engineering***](https://en.wikipedia.org/wiki/Exploratory_engineering)
	- [technology forecasting](https://en.wikipedia.org/wiki/Technology_forecasting)
		* [technology scouting](https://en.wikipedia.org/wiki/Technology_scouting)
			+ part of [corporate foresight](https://en.wikipedia.org/wiki/Corporate_foresight)
			+ improves [***competitive intelligence***, CI](https://en.wikipedia.org/wiki/Competitive_intelligence) to improve competitive strategy
		* part of [Technology management](https://en.wikipedia.org/wiki/Technology_management)
			+ part of [engineering management](https://en.wikipedia.org/wiki/Engineering_management)
			+ technology strategy
			+ technology forecasting
				- technology scouting
			+ technology roadmap
				- map technologies to business and market needs
			+ technology project portfolio
			+ [innovation management](https://en.wikipedia.org/wiki/Innovation_management)
				- Knowledge management tools
				- Market intelligence techniques
				- Cooperative and networking tools
				- Human resources management techniques
				- Interface management approaches
				- Creativity development techniques
				- Process improvement techniques
				- Innovation project management techniques
				- Design and product development management tools
				- Business creation tools
	- technology assessment
	- ***cross-impact analysis***
	- [frugal innovation/engineering](https://en.wikipedia.org/wiki/Frugal_innovation)
		* jugaad, or jugaar, Hindi for a stop-gap solution
		* inclusive innovation
		* catalytic innovation
		* reverse innovation
		* bottom of the pyramid (BOP) innovation
			+ bottom of the income pyramid
			+ bottom of the wealth pyramid





##	EDA, Electronic Design Automation


Skills for EDA software development, and other high-end software development:
+ Production quality coding standards and patterns.
	- You are curious and pragmatic: you want to explore extensions to our product but are motivated by delivering production code for business use cases
	- industry best practices
	- You will write clean, maintainable and production code with appropriate documentation and tests.
	- Experience in contributing to production code bases. Ability to rapidly prototype algorithmic ideas in notebook environments and translate them into production code.
	- Experience with building production code.
	- Be easy to go from test to production code.
	- Capable of designing high quality frameworks/toolings to reduce redundancy and ineffectiveness across components/services
+ Build system experience, like:
	- Apache Buildr, historic open-source build system, Rake-based, gives the full power of scripting in Ruby with integral support for most abilities wanted in a build system
	- ***Bazel***
		* For automating the building and testing of software.
		* Derived from the Google internal tool, Blaze.
		* for multiple programming languages
		* Build systems most similar to Bazel are:
			+ Pants
			+ Buck
			+ Please
	- Blaze, predecessor to Bazel
	- boost.build, for C++ projects, cross-platform, based on Perforce Jam
	- Buildout, a Python-based build system for creating, assembling and deploying applications from multiple parts
	- ***CMake***
	- Gradle, for JVM software, and C and C++
	- ***Jenkins***, an extensible continuous-integration engine, forked from Hudson
	- language-specific build systems:
		* Ant and Maven for Java
			+ ***Apache Ant***, popular for Java platform development and uses an XML file format
			+ ***Apache Maven***, a Java platform tool for dependency management and automated software build
		* ***Leiningen*** for Clojure
		* ***sbt*** for Scala
	- ***Maven*** (for JVM software, and other languages, such as C\# and Ruby)
	- ***Meson*** is a software tool for automating the building (compiling) of software. 
	- ***SCons***, Python-based, with integrated functionality similar to autoconf/automake
	- Stack, a tool to ***build Haskell projects***, manage their dependencies (compilers and libraries), and for testing and benchmarking
	- tinyrick, a ***Rust build tool***
	- ***Travis CI***, a hosted continuous-integration service
	- ***Waf***, a Python-based tool for configuring, compiling and installing applications. It is a replacement for other tools such as Autotools, Scons, CMake or Ant
	- Turbo, or Turborepo, for building JavaScript or TypeScript Web applications
+ project management tools:
	- Trello
	- Working with Jira and Confluence a plus.
		* Jira, for issue tracking.
		* Confluence, wiki-based collaboration platform
+ CI/CD with:
	- ***Docker***, software platform for container orchestration by exploiting OS-level virtualization
	- ***Kubernetes***, for container orchestration
	- AWS
	- continuous integration (CI) systems, deployment tools/platforms, such as:
		* ***Jenkins***
		* TeamCity
		* GitHub Actions
		* GitLab
		* Circle CI
		* Terraform
		* Saltstack/Ansible
		* Semaphore
		* Slurm
	- ***CI/CD pipelines***
	- microservice architecture
	- infrastructure as code, IaC
		* Pulumi - Infrastructure as Code in Any Programming Language
			+ https://www.pulumi.com
			+ Pulumi's open source infrastructure as code SDK enables you to create, deploy, and manage infrastructure on any cloud, using your favorite languages.
			+ Automate your infrastructure at any scale
			+ Your Code, Your Cloud, Your Success
			+ Build, manage, and scale your infrastructure, secrets, and configurations in one place.
	- Produce high quality and well-documented code in an automated CI/CD environment
+ configuration management:
	- software configuration management includes:
		* revision/version control
		* build automation
		* system configuration
		* process management
		* environment management
		* defect tracking
	- Experience with configuration management systems (Ansible and/or Puppet, Saltstack)
		* ***Ansible***, software tool suite to enable infrastructure as code, Python-based
		* CFEngine
		* Chef, Ruby-based
		* LCFG
		* ***Nagios Core***, or ***Nagios***, for monitoring systems, networks, and infrastructure
		* NixOS Declarative configuration model
		* OpenMake Software Release Engineer
		* Otter
		* ***Puppet***, for software configuration to specify system configuration, Ruby-based
		* Rex, Perl-based
		* Salt, Python-based
		* ***Saltstack***, for event-driven IT automation, remote task execution, and configuration management
+ tools for agile methods, such as XP and Scrum:
	- Git
	- JIRA
	- Confluence
+ package managers:
	- Mamba
		* reimplementation of *conda* package manager in *C++*.
+ documentation
	- *LaTeX*
	- Markdown
		* MDX markup language, authorable format for writing JSX in Markdown documents
			+ JSX, or JavaScript Extension, or JavaScript XML
				- similar in appearance to HTML
	- GitBook
		* Modern documentation format and toolchain using Git and Markdown
		* Good experiences with technologies used by GitBook: Go, Google Cloud Platform, Algolia, Firebase
+ Experience with unit testing, and performance benchmarking and tuning.
+ skill set:
	- Full ownership including: Designing, Implementing, Testing and Metric Analysis.
	- Production quality coding standards and patterns.
+ Hibernate ORM is an object-relational mapping tool for the Java programming language
	- object-relational mapping allows software developers to convert data between type systems using object-oriented programming languages, OOPL.
+ ***Where possible, exploit [incremental computing](https://en.wikipedia.org/wiki/Incremental_computing), to speed up the performance of EDA tools that I develop.***
	- use "checkpoint"s to save temporary results of computing
		* This allows results from computation performed thus far to be reused.
		* If computation crashes and has to be restarted from the most recent or second last checkpoint, this checkpoint provides intermittent results that the software can use to resume computing.
+ skill set:
	- Strive for high code standards (continuously improving testability and code quality).
	- Disciplined, methodical, minimalist approach to design and construct layered software components that can be embedded within larger frameworks or applications.
	- ***experiment driven development***
+ Proven capability to create maintainable, adaptable software that is non-brittle and capable of change
+ Take pride in the quality of the code you write. Your code is readable, testable, and understandable six months later. You adhere to the Zen of Python.
+ ship high quality software at scale
+ experience with these software testing methodologies:
	- unit tests
	- integration tests
	- regression tests
	- smoke tests
	- load tests
	- chaos tests
	- Practice disciplined software engineering (e.g. automated testing, code reviews, and writing beautiful, readable code).
+ Software libraries
	- C++ libraries:
		* Boost C++
		* http://doc.hc2.ch/c_cpp/en/cpp/links/libs.html
		* Eigen, C++ library for numerical computing
	- ***Python libraries***:
		* NetworkX, for graph computing
		* NumPy, for numerical linear algebra and tensor algebra
		* SciPy
			+ for scientific computing, or computational science, and computational engineering
			+ for the following:
				- optimization
				- linear algebra
				- integration
				- ODE solvers
				- interpolation
				- FFT
				- signal processing
				- image processing
		* mpmath, for arbitrary-precision floating-point arithmetic
		* Biopython, for computational biology and bioinformatics
		* CuPy, for GPU-accelerated parallel programming
		* Distributed Evolutionary Algorithms in Python, DEAP, framework for evolutionary computing to enable rapid prototyping and experimentation to test ideas
		* MuJoCo
			+ advanced simulator for multi-body dynamics with contact
			+ https://mujoco.org/
			+ https://github.com/deepmind/mujoco
	- for symbolic computing
		* SageMath, computer algebra system, CAS
			+ SageManifolds
			+ has bindings for C++ and Python
	- numerical computing:
		* GNU Octave
		* MATLAB, and Simulink
		* FreeMat
		* Intel oneAPI Math Kernel Library, Intel oneMKL
			+ formerly Intel Math Kernel Library, Intel MKL
		* Eigen, C++ library for numerical computing
+ parallel and distributed computing
	- parallel computing
		* parallel data structures
		* parallel algorithms
		* ***Knowledge of parallelism in shared (Intel TBB, OpenMP) and distributed (Intel MPI, Apache Spark, Dask) memory***
		* Knowledge of parallelism in shared memory:
			+ Intel TBB
			+ OpenMP
			+ Dask, for Python
			+ SCOOP, Scalable Concurrent Operations in Python, for Python
		* Knowledge of OpenCL/SYCL languages
			+ OpenCL, Open Computing Language
				- low-level API, and parallel computing/programming framework and run-time for heterogeneous platforms of:
					* general-purpose processors
					* graphics processors
					* digital signal processors
					* FPGAs
					* domain-specific architectures, including hardware accelerators
				- compile and execute kernel programs (kernels) in parallel in computer systems with heterogeneous system architecture (HSA)
				- enables GPGPU computing
				- speeds up numerical computing, and computation for applied machine learning and data science
				- has two APIs, application programming interfaces:
					* platform layer API
					* runtime API
			+ SYCL:
				- higher-level programming model for improving programming productivity on hardware accelerators
				- single-source embedded domain-specific language (eDSL) based on pure C++17
				- royalty-free, cross-platform abstraction layer for developing software that are executed on heterogeneous platforms
				- single-source C++ programming model for heterogeneous computing
		* GPU programming, GPGPU, using:
			+ NVIDIA CUDA
				- NVIDIA cuDNN
			+ OpenCL
	- distributed computing
		* distributed data structures
		* distributed algorithms
		* Knowledge of parallelism in distributed memory:
			+ Intel MPI
			+ Apache Spark
			+ ***Dask***
+ workflow management:
	- goals/tasks:
		* for data engineering pipelines
	- use ***workflow management systems, WfMS, WFMS*** for specific applications, such as:
		* data science
		* machine learning
		* Avoid the use of workflow management systems, WfMS, WFMS, for business process modeling and other activities not related to my projects.
	- Adobe Workfront, with built-in workflow management systems, WfMS, WFMS
	- ***Apache Airflow***
		* Cloud Composer, for Google Cloud Platform, GCP
	- Apache Flink
	- Apache Taverna ???
	- ***Azkaban***
	- Collective Knowledge, CK
	- Cuneiform programming language
		* based on Erlang, functional programming language
	- ***Dagster***
		* https://dagster.io/
		* Cloud-native orchestration of data pipelines
		* Ship data pipelines with extraordinary velocity
		* The cloud-native orchestrator for the whole development lifecycle, with integrated lineage and observability, a declarative programming model, and best-in-class testability.
		* Manage your data assets with code
		* An orchestration platform for the development, production, and observation of data assets.
	- ***Flyte***
		* https://flyte.org/
		* Build & deploy data & ML pipelines, hassle-free
		* The infinitely scalable and flexible workflow orchestration platform that seamlessly unifies data, ML and analytics stacks.
		* Create extremely flexible data and ML workflows
		* End-to-end data lineage
		* Collaborate with reusable components
		* Integrate at the platform level
		* Allocate resources dynamically
	- Intake: https://intake.readthedocs.io
	- Jenkins
	- Jira, with built-in workflow management systems, WfMS, WFMS
	- [***Luigi***](https://github.com/spotify/luigi), for workflow management and managing ML pipelines (machine learning pipelines)
	- Oozie
	- research workflow
		* The Collective Knowledge (CK) project is an open-source framework and repository to enable collaborative, reproducible and sustainable research and development of complex computational systems. CK is a small, portable, customizable and decentralized infrastructure helping researchers and practitioners
	- Salesforce.com Process Workflow
	+ ***data pipeline and workflow management tools: Azkaban, Luigi, Airflow***
+ program analysis tools:
	- PerfView
		* CPU, memory, garbage collection
+ ***Are language agnostic. We aren't overly concerned with tech stack - if you are interested in learning new things, we're interested in teaching you.***
	- knowledge of object-oriented and functional programming paradigms
	- ***Refactoring existing C++ libraries for modularity and extensibility.***
+ Identify scaling bottlenecks and propose solutions.
+ Familiarity with Agile methodologies, such as Scrum or Kanban, as well as software development practices such as Continuous Integration, Test-Driven Development and DevOps.
+
+ 














###	EDA: Electronic Design Automation Job Opportunities







####	Integrated Device Manufacturers (IDMs)


IDMs that may have their own EDA software develoment group:
+ [From Wikipedia, list of integrated device manufacturers (IDMs)](https://en.wikipedia.org/wiki/Integrated_device_manufacturer)
+ [From Wikipedia, list of semiconductor IP core vendors](https://en.wikipedia.org/wiki/List_of_semiconductor_IP_core_vendors)
+ [From Wikipedia, list of the top semiconductor companies in terms of the most revenue](https://en.wikipedia.org/wiki/Semiconductor_industry)









####	EDA Companies


List(s) of EDA companies:
+ Electronic System Design Alliance (ESD Alliance) members: https://www.semi.org/en/communities/esda/membership-directory
	- SEMI: http://www.semi.org/en/Membership/MemberDirectory
+ Silicon Integration Initiative, Inc.: https://si2.org/member-directory/
+ Accellera Systems Initiative: https://www.accellera.org/about/members
+ Global Semiconductor Alliance: https://www.gsaglobal.org/membership/
	- Their membership directory cannot be accessed, unless you are an employee of their member companies.
	- This is a list of fabless IC design companies.
+ Semiconductor Research Corporation: https://www.src.org/src/member/roster/
+ Semiconductor Industry Association: https://www.semiconductors.org/about/members/
+ MIPI Allliance: https://www.mipi.org/membership/all-member-directory
+ SNIA: https://www.snia.org/member_com/member_directory
+ TechJobsCafe: https://techjobscafe.com/employer_top.php
+ defunct resources:
	- list from SEMATECH.




Additional companies that hire EDA software developers:
+ [Achronix Semiconductor Corporation](https://www.achronix.com/company/careers)
+ BLAH






##	Companies in the Semiconductor Industry


List of semiconductor companies:
+ [Global Semiconductor Alliance](https://www.gsaglobal.org/)
+ FPGA companies
	- AMD/Xilinx
	- Intel Altera
	- [Lattice Semiconductor](https://www.latticesemi.com/)
	- [QuickLogic Corporation](https://www.quicklogic.com/company/careers/)
		* Not friendly to non- U.S. citizens.
	- [Menta S.A.S, Sophia Antipolis](https://www.menta-efpga.com/careers)
	- [Achronix Semiconductor Corporation](https://www.achronix.com/company/careers)
	- [Flex Logix Technologies, Inc.](https://flex-logix.com/)
	- [Microchip Technology](https://www.microchip.com/)
+ machine learning hardware accelerators (including coarse-grained reconfigurable architctures, CGRA), machine learning acceleration via domain-specific computing, heterogeneous computing systems for machine learning, VLSI deep learning, and embedded deep learning
	- [SimpleMachines, Inc.](https://www.simplemachines.ai/company)
	- [Codeplay Software Ltd.](https://www.codeplay.com/company/careers/#career-list)
	- [Thirdwayv](https://www.thirdwayv.com/careers/)
	- [Lightmatter](https://lightmatter.co/people/join-us/)
	- [Habana Labs](https://habana.ai/about-us/)
	- [Achronix Semiconductor Corporation](https://www.achronix.com/company/careers)
	- [AlphaICs Corp](https://alphaics.ai/company/careers/)
	- [Panmnesia](https://panmnesia.com/)
	- [Anari AI](https://anari.ai/)
	- [NAME](URL)
	- [NAME](URL)
	- [NAME](URL)
	- [NAME](URL)
	- [NAME](URL)
	- [NAME](URL)
	- [NAME](URL)
	- [Qualcomm Technologies, Inc.](https://www.qualcomm.com/research/artificial-intelligence/ai-research): https://www.qualcomm.com/company/careers
	- [Cornami, Inc.](https://cornami.com/)
+ companies selling RISC-V -based products
	- [SiFive, Inc.](https://www.sifive.com/careers)
+ edge computing
	- [EdgeImpulse Inc.](https://edgeimpulse.com/careers)
+ Open Compute Project (OCP): https://www.opencompute.org/membership/membership-directory














###	Machine Learning for EDA

+ skill set:
	- Required Machine Learning Experts for EDA Products, we need people who are passionate about technology, constantly seeking to learn and improve the skill set with good communication and interpersonal skills.
	- Should be proficient in Python and applying ML Algorithms.
	- Good knowledge of machine learning algorithms like Neural network, CNN, Logistic regression, KNN, Random forest, decision tree, clustering etc.
	- knowledge of C with good programming skills & logical interpretation.
	- Decent depth in understanding ML algorithm concepts like supervised/unsupervised, regression/classification, time series algorithms
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.







###	System-Technology Co-Optimization, STCO


####	Notes about STCO & DTCO

By definition, System-Technology Co-Optimization, STCO, includes Design-Technology Co-Optimization (DTCO).


System-Technology Co-Optimization, STCO
+ Design-Technology Co-Optimization, DTCO
+ AutoML for STCO
+ Benchmarking
	- for ***non- von Neumann computing paradigms***
		* hybrid non- von Neumann computing paradigms:
			+ quantum computing + optical computing
				- linear optical quantum computing, linear optics quantum computation, LOQC
					* Boson sampling
					* KLM scheme, KLM protocol
		* ***optical computing, photonic computing***
			+ approaches:
				- computing by xeroxing on transparencies
				- Ising machines
				- masking optical beams
				- optical Fourier co-processors
				- time delays optical computing
				- wavelength-based computing
			+ nanophotonics, or nano-optics
				- metamaterials
				- near-field optics
				- microphotonics
				- biophotonics
					* biofluorescence
					* biolasing
					* bioluminescence
					* biophosphorescence
					* fluorescence resonance energy transfer, Forster resonance energy transfer, FRET
			+ optical rectenna, or optical rectifying antenna
				- ["An optical rectenna is a rectenna (rectifying antenna) that works with visible or infrared light. A rectenna is a circuit containing an antenna and a diode, which turns electromagnetic waves into direct current electricity. While rectennas have long been used for radio waves or microwaves, an optical rectenna would operate the same way but with infrared or visible light, turning it into electricity."](https://en.wikipedia.org/wiki/Optical_rectenna)
			+ optical transistors
				- ["An optical transistor, also known as an optical switch or a light valve, is a device that switches or amplifies optical signals. Light occurring on an optical transistor's input changes the intensity of light emitted from the transistor's output while output power is supplied by an additional optical source. Since the input signal intensity may be weaker than that of the source, an optical transistor amplifies the optical signal. The device is the optical analog of the electronic transistor that forms the basis of modern electronic devices. Optical transistors provide a means to control light using only light and has applications in optical computing and fiber-optic communication networks. Such technology has the potential to exceed the speed of electronics, while conserving more power."](https://en.wikipedia.org/wiki/Optical_transistor)
			+ photonic ICs, PIC, integrated optical circuit
			+ photonic logic
				- require resonators
			+ silicon photonics
			+ related emerging technologies:
				- phased-array optics, optical phased array, OPA
				- screenless displays:
					* categories:
						+ visual image
						+ retinal direct
						+ synaptic interface
					* examples:
						+ virtual retinal display, VRD, retinal scan display, RSD, retinal projector, RP
							- use adaptive optics, AO
						+ bionic contact lens
						+ fog display, fog screen, vapor screen, vapor display
					* applications:
						+ augmented reality
						+ virtual reality
				- volumetric display devices, 3-D displays
					* are autostereoscopic				
		* in-memory computing
		* hyperdimensional computing, HDC
		* quantum computing
			+ based on [***atomtronic circuits***](https://en.wikipedia.org/wiki/Atomtronics)
		* hypercomputation, super-Turing computation
	- for heterogeneous system architectures, HSA
	- for von Neumann computing
	- other applications:
		* memory subsystems
			+ racetrack memory, domain-wall memory, DWM
		* digital scent technology, olfactory technology
			+ sense, transmit, and receive scent-enabled digital media
			+ sensor implementations:
				- olfactometers
					* dynamic dilution olfactometers
					* field olfactometers
					* flow olfactometers
				- electronic noses
				- fluctuation-enhanced sensing, FES
					* based on higher-order statistics, HOS
			+ scentography devices
			+ machine olfaction
		* electronic skin
			+ includes:
				- tactile sensors
			+ conductive electronic skin
			+ flexible and stretchy electronic skin
			+ recyclable electronic skin
		* electronic tongues
			+ artificial taste
		* flexible electronics, flex circuits
			+ flexible display, or rollable display
			+ flexible printed circuits, FPC
		* printed electronics
			+ printed technologies
				- aerosol jet printing
				- evaporation printing
				- inkjet printing
				- screen printing
		+ nanoradios
			+ biomedical applications, for drug delivery





Languages for creating dialects in the context of domain-specific languages and domain-specific compilers:
+ MicroPython










####	Skill sets for STCO and DTCO:



Skill sets for STCO and DTCO:
+ OpenAI Triton
	- A domain-specific language (DSL) and associated domain-specific compiler for domain-specific computing and STCO.
+ skill set:
	- Development of compilers and peripheral libraries for MN-Core
	- We will develop the compiler and peripheral libraries of MN-Core. Specifically, we are assuming the following themes
		* Utilization of domain-specialized languages such as JAX and Halide
		* Research and development of learning models with low accuracy
		* Implementation of kernels for MN-Core such as FFT
	- Development of peripheral tools such as profilers
	- Communication Language: Japanese
	- Coding ability using Python and C++
	- Experience with low-level optimization
	- Knowledge of compilers for deep learning
+ skill set:
	- Development of framework and library for deploying deep learning models in real world
	- Develop compiler/runtime (PFVM) that optimizes computational graphs of deep learning models to perform inference performantly (in terms of execution time and memory usage), targetting on various backends such as CUDA or edge devices. 
	- Develop an open-source library that uses GPU (CuPy).
	- Communication Language: English/Japanese
	- Programming in C++
	- Programming in Python
	- Basic knowledge of computer science
	- Experience on deep learning model development
	- Experience of running deep learning models on edge devices or smartphones
	- Development experience of multi-pass compilers
+ AI/ML for architectural exploration and bottleneck identification
+ AIML - Sr. Software Engineer, Large Language Models (MIND)
	- The Machine Intelligence, Neural Design (MIND) team employs HW/SW co-design to achieve best-in-class performance and energy efficiency for numerous use cases that deploy neural networks. We seek a Sr. Software Engineer to help define and implement features that accelerate and compress large language models (LLMs) in our next-gen inference engine. Our team is comprised of Efficient ML experts with skillsets in HW, SW, and ML. Our charter is to push the frontiers of perf and power for DNNs with minimal memory footprint.
	- As a SWE, you will be responsible for writing high-quality, well-tested code. Our ideal team member is courageous when it comes to trying new things, is adept at reasoning about systems performance, and is willing to iterate on ideas. We value team members with strong communication skills with experience working cross-functionally with HW, SW, and ML teams.
	- Proficient in C++, working knowledge of Python
	- Implement features that compress and accelerate LLMs in our on-device inference engine
	- Convert models from a high-level framework to a target device for correctness and performance issues
	- Write unit and system integration tests to ensure functional correctness and to reduce performance regressions
	- Diagnose performance bottlenecks and minimize memory footprint of large language models
	- Work with HW Arch teams to co-design solutions that further improve perf,  power, and memory footprint of neural workloads
	- Work with a variety of partners from all parts of the stack — from Apps to Compilation, HW Arch, and Silicon Validation
	- Strong communicator with ability to analyze complex and ambiguous problems
	- Familiarity with ML model compression techniques (e.g., quantization, pruning/sparsity) and their mapping to a target backend
	- Disciplined programming skillset with a strong attention to detail
	- Experience with backend compilation, HW/SW co-design, and/or performance optimization
	- The base pay range for this role is between $189,800 and $346,300, and your base pay will depend on your skills, qualifications, experience, and location.
+ Deep understanding of computer systems and the interactions between HW and SW
+ Familiarity with at least one deep learning framework (e.g., PyTorch, Keras, TensorFlow)
+ skill set:
	- Post-Moore Microelectronics/VLSI Co-Design Postdoctoral Scholar
	- Berkeley Lab's Applied math and Computational Sciences Division has an opening for a Postdoctoral Scholar to evaluate and develop devices to hardware/circuit co-design flow for architectural specializations for high performance computing and edge computing applications.
	- In the absence of Moore's Law Scaling, the Department of Energy (DOE) must investigate alternative paths to continuing computing performance improvements for scientific applications through architectural specialization. The successful candidate will contribute to the development and evaluation of novel heterogeneous device-based circuit design for extreme heterogeneous SoC (System on Chip) designs, and evaluate their merit for emerging computational workloads for the purpose of maximizing performance and energy efficiency. This work will have a broad impact on high performance and other larger-scale computing for critical applications for society and science. 
	- The successful applicant will need to have expertise with computer architecture and processor design and from the ground up, and have skills in Spice analog/digital circuit design, Verilog and use of CAD/EDA tools. It is desirable if the applicant has familiarity with higher-level hardware design languages such as CHISEL, PyMTL or other HDLs that target an FIRRTL intermediate representation. It is also beneficial if the candidate has experience with full tape-out experience of ASICs. Using those skills, the successful candidate will design post-Moore devices-based compute, memory, or data transfer blocks for key application kernels to demonstrate the merit of this approach. This position will also make key intellectual contributions and consequently publish papers to the emerging field of extreme heterogeneous computing and domain-specific specializations.
	- Design circuits, hardware accelerators and processor architectures using post-Moore devices to accelerate key HPC applications and application kernels.
	- Develop compact models and methodologies to use these circuits for performance and energy characterizations which can be used in architectural simulation framework for tightly integrating these accelerators into heterogeneous systems and SoCs that may contain multiple different kinds of accelerator devices.
	- Identify opportunities and challenges for devices to architectural design space exploration for several post-Moore devices to address those bottlenecks and develop circuit design models to determine the performance potential for those solutions.
	- Develop metrics and benchmark tests in order to compare conventional CMOS based processors/accelerators and enhanced post-Moore devices based computational accelerators for key HPC applications and algorithms. 
	- PhD or equivalent in a Computing Science or Computer Engineering related scientific discipline.
	- Past experience in either Machine learning accelerators or SRAM array design or basic blocks of processor at transistor level.
	- Courses or experience in CAD for VLSI algorithms and C++ Programming.
	- Proficient in Spice Circuit Simulations, Verilog and hardware design in CMOS, FeFET, NCFET etc.
	- Familiarity with hardware EDA/CAD tools and evaluation/modeling tools in order to extend existing infrastructure to rapidly evaluate CMOS designs.
	- Demonstrated creativity, initiative and ability to design, develop and implement complex solutions in consultation with designated technical expert(s) and/or supervisor.
	- Experience and track-record writing technical papers and reports.
	- Experience with the use of script languages and system utilities such as configure, Perl, UNIX shell scripts, and “make.”
	- Proven record of working effectively in a team, seeing projects through to completion, meeting deadlines, interacting with users, and thorough documentation of contributions.
	- Willingness to learn and develop skills in new topics.
	- Previous experience and publications in Processing-In-Memory and Logic-in-Memory architectures is highly desirable.
	- Experience with coding in C++/python for CAD tool development for ASIC design.
	- Experience with higher-level hardware design languages (HDLs) such as CHISEL, PyMTL, or others.
	- Experience with FPGA design flows would also be beneficial.
	- Demonstrated ability to lead technical efforts with teams of people will also be beneficial.
	- The monthly salary range for this position is $6431-$8642 and is expected to start at $7843 or above. 
	- This is a full-time 3 year, postdoctoral appointment with the possibility of renewal based upon satisfactory job performance, continuing availability of funds and ongoing operational needs. You must have less than 2 years of paid postdoctoral experience. Salary for Postdoctoral positions depends on years of experience post-degree.
+ skill set:
	- ML Hardware Accelerator Modeling (Boston or Bay Area)
	- Lightmatter builds chips for artificial intelligence computing. Our architecture leverages unique properties of light to enable fast and efficient inference and training engines. If you're a collaborative engineer or scientist who has a passion for innovation, solving challenging technical problems and doing impactful work like building the world's first optical computers, consider joining the team at Lightmatter!
	- We are looking for talented software engineers to help us build the next generation of AI processors and systems. In this role, you will be responsible for developing tools that enable the design of high performance ML accelerators and an optimized software stack. You'll be working with multiple software teams, as well as digital, analog, and photonic designers, to ensure that both our software and hardware can achieve a generational leap in ML performance.
	- Design, development, and maintenance of functional and performance models of upcoming hardware
	- Participate in the co-design process by working closely with hardware teams to iterate on early performance models, adding fidelity as designs progress
	- Collaborate with machine learning teams to construct and evaluate the performance of machine learning workloads
	- Build cycle approximate performance and bit-accurate functional models that further the co-design process and allow the software teams to build and optimize our next generation software stack
	- Collaborate with Design Verification teams to validate hardware against the simulators
	- Contribute to a system-level simulator that integrates the accelerator simulator into a larger system simulator
	- Support the development and optimization of our software stack by diagnosing and fixing issues across the simulator and software stack
	- BS or higher in computer/software engineering, electrical engineering, or related field.
	- 5+ years of industry experience in mapping algorithms to hardware accelerators, hardware modeling, computer architecture, or related fields
	- Proficient with C++ and Python
	- Strong understanding of computer architecture
	- Familiarity with machine learning workloads
	- Experience in mapping software algorithms to hardware accelerators
	- Experience with modeling and analysis of machine learning accelerator architectures
	- Proficient developing in a Linux-based environment
	- Experience working with or modeling distributed hardware and workloads
+ skill set:
	- Software Engineer – AI/Machine Learning software product development
	- To further sustain and accelerate its growth, Cadence Belgium is looking for a Software Engineer – AI/Machine learning software product development to join the international team based in Brussels. 
	- Cadence Belgium is part of Cadence, a pivotal leader in electronic design and computational expertise, using its Intelligent System Design strategy to turn design concepts into reality. Cadence customers are the world's most creative and innovative companies, delivering extraordinary electronic products from chips to boards to systems for the most dynamic market applications. 
	- Cadence Belgium develops simulation software for fluid flows, multiphysics and optimization, widely used by engineers and designers in a large range of fluid engineering applications, from aerospace, power generation and energy to race cars and ships. Cadence Belgium is extending its work force and is looking for qualified new colleagues. 
	- By joining Cadence Belgium you will build the next generation AI/ML based software product and collaborate with experts in the world of simulation and Artificial Intelligence/Machine Learning. Our teams are fully committed to develop and implement creative solutions. We believe that quality, rigor, and innovation are key to success. With a team of highly skilled and motivated co-workers, we offer a stimulating, young and multicultural environment with career growth opportunities and internal mobility. 
	- Join our technical team and contribute to the development of our CFD simulations. 
	- As a Software Engineer AI/Machine learning software product development, your main responsibilities will be: 
	- Building the next generation AI/ML software product 
	- Contributing to front-end developments in C++, QML, and Python 
	- Developing and maintaining the tool chain and Graphical User Interface of our novel Machine-Learning product 
	- Working with the Machine-Learning core team to identify and translate their requests into state-of-the-art interactive software 
	- Working with the Product Engineering teams identify and translate end user requirements into state-of-the-art interactive software 
	- Understand and follow best software practices through design and code review, testing and validation. 
	- Keeping abreast of the latest trends and technology in the field of human-computer interaction design pushing forward innovation and creativity in this domain 
	- A bachelor's or master's degree in computer science, Mathematics, Physics or Engineering, with experience in the development of 3D visualization applications 
	- In-depth knowledge of C++, Python and JavaScript (or QML) languages 
	- Knowledge of Linux and Windows (basics) 
	- Passionate about UI/UX development and keeping up to date with the latest trends 
	- Write clean, structured, and maintainable code 
	- Fluent English language is a prerequisite for the role. 
	- Experience using the Qt framework is an asset
	- A prior experience with development of GUI or tool chain for industrial CAE/CAD/CFD packages is an asset 
	- French or Dutch language skill is a plus 
	- You should be highly motivated and dynamic, have good communication and analytical skills, be a stress-resistant problem solver, be a team player able to meet the highest quality standards, and ideally have a passion for programming. 
+ skill set:
	- Staff Machine Learning Engineer
	- Synopsys Central Engineering (SCE) team is looking for Software Engineering Experts with an excellent focus on solving complex problems, and capable of leading & building an excellent team.
	- As a part of the Synopsys SCE team, you will be working with a world-class team of software engineers and architects on the mission to build our state of art tools, and you would be expected to conceptualize and develop new tools & applications with cutting-edge technology. You will work together from requirement elicitation, design, implementation, and testing phases to production deployment in the cloud environment and on-prem.
	- Leading and driving the team technically,
	- To design and implement  AI/ML based solutions
	- To incorporate AI/ML technology into existing tools
	- To re-design and develop existing applications for key R&D productivity
	- BSc / MSc in the domain of Computer/Electronics Engineering or Computer Science
	- 7+ years of relevant industry experience in developing and productizing software solutions
	- Exemplary leadership and team-working skills
	- Solid background in Data Structures & Algorithms
	- Knowledge of Machine Learning & Data Science
	- Excellent programming skills, preferably in Python
	- Knowledge of cloud technologies
	- Exposure to distributed computing will be an added advantage
	- Quick learning and adaption to new technologies
+ skill set:
	- Research Engineer / Senior Research Engineer (Advanced packaging design flow, PDK and DTCO)
	- Develop Process Design Kit for IME's advanced packaging line with state-of-the-art Interposer, high density fanout , chip on wafer technologies 
	- Develop parameterised cells, surrogate models, statistical models for various building block cells within PDK.
	- Develop essential scripts, automation, parsers needed for realising CAD flows with commercial EDA tools.
	- Develop QA strategies with defining test structures, CD, Design-of-Experiments to generate essential measurement data for PDK recalibration. 
	- Realise hybrid CAD flows using multi physics EDA tools and data exchange. 
	- Sole owner of advanced package PDK baseline and its derivatives. 
	- Support SiP design and technology co-optimization flow with nessasary automation and modelling
	- Bachelor or Master's Degree in Electronics / Computer Engineering or applied computer engineering streams
	- Min 2 years of Experience in development, deployment of CMOS based PDK, with various front, back end EDA tools and design flows.
	- Experience in developing machine learning/AI algorithms for clustering, regression, timeseries, multi modal data, optimization is a plus.
	- Able to work both independently and as a team when required
+ skill set:
	- Conduct fundamental research on new directions in computing systems
	- Develop academic research partnerships and cooperation with leading universities and professors in the area
	- Work with internal research colleagues and academic research partners to achieve new breakthroughs in research and innovation
	- Produce and present research papers at internationally leading conferences and events
	- Produce white papers on current developments and future directions in computing systems
	- Where appropriate, contribute insight and research expertise to committees and other organizations that are looking to establish new industry standards and platforms
	- Contribute to the research and academic community through service such as conference program committee membership, membership of journal editorial boards etc.
	- PhD in an area related to computing systems architecture, or equivalent research experience in industry
	- Record of publishing research papers in the area of computing systems architecture
	- Candidates should have research experience in computing systems, and be familiar with at least one of the following areas:
	- Design Space Exploration (DSE) Frameworks, Hierarchical DSE, Microarchitecture DSE, Architectural Models, Templates and Generators, Generator Methodology, Design Space Sampling, Constraint-Based DSE, Reusable Designs, System-Technology Exploration, Hardware-Software Co-Design and Co-Optimization
	- Strong interpersonal skills and ability to work productively in a research environment
+ DL HW/SW Codesign Engineer
	- We’re forming a new team to work with our partners on hardware optimization and co-design, and are looking for a founding engineer.
	- This team will be responsible for working with partners to optimize their hardware for our workloads, identifying promising new deep learning accelerators, and bringing those hardware platforms to production.
	- While primarily a software team, this team will be multidisciplinary and include experts in hardware design as well as data center facility design.
	- If you’re excited to work at the intersection of cutting edge deep learning and emerging hardware designs this role is for you!
	- Influence the roadmap of hardware partners to optimize them for OpenAI’s workloads.
	- Evaluate potential partners’ accelerators and platforms.
	- Build simulations and performance models to progressively improve decision making fidelity.
	- As the scope of the role and team grows, understand and influence roadmaps for hardware partners for our datacenter networks, racks, and buildings.
	- Have at least 4 years of industry experience, including experience harnessing compute at scale or building semiconductors.
	- Have a strong bias toward action, and won’t take no for an answer.
	- Experience with hardware/software co-design
	- Are familiar with the fundamentals of deep learning computing and chip microarchitecture.
	- Have a strong intrinsic desire to learn and fill in missing skills; and an equally strong talent for sharing that information clearly and concisely with others.
	- Are comfortable with ambiguity and rapidly changing conditions.
	- Annual Salary Range: $300,000—$370,000 USD
	- OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity. 
	- At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.
+ HW/SW Co-design Engineer
	- Our mission at OpenAI is to discover and enact the path to safe, beneficial AGI. To do this, we believe that many technical breakthroughs are needed in generative modeling, reinforcement learning, large scale optimization, active learning, among other topics.
	- The Research Platform team builds robust and scalable software to support our research efforts. It also offers core development services for mission critical goals and applications. In the Kernels team, we write Kernels for GPUs, we build a compiler to support important AI accelerators and we help with HW/SW co-design of future AI accelerators.
	- As a Research Engineer, you will help build AI systems that can perform previously impossible tasks or achieve outstanding levels of performance. This requires good engineering (for example designing, implementing, and optimizing state-of-the-art AI models), writing bug-free machine learning code (surprisingly difficult!), and building the science behind the algorithms employed. In all the projects this role pursues, the ultimate goal is to push the field forward.
	- As a Research Engineer for HW/SW co-design, you will co-design future hardware from different vendors for programmability and performance. You will work with our kernel, compiler and ML developers to understand their needs related to ML techniques, algorithms, numerical approximations, programming expressivity and compiler optimizations. You will evangelize these constraints with various vendors to develop future hardware architectures amenable for efficient training and inference. If you are excited about maximizing HBM bandwidth, optimizing for low arithmetic intensity, expressive SIMD ISA, low-precision formats, optimizing for memory hierarchies, simulating workloads at various resolutions of the hardware and evangelizing these ideas with hardware engineers, this is the perfect opportunity!
	- This role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.
	- Work with hardware vendors to help co-design their future hardware for programmability and performance
	- Assist hardware vendors in developing optimal kernels and add support for it in our compiler
	- Develop performance estimates for critical kernels for different hardware configurations 
	- Work with ML engineers, kernel engineers and compiler developers to understand their vision and needs from high performance accelerators
	- Manage communication and coordination with internal and external engagements
	- Have a deep understanding of GPU and/or other AI accelerators
	- Have good experience with CUDA or a related accelerator programming language
	- Have experience driving ML accuracy with low precision formats
	- Able to actively collaborate with ML engineers, kernel writers and compiler developers
	- Have 3+ years of relevant industry experience
	- Get a great deal of satisfaction with aligning future hardware with a well established HPC infrastructure
	- PhD in Computer Science and Engineering with a specialization in Computer Architecture, Parallel Computing. Compilers or other Systems
	- Are a strong coder with excellent skills in C/C++ and Python
	- Experience working with hardware developers
	- Experience building compilers
	- Good understanding of LLMs and challenges related to their training and inference 
	- OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity. 
	- At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.
+ HW/SW Co-design Engineer
	- Our mission at OpenAI is to discover and enact the path to safe, beneficial AGI. To do this, we believe that many technical breakthroughs are needed in generative modeling, reinforcement learning, large scale optimization, active learning, among other topics
	- The Research Platform team builds robust and scalable software to support our research efforts. It also offers core development services for mission critical goals and applications. In the Kernels team, we write Kernels for GPUs, we build a compiler to support important AI accelerators and we help with HW/SW co-design of future AI accelerators.
	- As a Research Engineer, you will help build AI systems that can perform previously impossible tasks or achieve outstanding levels of performance. This requires good engineering (for example designing, implementing, and optimizing state-of-the-art AI models), writing bug-free machine learning code (surprisingly difficult!), and building the science behind the algorithms employed. In all the projects this role pursues, the ultimate goal is to push the field forward.
	- As a Research Engineer for HW/SW co-design, you will co-design future hardware from different vendors for programmability and performance. You will work with our kernel, compiler and ML developers to understand their needs related to ML techniques, algorithms, numerical approximations, programming expressivity and compiler optimizations. You will evangelize these constraints with various vendors to develop future hardware architectures amenable for efficient training and inference. If you are excited about maximizing HBM bandwidth, optimizing for low arithmetic intensity, expressive SIMD ISA, low-precision formats, optimizing for memory hierarchies, simulating workloads at various resolutions of the hardware and evangelizing these ideas with hardware engineers, this is the perfect opportunity!
	- This role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.
	- Work with hardware vendors to help co-design their future hardware for programmability and performance
	- Assist hardware vendors in developing optimal kernels and add support for it in our compiler
	- Develop performance estimates for critical kernels for different hardware configurations
	- Work with ML engineers, kernel engineers and compiler developers to understand their vision and needs from high performance accelerators
	- Manage communication and coordination with internal and external engagements
	- Have a deep understanding of GPU and/or other AI accelerators
	- Have good experience with CUDA or a related accelerator programming language
	- Have experience driving ML accuracy with low precision formats
	- Able to actively collaborate with ML engineers, kernel writers and compiler developers
	- Have 3+ years of relevant industry experience
	- Get a great deal of satisfaction with aligning future hardware with a well established HPC infrastructure
	- PhD in Computer Science and Engineering with a specialization in Computer Architecture, Parallel Computing. Compilers or other Systems
	- Are a strong coder with excellent skills in C/C++ and Python
	- Experience working with hardware developers
	- Experience building compilers
	- Good understanding of LLMs and challenges related to their training and inference
	- Have a deep understanding of GPU and/or other AI accelerators
	- Have good experience with CUDA or a related accelerator programming language
	- Have experience driving ML accuracy with low precision formats
	- Able to actively collaborate with ML engineers, kernel writers and compiler developers
	- Have 3+ years of relevant industry experience
	- Get a great deal of satisfaction with aligning future hardware with a well established HPC infrastructure
	- PhD in Computer Science and Engineering with a specialization in Computer Architecture, Parallel Computing
	- Compilers or other Systems
	- Are a strong coder with excellent skills in C/C++ and Python
	- Experience working with hardware developers
	- Experience building compilers
	- Good understanding of LLMs and challenges related to their training and inference
	- As a Research Engineer, you will help build AI systems that can perform previously impossible tasks or achieve outstanding levels of performance
	- In all the projects this role pursues, the ultimate goal is to push the field forward
	- As a Research Engineer for HW/SW co-design, you will co-design future hardware from different vendors for programmability and performance
	- You will work with our kernel, compiler and ML developers to understand their needs related to ML techniques, algorithms, numerical approximations, programming expressivity and compiler optimizations
	- You will evangelize these constraints with various vendors to develop future hardware architectures amenable for efficient training and inference
	- Work with hardware vendors to help co-design their future hardware for programmability and performance
	- Assist hardware vendors in developing optimal kernels and add support for it in our compiler
	- Develop performance estimates for critical kernels for different hardware configurations
	- Work with ML engineers, kernel engineers and compiler developers to understand their vision and needs from high performance accelerators
	- Manage communication and coordination with internal and external engagements
+ skill set for AI HW/SW Co-design Intern:
	- Rain Neuromorphics Inc.: https://rain.ai/careers
	- $45/hr - $85/hr
	- Our mission is to radically reduce the cost of artificial intelligence.
	- We are the world leaders in algorithm/hardware co-design for artificial intelligence. Our roadmap begins with products 100x better than GPUs and will ultimately deliver products that are many orders of magnitude more cost effective than what is available today. We will ultimately be able to put models the size of ChatGPT into chips the size of a thumbnail.
	- The AI HW/SW Co-Design Intern will contribute to developing a framework for an in-memory compute AI accelerator to perform hardware/software co-design and optimization. This framework will guide the architecture and algorithm design to optimize Rain’s hardware. This is a collaborative role – as an intern, you will have the opportunity to work across many teams at Rain. 
	- This is a remote internship opportunity – you can work anywhere in the US. The duration of this internship will be 6 months.
	- Lead and contribute to the HW/SW co-optimization of Rain’s AI accelerators, including but not limited to:
		* Create functional models for Rain’s chips. 
		* Develop an HW/SW codesign framework. 
		* Optimize hardware architecture for Rain’s benchmarking suite. 
		* Develop new models for Rain’s next-generation hardware. 
		* Collaborate with the algorithms team to develop hardware-aware algorithms.
	- Document and present results.
	- Currently pursuing a PhD in Computer Engineering, electrical engineering or a related field. 
	- Strong Knowledge of computer architecture and AI accelerator architecture. 
	- Experience with hardware models for accelerators and RISC-V processors. 
	- Experience with DNN models mapping to hardware. 
	- Experience with hardware-software co-design and design space exploration. 
	- Experience in developing and debugging in C/C++, Python and/or PyTorch. 
	- Excellent communication skills.
	- Publications in top conferences on computer architecture and design automation conferences or related topics. 
+ Research Scientist Intern, AI & System Co-Design (PhD)
	- Bellevue, WA | Menlo Park, CA
	- AI System SW/HW Co-design team’s mission is to explore, develop and help productize high-performance software and hardware technologies for AI at datacenter scale. We achieve this via concurrent design and optimization of many aspects of the system such as models, algorithms, numerics, performance and AI hardware including compute, networking and storage. In essence, we drive the AI HW roadmap at Meta and ensure our existing and future AI workloads and software are well optimized and suited for the hardware infrastructure. 
	- We’re a diverse group of problem solvers driven by a culture of experimentation and innovation. As a Research Scientist Intern, you will be a key member of a team of innovators, working on leading AI workloads, distributed systems, and developing architecture to enable the future of AI SW/HW co-design. 
	- Our team at Meta AI offers twelve (12) to sixteen (16) weeks long internships and we have various start dates throughout the year. To learn more about our research, visit https://ai.facebook.com.
	- Lead and support research that accelerates ML applications over one or more of software, system and accelerator architectures, optimizing training and/or inference of next gen AI workloads here at Meta.
	- Work towards long-term ambitious research goals, while identifying intermediate milestones.
	- Lead and collaborate on research projects with other researchers and engineers across diverse disciplines.
	- Communicate research agenda, progress and results.
	- Influence progress of relevant research communities by producing publications.
	- Minimum Qualifications
		* Prior experience with Meta can be considered to supplement an applicant’s prior years of experience or types of prior experience to meet the minimum qualifications of the position.
		* Currently has, or is in the process of obtaining, PhD degree in the field of Computer Science or a related STEM field.
		* Strong knowledge of Computer Architecture and Distributed systems with interest in one or more of High Performance Computing, Numerics, Performance and AI hardware including compute, networking and storage.
		* Must obtain work authorization in the country of employment at the time of hire, and maintain ongoing work authorization during employment.
	- Preferred Qualifications
		* Track record of achieving results as demonstrated by grants, fellowships, patents, as well as first-authored publications at leading workshops or conferences such as MICRO, ISCA, HPCA, ASPLOS, ATC, SOSP, OSDI, MLSys or similar.
		* 2+ years experience in one or more of High Performance Computing, Numerics, Performance and AI hardware including compute, networking and storage.
		* Experience or knowledge in developing and debugging in C/C++, Python and/or PyTorch.
		* Experience driving original scholarship in collaboration with a team.
		* Experience leading a team in solving analytical problems using quantitative approaches.
		* Interpersonal experience: cross-group and cross-culture collaboration.
		* Experience in theoretical and empirical research and for answering questions with research.
		* Experience communicating research for public audiences of peers.
		* Intent to return to degree-program after the completion of the internship/co-op.
	- $7,650/month to $11,333/month + benefits



































































###	Mixed-Signal/RF Multi-Processor System-on-Chip Generators, Mixed-Signal/RF MPSoC Generators, or Mixed-Signal/RF MPSoC Synthesis




Sets of skills for mixed-signal/RF multi-processor system-on-chip generators, mixed-signal/RF MPSoC generators, or mixed-signal/RF MPSoC synthesis:
+ skill set:
	- Architect, design and implement new features, performance improvements, and ISA extensions in RISC-V CPU core generators.
	- Microarchitecture development and specification. Ensure that knowledge is shared via great documentation and participation in a culture of collaborative design.
	- ***Perform initial sandbox verification***, and work with design verification team to create and execute thorough verification test plans.
	- Work with physical implementation team to implement and optimize physical design to meet frequency, area, power goals.
	- Collaborate with performance modelling team for performance exploration and optimization to meet performance goals.
	- 5+ yrs of recent industry experience in high-performance, energy-efficient CPU designs.
	- Expertise in CPU processor designs in one or more of the following areas: instruction fetch and decode; branch prediction; register renaming and instruction scheduling; integer; floating-point, and vector units; load-store unit; cache and memory subsystems.
	- Knowledge of RISC-V architecture is a plus.
	- Proficiency with hardware (RTL) design in Verilog, System Verilog, or VHDL.
	- Experience with Scala and/or Chisel is a plus.
	- Attention to detail and a focus on high-quality design.
	- Ability to work well with others and a belief that engineering is a team sport.
	- Knowledge of at least one object-oriented and/or functional programming language.
	- Background of successful CPU development from architecture through tapeout.
	- BS/MS degree in EE, CE, CS or a related technical discipline, or equivalent experience.
+ skill set:
	- SiFive is looking for hardware engineers who are passionate about designing industry-leading CPU and interconnect IP to help drive the tidal wave of adoption of RISC-V as the architecture of choice for SoC designs across a broad variety of vertical applications. We build and maintain multiple CPU family lines, TileLink interconnects and other uncore/infrastructure IP, and are seeking motivated individuals to improve/evolve our existing IP, as well as develop new IP. Join us and surf the RISC-V wave with SiFive!
	- Architect, design and implement an enhanced TileLink interconnect, protocol bridges, and other infrastructure/uncore logic as RTL generators, including both open-source and proprietary designs.
	- Improve current designs and work on future designs to provide higher performance, more efficient multi-core and multi-cluster system coherence.
	- Integrate new design content into SiFive's Chisel/FIRRTL framework and contribute to improvements to that framework to enable automatic configuration/generation of design collateral.
	- Microarchitecture development and specification. Ensure that knowledge is shared via great documentation and participation in a culture of collaborative design.
	- ***Perform initial sandbox verification***, and work with design verification team to create and execute thorough verification test plans.
	- Work with physical implementation team to implement and optimize physical design to meet frequency, area, power goals.
	- 5+ yrs of recent industry experience with coherent fabric, protocols for scalable multi-core and multi-cluster SoC designs.
	- Experience with NoC or other interconnect fabrics.
	- Experience with industry standard bus protocols (e.g. AMBA). Knowledge of TileLink is a plus.
	- Knowledge of cache coherence protocols, architectures and concepts.
	- Ability to architect solutions to connect bus fabrics of disparate protocols.
	- Strong software engineering skills/background, including:
		* object-oriented, aspect-oriented, and particularly functional programming;
		* compiler infrastructures and data modeling for intermediate representations, particularly for domain-specific languages.
	- Proficiency with hardware (RTL) design in Verilog, System Verilog, or VHDL.
	- Experience with Chisel, Bluespec, or other HDL for expressing configurable hardware via software is a plus.
	- Attention to detail and a focus on high-quality design.
	- Ability to work well with others and a belief that engineering is a team sport.
	- BS/MS degree in EE, CE, CS or a related technical discipline, or equivalent experience.
+ skill set:
	- Architect, design and implement enhanced and new arithmetic functional units for RISC-V CPU Core generators in Chisel
	- Create more efficient shared arithmetic units; combining capabilities for single/double/half-precision floating point, integer, and/or fixed-point operations
	- Design in extensive configurability as a first-class consideration, including reuse of ALU designs for vector and scalar operations
	- “Plumb” new design content into the SiFive's Chisel/FIRRTL framework to enable automatic configuration/generation of documentation, verification testbenches and tests, and packaged software.
	- ***Perform initial sandbox verification***, and work with design verification team to create and execute thorough verification test plans
	- Ensure that knowledge is shared via great documentation and a participation in a culture of collaborative design
	- 4+ years of recent industry experience in CPU design
	- Knowledge of vector architecture and concepts.
	- Prior experience designing high-performance vector and/or SIMD processors/units.
	- Proficiency with hardware (RTL) design in Verilog, System Verilog, or VHDL.
	- Attention to detail and a focus on high-quality design.
	- Ability to work well with others and a belief that engineering is a team sport.
	- Knowledge of at least one object-oriented and/or functional programming language.
	- BS/MS in EE, CE, CS or a related technical discipline, or equivalent experience.
+ skill set:
	- The SiFive Platform Engineering team is building an ambitious new infrastructure to support accelerated ASIC and FPGA design flows, IP delivery and SoC development - driving the next generation of SiFive's "Silicon at the speed of Software" mission. This infrastructure leverages state of the art compiler algorithms (built on open source MLIR and LLVM technologies), novel build system integration, and new Verilog RTL generation techniques.
	- Our team combines many different perspectives and experiences, and we love working with people who combine a passion for learning and growth with product focus, practical experience, and a desire to build world-changing technologies.
	- We encourage applicants from traditionally underrepresented groups in computer science to apply! 
	- Evolve, design and build new compiler intermediate representations for hardware design and tool flows.
	- Implement specific compiler optimization and lowering algorithms for chip design flows.
	- Implement state of the art mechanisms for hierarchical caching that crosscut compiler and build systems.
	- Participate in design discussions, planning, code review, documentation, open source processes, and other standard software practices.
	- Collaborate with hardware architects to develop the approach and design flows.
	- Manage your individual project priorities, deadlines and deliverables.
	- We are hiring for several positions with different levels of seniority, but require a minimum of 2 years of compiler engineering experience.
	- Strong oral and written communication skills, excellent team collaboration.
	- Experience with C++ programming and git-based development workflows.
	- Experience with Verilog and other chip design technologies is NOT required.
+ skill set:
	- As a Software Engineer in the Platform Engineering Technologies team, you will be responsible for building and maintaining cutting-edge tools for System-on-Chip (SoC) design. You will apply your programming language expertise to architect domain-specific languages for hardware design. You will participate in the open source Chisel and CIRCT communities while ensuring that SiFive engineers have the best tools to build and verify advanced RISC-V CPUs, IPs, and SoCs. You will be part of a tight-knit, supportive, challenge-loving team who likes to learn and apply new technologies to change the paradigm of designing custom silicon.
	- Developing and enhancing embedded Domain Specific Languages (DSLs) in Scala and/or Swift, along with associated build tooling, for use by hardware industry professionals.
	- Soliciting and responding to user requests and feedback to continuously improve the tooling.
	- Writing excellent documentation, tutorials and help train experienced hardware designers and verification engineers in new techniques.
	- Collaborating with colleagues to integrate with MLIR Compiler stack written in C++.
	- Participating in open source communities such as Chisel and LLVM CIRCT.
	- 3+ years of relevant industry experience or a PhD with relevant academic experience.
	- Familiarity with object oriented and functional programming languages. Experience in Scala and/or Swift highly desirable.
	- Ability to communicate and teach others both inside and outside the company.
	- Exposure to hardware design and verification techniques is a plus but not required.
+ We at SiFive are proud to take a "software first" approach to develop tools and frameworks that achieve cutting edge performance without compromising quality for the SiFive Intelligence processor family. The SiFive Intelligence processors deliver AI acceleration for the edge and beyond. SiFive intelligence builds on RISC-V Vectors (RVV) allowing SiFive to design Core IPs that deliver performance, are optimized for power and area, but do not sacrifice flexibility or programmability. Our software stack is co-designed with the hardware, developed with scalability and quality in mind, and driven by well known leaders in the compiler, ML and system infrastructure space. Join us to develop a revolutionary software from the ground up.
+ skill set:
	- As an SoC Generator Design Engineer, you will be joining a small team to architect, build and maintain configurable RTL generators for SoCs and SoC components such as DMA, NoC, cache, peripheral and security subsystems. You will work closely with verification, physical design, IP integration, software, FPGA and other teams to design, tape out and bring up multiple SoCs in a variety of vertical markets, as well as develop infrastructure and automation for SoC design and integration.
	- Develop reusable, scalable RTL generators in the Chisel hardware design language.
	- Create, deploy, support, and maintain frameworks for automating SoC and FPGA integration in Chisel.
	- Collaborate with verification engineers to bring-up and debug designs, ensuring conformance to specifications and full stimulus coverage.
	- Work with physical design engineers to satisfy design performance, power, and area requirements.
	- Document microarchitectural specifications and generator source code.
	- BS, MS, or PhD in Computer Engineering, Computer Science, or Electrical Engineering.
	- At least 2 years experience developing RTL in Verilog, SystemVerilog, or VHDL.
	- Strong written and spoken communication skills.
	- Interest in learning and developing new methodologies for SoC design in functional programming languages, eg Scala.
	- Experience with scripting languages such as Python, Bash, or Ruby.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.




























###	VLSI Formal Verification


####	Notes about VLSI Formal Verification


Notes about VLSI formal verification:
+ Focus on mostly equivalence checking and model checking, and less on theorem proving (except in combination with decision procedures and automated reasoning, such as SAT/SMT solvers).
+ This includes:
	- clock domain crossing (CDC) verification, or CDC check
		* for functional static sign-off checks



VLSI formal verification companies:
+ Axiomise: https://www.axiomise.com/careers/









####	Sets of Skills for about VLSI Formal Verification


Sets of skills for VLSI formal verification, in terms of developing VLSI formal verification tools:
+ skill set:
	- As a senior software engineer at Breker, you will work closely with our core product team to develop cutting-edge technologies to address the SoC verification crisis. You will communicate with our product definition team and translate the product specification into executable R&D tasks. You will independently design and implement the software components and take the ownership of one or more software modules. Your day-to-day work will also include participating in technical meetings and design reviews. As a product developer, you will also have the opportunity to interact directly with our customers and receive feedback about the work you have done. We are a small software team and believe in agile development philosophies. We insist on clean design and readable code. When Breker customers produce successful, reliable SoC products, you will know that you helped make them possible.
	- requirements:
		* MSEE/MSCS with 3 years of software industry experience
		* Excellent understanding of software design concepts, including object-oriented design and patterns
		* Extremely strong C/C++ coding skills and practices, including ability to debug complex software systems
		* Excellent written and oral communication skills
		* Self-starter, high energy, and able to develop effective plans for software component implementation
		* Eagerness to be part of a startup and a desire to experience the excitement of offering powerful new technology
	- preferred experience:
		* PhD with relevant experience in circuit design and verification
		* Knowledge about constraint solving techniques, such as Boolean Satisfiability (SAT), Binary Decision Diagrams (BDD), and Satisfiability Modular Theory (SMT)
		* Adoption of agile software development methodologies
		* Familiarity with hardware design and verification languages, such as Verilog and SystemVerilog
		* Hands-on use of software construction tools, such as GNU Make and SVN
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






###	Embedded Formal Verification, and Formal Verification of Cyber-Physical Systems


Focus on mostly model checking, and less on theorem proving (except in combination with decision procedures and automated reasoning, such as SAT/SMT solvers).

Can include equivalence checking.


List of formal verification companies for cyber-physical systems:
+ [Prover](https://www.prover.com/about-us/career/#available-positions)
+ [Galois](https://galois.com/careers/)






The sets of skills are:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






###	Software Formal Verification



List of software formal verification companies:
+ CertiK: https://www.certik.com/company/careers
+ Elasticsearch B.V.: https://www.elastic.co/careers
+ Formal Vindication: https://formalv.com/
+ Trellix, which is part of Musarubra US LLC: https://careers.trellix.com/





+ skill set:
	- Tezos is a leading crypto-currency featuring the unique capability to evolve thanks to a voting system. In addition, formal verification is a strong community focus to make Tezos the safest platform, usable by individuals and large corporates.
	- In this job, you will participate in the verification effort project of the crypto-currency Tezos. We publish all our results in open-source on https://nomadic-labs.gitlab.io/coq-tezos-of-ocaml/ Explore this website beforehand to have more details. We use the automated system coq-ofocaml to convert the OCaml code of Tezos to Coq. Your job will be to write and automate Coq proofs on various sub-systems of the blockchain.
	- We are looking for profiles who are interested in functional programming and proof assistants. Prior knowledge of OCaml or Haskell is a plus. Prior knowledge of a proof assistant is mandatory. Prior knowledge of crypto-currencies is optional.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.













###	Circuit Simulation


###	Notes about Circuit Simulation

Skill sets for circuit simulation include those for:
+ analog ICs
+ RFICs
+ digital ICs, especially "FastSPICE"
+ mixed-signal ICs
	- especially mixed-signal ICs.
+ model order reduction, or macromodeling
	- ***nonlinear model order reduction***




###	Skill Sets for Circuit Simulation



The sets of skills for circuit simulation are:
+ skill set:
	- Software Developer- Circuit Simulation- Remote · Siemens EDA · Remote Position
	- At Siemens, we are always challenging ourselves to build a better future. We need the most innovative and diverse Digital Minds to develop tomorrow's reality. Find out more about the Digital world of Siemens here: [1] www.siemens.com/careers/digitalminds
	- Siemens EDA is part of Siemens Digital Industries Software, a Siemens Group company and world leader in the global digitalization of companies. Siemens EDA, a world leader of Electronic Design Automation (EDA), develops and markets software products and hardware solutions (emulators) covering the entire design & verification flow.
	- Siemens EDA counts among its customers the majority of the world's Top 50 in the fields of Semiconductors, Computing, Consumer, Automotive, Telecommunications and the Defense and Space sector.
	- Siemens EDA R&D teams, located across the globe, develop disruptive semiconductor chip design CAD software, including the Analog FastSPICE™ (AFS), the world's fastest nanometer accurate circuit verification platform. AFS is used by over 200 semiconductor companies worldwide for their toughest circuit verification challenges while designing high-speed I/Os, PLLs, ADCs/DACs, CMOS image sensors, RFICs, and embedded memory.
	- This position will be part of the AFS R&D team, focused on circuit simulation. As a key member of a highly proficient, productive, and motivated R&D team, developing industry's leading circuit simulator, using cutting edge software development techniques, you will be offered:
		* Technical challenges to solve toughest nanometer scale circuit verification problems for the leading semiconductor companies in the world.
		* A motivating, stimulating, and rewarding work environment
		* Excellent training and growth opportunities throughout your career
		* Attractive compensation and benefits
		* A motivating, stimulating, and rewarding work environment
		* Excellent training and growth opportunities throughout your career
		* Attractive compensation and benefits
	- As a member of AFS R&D team you will participate in the design and implementation of efficient algorithms using state of the art software engineering processes and development tools, with a strong emphasis on software quality; thus, adding to your industry level experience in solving tough computational complexity problems while participating in entire software development lifecycle. We are looking for a self-motivated and inspiring team player with outstanding problem-solving skills to maintain and grow the technical dominance of the AFS product.
	- Develop new and compatibility features for the core circuit simulator.
	- Participate in the specification, architecture, design, and development of features
	- Enhance core circuit simulator, e.g., performance, accuracy, capacity, convergence.
	- Maintain and enhance compatibility with other simulators.
	- Profile and identify bottlenecks in performance of various analyses for very large circuits.
	- Improve numerical algorithms used in the core engine.
	- Debug difficult testcases with accuracy, performance, capacity, or functional issues.
	- Extend and maintain the capabilities of the AFS circuit simulator.
	- Be a force for improving development processes and product quality.
	- Work effectively with globally distributed engineering teams and the Product Validation team
	- Minimum 7 years of proven strong background in developing efficient, high-quality software for engineering applications using numerical methods and sparse matrix techniques
	- Deep understanding of numerical methods and sparse matrix techniques
	- Working knowledge of analog electrical circuit analysis
	- Outstanding programming skills in C and C++, preferably on Linux platform
	- Proficiency in memory optimization, high-performance data structures and algorithms
	- Advanced multithreading programming experience.
	- Understanding of advanced computer architectures
	- Solid background in object-oriented design and software engineering processes.
	- Self-motivated individual with excellent problem-solving skills.
	- Strong interpersonal and excellent oral and written communication skills.
	- Highly motivated to work in globally distributed engineering environment
	- M.S or PhD in Computer Science, Electrical Engineering, Applied Mathematics, or relevant area
	- Understanding of the internal workings of a circuit simulator
	- Knowledge of Verilog-A and modeling in Verilog-A.
	- Background in semiconductor devices and their modeling
	- Python programming experience
	- EDA industry level work experience
+ skill set:
	- Software Developer, RF Circuit Simulation-Remote · Siemens EDA · Remote Position
	- At Siemens, we are always challenging ourselves to build a better future. We need the most innovative and diverse Digital Minds to develop tomorrow's reality. Find out more about the Digital world of Siemens here: [1] www.siemens.com/careers/digitalminds
	- Siemens EDA R&Dteams, located across the globe, develop disruptive semiconductor chip design CAD software, including the Analog FastSPICE™ (AFS), the world's fastest nanometer accurate circuit verification platform. AFS is used by over 200 semiconductor companies worldwide for their toughest circuit verification challenges while designing high-speed I/Os, PLLs, ADCs/DACs, CMOS image sensors, RFICs, and embedded memory.
	- This position will be part of the AFS R&D team, focused on RF (Radio frequency) circuit simulation. As a key member of a highly proficient, productive, and motivated R&D team, developing industry's leading circuit simulator, using cutting edge software development techniques, you will be offered:
	- Technical challenges to solve toughest nanometer scale circuit verification problems for the leading semiconductor companies in the world.
	- A motivating, stimulating, and rewarding work environment
	- Excellent training and growth opportunities throughout your career
	- Attractive compensation and benefits
	- As a member of AFS R&D team you will participate in the design and implementation of efficient algorithms using state of the art software engineering processes and development tools, with a strong emphasis on software quality; thus, adding to your industry level experience in solving tough computational complexity problems while participating in entire software development lifecycle. We are looking for a self-motivated and inspiring team player with outstanding problem-solving skills to maintain and grow the technical dominance of the AFS product.
	- Develop new and compatibility RF features for AFS circuit simulator
	- Participate in the specification, architecture, design, and development of RF features
	- Enhance performance, accuracy, capacity, and convergence for RF analyses
	- Profile and identify bottlenecks in performance of RF analyses for very large circuits.
	- Improve numerical algorithms used in the core RF engine.
	- Debug difficult testcases with accuracy, performance, capacity, or functional issues.
	- Extend and maintain the RF capabilities of the AFS circuit simulator.
	- Work effectively with globally distributed engineering teams and the Product Validation team
	- Experience in large-scale periodic and quasi-periodic solution of differential-algebraic circuit equations, including distributed elements
	- expertise in large-scale sparse matrix, krylov, and eigen solvers
	- expertise in high-performance multi-threaded numerical software development in C++
	- Outstanding programming skills in C and C++, preferably on Linux platform
	- Proficiency in memory optimization, high-performance data structures and algorithms
	- Advanced multithreading programming experience.
	- Solid background in object-oriented design and software engineering processes.
	- Self-motivated individual with excellent problem-solving skills.
	- Strong interpersonal and excellent oral and written communication skills.
	- Highly motivated to work in globally distributed engineering environment
	- M.S or PhD (preferred) in Computer Science, Electrical Engineering or Applied Mathematics
	- 7+ years of relevant industry experience
	- The salary range for this position is $141,100 to $225,800 and this role is eligible to earn incentive compensation.
+ Consider different quality attributes (FURPS) while validating the various products with special emphasis on Performance attributes.
+ skill set:
	- Software Engineer - Circuit Simulation (EMIR Analysis)
	- Circuit simulation developer with an emphasis on EMIR analysis
	- The Circuit Simulation Developer is responsible for designing, implementing and maintaining software designed to perform transistor-level VLSI circuit simulation, with an emphasis on EMIR analysis.  The ideal candidate would have expertise in device modeling and numerical techniques for VLSI circuit simulation. Understanding or experience of parasitic extraction is a strong plus.   Candidate should have an advanced degree in electrical engineering, computer science, applied mathematics, or similar.  Candidates with experience in related fields will be considered, particularly:  
	- 1. Transistor-level SPICE analysis algorithms
	- 2. Parasitic linear network reduction and analysis algorithms
	- 3. Statistical analysis, EMIR analysis, electro-thermal analysis algorithms
	- 4. Device physics, compact device modeling, behavioral modeling, macro modelling, statistical modeling, reliability modeling
	- 5. Numerical analysis, especially numerical linear algebra, sparse matrix techniques, or numerical methods for solution of ordinary and partial differential equations
	- 6. High performance computing / large scale scientific computing and deployment of parallel numerical algorithms
	- Candidate should be proficient in C/C++ development.  Experience with scripting languages like Python and GUI frame works like QT is a plus. Knowledge or Demonstrated software engineering skills, with a good understanding of efficient implementation of high-performance numerical algorithms and associated data structure design, and experience  in relevant software frameworks is a plus. Exposure to high-performance numerical computing, CPU/GPU systems. The candidate should have ability to work with an engineering and cross-functional team to deliver innovative technologies in a production environment. 
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.










###	Electronic System-Level Design & Verification


####	Notes about Electronic System-Level Design & Verification

The emphasis regarding the design and verification processes for electronic-system level tasks are about embedded computing, or computer systems. See Subsubsection on the design automation of cyber-physical systems, and related systems, to address the interactions with the physical environment, via sensing and actuation.


Includes the following:
+ high-level synthesis, or synthesis of HCL (hardware construction languages) models into logic circuits.
+ hardware/software co-design
+ hardware/software co-verification
+ hardware/software partitioning
+ software synthesis, program synthesis, or automated source code generation
+ transaction-level modeling
	- verification
	- synthesis, via HLS
+ power optimization, energy-efficient designs



####	Skill Sets for Electronic System-Level Design & Verification



The sets of skills are:
+ skill set:
	- Collaborate with the software team and platform architecture team to understand CPU hardware requirements for AI accelerator compiler, OS, video/image/voice processing, security, networking, and virtualization technology. Identify the application performance bottlenecks.
	- Identify representative benchmarks for the software applications. Use the benchmarks and the performance model to perform data-driven analysis to evaluate software, architecture, and u-architecture solutions to improve performance, power efficiency, or reduce hardware.
	- Set CPU architecture direction based on the data analysis and work with a cross-functional team to achieve the best hardware/software solutions to meet PPA goals.
	- Develop a cycle-accurate CPU model that describes the microarchitecture, use it for evaluation of new features.
	- Collaborate with RTL and Physical design engineers to make power, performance, and area trade-offs.
	- Drive analysis and correlation of performance feature both pre and post-silicon.
	- BS/MS/PhD in EE/ECE/CE/CS
	- Strong background in CPU ISA's, u-architecture research, and performance benchmarks.
	- Understanding SOC fabric, coherency protocols, memory technology, and accelerator technology is a plus.
	- Prior experience or strong understanding of ML/AI algorithms, compiler, and OS kernel is a plus.
	- Proficient in C/C++ programming. Experience in the development of highly efficient C/C++ CPU models.
+ skill set:
	- Able to solve a wide-range of difficult problems in imaginative and creative ways, exercising judgment within broadly defined practices and policies.
	- MSc in Computer Science, Applied Mathematics or related field with 3+ years of experience, or BSc with 5+ years of experience
	- ***Proficiency in developing and maintaining modern C++ based applications in a Unix/Linux and Windows environment. Proficiency in Qt, Python, and Tcl a plus. Experience with OpenAccess also a plus.***
	- Experience in developing enterprise level software, proficiency with debug and configuration management tools as well as quality and performance metric tools.
	- Strong communication skills and ability to write specifications and reference documentation.
	- Proficiency in English is a must.
	- Interest in high performance data structures and algorithms.
	- Prior experience with or developing CAD/EDA tools and/or hardware design also a plus as is experience with geometric algorithms.
	- ***Excellent organizational, prioritization, time management skills and an unwavering commitment to integrity and professionalism.***
	- ***Self-starter and strong closer with multitasking ability***
	- Any other duties as assigned by the Department head
	- ***Computational Geometry/Topology***
	- ***Graph theory***
	- ***Pattern recognition/machine learning***
	- ***Compilers/parsers (experience with Flex/Bison a plus)***
	- Computer architecture (caching, memory, networking, etc.)
	- ***Boost***
	- Test Driven Development
	- Displays strong analytical abilities both quantitative and qualitative.
	- Excellent communication skills and the ability to interface with all levels of management.
	- Relies on experience and judgment to plan and accomplish goals.
	- Performs a variety of complicated tasks - a certain degree of creativity and latitude is required.
	- ***A key requirement of this role is being the master of all details.***
	- ***Ability to multi-task and handle matters with little supervision and with excellent follow up.***
	- ***A strong entrepreneurial and can-do mindset, undaunted by shifting priorities, uncertainty, and a “figuring it out as we go” environment.***
	- ***Enough courage to say “I don't know”.***
+ skill set:
	- You integrate the award-winning SLX technology with commercially available high-level synthesis compilers
	- You adapt the SLX FPGA design space exploration algorithms to the specific characteristics of the HLS compiler
	- You test and verify that a good quality of results is achieved after the integration process
	- You ideally have experience with file interchange libraries and formats (boost serialization, XML serialization schemas)
	- You have excellent C/C++ and python programming skills
	- You are familiar with version control systems (git), and with build systems (cmake, ninja, GNU make)
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.





####	Skill Sets for the Design Automation of Networks-on-Chip



+ Design Automation Engineer, NoC Interconnect
	- Piece Together The World’s Most Powerful Puzzle
	- This world has a design. It’s infinite yet discoverable. Small yet powerful. Our design engineers must all at once predict it and create it. From implementation of the most advanced CPU, GPU and HPC processors on the planet to dreaming up every eventuality that could put our SoC and system IP to the test, we puzzle over the biggest questions of our time. And microarchitect the future.
	- Work At The Very Edge
	- At Arm, you’re in a position to influence 95% of the world’s connected devices and all of their applications. Healthcare, infrastructure, virtual reality… you’ll affect hundreds, if not thousands of industries worldwide, racing towards new milestones in human endeavour.
	- Learning And Development: Whether you want to learn a new programming language, explore your management potential or witness the latest innovations at industry conferences, we promise you both the freedom and the support to develop when you want it.
	- Sabbatical: We'll always encourage you to take plenty of annual leave, so you stay fresh and inspired. But you know what really does it? When we encourage you to take an extended, paid four-week sabbatical after 4 years of service.
	- Progressive Leave: You're a human being, not a resource. So it's important to us that we're there for you at significant points in your life. Whether you're having kids, acting as a primary care giver or have lost a loved one, our flexible progressive leave allows you to put your family first without worrying about your career.
	- Wellbeing: We create a safe space for you to look after your mental and physical health, with support ranging from medical insurance to the workplace mental health platform, Unmind. Alongside a growing number of onsite gyms, yoga, cycling and running clubs. All of which comes with a flexible working policy, so you can live life and be your brilliant self.
	- The Arm Network-on-Chip Interconnect (NI) is designed for intelligent connected systems across a wide range of applications including mobile, networking infrastructure, storage, server, HPC, automotive, and industrial solutions. The highly scalable and configurable interconnect is optimized for Armv8/ArmV9 processors, supports the latest versions of AXI, ACE-Lite, CHI, AHB, APB, AXI-Stream and multi-chip protocols, and can be customized across a wide range of PPA points. Our Austin-based team drives the specification, planning and development of the current and next generation NoC Interconnect IP!
	- As a member of the NoC interconnected team, you will be working on the infrastructure and tooling for auto-rendering configured interconnect RTL based on the user input, building infrastructure for design flows including DRCs, Lint, DFT Lint, CDC, RDC, Autocheck, UPF, SDC, IPXACT, and power analysis to deliver a high-quality interconnect product. We’d like you to join us!
	- We are looking for an experienced Design Automation Engineer who will contribute to all tooling aspects of the interconnect design. Primary responsibilities include development of tools for configuring and building the Interconnect IP, as well as defining and building different flows required for RTL quality. On a day-to-day basis you will be working closely with the interconnect IP design, verification and front-end tooling teams. Your responsibilities include:
	- Participate in IP microarchitecture discussions to identify the design automation requirements for our current and next-generation interconnect IP products.
	- Work with senior members of the design/tooling/verification teams to make sure the configurability is built into the infrastructure, and it follows the functional/system level requirements.
	- Create the scripts needed to absorb the input requirements to develop an engine which will auto render configured RTL. Develop and maintain infrastructure and flows to produce high quality RTL. Define, update and maintain internal flows to run different EDA tools including but not limited to lint, DFT lint, auto-check, CDC, RDC, power analysis etc. for a highly configurable interconnect.
	- Identify and implement enhancements to flows in collaboration with the methodology group.
	- Background in software development in connection with the delivery of hardware and/or IP projects, including tools, workflow automation, hardware design automation (EDA or EDA-like software)
	- Proven programming and scripting skills e.g., C, C++, Java, Python, Perl, Ruby, etc.
	- Experience with developing and maintaining infrastructure and flows to run different EDA tools for lint, DFT lint, auto-check, CDC, RDC, power analysis etc.
	- Familiarity with version control software, such as Git or SVN. Experience with tools and platforms for continuous integration and delivery.
	- Reasonable understanding of all stages of the design cycle: initial concept, specification, implementation, verification, documentation and support.
	- Knowledge around highly configurable and parameterized RTL designs.
	- Developed skills and experience in solving complex software engineering challenges, including ability to manage multiple tasks concurrently.
	- Ability to understand/drive/challenge technical solutions. Possess a high level of dedication, initiative, and problem-solving skills.
	- An ideal candidate will have between 5-10 years of work experience in design automation, infrastructure development for design flows, SoC/IP design workflows.
	- Experience in hardware development and RTL design using Verilog or System Verilog.
	- Experience with interconnect and bus architectures. Knowledge around Arm-based SoCs.
	- Experience of working in a functional safety related development project applying standards such as ISO 26262 and/or IEC 61508.
	- At Arm, we are proud to have a set of behaviors that reflect our culture and guide our decisions, defining how we work together to defy ordinary and shape extraordinary. These behaviors are assessed as part of the recruitment process:
		* Partner and customer focus
		* Collaboration and communication
		* Creativity and innovation
		* Team and personal development
		* Impact and influence
		* Deliver on your promises
	- We offer a hybrid approach to home and office working to provide an adaptable experience for all employees. We expect some working time to be spent in office, to promote a strong collaborative environment with good team integration but are accommodating to different home working requirements.




















###	Design Automation of Cyber-Physical Systems and Their Networks



####	Notes about Design Automation of Cyber-Physical Systems and Their Networks


This section covers the design automation of cyber-physical systems, and networks of cyber-physical systems (or, networked cyber-physical systems, including networked embedded systems).
+ [ambient intelligence](https://en.wikipedia.org/wiki/Ambient_intelligence), AmI
+ networks of cyber-physical systems
	- Internet of Things, IoT
		* AIoT, AI-based IoT
			+ global brain
				- From the CACM paper.
				- ***extended intelligence***, EI or XI
					* extend human intelligence with AI
		* ***Supranet***
			+ see Gartner research report
+ Intelligent Environments, IE
	- ["IEs describe physical environments in which information and communication technologies and sensor systems disappear as they become embedded into physical objects, infrastructures, and the surroundings in which we live, travel and work. The goal here is to allow computers to take part in activities never previously involved and allow people to interact with computers via gesture, voice, movement, and context."](https://en.wikipedia.org/wiki/Intelligent_environment)
+ [pervasive computing](https://en.wikipedia.org/wiki/Pervasive_computing)
+ [physical computing](https://en.wikipedia.org/wiki/Physical_computing)
+ [ubiquitous computing](https://en.wikipedia.org/wiki/Ubiquitous_computing)
+ with users
	- [haptic technology](https://en.wikipedia.org/wiki/Haptic_technology), or haptic computing
		* brain-computer interface, BCI; or brain-machine interface, BMCI,
			+ neural dust




####	Skill Sets for Design Automation of Cyber-Physical Systems and Their Networks



Skill set for the design automation of cyber-physical systems, and networks of cyber-physical systems:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.













###	Energy-Efficent EDA, or Low-Power EDA



####	Notes about Energy-Efficent EDA, or Low-Power EDA


circuit-level power optimization: 
+ transistor sizing
+ voltage scaling
+ voltage islands
+ variable VDD
+ multiple threshold voltages
	- Modern processes can build transistors with different thresholds. Power can be saved by using a mixture of CMOS transistors with two or more different threshold voltages. In the simplest form there are two different thresholds available, common called High-Vt and Low-Vt, where Vt stands for threshold voltage. ***High threshold transistors are slower but leak less, and can be used in non-critical circuits.***
+ power gating
	- This technique uses high Vt sleep transistors which cut-off a circuit block when the block is not switching. The sleep transistor sizing is an important design parameter. This technique, also known as MTCMOS, or Multi-Threshold CMOS reduces stand-by or leakage power, and also enables Iddq testing.
+ long-channel transistors
	- Transistors of more than minimum length leak less, but are bigger and slower.
+ stacking and parking states
	- Logic gates may leak differently during logically equivalent input states (say 10 on a NAND gate, as opposed to 01). State machines may have less leakage in certain states.
+ logic styles:
	- dynamic and static logic





logic synthesis for low power
+ clock gating
+ logic factorization
+ path balancing
+ technology mapping
+ state encoding
+ finite-state machine decomposition
+ retiming
+ as part of FPGA logic synthesis


Data organization for low power: https://en.wikipedia.org/wiki/Data_organization_for_low_power
 


Energy harvesting, EH, power harvesting, energy scavenging, or ambient power:
+ Circuits and systems that exploit ambient energy to power low-energy electronic circuits and systems, in applications such as:
	- wearable electronics
	- wireless sensor networks
	- other wireless autonomous devices



####	Skill Sets for Energy-Efficent EDA, or Low-Power EDA

The sets of skills are:
+ skill set:
	- We are looking for a highly motivated, creative, and energetic Principal Software Engineer to work on a new award-winning product for three-dimensional Integrated Circuit power sign-off verification. In this role, you will report to the Senior Engineering Director of Software Development with the following objectives:
	- Develop accurate and efficient models for IC behavior at advanced process technology nodes to analyze reliability, electrical, and thermal effects in digital and analog circuits.
	- Design, implement, and enhance scalable software solutions for large linear systems modeling on-chip power grids and system-level power delivery networks.
	- Effectively collaborate with the Product Engineering team in defining the product enhancement roadmap with solutions addressing customer requirements and ensuring competitive leadership of the product.
	- Work on simulation/extraction / static-timing / thermal analysis code.
	- Lead complex projects with minimal supervision and guide junior engineers.
	- Research, propose, and prototype solutions for advanced 3D IC power analysis. Maintain technical expertise by following technical advances in industry and academia.
	- Manage assigned projects, including defining scope, plans, schedules, and deliverables.
	- BS Degree in Electrical Engineering, Physics, Mathematics, or Computer Science/Engineering from an accredited institution.
	- Minimum 10+ years of experience in designing and developing EDA software products, preferably for ICdesign, analysis, and verification.
	- Strong knowledge of data structures and algorithms , and their complexities.
	- Strong C++ / STL programming skills, and good knowledge of OOD.
	- Ability to understand and support complex software products.
	- Experience in reliable planning and software effort estimation.
	- Ability to provide comprehensive testing of the developed solutions.
	- Experience with modern software development lifecycle flows and tools, including issue tracking, builds, and static and dynamic code analysis tools.
	- Ability to design high-quality software with on-time delivery.
	- Knowledge of Linux .
	- Excellent communication skills: ability to effectively interact with cross-functional teams (R&D, QA, Product Engineering), ability to work in a team. Ability to communicate complex technical concepts clearly and effectively.
	- MS or Ph.D. in Electrical Engineering, Physics, Mathematics, or Computer Science/Engineering from an accredited institution.
	- Knowledge of TCL .
	- Knowledge of AI/ML and their applications for IC verification.
	- Familiarity with Computational Geometry , Graph Theory.
	- Familiarity with HPC (high-performance computing).
	- Strong mathematic knowledge, of matrix and numerical algorithms.
	- Previous experience designing efficient algorithms and tools for IR/EM analysis, parasitic extraction, circuit simulation, or static timing analysis.
	- Familiarity with design patterns and code refactoring.
	- The salary range for this position is $136,700 to $246,100 and this role is eligible to earn incentive compensation.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.












###	Logic Synthesis


Includes information on:
+ FPGA logic synthesis



The sets of skills are:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.












###	Physical Design & Physical Synthesis



####	Notes about Physical Design & Physical Synthesis


Sets of skills for physical design of digital ICs/SoCs:
+ placement
+ routing
+ physical design for 3-D ICs
	- placement for 3-D ICs
	- routing for 3-D ICs
	- account for different types of 3-D ICs that connect dies or wafers, using:
		* TSVs, through-silicon vias
		* Cu-Cu connections
		* classification by level of interconnect hierarchy:
			+ global level, using packages
				- 3DWLP, 3-D wafer-level packaging
			+ intermediate level, using bond pads
			+ local level, using transistors
		* alternate classifications:
			+ 3DWLP, 3-D wafer-level packaging
			+ 2.5D interposer-based integration
			+ 3-D interposer-based integration
			+ 3-D stacked ICs
			+ monolithic 3-D ICs
			+ 3-D heterogeneous integration
			+ 3-D systems integration
	- Notes:
		* 3-D packaging:
			+ 3-D integration schemes that rely on traditional interconnection methods for vertical stacking, such as:
				- wire bonding
				- flip chip
			+ classifications:
				- 3-D SiP, 3-D system-in-package
					* for stacked memory dies interconnected with:
						+ wire bonds
						+ package on package PoP
				- 3-D WLP, 3-D wafer-level package
					+ uses wafer-level processes such as redistribution layers (RDLs) and wafer bumping processes to form interconnects
					* 2.5D interposer, using silicon/glass/organic interposer using through silicon vias (TSVs) and RDL
		* 3-D ICs
			+ 3-D SIC, 3-D stacked ICs
				- stack ICs chips
					* using TSV interconnects
					* stacking approaches:
						+ die-to-die
						+ die-to-wafer
						+ wafer-to-wafer
				- monolithic 3-D ICs
					* use fabrication processes to realize 3-D interconnects at the local levels of the on-chip wiring hierarchy (dictated by IRDS/ITRS)
		* Benefits:
			+ footprint, or volume that the package takes up on a board.
			+ cost
			+ heterogeneous integration
			+ shorter interconnect
			+ power
			+ design
			+ circuit security
			+ bandwidth
		* challenges:
			+ cost
			+ yield
			+ heat, thermal hotspots
				- correlation between electrical proximity and thermal proximity
			+ design complexity
			+ TSV-introduced overhead
			+ testing
			+ lack of standards
			+ heterogeneous integration supply chain
			+ lack of clearly defined ownership
		* design styles
			+ gate-level integration
			+ block-level integration
+ clock network synthesis
	- clock tree synthesis
+ cell library synthesis
	- cell library migration from a given semiconductor manufacturing process technology node to a more advanced node
+ chip-package-board co-design
	- hybrid integrated circuits, HIC, hybrid microcircuits
+ FPGA physical design
+ DFM-aware physical design
+ power supply networks
	- or, power and ground routing




Sets of skills for physical design of analog, RF, and mixed-signal ICs/SoCs:
+ placement
+ routing





Sets of skills for physical synthesis:
+ gate sizing
+ buffer insertion
+ wire sizing
+ yield-aware physical synthesis
	- as part of DFM-aware physical synthesis, to support proactive DFM.












####	Skill Sets for Physical Design & Physical Synthesis




Here are the sets of skills for physical design and physical synthesis.
+ skill set:
	- We are looking for an experienced software engineer to work in the Efinity Place & Route team. Develop state-of-the-art techniques for placement, routing, and/or physical synthesis. Work on our software to utilize the full potential from our next generation Titanium FPGA family.
	- Drive research and development of placement, routing, and/or physical synthesis.
	- Improve run-time / memory consumption for future large FPGA devices.
	- Develop custom solutions to support customer engagements
	- B.Sc. + 10 years, M.Sc. + 8 years, PhD + 4 years in Computer Engineering / Computer Science
		- For senior position.
		- For mid-level position: B.Sc. + 6 years, M.Sc. + 4 years, PhD +0 years in Computer Engineering / Computer Science.
		- For junior positions: B.Sc. + 6 years, M.Sc. + 4 years, PhD +0 years in Computer Engineering / Computer Science.
	- Knowledge of FPGAs
	- C++, Python
	- Experience with EDA algorithms (Global/Detailed Placement, Routing, Physical Synthesis)
	- Machine Learning experience is an asset
	- Strong analytical/programming abilities.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.












###	Memory Compilers



+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.

















###	Static Timing Analysis (STA), and Statistical Static Timing Analysis (SSTA)



+ skill set:
	- timing convergence issues associated with deep-submicron processes for high-performance design
		* crosstalk delay
		* noise
		* glitch
		* POCV
		* IR-STA
+ skill set:
	- SDC, .lib/CCS/ECSM
	- noise analysis
	- multi-thread technology
	- multi-tasking MMMC
	- cross-talk analysis
		* timing window -based analysis
		* composite aggressors
		* advanced pessimism reductions considering the effects of logic correlations with complex structure
		* discrete timing window
		* CRPR
	- VCD, SAIF, and FSDB formats
	- switching power, state-dependent path dependent (SDPD) internal power, SDPD leakage power, X-transition power, glitech power, clock tree power
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.












###	VLSI Verification



Focuses on non-formal VLSI verification, other than circuit simulation and physical verification, such as:
+ logic simulation
+ fault simulation
+ RTL simulation
+ intelligent verification, intelligent testbench automation



The sets of skills are:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.























###	VLSI Design for Manufacturing, DFM


####	Notes about VLSI DFM



Skills sets for DFM, especially reactive DRM (e.g., exploiting computational lithography for pixelization of layout designs), include:
+ RET, resolution enhancement techniques
+ OPC, optical proximity correction
	- rules-based OPC
	- model-based OPC
	- inverse OPC
	- SRAF, sub-resolution assist features
+ PSM, phase-shifting mask
+ parametric DFM for semiconductor manufacturing yield optimization
	- statistical circuit simulation, with statistical SPICE models
		* Monte Carlo analysis
		* response surface modeling
		* mismatch simulation
+ OAI, off-axis illumination
+ STI, shallow-trench isolation




####	Skill Sets for VLSI DFM



Sets of skills for DFM:
+ Direct or indirect experience in OPC (Optical Proximity Correction), including rogorious lithography simulation (Hyperlith, Prolith), RET, and advanced mask technology.
+ Solid understanding of imaging theories (Abbe, Hopkins).
	- Abbe-PCA (Abbe-Hopkins): microlithography aerial image analytical compact kernel generation based on principle component analysis
	- Hybrid Hopkins-Abbe method for modeling oblique angle mask effects in OPC
	- Application of the hybrid Hopkins–Abbe method in full-chip OPC
	- transmission cross coefficients (TCCs)
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.









###	Numerical EDA, other than circuit simulation


####	Notes about Numerical EDA, other than circuit simulation

This includes:
+ electromagnetic field solvers
+ layout extraction
+ parasitic extraction
+ signal integrity analysis
+ power integrity analysis
+ voltage drop analysis
+ electromigration lifetime checks
+ noise analysis
	- static noise analysis
	- crosstalk analysis
	- mitigation of noise coupling



####	Skill Sets for Numerical EDA, other than circuit simulation


The sets of skills are:
+ The successful candidate must be an expert in field solver-based parasitic extraction and be able to quickly become an expert in new simulation approaches and to develop robust, maintainable, and efficient code.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.








###	IC Testing, including digital and mixed-signal VLSI Testing


####	Notes about IC Testing

This includes:
+ ATPG, automatic test pattern generation
+ BIST, built-in self-test
+ DFT, design for testability
+ high-level test synthesis



####	Skill Sets for IC Testing


The sets of skills are:
+ skill set:
	- Background in 3D computer graphics, including APIs such as OpenGL
	- Proficient in Java, Maven, Python, Jenkins/Groovy, Vagrant/Docker
	- Good knowledge in DFT: OCC insertion (for on-chip clock controllers), ATPG generation
+ skill set:
	- This role will support the Siemens EDA DFT products which will involve building relationships with our customers, helping them embrace and deploy the Tessent product lines. It is a frontend team which works on top of the analyzer and elaborator.
	- We are not looking for hard workers, just super minds
	- You're a Graduate / Postgraduate (Bachelors/Masters) in EEE) / ECE/Computer Science (CS) from top reputed Engineering colleges with significant experience in software development.
	- Working Experience should be 8 + Years of experience.
	- Experience in EDA will be a phenomenal plus.
	- Your sound understanding of C/C++ languages, design patterns along with data structure and algorithms will be key to development of software.
	- Your understanding of HDL languages – Verilog/VHDL/System Verilog - low power aware synthesis and power formats - UPF/CPF – will supplemental.
		* ***Si2 Common Power Format, or CPF***
		* ***Unified Power Format, or UPF***
	- Knowledge or experience on flex/bison will be advantage.
	- Understanding of gate level digital logic design.
	- Experience in Analyzer/Compiler development.
	- Your good analytical, abstraction and communication skills will help in creating bigger and sustainable solutions for complex systems.
	- Your ability to work with multi-functional teams will help in good crafting solutions that resolve actual customer issues.
+ Experience in usage of debugging targets JTAG, BDI
	- ***Joint Test Action Group, JTAG***
	- ***BDI (Background Debug Interface)***
	- ***BDM (Background Debug Mode)***
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.











###	Post-Silicon Validation


####	Notes about Post-Silicon Validation

Skill set for post-silicon validation and post-silicon debugging.
+ complements VLSI simulation (ESL/TLM simulation, RTL simulation, logic simulation, and circuit simulation), VLSI formal verification and logic emulation
+ use system-boards, logic analyzers, and assertion-based tools with VLSI testing for post-silicon validation and post-silicon debugging
+ use of hardware emulator, which is like hardware acceleration for RTL/logic simulation
+ in-circuit emulation
+ hardware virtualization
	- hardware-assisted virtualization, via platform virtualization
		* also known as accelerated virtualization, hardware virtual machine or HVM, native virtualization


####	Skills about Post-Silicon Validation

The sets of skills are:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.















###	Skill Sets for FPGA Design Automation, or FPGA CAD



Skill sets for FPGA design automation, or FPGA CAD:
+ skill set:
	- Senior Software Engineer
	- The Senior Software Manager is a Key member of QuickLogic eFPGA Engineering team, reporting to the Director of Engineering, eFPGA. This is a key role at QuickLogic, with primary responsibility for leading the Software tools development for eFPGA products. The role holder is responsible for software roadmap creation, release planning, coordinate the execution of projects with the help of internal engineers/contract resources. This is a remote opportunity operating mostly in the Pacific time zone.
	- This individual will collaborate with key stake holders, and handle projects of varying complexity, by providing appropriate direction, and strategy to reach long term goals. The individual needs to be a self-starter, with good planning and organization skills, as the role holder works closely in terms of coordination and functional integration with various groups located in multiple sites and geographies
	- Well-developed, mature communication, influencing and self-management skills are required as the role holder would need to juggle multiple tasks and priorities. Key partners would include the eFPGA Silicon development team, External Contractors, Application Engineering team.
	- BS/MS/PhD in CS/Computer Engineering with 12-15 years of experience in EDA related software development with minimum 3-5 years in leadership role.
	- ***Must be a US Citizen***
	- Prior experience in EDA software tools development, specifically in one or preferably more of the following areas:
	- Routing and/or Placement
	- FPGA architecture evaluation
	- Software flows to simplify and automate the FPGA development
	- Bit stream generation
	- Good knowledge of FPGA hardware architecture and Digital logic design
	- Strong C/C++ development experience
	- Good experience of TCL/Python scripting languages
	- Apply sound and diversified knowledge of principles, practices, and procedures of software architecture.
	- Familiarity with VHDL and/or Verilog
	- Exposure to Synthesis and Simulation tools
+ skill set:
	- Responsible for development of EDA database and FPGA design tools.
	- Responsible for optimizing EDA database and enhancing current software architecture.
	- Responsible for the design of state-of-art infrastructure for next generation FPGA products.
	- Working with other software development teams to strongly support EDA tools capacities efficiently.
	- Improve development methodologies and processes
	- BS/MS/PHD in Electric Engineering or Computer Science or Mathmatics.
	- 1+ years of experience in EDA, CAD, ASIC or FPGA.
	- Experience with C/C++, Python, TCL on LINUX and/or WINDOWS platforms.
	- Strong background in EDA algorithms and data structures is preferred.
	- Strong and effective inter-personal and communication skills.
	- Self-motivated, self-disciplined with the ability to set the team goals and work consistently towards achieving them.
	- Experience of development of large existing software systems is highly desirable.
	- Individuals with strong desire and ability to explore new technologies and who are able to demonstrate excellent analysis and problem-solving skills are preferred.
+ skill set:
	- A successful candidate will join a team designing and developing Lattice FPGA software tools at San Jose. The candidate will contribute to delivering software solution for Lattice FPGA development with emphasis on placement and routing tools. The candidate is expected to research and develop novel algorithms to improve Lattice FPGA placement and routing engines to achieve better Fmax, runtime as well as memory footprint. The candidate is also expected to support new FPGA architecture evaluation and assess its potential impact on existing software tools. The candidate will be responsible for maintaining existing software product too and interacting with other teams to facilitate a value added solution.
	- Responsible for new architecture evaluation, placement and routing tool's QoR improvement and support for Radiant/Diamond software release.
	- Behaviors
		* Team Player: Works well as a member of a group
		* Dedicated: Devoted to a task or purpose with loyalty or integrity
		* Functional Expert: Considered a thought leader on a subject
	- Motivations
		* Self-Starter: Inspired to perform without outside help
		* Growth Opportunities: Inspired to perform well by the chance to take on more responsibility
		* Ability to Make an Impact: Inspired to perform well by the ability to contribute to the success of a project or the organization
	- Education
		* Required: Masters or better in Electrical Engineering or related field.
		* Preferred: Doctorate or better in Computer Science or related field.
	- Experience
		* 8 years: 8+ years experience in EDA place and route development. Expertise in C++, knowledge of data structure and graph algorithms, and strong communication skills are required. Knowledge or experience in FPGA development is a plus.
+ skill set:
	- A successful candidate will join a team designing and developing Lattice FPGA software tools at San Jose. The candidate will contribute to delivering software solution for Lattice FPGA development with emphasis on device support including device modeling, simulation model and bitstream generation. The candidate is expected to work closely with FPGA silicon design teams and FPGA SW implementation team (MAP, Place & Route and Timing Analysis) and programming teams to provide an entire FPGA solution from Synthesis to bitstream download. The candidate is also expected to support new FPGA architecture evaluation and assess its potential impact on existing software tools. The candidate will be responsible for maintaining existing software product too and interacting with other teams to facilitate a value added solution.
	- Behaviors
		* Team Player: Works well as a member of a group
		* Innovative: Consistently introduces new ideas and demonstrates original thinking
		* Detail Oriented: Capable of carrying out a given task with all details necessary to get the task done well
	- Motivations
		* Growth Opportunities: Inspired to perform well by the chance to take on more responsibility
		* Goal Completion: Inspired to perform well by the completion of tasks
		* Self-Starter: Inspired to perform without outside help
	- Education
		* Required: Bachelors or better in Electrical and Electronics Engineering or related field.
		* Preferred: Masters or better in Electrical Engineering or related field.
	- Experience
		* Required
			+ C++ programming and data structure
			+ 5 years: Expertise in C++, Verilog, and scripts, knowledge of logic design, simulation and data structure
		* Preferred
			+ knowledge of FPGA, logic design & simulation
			+ EDA tool development
			+ Logic design & familiar with Verilog & VHDL
			+ Strong communication skills are required
			+ Knowledge or experience in FPGA development and System Verilog is a plus
			+ 3 years: Experience in EDA development
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.




















###	Technology CAD, TCAD


####	Notes about Technology CAD

+ DTCO
	- Support tools
		* BACPAC, Berkeley Advanced Chip Performance Calculator
			+ Estimate impact of semiconductor manufacturing process technology node, or process node
				- semiconductor manufacturing process technology node is defined by the minimum feature size





####	TCAD for Process Simulation



Notes about TCAD for process simulation:
+ ion implantation
+ diffusion
+ oxidation
+ dry/wet etching
+ deposition
+ ***optical lithography, photolithography, or optical photolithography***, and next-generation lithography (NGL) techniques for optical lithography
	- ***computational lithography***, or computational scaling
		* Mathematical and algorithmic approaches to improve attainable resolution from optical lithography.
		* For 22 nm semiconductor manufacturing process technology nodes and beyond.
		* To fix problems with:
			+ 193 nm deep UV optical lithography.
		* includes DFM techniques, such as:
			+ resolution enhancement technologies, RET
				- scattering bars
				- phase-shoft masks
				- multiple/double patterning
			+ optical proximity correction, OPC
			+ source mask optimization
				- or, complex modeling of the lens system and photoresist
					* aims to improve chip manufacturability and manufacturing yield
					* use signature of scanner to improve:
						+ OPC model
						+ polarization characteristics of the lens pupil
						+ Jones matrix of the stepper lens
						+ optical parameters of the photoresist stack
						+ diffusion through the photoresist
						+ stepper illumination control variables
	- multiple patterning, or multi-patterning
	- classifications:
		* ultraviolet lithography, UV lithography
		* X-ray lithography
		* EUV lithography
	- EUV lithography, extreme ultraviolet lithography, EUVL
		* 13.5 nm extreme ultraviolet lithography
		* assist features
		* source mask optimization
		* phase shift masks
		* EUV photoresist exposure
		* contamination effects
			+ resist outgassing
			+ tin deposition
			+ hydrogen blistering
			+ resist erosion
			+ membrane
		* mask defects
		* throughput scaling issues
			+ EUV stochastic issues
		* used with multile patterning
		* single patterning extension, anamorphic high-NA (NA, numerical aperture)
	- deep UV immersion lithography, immersion lithography
	- X-ray lithography
	- BEUV lithography, or beyond extreme ultraviolet lithography
		* about 6.7 nm wavelength
	- maskless lithography, MPL
		* electronic beam lithography, e-beam lithography, EBL
		* plasmonic direct writing lithography
		* optical maskless lithography
			+ multiphoton lithography, ***direct laser writing***, direct laser lithography
	- quantum optical lithography, QOL
	- other non-mainstream lithography techniques
		* nanoimprint lithography
			+ thermoplastic nanoimprint lithography
			+ photo nanoimprint lithography
			+ resist-free direct thermal nanoimprint lithography
		* molecular self-assembly lithography
		* stencil lithography
		* charged-beam lithography
			+ ion beam lithography, or ion-beam lithography, or ion-projection lithography
				- ion beam proximity lithography, IBL
				- focused ion beam lithography, FIB
				- similar to:
					* electronic beam lithography
				- electron-projection lithography
		* magnetolithography, ML
			+ photoresist-less and photomaskless lithography
			+ backside lithography
		* plasmonic lithography, plasmonic nanolithography, plasmonic photolithography
		* ***soft lithography***
			+ use elastomeric stamps, molds, and conformable photomasks to fabricate or replicate structures
			* PDMS lithography
			* microcontact printing
			* multilayer soft lithography
		* laser printing lithography
			+ laser printing of single nanoparticles
		* nanosphere lithography, NSL
		* direct-write lithography process
			+ proton beam lithography, or p-beam writing, or proton beam writing
		* multiphoton lithography, direct laser lithography, direct laser writing
		* ***scanning probe lithography, SPL***
			+ mechanical/thermo-mechanical SPL, m-SPL
			+ thermal SPL, t-SPL
			+ thermo-chemical SPL, tc-SPL, or thermochemical nanolithography, TCNL
			+ dip-pen SPL, dp-SPL, or dip-pen nanolithography, DPN
				- thermal dip-pen lithography
				- beam pen lithography
			+ local oxidation lithography, o-SPL
			+ bias-induced SPL, b-SPL
			+ current-induced SPL, c-SPL
			+ thermally-assisted magnetic SPL, tam-SPL
		* local oxidation nanolithography, LON
		* interference lithography, or holographic lithography
			+ not maskless lithography
			+ no 1:1 imaging system in between
			+ electron holographic lithography
			+ atom holographic lithography
		* nanofountain darwing, or nanofountain probe
+ silicidation
+ modeling mechanics of semiconductor manufacturing processes
+ CMP, chemical-mechanical polishing, chemical-mechanical planarization
+ annealing (diffusion and dopant activation)
+ epitaxy










Sets of skills for process simulation TCAD are:
+ skill set:
	- Component Simulation Engineer
	- Familiar with GaN (or HV, PMIC), process.
	- Familiar with HV/PMIC Reliability is a plus.
+ skill set:
	- Senior Software Engineer · ASML · United States
	- ASML is an innovation leader in the semiconductor industry. We provide chipmakers with everything they need – hardware, software, and services – to mass-produce patterns on silicon through lithography. Our lithography machines are a hybrid of high-tech hardware and advanced software
	- Senior Software Engineer at ASML play a critical role in owning and driving the technical details of the projects that would ultimately drive customer satisfaction. We are looking for an experienced engineer and technical leader with strong analytical, design and development skills, technical depth, curiosity, enthusiasm, integrity and being results oriented. You will be a key member of our highly integrated multi-disciplinary matrixed team of software, systems, applications and algorithm engineers. If you have a desire to work collaboratively while solving tough problems across real full software stacks including hardware, firmware, OS, desktop applications and web applications, we want to hear from you.
	- Working at the cutting edge of tech, you'll always have new challenges and new problems to solve – and working together is the only way to do that. You won't work in a silo. Instead, you'll be part of a creative, dynamic work environment where you'll collaborate with supportive colleagues. There is always space for creative and unique points of view. You'll have the flexibility and trust to choose how best to tackle tasks and solve problems.
	- The California base annual salary/hourly range for this role is currently $154,125 - $256,875.
+ skill set:
	- computational lithography
	- If you're a motivated individual with a strong understanding of software development, and you'd like to collaborate and continue learning with other engineers who are passionate about and experienced in developing our computational lithography models (optics, photoresist, etching, machine learning, etc.), come and join our computational lithography modeling team!
	- To learn more about what we do: https://eda.sw.siemens.com/en-US/ic/calibre-manufacturing/computational-lithography/
	- You bring your programming and scientific experience to learn how to model semiconductor manufacturing processes and implement these models in a computational framework with C++.
	- You'll be responsible for developing new features, debugging and supporting existing models, and you'll be able to suggest and provide new directions for improving existing algorithms.
	- We would love to hear from you if you have B.S. or M.S. in Computer Science, Electrical Engineering, Physics, Mathematics, or similar and you have a good Understanding of physics, mathematics, optimization, or engineering and Experience in C++ on UNIX and/or LINUX platforms.
	- Your collaborative spirit is essential to develop critical components consistently and on time with other team members.
	- You are curious and enjoy discovering new technologies.
	- You have initial project experience as well as good analytical skills and an appetite for problem-solving.
	- Ideally, you will have some initial experience with Python, MATLAB and Tcl/Tk, and some knowledge of semiconductor manufacturing and computational lithography is a plus.
	- As you work in an international team, English (spoken and written) is a must to have
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






####	TCAD for Device Simulation



Notes about TCAD for device simulation includes:
+ device modeling for common transistors
	- MOSFET, metal-oxide-semiconductor FETs 
		* a type of insulated-gate FET
			+ enhancement mode MOSFET
			+ depletion mode MOSFET
		* p-channel MOSFET, PMOS
		* n-channel MOSFET, NMOS
			+ ggNMOS, grounded-gate NMOS
				- electrostatic discharge (ESD) protection device
		* CMOS, complementary MOSFET
			+ advantages:
				- high noise immunity
				- low static power consumption
		* ***FGMOS, floating-gate MOSFETs***
			+ for floating-gate memory cell, digital storage element in:
				- EPROM
				- EEPROM
				- flash memory
		* MOS capacitor
		* intrinsic MOSFET device modeling
			+ inversion-layer mobility modeling
			+ channel charge modeling
			+ threshold voltage modeling
		* substrate effects on MOSFETs
			+ subthreshold current
			+ drain-induced-barrier-lowering current
		* parasitic junction & inhomogeneous substrate effects
		* ***MuGFETs, multi-gate MOSFETs, multi-gate FETs***, or ***multi-gate semiconductor devices***
			+ The multiple gates can be controlled by:
				- a single gate electrode, where the multiple gate surfaces act electrically as a single gate
				- independent gate electrodes
					* ***MIGFETs, multiple-independent-gate FETs***
			+ 3-D transistors, or non-planar transistors
				- ***FinFET, fin FETs***
				- ***GAAFET, gate-all-around FETs***
					* sometimes called, SGT, "surrounding gate transistors"
					* MBCFETs, multi-bridge channel FETs
			+ ***DGMOS, DGMOSFET, dual-gate MOFETs, double-gate MOFETs***
				- planar double-gate MOFETs
				- double-gate TFT, double-gate thin-film transistors
				- with silicon thin film in:
					* strong inversion, volume-inversion MOSFET
					* strong accumulation, volume-accumulation MOSFET
			+ tri-gate MOSFETs
			+ FlexFET: planar, independently double-gated transistor
	- other field-effect transistors, FETs
		* propeties and charracteristics
			+ FETs are 3-terminal devices:
				- source
				- gate
				- drain
			+ FETs are unipolar transistors
			+ source-gated transistors
		* ***MISFET, metal-insulator-semiconductor FETs***, or ***insulator-gate FETs (IGFETs)***
			+ all MOSFETs are MISFETs
			+ but, not all MISFETs are MOSFETs
			+ insulators can be:
				- silicon dioxide
				- organic insulators for organic FETs
		* ***QFET, quantum FET***; or, ***QWFET, quantum well FET***
			- exploit quantum tunneling
		* ***TFT, thin-film transistors***
			+ metal oxide thin-film transistors, metal oxide TFT
				- or, oxide thin-film transistors, oxide TFT
			+ TFT LCDs, TFT liquid-crystal displays
		* ***CNTFET, carbon nanotube FET***
		* MESFET, metal-semiconductor FET
		* JFETs, junction FETs, junction-gate FETs
		* VTFET, vertical-transport FET
		* Fe FET, ferroelectric FET
		* GFET, graphene-based FET
			+ GNRFET, graphene nanoribbon FET
		* NOMFET, nanoparticle organic memory FET
		* SB-FET. Schottky-barrier FET
		* VeSFET, vertical-slit FET
		* HEMT, high-electron-mobility FET, HFET, heterostructure FET
		* TQFET, topological quantum FET
		* TFET, tunnel FET
		* MODFET, modulation-doped FET
		* HIGFET, heterostructure insulated-gate FET
		* DEPFET, FET formed in fully depleted substrate and simultaneously act as a sensor, amplifier, and memory node
		* JLNT, junctionless nanowire transistor
		* Bipolar-MOS transistors:
			+ BiCMOS, Bipolar CMOS
			+ IGBT, see information under "power semiconductor devices"
		* MOS sensors
		* RHBD, radiation-hardened-by-design
			+ use enclosed-layout-transistors, ELTs
			+ H-gate, another RHBD MOSFET
			+ shallow trench isolation designs
		* OFET, organic FET
			+ use semiconductor device architecture of TFT, thin-film transistors
		* ChemFET, chemically-sensitive FET
			+ FET used as a sensor for measuring chemical concentrations in a solution
			+ compare to chemiresistors
		* ISFET, ion-sensitive FET
			+ for measuring ion concentrations in a solution
		* BioFET, Bio-FET, biosensor FET, FET-based biosensor, field-effect biosensor, FEB, biosensor MOSFET
		* DNAFET, DNA FET
			+ biosensor that is based the field effect due to partial charges of DNA molecules
		* VMOS, vertical MOSFET, V-groove MOSFET
			+ MOSFET with V-groove shape vertically cut into the substrate material
		* Additional notes:
			+ flowFET
				- microfluidic analog of FETs
				- a microfluidic component
	- transistors manufactured using:
		* SOI, silicon-on-insulator
			+ types of insulators:
				- silicon dioxide
				- sapphire
					* SOS, silicon on sapphire
			+ ***SOI MOSFETs***
				- ***PDSOI, partially depleted SOI MOSFETs***
				- ***FDSOI, fully depleted SOI MOSFETs***
		* GOI, germanium-on-insulator
	- BJTs, bipolar junction transistors
	- SiGe, silicon germanium
	- GaAs, gallium arsenide
	- SiC, silicon carbide
	- LET, light-emitting transistors
		* organic LETs
			+ for digital displays and on-chip optical interconnects
			+ can be used in an active matrix of OLETs, which OLEDs cannot be used to form
				- OLEDs can only form active matrix of OLEDs, in combination with switching elements (such as TFTs, thin-film transistors)
	- for LEDs:
		* InAs, indium arsenide
		* InSb, indium antimonide
		* InP, indium phosphide
		* organic LEDs:
			+ use organic semiconductors
	- for photovoltaic solar cells:
		* selenium sulfide
	- RF CMOS
		* based on LDMOS
	- power semiconductor devices, for power electronics:
		* power MOSFETs
			+ HexFET, hexagonal type of power MOSFET
			+ UMOS, trench-MOS, trench-gate MOSFET
		* DMOS, double-diffused MOSFET
			+ LDMOS, lateral DMOS, lateral-diffused MOSFET, laterally-diffused MOSFET
				- planar double-diffused MOSFET
				- RF LDMOS
					* for power amplifiers and other applications
			+ VDMOS, vertical DMOS
		* IGBT, insulated-gate bipolar transistor
		* SCR, silicon-controlled rectifiers
		* thyristors
			+ GTO, gate turn-off thyristors
			+ MCT, MOS-controlled thyristors, or MCT, MOSFET-controlled thyristors
				- MOS-gated thyristors
			+ IGCT, integrated gate-commutated thyristors
		* triac
		* diodes
			+ Schottky diodes, or Schottky barrier diodes, or hot-carrier diodes
			+ PiN diodes
				- has wide, undoped instrinsic semiconductor region between p-type semiconductor and n-type semiconductor
				- for RF applications:
					* RF power amplifiers
		* silicon-controlled switches
		* classifications:
			+ based on number of terminals:
				- 2-terminal semiconductor devices
				- 3-terminal semiconductor devices
				- 4-terminal semiconductor devices
			+ based on proportion of carriers:
				- majority carrier devices
				- minority carrier devices
		* parameters:
			+ breakdown voltage
			+ on-resistance
			+ rise & fall times
				- rise times
				- fall times
			+ safe-operating area
			+ thermal resistance
	- point-contact transistors
	- UJT, unijunction transistor
		* programmable UJT, or programmable unijunction transistor
	- *transistor classification based on number of terminals*:
		* tetrode transistors:
			+ 4 active terminals
		* pentode transistors:
			+ 5 active terminals
+ device modeling for other devices:
	- memristors
	- memtransistors
		* 2-terminal devices
		* 7-terminal devices
	- memistors
		* 7-terminal devices
	- molecular electronics
		* molecular scale electronics, or single-molecule electronics
	- [organic electronics](https://en.wikipedia.org/wiki/Organic_electronics)
		* organic electronics
			+ organic solar cells
			+ photovoltaics
		* organic field-effect transistors, organic FETs, OFETs
		* organic light-emitting diodes, OLED
			+ active-matrix OLED, AMOLED
	- supramolecular electronics
	- trancitors, "transfer-capacitors"
+ large-signal nonlinear semiconductor device modeling
	- physical models, based on semiconductor device physics
		* approximate physical phenomena
		* pamateric models for physical properties:
			+ oxide thickness
			+ substrate doping concentration
			+ carrier mobility
		* for simplified estimates of signal-swing limitations
	- empirical models, using curve fitting with experimental data to obtain statistical models
+ small-signal nonlinear semiconductor device modeling
	- to evaluate:
		* stability
		* gain
		* noise
		* bandwidth
		* bias point, or Q-point or quiescent point
	- small-signal parameters, from production-line testing and circuit design
		* for predicting:
			+ circuit gain
			+ input impedance
			+ output impedance
		* from parameter sets of 2-port networks:
			+ T-parameters, transmission parameters
			+ h-parameters, hybrid-parameters
			+ z-parameters, impedance parameters
			+ y-parameters, admittance parameters
			+ S-parameters, scattering parameters
+ methods:
	- explicit solution
	- iterative solution
	- graphical solution
+ types of modeling approximation
	- piecewise linear model
	- mathematically idealized semiconductor device models



Sets of skills for device simulation TCAD are:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.








###	Mask Data Preparation, MDP


This includes:
+ layout-to-mask preparation
+ mask generation



The sets of skills are:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.







###	Process Design Kit (PDK) Development



The sets of skills for Process Design Kit (PDK) are:
+ skill set:
	- Design Kit Development: Developing Siemens EDA Design Kits for worldwide foundries, including OpenAccess PDK, iPDK, and TDK development to keep competence and leading the innovation.
	- Technical Contribution: Growing the development of design kits in Taiwan. Demonstrate the ability to drive and encourage a highly productive development team.
	- Communication: Being passionate to communicate technical issues within the team and division efficiency and optimally. Demonstrating the ability to communicate within a globally distributed division.
	- Technological Comprehension: Understanding the several methods used to develop Design Kits, identifying weaknesses and advantages of each. The candidate will chip in technical expertise to a team, develop the kits, the software, and the processes used to build each.
	- The Design Kit Development Engineer will be part of a team of design kit developers responsible for the development, QA, and delivery of high quality Process Design Kits (PDK) to Siemens EDA foundry partners. The appropriate candidate will have experience in the development and QA of process design kits including Pcell, symbol, and device callbacks. We are looking for an engineer who can adapt to different methodologies used in the development, QA and use of Design Kits from different EDA companies and foundries.
	- BS in CS/EE with 5+ years or MS with 3+ years of practicing in EDA/CAD engineering is needed.
	- Showing strong programming skill in languages like Python, TCL, Perl, C or C+ - Deep understanding of scripting, CAD engineering and layout design methodologies.
	- Proven experience in any of design kits development cycle, devices layout and physics is a must.
	- Self motivated, quick learner and able to work independently in a large amount of automatically generated code.
	- Ability to lead multi-functional projects, working closely with marketing and sales on the entire development process from requirements through end-customer delivery.
+ skill set:
	- With Bachelor or Master's degree in EE, CE, or CS with above 24-year validated experiences on large-scale enterprise software projects is extraordinary but not required. Although, of course, that if you know how to develop new algorithms, handle external tool integration and optimization in large-scale software projects, is much appreciated.
	- You have a good understanding of topics around C/C++ software development and debugging techniques.
	- Bachelor of Science or Master of Science. in Electrical Engineering, Computer Science, Computer Engineering with 24-year experiences in ASIC multiple die graphic presentation in OpenGL & design multiple die data.
	- C/C++ proficiency
	- Knowledge of algorithm development, graph theory and geometry manipulation and debugging skill
	- Knowledge of Lex, Yacc, Qt / OpenGL, Linux, Shell script and Tcl language would be a plus
	- Knowledge of multithreaded implementation and Linux/UNIX is a plus
	- Prior experience with EDA design file formats is highly preferred
	- Excellent English & Mandarine languages communication skill
+ skill set:
	- Principal Software Engineer
	- Cadence is seeking candidates to fill open positions in the EMX Product Engineering team as more customers utilize EMX's world-class capabilities to design and develop their new products.
	- Cadence is a pivotal leader in electronic design, building upon more than 30 years of computational software expertise. The company applies its underlying Intelligent System Design strategy to deliver software, hardware and IP that turn design concepts into reality.
	- Cadence customers are the world's most innovative companies, delivering extraordinary electronic products from chips to boards to systems for the most dynamic market applications including consumer, hyperscale computing, 5G communications, automotive, aerospace industrial and health.
	- As an EDA Development Engineer for the EMX family of products, you will be responsible for capturing the requirements of, developing, testing and delivering software integrations between EMX / EMX Designer and other EDA tools within the Cadence EDA portfolio. You will work closely with other members of the EMX Product Engineering and R&D teams to respond to development and enhancement requests, focusing primarily upon the usability and user experience of EMX and EMX Designer and their interactions with other Cadence tools. Some travel may be required.
	- Develop, enhance and maintain the integrations of the EMX product family and their interactions with the Cadence Virtuoso Studio and Virtuoso ADE product families.
 	- Work in cooperation with local/international Field Applications team members to capture feedback and usability improvement requests for the EMX family of products.
 	- Work in cooperation with the EMX Product Engineering and R&D teams to transform feedback and improvement requests into detailed requirement specifications.
 	- Translate the requirement specifications into working software implementations.
 	- Develop in SKILL / SKILL++ / Python / Perl / shell scripting.
 	- Perform detailed testing of the software implementations in preparation for release to customers.
 	- Author documentation and work with Technical Publications to ensure its inclusion into correct and easy to understand documents.
 	- Bachelor or master's degree (or equivalent) in Computer Science/Engineering
 	- A programming background with at least 8 years of professional experience
 	- Experience writing clean, structured and maintainable code
 	- In-depth knowledge of SKILL, SKILL++, Python, Perl and shell scripting and their usage in EDA tool and flow development
 	- Prior development experience with integrations into Cadence EDA tools such as Cadence Virtuoso Studio and Virtuoso ADE product families
 	- Passionate about usability and delivery of right-the-first-time integrations
 	- Creativity and out-of-the-box thinking
 	- Capable of giving and accepting constructive feedback
 	- Collaboration and customer interaction skills
 	- Oral and written English proficiency
 	- Experience working in an agile and fast-paced product development environment
 	- Experience with GUI development is a plus
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.











###	Physical Verification


Includes:
+ DRC, design rule check
+ LVS, layout verses schematic check
+ XOR check
+ antenna check
	- check for antenna effects
+ ERC, electrical rule check
	




The sets of skills are:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.





###	MEMS CAD, and NEMS CAD



The sets of skills are:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






















###	Other EDA topics


Other EDA topics:
+ design databases
+ ***radiation hardening***
	- ***radiation-hardened*** ICs, ***rad-hardened*** ICs, ***rad(iation)-hardened*** ICs, or ***rad-hard*** ICs, or ***hardened*** ICs (with context provided to indicate ***radiation-hardened*** ICs)
	- protect against:
		* TID, total ionizing dose
		* ELDRS, enhanced low dose rate effects
		* neutron and proton displacement damage
		* SEEs, single event effects
	- sources of radiation damage:
		* cosmic ray radiation
		* solar particle events
		* Van Allen radiation belts* 
		* secondary particles resulting from the interaction of other kinds of radiation with structures around the electronic devices
		* nuclear reactors, in nuclear power plants
			+ gamma radiation
			+ neutron radiation
		* particle accelerators
		* nuclear explosions
		* chip packaging materials
			+ fixed by using:
				- more pure, or purer, chip packaging materials
				- error correction code, or error correcting code, ECC
	- radiation effects on electronics
		* fundamental mechanisms
			+ lattice displacement
			+ ionizing effects
		* resultant effects
			+ total ionizing dose effects
			+ transient dose effects
			+ systems-generated EMP effects
		* digital damage of SEEs, single event effects
			+ single-event transient
			+ single-event upset
			+ single-event latchup
			+ single-event snapback
			+ single-event induced burnout
			+ single-event gate rupture
		+ SEE testing, or testing for single event effects
	- radiation hardening techniques
		+ physical radiation hardening
		+ logical radiation hardening








###	Hardware Security


####	Notes about Hardware Security

hardware security topics from Trust-Hub website Trust-Hub.org:
+ System-on-chip (SoC) Attacks and Security
+ Intellectual Property (IP) Trust and Assurance
+ Reverse Engineering
+ Invasive and Semi-invasive Physical Attacks
+ Computer-aided design (CAD) for Security
+ Side Channel Attacks and Mitigation
+ Hardware Security Primitives (PUFs, TRNGs, etc.)
+ Hardware Obfuscation
+ Hardware Trojans and Backdoors
+ Counterfeit Electronics
+ FPGA/eFPGA Security
+ IoT and Cyber-physical System Security
+ Emerging and Nanoscale Device Security




####	Skill Sets for Hardware Security



+ skill set:
	- Broad understanding to computer security and crypto algorithms like AES/SHA/RSA/ECC
	- Familiar with Tilelink/AMBA/AXI bus protocol
+ skill set:
	- Experience with hypervisor / container development
		* Especially, Xen or OpenXT
	- Experience with Trusted Platform Module (TPM)
	- Experience with firmware-level code
	- FPGA physical design
	- Experience with device characterization or PUF techniques
		* physical unclonable function
	- Experience with ASIC analog and/or digital design
+ skill set:
	- Experience with RoT techniques including TPM
	- Silicon Root of Trust (RoT)
	- trusted platform module (TPM)
+ skill set for Sr. SW Engineer - HW Security Analysis:
	- Reporting to the VP of Engineering, the Sr. SW Engineer – HW Security Analysis will be responsible for developing innovative solutions that shape the way the emerging process of HW security verification and analysis is performed.
	- Bachelor's degree in Computer Science/Engineering (MS or PhD preferred)
	- Expert level engineer with a minimum of 10 years of proficiency in algorithms and data structures for digital logic in the domains of Simulation, Synthesis or Formal Verification or similar products
	- Deep knowledge in design and architecture of efficient, scalable software systems and data structures to support compilation of billion gate designs
	- Experience in multi-threading, multi-tasking and job distribution to support analysis and netlist transformations to minimize runtime and memory footprint
	- Expert programming and debug skills in C/C++.
	- Ability to operate in a small team and be an effective communicator.
	- This position can be based anywhere in the continental USA. Some travel may be required with return to normal business from COVID.
	- Preferred qualifications
		* Experience in the development and support of commercial EDA software
		* Experience in the implementation and verification of SoC designs
		* A background in Computer Security or familiarity with Computer Security topics
+ skill set:
	- The PhD candidate will contribute to the research, development, publication and product adoption of system security technologies for future computing architectures targeting AI and compute, working on real world problems for a wide range of Huawei products and services to preserve and prove their trustworthiness through technology, from a unique research position connecting Academia and Industry.
	- Assess system security and platform resilience risks of application scenarios such as AI and compute
	- Research on innovative concepts and architectures in the field of Trustworthy Computing
	- Implement proof of concepts and support technology adoption in products
	- Publish research papers and technical reports at top security conferences and collaborate with academic partners
	- Improve, by design, the end to end system security capabilities of future Huawei products
	- You have recently completed or will soon complete your master studies in computer science, information technology, cybersecurity, electrical engineering, or mathematics
	- You have research experience in system security, applied cryptography, computer architectures, OS design
	- Experience with enclave engines, TEEs, secure processing architectures and accelerator designs is a plus
		* TEEs, trusted execution environment
	- You have good programming skills in C, Rust, C++, Python, Go and in system programming
	- You have demonstrated affinity for concept design and hands-on validation
	- You have a passion for finding solutions for complex technology issues
	- You have excellent collaboration and communication skills
	- You are self-starting and self-motivating, willing to take initiatives and feel the responsibility for your project
+ skill set:
	- We are looking for a senior SoC engineer who can leverage their understanding of system-level security goals to disseminate security requirements into the definition and development of ISA, platform, and firmware security capabilities for Ampere products spanning processors cores, IP, SoC, and platforms, while keeping up to date with the latest security threats and standards.
	- The Hardware Security Architect candidate will join a small but growing CPU architecture team, advancing the art of high performance SoC development targeted for data center customers. Ideal candidates will channel their passion for secure products to contribute in cross-spectrum flow and methodology, working closely with processor and SoC architects and software architects to enhance Ampere's security solution end-to-end. They will have high levels of flexibility to craft productivity flows to make highly visible contributions.
	- The Ampere Architecture Group team turns ideas into reality. We are a group of technologists with tremendous experience shipping dozens of server products at multiple semiconductor companies. By listening to customers, driving industry standard protocols, and designing high-performance IPs and SoCs, Architects push products forward past the bleeding edge of microprocessor design. Architects are resourceful, and craft well-tuned designs to meet ecosystem requirements in a timely cadence, ultimately delighting Ampere's cloud customers.
	- You will be the technical leader, at the heart of the solutions teams working closely with hardware SoC and IP development teams. Your role will be to understand security solutions at the system level and then provide expert input to product teams to help them understand and correctly implement their parts of the overall solution. This may include:
		* Collaborate across the company to guide the direction of platform security and develop a long-term security roadmap for our products, working with hardware, software, and field support teams.
		* Work with customers and partners to identify and address security issues and threats.
		* Own product-level security requirements and work with the solution teams and IP product teams to ensure product implementation.
		* Contribute to product design reviews via threat modeling. You will identify security needs, provide optimal design mitigations, and contribute to the security verification plans.
		* Engage with our ARM partners and be the expert in new security architecture features and provide guidance for integration into future Ampere products.
		* Deliver product-level proposals for how the security objectives will be implemented and provide guidance on appropriate design mitigations.
		* Analyze requirements, as well as software and integration approaches to identify vulnerabilities and solution architecture, design, and implementation flaws.
		* Provide security guidance and assistance throughout the development lifecycle ensuring Ampere solutions and IP products are specified, designed, developed, implemented, integrated, and tested to meet the requirements for product level security.
		* Stay up to date with the latest security threats, have a good understanding of the state of the art techniques spanning software and hardware developed to address those threats, and ensure the security objectives that are fed into product teams adequately reflect the needs of the product to mitigate relevant threats and continue to contribute to the external security community.
		* Assist in responding to high-priority issues or customer questions where your expertise can help.
	- What You'll Bring
		* Great communication skills, comfortable with reaching out and asking questions. This is the most important qualification!
		* Technical curiosity, and ability to learn and grow. Nobody around you will have all the answers!
	- Education
		* MSEE/MSCS with 8+ years of experience, or
		* PhD in EE/CE/CS with 5+ years of experience, concentrating in cybersecurity
	- Preferred Qualifications
		* Knowledge of Secure Development Lifecycles (SDLs), ideally as applied to semiconductor hardware
		* Extensive understanding of industry standard encryption, security protocols, and current ISA, SoC and System Software/FW mechanisms for mitigating typical security attacks for data center and computing platforms
		* Experience designing & testing SoC hardware and low-level software security
		* Knowledge of system security processes and standards and how these standards are incorporated into solution definition, design, development, and validation/verification activities
		* An understanding of how hardware and software security interact and influence one another
		* A natural inclination to persuade (not push) when introducing new concepts and processes
		* You have directly worked on several of the following:
		* System architecture for server platforms
		* SoC security architecture and security fundamentals including secure boot
		* Modern server manageability protocols
		* ARMv8 architectures and related security functionality
		* Cryptography algorithms and standards, including implementations and application
		* Security mitigations against physical attacks including fault injection and side channel attacks
		* Remote attestation mechanisms based on TPM or other solutions
		* Digital Rights Management (DRM) standards
		* Security threat modelling and penetration testing
		* Certification standards and compliance testing
		* Security testing on covert red team campaigns, or similar offensive security experience
+ skill set:
	- Principal Security Architect will develop a strategic direction for the security-related architecture of Lattice products, working closely with FPGA system and architecture experts to advance the company's presence within security-sensitive systems
		* Reduce risks, threats, and vulnerabilities in systems built with Lattice products
		* Drive Lattice's roadmap for data and design security within our programmable logic product line
		* Meet with customers and ecosystem partners to ensure requirements are understood, implementations are sound, and the broader ecosystem is moving to meet the future challenges
		* Coordinate across functional business units to ensure robust, secure posture from design to implementation
		* Represent Lattice at industry forums related to data and design security
		* Coordinate development of tools, methods, and training to support staff in achieving security objectives and ensure effectiveness of security standards
		* Will partner closely with engineering, sales, marketing, applications, and end to end customers
		* Strong customer facing skills
	- Behaviors
		* Dedicated: Devoted to a task or purpose with loyalty or integrity
		* Team Player: Works well as a member of a group
		* Leader: Inspires teammates to follow them
	- Motivations
		* Goal Completion: Inspired to perform well by the completion of tasks
		* Ability to Make an Impact: Inspired to perform well by the ability to contribute to the success of a project or the organization
		* Entrepreneurial Spirit: Inspired to perform well by an ability to drive new ventures within the business
	- Education
		* Required: Bachelors or better in Computer Science or related field.
		* Preferred: Masters or better in Computer Science or related field.
	- Experience
		* Expert knowledge/background in secure code authentication/attestation and chains of trust
		* Experience in industry attack, vulnerabilities and solutions around design and data security
		* Working knowledge of online service architectures for connected/IOT systems
		* Well versed in Secure Architecture and Design fundamentals
		* 10 years: 10+ years of experience in the hardware data security industry



















####	Skill Sets for Cyber-Physical System Security


Cyber-physical system security includes:
+ automotive security
+ autonomous underwater glider, AUG
+ robotics security



Skill sets for cyber-physical system security, including robotics security and automotive security:
+ experience with automotive security:
	- CAN
	- OTA
	- Autosar
	- SILS/HILS
		* SILS, software-in-the-loop simulation
		* HILS, hardware-in-the-loop simulation, HWIL, HITL
			+ for automotive anti-lock braking systems
				- vehicle dynamics, such as suspension, wheeels, tires, roll, pitch, and yaw
				- dynamics of brake systems's hydraulic components
				- road characteristics
			+ fixed-wing aircraft flight control systems
				- fly-by-wire control systems
		* EILS, emulation-in-the-loop simulation
	- RTOS
	- QNX
	- AGL
+ programming language security, for RISC processes:
	- function block diagram, FBD
	- ladder diagram, LBD
	- structured text, ST
	- instruction list
	- sequential function chart, SFC
+ skill set for vehicle security architect (middleware), or product security engineer:
	- open software ecosystem
	- collaborate with cross-functional partners
	- lead and influence security architecture, risk analysis, vulnerability testing, and security reviews for vehicle products across Woven Planet cross-functional teams
	- ensure security and privacy by design for embedded or middleware software products
	- assist development teams in architecting and securing the software and hardware ecosystem
	- evaluate the security of middleware, libraries, and protocols for embedded systems
	- lead threat modeling towards components of the hardware abstraction layer, service layer, runtime environment and application layer
		* identify security issues, risks, and associated mitigations
	- audit C++ code to identify and patch security vulnerabilities
	- provide designs to implement the architected solutions
	- evaluate and recommend new and emerging security products and technologies
	- 3 years of experience in software security as an architect, or a developer of security solutions
	- knowledge and experience in the following domains:
		* security engineering
		* system and network security
		* authentication and security protocols
		* cryptography
		* operating systems
		* application security
	- security expertise in at least one of the following:
		* implementation of multilayered independent levels of security (MILS) architecture for high-assurance embedded systems
		* operating system, ARM, and kernel security
		* security of components of compile time and runtime environment (RTE)
		* practical experience of development of libraries (C/C++) for software security
	- knowledge of DevSecOps methodology and components of a secure SDLC
	- experience with secure operating systems architecture, security design, and threat modeling
	- experience with:
		* development of:
			+ software components for automotive systems or robots
			+ hardware abstraction layer (HAL) components
		* security of real-time operating system, RTOS
		* in-depth knowledge of UNIX-like operating systems and their security components, preferable - used in automotive industry, such as automotive grade Linux
		* vehicle software development
		* kernel and hypervisor security
	- understanding of standards:
		* ISO 21434
		* ISO 26262
+ skill set:
	- develop and review requirements, and strategy and road map, for:
		* static security testing
		* dynamic security testing
	- drive investigations into security issues, identify opportunities for further automation to eliminate future issues
	- knowledge of application security tools:
		* SAST
		* DAST
		* SCA
	- experience managing execution and high-quality product delivery
	- ability to handle multiple competing priorities in a fast-paced environment
	- excellent analytical and communication skills, as well as ability to take initiative and build productive relationships
	- experience in the design and implementation of security solutions, systems, and mechanisms:
		* data security
		* application security
		* cryptography
		* systems security
		* network security
		* exploit development
+ skill set:
	- participate in threat modeling and application security reviews
	- audit embedded code to identify security vulnerabilities
	- vehicle penetration testing experience
	- knowledge or experience of advanced smart fuzzing strategies:
		* mutational
		* symbolic
		* American Fuzzy Lop, AFL
	- experience with QNX
	- understanding of vehicle functional safety standards:
		* ISO26262
+ skill set:
	- security-critical code at scale
	- security automation tools and processes
	- information security:
		* threat modeling
		* secure code review
		* security testing
	- build and maintain security tooling and infrastructure
	- lead the design and engineering of static analysis tooling
		* SAST
		* semantic code analysis
		* vulnerability management
	- foster a culture of automation, and build sustainable tooling systems
	- identify application security risks, define requirements, and then build and extend systems to help reduce and track these risks






##	Additional Information about EDA

+ [IP-XACT is an XML format that defines and describes individual, re-usable electronic circuit designs (individual pieces of intellectual property, or IPs) to facilitate their use in creating integrated circuits (i.e. microchips). IP-XACT was created by the SPIRIT Consortium as a standard to enable automated configuration and integration through tools.](https://en.wikipedia.org/wiki/IP-XACT)
+ [The SystemRDL language, supported by the SPIRIT Consortium, was specifically designed to describe and implement a wide variety of control status registers. Using SystemRDL, developers can automatically generate and synchronize register views for specification, hardware design, software development, verification, and documentation.](https://en.wikipedia.org/wiki/SystemRDL)
	- [SystemRDL Compiler](https://github.com/SystemRDL/systemrdl-compilerSystemRDL Compiler)
	- [open-register-design-tool, Ordt](https://github.com/Juniper/open-register-design-tool)
	- https://www.eda.org/images/downloads/standards/systemrdl/SystemRDL_2.0_Jan2018.pdf
+ Automatic Register Verification (ARV)
+ synthesizable RTL, UVM, c-header, RALF eRM, SystemRDL, IP-XACT
+ UVM, Universal Verification Methodology, SystemVerilog based
+ VMM, Verification Methodology Manual
+ OVM, Open Verification Methodology
+ URM, Universal Reuse Methodology
+ eRM, e Reuse Methodology, e Verification Language











##	Generic Skill Sets for Lower-Level EDA Software Development




+ skill set:
	- Python Experts for Electronic Design Automation (EDA) tool development  
	- EDA tool development for SoC design, integration & verification
	- Model hardware design problems in software and provide automation
	- Create UML models for design data and generate code from it
	- Create data structure to hold design data, fill them with formalized data (e.g. XML, HDL-Models), and generate code out of it.
	- Educational Qualification:  Bachelor's / Master Degree in  Electronics & Communication Engineering / VLSI 
	- Experience: 1 - 4 years related experience.
	- Strong Expertise in Python / C++ , Data structures, Algorithms, OOPS concepts
	- Exposure to Artificial Intelligence / Machine Learning / Deep Learning concepts
	- Experienced in designing/ coding in software/EDA tools and flows
	- Exposure to Verilog / VHDL / System Verilog / SystemC
	- Understanding of UML modelling language preferred
	- Experienced in using test automation framework like pytest or Google Test.
	- C++, SoC Design, FPGA
	- Willing to dive into new things and pick them up fast
	- Good analytical skills required to evaluate complex situations
	- Focus on exchange of complex technical information
	- Good reporting and presentation skills
	- Good understanding of internal interfaces













##	VLSI Deep Learning & Embedded Deep Learning





Sets of skills for embedded machine learning engineers, VLSI machine learning engineers, embedded deep learning engineers, and VLSI deep learning engineers as well as related roles like embedded computer vision engineers:
+ Research and develop CNN/RNN neural network compression algorithms, focusing on quantization and pruning
+ Either in AI tools; or autonomous embedded area; or FPGA
+ Knowledge of distributed machine learning framework (distributedTensorFlow/MXNET) or cloud/edge federation is a plus
+ skill set:
	- Understanding On TensorRT is an Added Advantage
	- Knowledge of Frameworks like DNN,BLAS,RAND,SPARSE.
+ workflow for embedded computer vision product development:
	- dataset sourcing
	- dataset curation
	- dataset annotation
	- algorithm design
	- algorithm implementation and optimization
	- identifying the right hardware platform for the embedded computer vision system
	- hardware design
	- software integration
	- product testing and validation
+ embedded deep learning:
	- Analyze, test and improve neural network compression algorithms
	- Experience with at least one deep learning algorithm, such as CNN/LSTM/GRU
	- Experience with at least one deep learning framework, such as Tensorflow, Pytorch, Caffe, Kaldi
+ Strong knowledge of SOC SW development, such as Nvidia Tegra, T.I. TDA series, Qualcomm Snapdragon.
+ skill set of Senior ML Hardware Architect:
	- $220,000/yr - $320,000/yr
	- Our mission is to radically reduce the cost of Artificial Intelligence.
	- We are the world leaders in algorithm/hardware co-design for artificial intelligence. Our roadmap begins with products 100x better than GPUs and will ultimately deliver products that are many orders of magnitude more cost effective than what is available today. We will ultimately be able to put models the size of ChatGPT into chips the size of a thumbnail.
	- We’re looking for an experienced ML Hardware Architect to help define the architecture of Rain’s next-generation AI accelerators! This person will report to our Lead Architect. 
	- This is a remote role, so you can work from anywhere in the United States.
	- Define the architecture of next-generation AI accelerators to enable novel online learning algorithms 
	- Work closely with the algorithms team to understand and evaluate local and global data movement in systolic and data-flow architectures 
	- Develop architecture simulators for system design, verification, prototyping, and hardware-software co-optimizations 
	- Work closely with the design team to define the micro-architecture of key IP blocks 
	- Work closely with the system software team to develop compilers and ISA extensions to enable new hardware functional units in an SoC 
	- Integrate proprietary accelerators and design macros with standard service cores
	- MSEE with 5+ years or PhD in Electrical Engineering and/or Computer Engineering with a focus on SoC architecture design, AI accelerator design, system modeling, and PPA analysis 
	- Deep understanding of processor ISA including x86, ARM, and RISC-V 
	- Strong understanding of memory management schemes, on-chip and off-chip data movement, logic-memory optimizations, and efficient code placement techniques 
	- Experience with SystemC, Python, C/C++, and the ability to write production-ready, annotated code 
	- Experience designing state-of-the-art data flow, spatial, and systolic architectures and the ability to integrate synchronous and asynchronous design macros with both digital and mixed-signal circuit collaterals 
	- Familiarity with compiler optimizations, synthesis, code generation, programming models and computer architecture 
	- Familiarity with the integration of novel accelerators and design macros with service cores 
	- Familiarity with algorithmic techniques for on-device learning (online/continuous learning) 
	- Developed the architecture of at least one state-of-the-art AI accelerator 
	- Familiarity with deep learning models and willingness to learn novel algorithms and translate them into specifications for hardware accelerators 
	- Exhibit a high degree of motivation and independence 
	- Strong communication skills, both written and verbal
	- PhD in Electrical Engineering and/or Computer Engineering with focus on near- and in-memory computing architectures for AI acceleration 
	- Understanding of state-of-the-art SRAM based in-memory computing macros
+ skill set:
	- As a Software Engineer in computer vision/deep learning, you will be developing the “eye” of our vehicles. This includes designing, training, and evaluating perception solutions, specifically, large scale image/LIDAR data classification, segmentation, tracking, etc. You will also research and apply state-of-the-art computer vision algorithms into production.
	- Strong programming skills in C/C++ or Python
	- Strong mathematics and analytical skills
	- Work experience in deep learning platforms such as Caffe or Tensorflow
	- Minimum of a Masters Degree in Computer Science or equivalent with 3+ years experiences of deep/machine learning or computer vision
	- Work experience with LIDAR data is preferred
+ skill set:
	- Knowledge in digital logic for HW safety/protection – ECC, Parity, WDT etc.
	- Experience in AMBA AXI, AHB, and APB protocols
	- Experience in lint checks, synthesis, and timing analysis
	- Knowledge in Automotive ISO 26262 Functional Safety Standard is a plus.
	- Experience with DSP, Datapath design and floating-point math a plus
	- Understanding of GPU/AI/ML Processor architecture
+ skill set:
	- Feature engineering infrastructure
		* Feature engineering infra
	- Develop and maintain a set of frameworks, APIs and tools on top of Tensorflow that enable a fast research to production lifecycle
	- Provide tooling to help ML practitioners evaluate, debug, and improve ML algorithms, data and hyperparameters
	- Web app for managing data lineage, experiment / metadata / artifacts, visualizing metrics (P/R, custom metrics etc.) and data distribution
	- Collaborate with other Bets to productionize ML research (e.g. PBT, AutoML, Model/Data understanding, compression)
	- Apply software engineering rigor on ML (CI/CD, automation etc.)
	- Optimize everything around the nets (pruning, quantization etc.) and robotics system performance analysis / optimization through hardware/software co-play
	- BS, MS or PhD in Computer Science, similar technical field of study, or equivalent practical experience
	- Passion in making things run fast
	- Experience programming in Python or C++.
	- Elementary Tensorflow and Machine Learning knowledge
	- Experience building and architecting large-scale, production quality backend systems, especially in applied machine learning or data pipeline
	- Familiar with TensorFlow
	- Familiar with parallel / distributed systems
	- Experience with modern web stack /data visualization techniques (e.g. Angular, JavaScript/TypeScript).
	- Experience with embedded / real time / robotics systems, and performance optimizations
	- Experience with machine learning compiler / runtime or GPU/AI accelerator
	- Experience/interest with ML acceleration ( compression, quantization, pruning etc.)
	- Experience with metrics and evaluation for large systems
	- SRE/Devops and passionate about applying software engineering best practices to ML
+ skill set:
	- Strong C/C++ and Python programming skills;
	- Experience with embedded systems and hardware;
	- Working knowledge of Git.
	- Familiarity with deploying machine learning on embedded devices using TensorFlow Lite or similar framework;
	- Experience training models using machine learning frameworks like TensorFlow, PyTorch or MXNet;
	- Experience optimizing code to run on GPU, DSP or neural processors;
	- Experience with real-time operating systems like FreeRTOS or ThreadX;
	- Experience with unit tests and Test Driven Development;
	- An understanding of Continuous Integration systems.
	- Software design and implementation;
	- Collaboration in the team's agile planning processes;
	- Code reviews and support for other development on going within the team;
	- Collaboration with engineers from a range of disciplines to deliver production ready systems.
+ skill set:
	- Develop highly scalable tools leveraging machine learning models to solve problems such as classification, clustering, topic modeling, natural language processing and recommendation
	- Develop in-house machine learning tools and pipelines to support fast experimentation of machine learning models
	- Work with other engineers to identify and solve machine learning problems
	- Minimum Qualifications
		* Experience in one or more of the following areas: machine learning, recommendation systems, deep learning and data mining
		* Expert knowledge in Java or Scala
		* Experience with scripting languages such as Perl, Python, and shell scripts
	- Preferred Qualifications
		* MS degree in Computer Science or related quantitative field with 3+ years of machine learning related work or research, or PhD degree in Computer Science or related quantitative field
		* Experience with machine learning frameworks such as TensorFlow, PyTorch or MxNet
		* Publications in trade journals such as JMLR or Machine Learning, or Presentations at related conferences such as ICML, NeurIPS, KDD, SIGIR and etc.
+ skill set:
	- GrAI Matter Labs is looking for a talented Senior AI Processor Architect to help us shape the next generation of our GrAI Core Architecture and its pre- and post-processing peripherals (such as image processing, FFT, IFFT...). As a Senior Core Architect you will own the specifications of one or more components of our core architecture. You will analyse the performance of our processors for selected applications, and propose, quantify and specify architectural features and optimisations to improve the performance, cost and power consumption of our next generation GrAI Core.
	- You are expected to play a key role in innovation, working with partners on benchmarking and optimizing architectural features to match the needs of the application and efficiently mapping and prototyping them on the company's architecture, as well as adapting such concepts to work in production-grade systems.
	- Our ideal architect is creative, curious, knowledgeable, and not afraid to get their hands dirty by helping the hardware and tools teams with implementation tasks when necessary. The right candidate knows how to find solutions that are both theoretically sound and provide the best cost-performance trade-offs, while also considering all the practical constraints created by the development process.
	- As part of the architecture team your main responsibilities are:
		* to carry out analysis of the performance and cost of the existing core architecture;
		* to propose and evaluate new architectural features in collaboration with the other members of the architecture team;
		* to draft and own specifications of features in the next generations of the GrAI Core;
		* to provide guidance and assistance to hardware and tools engineers;
		* to contribute to the long-term technological direction of the company.
		* You will be working on exciting and emerging topics, finding new techniques and silicon technologies to exploit sparsity and event-driven processing of neural networks to enable new applications on the Edge.
	- Master or PhD in Electrical engineering, Computer Engineering or Computer Science;
	- 5+ years of experience in designing chips and hardware;
	- Excellent theoretical knowledge and practical experience in computer architecture and hardware design, including network-on-chip, datapath, memory hierarchy;
	- Excellent skills and experience as a hardware designer;
	- Knowledge of VLSI process technology and backend is a big plus;
	- Knowledge of compilers, simulators and other software development tools is a plus.
	- Knowledge of machine learning, deep learning and AI applications is a plus.
+ skill set:
	- AI Silicon Design – RTL/Architecture Engineer:
	- RTL design and microarchitecture definition of high-performance microprocessors going into industry leading AI/ML architecture. The person coming into this role will define new features and code the RTL across multiple areas of our processor Core. The work is done alongside with a group of highly experienced engineers across various domains of the AI chip.
	- ***Define architecture and logic design requirements by understanding rapidly evolving AI/ML models; work with engineers across domains to understand real world use cases***
	- RTL coding in Verilog leveraging on both industry tools as well as open-source infrastructure
	- Drive trade-offs for your logic by working closely with performance, DV and physical design engineers to craft optimal solutions that meet the design goals
	- ***Deploy innovative techniques for improving power, performance and area of the design, drive experiments with RTL and evaluate synthesis, timing and power results***
	- ***Debug RTL/logic issues across various hierarchies (ex: core, chip) in both pre-silicon and post-silicon environment***
	- BS/MS/PhD in EE/ECE/CE/CS with at least 5 years of experience
	- ***Experience with computer architecture/system components/network/fabrics as a part of a CPU, ASIC or SOC design team***
	- Expertise in logic design and ability to evaluate functional, performance, timing and power for you design
	- Strong experience with hardware description languages (Verilog, VHDL) and simulators (VCS, NC, Verilator)
	- ***Expertise in microarchitecture definition and specification development***
	- ***Prior experience in industry standard ISAs – ARM, RISC-V, X86 preferred***
	- ***Strong problem solving and debug skills across various levels of design hierarchies***
+ skill set:
	- Implementation of Tenstorrent IP and SOC RTL logic in Verilog
	- Architecture exploration and modeling
	- ***Occasional verification of Tenstorrent's IP and SOC logic, using advanced verification methodologies –UVM, FPGA prototyping, and emulation***
	- Performance and power verification and validation of Tenstorrent's IP and SOC
	- Runtime firmware and low-level software implementation
	- Benchmark and analyze performance optimizations for key machine learning algorithms across Tenstorrent hardware and software stack
	- Development of frameworks for automating post-silicon verification, data analysis and debug
	- Support board/system design and debug
	- Knowledge of Hardware Description Languages (Verilog/VHDL)
	- Interest and knowledge of processor/computer architecture
	- Interest and knowledge of the full ASIC design flow, including design, verification, synthesis, P&R
	- C/C++ as well as scripting languages (C, C++, Python, Perl, tcl)
	- Experience with high frequency logic design, scalar and vector processor architecture, GPU architecture and programming models, digital signal processing hardware, SoC architecture, memory sub system architecture, real time hardware/firmware systems and PCB design is very beneficial
	- Understanding of deep learning concepts and familiarity with popular machine learning frameworks and models
	- Strong analytical and problem-solving skills
+ skill set:
	- Flex Logix is seeking Inference SoC (System on Chip) and Logic Design Engineers to join our team developing the SoC RTL that controls our Inference SoCs and interfaces; and the “SoftLogic” RTL that controls the execution of the compute kernels of our neural network model operators.
	- Be part of our exciting team developing responsible for designing the RTL that runs on eFPGA (embedded FPGA) and is used to control the execution of neural network layers (we call this SoftLogic).
	- The candidate must be able to micro-architect and deliver eFPGA RTL for the Reconfigurable Tensor Processor to implement neural network operators.
	- The candidate must provide technical leadership in solving new and challenging problems that require coordination with other hardware, software and system engineering teams.
	- Preferred candidate would be able to work in every stage of silicon development: specification, coding, verification, place and route, timing closure and post-silicon validation for SoC to deliver micro-architecture and RTL for SoC and softlogic blocks.
	- BS/MSEE/CE/CS with a minimum of 5 years of experience designing functional units or SOC RTL.
	- Extensive experience coding Verilog or SystemVerilog RTL.
	- Demonstrated experience with very high-speed, pipelined designs (>3 GHz).
	- Proven track record on delivering micro-architecture and RTL code that works on Silicon and meets timing for high-speed designs.
	- Experience fixing critical paths in the design using front-end RTL techniques for FPGA synthesis/place and route tool chain.
	- Experience running Lint, CDC, and other static quality checks.
	- Experience with starting designs from scratch.
	- Experience interfacing with internal and 3rd party IP suppliers.
	- Experience scripting in Python or Perl.
	- Familiarity with C or C++ coding.
	- Familiarity with memory architecture in SoCs.
	- Familiarity with DDR and PCIe standards.
	- Familiarity with NoC or AXI Crossbars.
	- Knowledge of computer architecture, especially in systolic arrays.
	- Experience with FPGA design and emulation.
	- Experience with FPGA and ASIC EDA tools.
+ skill set:
	- Flex Logix is seeking Inference SoC (System on Chip) and Logic Design Engineers to join our team. You would be developing the SoC RTL that controls our Inference SoCs and interfaces and the “Softlogic” RTL that controls the execution of the compute kernels of our neural network model operators. You'll be working with software engineers, marketing specialists, physical design engineers, verification engineers, & deep learning scientists, to implement the features needed to accelerate the next generation of machine learning algorithms.
	- Develop chips that accelerate the execution of neural networks. 
	- Own major portions of our chips; developing them from concept through execution and silicon brings up support. 
	- Provide technical leadership in solving new and challenging problems that require coordination with other hardware, software and system engineering teams. 
	- Work in every stage of silicon development: specification, coding, verification, timing closure and post-silicon validation for SoC to deliver microarchitecture and RTL for the full SoC.
	- BS/MSEE/CE/CS with a minimum of 10 years of experience designing functional units or SOC RTL.
	- Proven track record on delivering micro-architecture and RTL code that works on Silicon and meets timing for high-speed designs.
	- Extensive experience coding Verilog or SystemVerilog RTL.
	- Experience interfacing with internal and 3rd party IP suppliers.
	- Experience scripting in Python or Perl.
	- Experience running Lint, CDC, and other static quality checks.
	- Experience with starting designs from scratch.
	- Familiarity with memory architecture in SoCs.
	- Familiarity with DDR and PCIe standards.
	- Familiarity with NoC or AXI Crossbars.
	- Experience with low power design techniques.
	- Proven track record of first pass silicon success.
	- Familiarity with C or C++ coding.
	- Knowledge of computer architecture, especially in systolic arrays.
	- Experience with FPGA design and emulation.
	- Experience with FPGA and ASIC EDA tools.
+ skill set:
	- Flex-Logix Inference Software team is looking for highly motivated, proactive and curious AI Inference Staff Software Engineer to be a part of its excellent team responsible for the development of the Infer-X Model Compiler. The compiler generates binaries for the Flex-Logix eFPGA platform which controls the nnMAX/TPU computation blocks and memory connections. The individual must be passionate about being part of an aggressive, venture-backed startup team that is revolutionizing the way chips are architected, designed and programmed. This is an exceptional opportunity to develop the technology that breathes life into AI inferencing solutions targeting systems in medical, industrial, automotive and other Enterprise edge applications.
	- Architect, develop, and integrate new DNN Model descriptions to InferX Model Compiler.
	- Design, develop, and maintain efficient, reusable, and reliable InferX Model Compiler software and documentation.
	- Expand functionality of InferX Compiler components, written in modern C++.
	- Bring-up and debug new/existing compiler components.
	- Develop and maintain unit tests for new compiler components.
	- Collaborate with other teams such as HW Design, Solutions Architects and Test/QA.
	- Work closely with Field teams to support customer engagements.
	- Perform defect tracking and peer code reviews.
	- Bachelor's or Masters in CS/EE with 10+ years of industry experience.
	- Knowledgeable with C/C++ and Python.
	- Knowledgeable in data structures, graphs and algorithms.
	- Incorporate strong troubleshooting skills using software (automated tests), hardware (RTL simulations) and other resources (datasheets and design documents).
	- Knowledgeable in Computer Architecture, Digital Logic SOC Design and FPGA Design.
	- Familiarity with modern version control systems like GIT.
	- Highly dynamic, results-oriented, and self-motivated personality able to work in a small team with minimal direction.
	- Excellent written and verbal interpersonal skills.
	- Ability to work across functional groups, sites and organizations.
	- Experience with DNN/Convolution AI models for Computer Vision applications.
	- Experience with frameworks such as TensorFlow Lite and PyTorch.
	- Experience writing applications for SIMD processors or accelerators like GPUs.
	- Experience with PC architectures and chipsets.
	- Experience with Multicore Programming.
	- Experience with FPGA Synthesis Tools such as Synopsys Synplify.
	- SCM experience in a GitLab based workflow.
	- Experience with Continuous Integration Systems (Jenkins, SonarQube) and static analysis tools.
	- Test Driven Development experience.
+ skill set:
	- 5+ years of experience building production software systems within large engineering projects for consumer products on mobile SoCs, specially iOS devices
	- Hands-on experience with at least one compiled language (C/C++/Objective-C, Swift, Go, Java, Rust, etc.), and multi-threaded applications
	- Familiarity with modern mobile development frameworks (e.g., Flutter, Xamarin, Swiftic) and tools (e.g., IoC/DI, analytics, A/B testing, CI-CD and build systems like Bit, Buck, Bazel)
		* https://en.wikipedia.org/wiki/List_of_build_automation_software
		* https://en.wikipedia.org/wiki/Buck_(software)
		* https://en.wikipedia.org/wiki/BitBake
		* https://bit.dev/
	- Experience with profiling and tracing tools
	- Experience with Model Compression techniques (Quantization, Pruning, Distillation)
	- Experience with ***PyTorch Mobile, Tensorflow Lite*** or other similar Edge Inference frameworks
	- Experience with techniques to offload compute to GPU, DSP etc.
	- Experience developing Machine Learning models, especially for resource constrained computing environments
+ skill set:
	- Responsible for or assist in the definition of next-generation GPGPU chips and the planning of related software and hardware products. Collect key appeals through architecture research, market research, competitive product analysis, customer interviews, etc., plan chips and hardware products and be responsible for product competitiveness;
	- Lead or participate in the definition of chip specifications, participate in the whole process management of chip architecture design, chip mass production, chip enablement and product optimization; and be responsible for defining various hardware products to meet customer scenario needs;
	- Familiar with various GPGPU and AI chip architectures, and have a deep understanding of deep learning applications (such as CV/NLP/ASR/RecSys, etc.);
	- Familiar with mainstream artificial intelligence frameworks in the industry, and understand the requirements for high-performance GPGPU deployment in data centers;
+ skill set:
	- Perception System Engineer - SPG
	- As Perception System Engineer on a revolutionary Apple project, you will be working on an autonomous system built on state of the art sensing technologies and ground breaking machine learning algorithms. The Perception team provides sense capabilities such as detection, classification, tracking, and observed maps in complex environments using a range of sensing modalities. You will play a key role in measuring end-to-end system performance, identifying key issues and provide detailed feedback for performance improvement. You will engage cross functionally with a wider range of experts to build a robust and scalable triage and measurement system. You will use statistical modeling and develop expertise in Perception system performance trends, forecasting methodologies, and synthesize key findings for leadership reviews.
	- 5+ years of experience in testing, QA or algorithm development for Autonomous Perception systems
	- A deep understanding of perception functions its impact on motion planning
	- Knowledge of machine learning models and deep learning fundamentals
	- A background in statistical analysis, system-level triage of complex systems
	- Proficient in data analysis, scripting and automation using python
	- Familiarity with data products from optical sensors like lidar and camera is desired
	- You will be developing and maintaining a Perception performance measurement pipeline that provides continuous feedback to developers for performance improvement and debugging. The work involves significant cross functional interaction with system test engineers, model, and tooling developers.
	- Defining procedure and tooling requirements for a triage and test pipeline that identifies, classifies, and measures perception failure rates.
	- Engaging with relevant partners to ensure timely implementation and delivery. 
	- Synthesize failure rate data to derive meaningful trends and sensitivities, and track measured improvements and regressions over time. 
	- Create and own dashboards for leadership reviews and develop expertise in observed system performance. 
	- Root causing and failure analyses in partnership with deep learning model developers will be essential to be effective in this role. 
	- You will also have opportunities to develop statistical models to forecast full system performance using developer metrics, critical scenario testing, and past performance.
	- Masters degree in engineering, data science, statistics, or mathematics
	- 5+ years of relevant Industry experience in robotics or autonomous systems
+ skill set:
	- At Nextdoor, machine learning is starting to transform our product through personalization, driving major impact across different parts of our platform including our newsfeed, our notifications, and our ads relevance. Our machine learning team is lean but hungry to drive even more impact and make Nextdoor the neighborhood hub for local exchange. We are scrappy and believe that ML will be an integral part of making Nextdoor valuable to our members. We also believe that ML should be ethical and encourage healthy habits and interaction, not addictive behavior. We are looking for great engineers who believe in the power of local community to empower our members to make their communities great places to live.
	- The Impact You'll Make
		* You will be part of a scrappy and impactful team building data-intensive products, working with data and features, building machine learning models, and sharing insights around data and experiments. Some of the current products / projects you could work on include the newsfeed, ad relevance, search, notifications, trust and safety, and neighborhood vitality. You will build critical decision-making models for the product, enhancing the relevance and value of our products. Finally, you will help build the foundational patterns that ML engineers will use for years to come as we ramp up our effort to introduce machine learning into our platform.
		* Collect and gather datasets to build machine learning (ML) models that make real-time decisions for the Nextdoor platform
		* Analyze datasets and and use important features to build low-latency models for decisions that need to be made quickly
		* Deploy ML models into production environments and integrate them into the product
		* Run and analyze live user-facing experiments to iterate on model quality by measuring impact on business metrics
		* Collaborate with other engineers and data scientists to create optimal experiences on the platform
	- What You'll Bring to The House
		* B.S. in Computer Science, Applied Math, Statistics, Computational Biology or a related field
		* 5+ years of industry/academic experience applying machine learning at scale.
		* Proven engineering skills. Experience writing and maintaining high-quality production code. Python experience a plus.
		* Ability to work with and analyze large amounts of data.
		* Ability to succeed in a dynamic startup environment.  
	- Bonus Points
		* Experience building ML products at large consumer-facing companies
		* Experience building ML products related to ads relevance or newsfeed products
+ skill set:
	- R&D Director - ML Systems
	- We are a Cambridge-based startup developing a revolutionary B2B SaaS product for automated synthesis of ultra-efficient Intelligent Systems. Our product will empower Edge AI & Robotics companies to achieve supreme efficiency and flexibility, while slash the development time and costs tenfold.
	- To perform advanced R&D critical for the success of our product, we are looking for a passionate and impactful leader to direct our growing activities in designing and optimizing Computer Systems for Machine Learning (ML Systems).
	- Perform critical R&D for a revolutionary neuralware/middleware/hardware co-design product.
	- Lead a team of ninja-class engineers (many at PhD-level) with glorious achievements in performance analysis and optimization.
	- Collaborate with high-profile ML Hardware customers to create highly competitive and fully compliant submissions to MLPerf.
	- Collaborate with Robotics and Edge AI customers to apply the hard-earned optimization knowledge to real-world use cases.
	- Represent KRAI in the most active working groups of MLCommons, including Inference and Power, and contribute to the roadmap.
	- Push the number of automated KRAI submissions in each round from hundreds to hundreds of thousands!
	- A PhD or MSc in Computing or Natural Sciences, with 5+ years of post-graduate experience.
	- Deep understanding of the full software/hardware stack, including algorithms, compilers, libraries, computer architecture.
	- Expertise in domain-specific accelerators (e.g. NPUs, GPUs, DSPs).
	- Hands-on experience with ML frameworks (e.g. Torch, TensorFlow) and ***inference engines (e.g. OpenVINO, TensorRT, TFLite, ArmNN)***.
	- Familiarity with ML optimization techniques (e.g. quantization, pruning).
	- If you're a systems person, you can play to your strengths and keep growing your expertise in any of the above areas, or instead jump outside your comfort zone and learn more about Edge AI & Robotics applications. Two things are certain: a) you'll be constantly learning and pushing the boundaries of your skills and knowledge; b) it'll be fun!
	- It is a unique opportunity to advance the state-of-the-art in ML Systems by considering all critical elements of the stack: from hardware to middleware to neuralware, akin to the amazing Nand-to-Tetris approach. (In fact, we hope to write our own book about our learnings one day!)
	- Please send your CV and short covering letter to info@krai.ai - we will be happy to arrange a friendly chat! What we ask for is evidence supporting your abilities and motivation: it's up to you to decide what that evidence might be.
	- Our team at KRAI (formerly, dividiti) has come a long way from co-organizing the ReQuEST tournament at ASPLOS'18 to becoming leading contributors to MLCommons/MLPerf™, the industry-leading forum for benchmarking Computer Systems for Machine Learning (ML). As part of our journey, we have collaborated with Arm, Dell, Intel, VMware, Qualcomm and leading ML hardware startups. In particular, in our public collaboration with Qualcomm we have produced some of the fastest and most energy-efficient Inference results, both in the Datacenter and Edge category. Over the three year history of MLPerf Inference, we submitted over 50% of all results, that is, more than other 40+ submitters combined.
+ skill set:
	- Ultra-efficient Computer Systems for Edge AI and Robotics
	- Krai is a Cambridge-based startup focusing on creating ultra-efficient computer systems for Edge AI and Robotics applications. We are looking for curious and motivated R&D engineers to join us on our exciting journey!
	- Automating software/hardware co-design
	- We are building an automated platform for software/hardware (SW/HW) co-design. We envision our customers will provide their requirements such as training and validation datasets, quality targets, performance and energy efficiency constraints, etc. Then, our platform will design several candidate AI/SW/HW stacks composed of neural networks, libraries, inference engines, etc., for running on one or more HW platforms. The platform will integrate many state-of-the-art and emerging techniques such as network architecture search, network optimisation, graph compilers, etc. - all wrapped up in an intelligent meta-technology for searching through myriads of combinations and configuration options. Our automated platform will produce superior designs and slash development time and cost by 10-100 times, opening up unprecedented opportunities for Edge AI and Robotics applications.
	- Collaborating with a broad computer systems community
	- As part of our strategy, we collaborate with many leading organisations ranging from stealth-mode AI HW startups to global corporations. Our core expertise and responsibilities include compilers, runtime systems, architecture definition, performance modelling, optimization, workload mapping and benchmarking. For example, we implemented, validated and optimized the MLPerf Inference benchmarks for Qualcomm's impressive entrance with their Cloud AI 100 accelerators, achieving up to 6x energy efficiency over the entrenched competition.
	- If you're a systems person, you can play to your strengths and keep growing your expertise in any of the above areas, or instead jump outside your comfort zone and learn more about AI applications. Two things are certain: a) you'll be constantly learning and pushing the boundaries of your skills and knowledge; b) it'll be fun! What we ask for is evidence supporting your abilities and motivation: it's up to you to decide what that evidence might be.
	- If that sounds like your cup of tea, please send us your CV and covering letter to info@krai.ai - we will be happy to arrange a friendly chat.
+ skill set:
	- Microarchitecture study of next-generation MN-Core
	- We will work on various studies to improve the performance, power, and area of the next-generation MN-Core microarchitecture.
	- Communication Language: Japanese
	- Knowledge of computer architecture
	- Advanced Verilog HDL/System Verilog coding skills
	- Experience in verifying RTL by logic simulation
	- Experience in using synthesis/place-and-route tools
	- Knowledge of STA
	- Basic knowledge of deep learning
+ skill set:
	- AIML - Sr. Software Engineer, On-Device Machine Learning, Foundation Models
	- Help us bring state-of-the-art foundation models to the phone in your pocket, enabling the next generation of ML-based experiences in a privacy-preserving way! Our team is responsible for the core framework that launches neural-network workloads on Apple devices. We build the bridge between the compute resources available on Apple hardware and an entire universe of ML models, trained by feature teams throughout Apple and by our developer community. Your work on our team will enable increasingly sophisticated models throughout our products, from the computer vision models that process every camera frame in the Apple Vision Pro, to potential large language models that could transform how we interact with our computing devices. By developing the underlying representation and pipeline for these workloads, and the mechanisms for mapping them to the CPU, GPU, and Neural Engine, you will play a critical role in expanding what is possible in the Apple ecosystem.
	- Excellent C/C++ programming and debugging skills
	- Passion for API design and software architecture
	- Outstanding verbal and written communication skills
	- Experience with modern neural-network architectures and deep learning libraries
	- Expertise with performance optimization (preferred)
	- Design and implement improvements to Apple's Model Intermediate Language (MIL), the intermediate representation of neural-network workloads shared across the inference stack
	- Develop the mechanisms for analyzing and transforming MIL workloads
	- Build the tightly integrated pipeline that optimizes and compiles models and then orchestrates their execution on device
	- Collaborate with CPU, GPU, and Neural Engine hardware backends to push inference performance and efficiency
	- Work closely with feature teams to facilitate and debug the integration of increasingly sophisticated models, including large language models
	- BS/MS/PhD in Computer Science or Electrical Engineering
	- Solid industry experience (2+ years)
+ skill set:
	- Neural Engine HW Modeling Engineer, Platform Architecture
	- At Apple, Platform Architecture is responsible for connecting our hardware and software into one unified system. Join this team, and you'll collaborate with engineers across Apple to design how all of our technologies work in unison. In this role, you will be part of the Neural Engine IP architecture team to define, architect, design, implement and deploy models for Neural Engine IP.
	- 3+ years in developing models for hardware validation
	- Domain experience in hardware IP including ML HW accelerator, GPU and image/video processing units.
	- Proficient experience developing C++ bit accurate models for hardware verification.
	- Experience working in a chip development environment with RTL designers and verification engineers.
	- Experience integrating IP models into chip simulation platforms
	- Experience debugging complex models
	- Experience working with C++ modeling tools, including C++, SystemC and scripting languages such as Perl and/or Python
	- As a Neural Engine Modeling Engineer, you will be responsible for developing, integrating and maintaining software models for Neural Engine.
	- Define, document and implement C/C++ bit-accurate and transaction level models with SoC and Neural Engine arch teams
	- Collaborate with design and verification teams to define C-model interfaces for validation and debug
	- Develop and maintain architecture test cases and automated workflows to verify the correct functionality of the models
	- BS with 3 years relevant industry experience. M.S. or Ph.D. preferred.
+ skill set:
	- Sr Staff Chip Engineer
	- Lightmatter is a photonic computer company that is redefining what computers and human beings are capable of by building the engines that will drive discoveries and progress sustainably. With modern human progress relying heavily on computers, the world has hit a dead end with traditional transistors, and the prospect of constantly building data centers is an environmental nightmare. Lightmatter builds chips for artificial intelligence computing. Our architecture leverages the unique properties of light to enable a fast and efficient compute platform. We created a solution in photonic computing: using photons instead of electrons to take advantage of their higher bandwidth.
	- If you have a passion for working cross-functionally, leading projects to success, and doing impactful work, like helping build the world's first optical computers, you should join the team at Lightmatter!
	- We are hiring a Sr Staff Chip Engineer to join our Chip team to guide the next generations of Lightmatter's innovative AI/ML silicon designs. If you have high-performance and/or AI/ML accelerator chip design experience, this would be a great opportunity!
	- In this job you will work in constant collaboration with hardware and software engineering teams across the company to create chips and systems that address a broad range of generative AI workloads. You'll be understanding the target workloads, managing technical risks, and innovating to solve problems these new applications face. You will work with company and engineering leadership to develop and manage the roadmap.
	- Own the chip architecture and roadmap for the AI Inference product line.
	- Work with hardware, software, program management and supply chain teams to define state-of-the-art silicon products.
	- Understand AI/ML models for existing and upcoming applications in terms of hardware acceleration architecture. Specifically, translate AI model architecture trends to specific hardware architecture requirements.
	- Develop and maintain competitive analysis of the AI/ML hardware landscape relative to Envise product line.
	- Collaborate with silicon design, verification and implementation teams to build efficient and performant chips.
	- Communicate the value proposition of Envise internally and externally.
	- Collaborate with sales and field teams to drive customer engagements.
	- 8 years and a Master's degree; or a PhD with 5 years experience; or equivalent experience.
	- At least 3+ years of previous experience in high-performance or AI/ML semiconductor chip architecture resulting in silicon products.
	- Experience in Python, C++ or other performance simulation tools.
	- Strong teamwork skills with the ability to collaborate with multiple functional teams across a variety of fields.
	- Ability to react to change and thrive in a fast-paced (startup) environment.
	- Attention to detail and strong ability to multitask.
	- Experience influencing decisions and providing technical leadership in a matrix environment.
	- Enthusiastic, responsive, and passionate about finding innovative solutions to challenges.
	- Excellent communications and technical presentation skills
	- Previous experience working on startups is a plus
+ skill set:
	- Machine Learning Engineer - Generative AI and Deep Learning
	- USA - California - Mountain View/Sunnyvale
	- Synopsys' Generative AI Center of Excellence defines the technology strategy to advance applications of Generative AI across the company. The GenAI COE pioneers the core technologies – platforms, processes, data, and foundation models – to enable generative AI solutions, and partners with business groups and corporate functions to advance AI-focused roadmaps.
	- As an ML Engineer in Gen-AI, you will innovate and translate cutting edge research into user experiences on questions like the following:
	- How to prompt an LLM like Llama-2, GPT-4, etc. effectively?
	- How to build a foundation model for a specific domain like EDA?
	- How to blend prompt engineering, retrieval augmentation, and fine-tuning to customize models with the least human time and effort?
	- Design and implement machine learning models and algorithms for Generative AI and Deep Learning applications.
	- Conduct experiments to evaluate model performance, identify areas for improvement, and implement optimizations.
	- Partner with cross-functional teams to design and develop scalable solutions that meet business goals.
	- Stay up to date with the latest research and advancements in the field of Generative AI and Deep Learning and apply this knowledge to improve our models and algorithms.
	- Communicate complex technical concepts and findings to both technical and non-technical stakeholders.
	- Participate in code reviews, testing, and deployment of machine learning models and algorithms.
	- BS with 5+ years' experience or MS degree with 1+ years' experience in computer science, Electrical Engineering, Mathematics, or related field.
	- A Ph.D. in machine learning or a related area with good publication history would be a good fit for this position. We would also love to hear from people with similar skill sets acquired through other career paths.
	- 2-5 years of experience in machine learning engineering, with a focus on AI/ML and Deep Learning.
	- Proven familiarity with python, and excellent background in data structures and algorithms.
	- Good expertise of Probability and Statistics concepts, including Probability, Conditional Probability, Bayes Theorem, Normal Distribution, and Central Limit Theorem.
	- Sound knowledge of Linear Algebra and Calculus concepts
	- Sound knowledge of deep learning architectures like Recurrent Neural Networks (RNNs), Long-Short-Term-Memory models (LSTMs), and Convolutional Neural Networks (CNNs).
	- Experience with deep learning frameworks like Tensorflow or PyTorch.
	- Experience with LLMs, Encoder-Decoder Models, and other Generative AI techniques.
	- Experience with Natural Language Processing (NLP) and Text Generation using Deep Learning.
	- Excellent problem-solving skills and ability to work autonomously as well as collaboratively in a team environment.
	- Excellent communication and presentation skills, with the ability to communicate complex technical concepts to both technical and non-technical stakeholders.
	- Good expertise with hands-on experience in data cleansing and modeling for deep learning models in at least one domain (language, image, graphs, etc.)
	- Experience with cloud-based machine learning platforms such as AWS, GCP, or Azure
	- Proven publication record in top-tier conferences and journals in the field of Machine Learning or NLP or Generative AI.
	- Experience with standard machine learning frameworks and tools (Huggingface Transformers, NumPy, Scikit-learn, Pandas, PyTorch, TensorFlow, etc.) and machine learning cloud infrastructure and accelerators (AWS, Google Cloud, GPUs and TPUs).
	- Familiarity with supervised and unsupervised learning algorithms like linear regression, logistic regression, random forests, and k-means.
	- Prior exposure to AI/ML workflows and tools
	- Knowledge and/or exposure to cloud computing technologies like containerization platforms (Docker, Kubernetes, microservices)
	- Broad expertise and understanding of AI, NLP, LLM, and generative AI trends.
	- Proficiency in advanced concepts and techniques like Proximal Policy Optimization (PPO) and RLHF for building generative models is a big plus
	- Experience prototyping, experimenting, and testing with large datasets and training models.
	- BS in EE or CS with 5+ years of relevant experience.
	- MS in EE or CS with 1+ years of relevant experience.
	- PhD in EE or CS with published academic papers and/or relevant experience.
	- The base salary range across the U.S. for this role is between $106,000 to $185,000.
+ skill set:
	- Machine Learning Engr, II
	- USA - California - Mountain View/Sunnyvale
	- The Artificial Intelligence team designs and develops the next generation Machine Learning, Artificial Intelligence and Cloud architecture for Synopsys tools. We are looking for a ML engineer to work in areas such as microservices architecture, containers, distributed systems, webservers fine-tuning, and Application Program Interface design. The ML engineer will help develop and deploy robust software components that meet our high-quality requirements both on-prem and in public cloud.
 	- Designing, developing, troubleshooting, or debugging on-prem and cloud infrastructure for ML/ Artificial Intelligence based tools and applications.
 	- This role may span many tiers such as data management, backend services, visualization, presentation, and APIs for the infrastructure.
 	- The candidate will work with other members of the engineering team to design, code and deploy optimal solutions.
 	- Expected to exercise judgment in selecting methods and techniques to obtain solutions. Work on diverse problems where study of situations or data requires evaluation of various factors.
 	- Work with engineering project management system. Provides regular updates to manager/team on project status. Able to work autonomously and collaboratively. Exceptional communications and synergy skills are a must.
 	- BS/MS EE/CS/CE
 	- Expertise in one or more languages such as C/C++, Python, Java, JavaScript
 	- Requires a sound background in file systems, data structures, algorithms, performance, and scalability.
 	- Demonstrates good investigation and problem-solving skills.
 	- Knowledge of microservices-based software design and architecture
 	- Knowledge about containerization, distributed computing, fault tolerance, throughput and latency tuning.
 	- Knowlegde about CI/CD pipelines, ML model versioning and deployment.
 	- Knowledge of Data Engineering tools such as Kafka, Spark, Hive. Also HDFS, Airflow, NOSQL Databases, in-memory databases such as redis, ignite, and/or similar.
 	- Knowledge of designing / deploying micro services application on Kubernetes both on-prem and public clouds
 	- Knowledge about working with AWS, GCP, and/or Microsoft Azure. May include configuring, deploying, managing and monitoring.
 	- Certifications are a plus: AWS Solutions Architect, Cloud Security Certification, OpenStack Certification
+ skill set:
	- Senior RTL Design Engineer
	- AlphaIC, based in the US and India, designs and manufactures AI/ ML Co-Processor targeted for vision inference applications. Gluon, AlphaIC's first AI/ ML Co-Processor, has been successfully taped out and we are planning to develop a more advanced AI/ ML Co-Processor which can be used in Edge Inference as well as Edge Learning applications. We have applied for multiple patents among which quite a few are granted and will continue to apply more to enhance our IP portfolio. The engineering team is led by Industry experts from SoC Design, System Design and Edge AI/ ML Application Development areas. We have raised Series A funding and in the process of raising further funds from leading VC firms
	- 1) Will work with system architects to understand the functional and performance requirements of a unit or feature.
	- 2) Define micro-architecture and develop RTL for a module and feature.
	- 3) Responsible for IP / sub-system level micro-architecture development and RTL coding.
	- 4) Prepare block/sub-system level timing constraints.
	- 5) Integrate IP/sub-system.
	- 6) Work with verification and physical design team to ensure that the unit or feature is accurately verified and implemented.
	- 7) Silicon bring-up in conjunction with post silicon validation and SW teams.
	- 1) BS / MS in Electrical Engineering or Computer Science from a leading university.
	- 2) Strong analytical and problem-solving skills.
	- 3) 5+ years of minimum experience as RTL Design Engineer.
	- 4) Expertise in using design and verification tools (Synthesis, lint, Xcelium or equivalent simulation tools, debug tools etc.)
	- 5) Experience with high-speed interfaces such as LPDDR, AXI, PCIe, etc.
	- 6) Experience with Memory sub-system, DDR interfacing.
	- 7) Experience with Deep Learning and Deep Learning HW acceleration.
+ skill set:
	- AI Accelerator Engineer
	- Design neural network accelerator for vision and audio application.
	- Inference trained network on FPGA.
	- Research on key algorithms of deep learning (including various network architectures and applications), and computer vision tasks (including classification, object detection, and semantic segmentation).
	- Adapt key algorithms to real-world applications, such as Smart Sensing, Intelligent Surveillance, and ADAS.
	- Understanding of ML/AI algorithms, neural network, software framework
	- Experience in FPGAs & related tools flow
	- Experience with framework like TensorFlow, Keras, Pytorch
	- Experience in video streaming and/or image processing design will be added advantage
	- Neural network inference experience with resource constrained devices like FPGA/microprocessors will be added advantage
+ skill set:
	- “Plumb” new design content into the SiFive's Chisel/FIRRTL framework to enable automatic configuration/generation of documentation, verification testbenches and tests, and packaged software.
	- Performing initial sandbox verification, and work with design verification team to create and execute thorough verification test plans.
	- Knowledge of vector architecture and concepts.
	- Prior experience designing high-performance vector and/or SIMD processors/units.
+ skill set:
	- strong programming skills in C++ with experience in developing latency-critical software
	- demonstrated ability to take neural network models from concept to production with in-depth knowledge in deep learning frameworks, such as TensorFlow
+ skill set:
	- We are looking for a senior staff engineer with good understanding of neural network implementation on resource constrained embedded devices. In this position you will have an opportunity to influence how customers can efficiently utilize Lattice solution for neural network inference. In-depth understanding of neural network topologies, training with TensorFlow and/or Caffe framework is essential. Candidate need to possess good programming skills with Python, C/C++ with basic understanding of data structures. Candidates need to have the expertise to use embedded architectures such as FPGAs, GPUs, or other embedded processors to realize complex applications using deep learning.
	- The ideal candidate would possess the following skills:
		* Ability to create and use deep learning training frameworks for creating new applications.
		* Expertise in one of Tensorflow, Caffe, Keras, or any other deep learning framework.
		* Python programming expertise.
		* Understand different kinds of numerical precisions in implementing deep learning solutions. Ability to translate networks trained with floating point to different fixed point formats. Understand the accuracy loss, and come up with ways to address them.
		* Be up to date with the current research in neural networks, implementations, competitive solutions, etc.
	- Able to present solutions to customers, understand their requirements and come up with solutions to address them.
	- Create neural network models, add new features to neural network compiler for efficient inference, mentor junior engineers, deliver functionally correct software, debug customer issues, document features, develop new testcases, publish papers, file patents
	- Behaviors
		* Enthusiastic: Shows intense and eager enjoyment and interest
		* Detail Oriented: Capable of carrying out a given task with all details necessary to get the task done well
		* Innovative: Consistently introduces new ideas and demonstrates original thinking
	- Motivations
		* Self-Starter: Inspired to perform without outside help
		* Ability to Make an Impact: Inspired to perform well by the ability to contribute to the success of a project or the organization
	- Education
		* Required: Masters or better in Electrical Engineering or related field.
		* Preferred: Doctorate or better in Computer Engineering or related field.
	- Experience
		* PHD on relevant topic, MS with 8+ years experience, BS with 10+ years experience
+ skill set:
	- Machine learning engineer who develops neural network for a given application and map to FPGA solution. Need to develop technology to map the neural network into FPGA including neural network compiler and HW acceleration engine development.
	- Need to know the details of machine learning including network design, network training, and training dataset build up. Also need to understand the general accelerator structure of machine learning inferencing engine.
	- Behaviors
		* Team Player: Works well as a member of a group
		* Functional Expert: Considered a thought leader on a subject
		* Enthusiastic: Shows intense and eager enjoyment and interest
	- Motivations
		* Self-Starter: Inspired to perform without outside help
		* Ability to Make an Impact: Inspired to perform well by the ability to contribute to the success of a project or the organization
	- Education
		* Doctorate or better in Electrical Engineering or related field.
	- Experience
		* Hands on experience on network design and training. RTL design experience, FPGA design experience
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.














###	Start-ups related to VLSI Deep Learning & Embedded Deep Learning

+ Covariant: https://covariant.ai/careers/
+ Rain Neuromorphics Inc.: https://rain.ai/careers

































##	Application engineers of different EDA products

Skill sets for application engineers of different EDA products:
+ skill set:
	- Bus protocols such as AMBA-AXI, AHB, APB, I2C, SPI
	- Expert in coding SV Testbench, drivers, monitors, scoreboards, checkers
	- Experience in C/C++,Shell/Perl scripting.
	- Understanding of AHB, AXI and other bus protocols and system architecture is a plus.
	- Expert in System Verilog and OVM/UVM based verification.
	- Preferred Expertise in MIPI UniPro/UFS Protocol and UVM.
	- To help the team to verify the existing design (UFS/UniPro)
	- Preferable: Experience in one/more of the following areas PCI_Express, USB, SATA, SDIO, MIPI and /or AMBA standards (OCP, AXI, AHB etc.)
	- Experience with verification methodology like OVM/VMM/UVM
	- Experience in constrained-random verification is a strong plus
+ skill set:
	- Flex-Logix Inference Software team is looking for Applications engineer or Software engineer, ideally with an EDA background. You will serve as an internal application engineer between its Softlogic group (Verilog generation and optimization) and its EFLX compiler (primarily place-and-route technology).  The position will report to the Senior Director of FPGA Technology. The successful applicant will serve as a bridge between the two groups and as an ambassador for the backend technology (these groups) to the customer application engineering group.  As such, the position offers great upward growth potential, including direct paths into either software or hardware engineering, customer application engineering, or management.
	- As senior EDA application engineer, you will be the bridge between the Verilog and Place and Route teams, and from those groups to the rest of Flex Logix.  You will work at the application level to understand the performance of Flex Logix's backend solutions, provide ideas and suggestions to the backend team to improve performance, debug applications that are failing, and pinpoint areas of improvement for the backend team. In order to perform these responsibilities, you will need to develop a reasonably deep understanding of backend eFPGA implementation as well as a user level understanding of neural network applications.
	* Collaborating with the applications, softlogic, architecture, and compiler teams to determine low-latency, high-throughput schemes for executing neural networks on our ML accelerator.
	* Understanding low level operator/algorithm implementation and developing APIs to invoke individual operators at the graph level.
	* Making minor modifications to operator/algorithm implementations.
	* Devising unit tests for new deep learning models.
	* Evaluating the performance of the neural network on silicon.
	* Designing and developing supporting libraries that run some neural network operators on CPUs.
	* Diagnosing and fixing performance and integration issues across the software stack using simulators and hardware.
	* Reasonably proficient in Verilog and understanding general FPGA implementation.
	* Excellent communication skills, and the ability to support internal and external customers of eFPGA backend technology.  
	* BS/MSEE/CE/CS with a minimum of 2 years of experience in software support.
	* Experience debugging Verilog or SystemVerilog RTL designs.
	* Experience in debugging and maintaining SystemVerilog test-benches.
	* Experience in debugging gate-level timing simulations.
	* Experience in maintaining scripts and automation framework for test regressions.
	* Knowledge of eFPGA architecture.
	* Knowledge of Digital Designs.
	* Knowledge of Software architecture and place and route algorithms.
	* Familiarity with C/C++ coding.
	* Familiarity with SystemVerilog RTL coding.
	* Familiarity with scripting in Python or Perl.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.










#	Artificial Intelligence + Machine Learning










##	Machine Learning, ML



###	Notes about Machine Learning, ML

+ ML/AI compiler design
	- Poplar framework for IPU architecture compiler.
+ ML/AI compilers, or deep learning compilers:
	- MLIR
	- TVM
	- Glow
	- XLA
+ ML/AI frameworks
	- ***JAX***:
		* JAX = Autograd + XLA (from TensorFlow)
			+ Google JAX
		* for high-performance machine learning research
		* https://github.com/google/jax
	- ***TensorFlow***
		* ***TensorFlow Lite, TFLite***
			+ ***TensorFlow Lite Micro***
		* TFX, TensorFlow Extended
		* TensorFlow Probability
		* ***Keras***
	- ***PyTorch***
		* based on ***Torch*** library
		* PyTorch JIT
		* includes:
			+ ***PyTorch Mobile***
			+ Deep Speed
				- deep learning optimization engine
				- Zero Redundancy Optimizer, ZeRO, can optimize deep learning models with >1 trillion parameters
			+ Caffe, Convolutional Architecture for Fast Feature Embedding, and Caffe2, which has been merged into PyTorch.
			+ Torch, which is based on Lua
			+ Lightning/Fast.ai
	- Open Neural Network Exchange, ONNX
		* open-source AI ecosystem
		* Neural Network Exchange Format, NNEF
	- ***scikit-learn***
		* mlpy
		* SpaCy, for NLP
		* Natural Language Tookit, NLTK, for NLP
		* Orange
		* PyTorch
		* TensorFlow
		* Infer.NET, for Bayesian inference in graphical models, for probabilistic programming
		* scikit-multiflow, for multi-output/multi-label and stream data
		* RAPIDS:
			+ https://rapids.ai/about.html
			+ RAPIDS is basically a tool for running Pandas, Scikit-Learn, and NetworkX (graph analytics library) on GPUs. It also integrates with some deep learning libraries
	- ***pandas***, for data analysis
	- high-performance inference frameworks, or inference engines:
		* ArmNN
		* ONNX Runtime
		* OpenVINO
		* ***NVIDIA TensorRT***, or ***TensorRT***
		* edge inference frameworks:
			+ [***Lightning, or Lightning AI***](https://lightning.ai)
				- Or, ***PyTorch Lightning***
			+ ***PyTorch Mobile***
			+ ***Tensorflow Lite, TFLite***
				- ***TensorFlow Lite Micro***
			+ benchmark for embededded-ai deep learning inference engines:
				- NCNN
				- TNN
				- MNN
				- TensorFlow Lite
				- www.ai-performance.com
		* inference server or model serving frameworks
			+ Triton
			+ TFServe
			+ ***KubeFlow***
		* related tools:
			+ CuBlas
			+ CuDNN
			+ CuFFT
			+ HugeCTR
			+ MLIR
			+ MNN
			+ OpenPPL
			+ Paddle
			+ TNN
			+ TVM
			+ XLA
	- Chainer/ChainerMN
	- ***ML.NET***
		* Microsoft Cognitive Toolkit, CNTK, The Microsoft Cognitive Toolkit (deprecated)
	- ***Apache MXNet***, for deep learning
	- ***OpenVINO toolkit***, Open Visual Interference and Neural Network Optimization
		* includes:
			+ nGraph
	- ***BigDL***, distributed deep learning framework for Apche Spark
	- Dlib
	- PaddlePaddle
	- Caffe and Caffe2
	- Theano
	- Apache SINGA
	- Horovod
	- Deepspeed
	- K-means
	- Dask
	- Flux machine learning framework, Julia based
	- Flax, from Google Brain
	- PlaidML, portable tensor compiler
	- Optax, for gradient processing and optimization, by DeepMind
	- [***Chainer***](https://chainer.org)
	- Apple Core ML:
		* https://pypi.org/project/coremltools/
			+ pip install coremltools
		* https://developer.apple.com/documentation/coreml
		* https://coremltools.readme.io/docs
			+ https://developer.apple.com/machine-learning/core-ml/
		* https://developer.apple.com/machine-learning/create-ml/
		* https://developer.apple.com/machine-learning/models/
		* https://developer.apple.com/machine-learning/
		* https://developer.apple.com/documentation/vision/classifying_images_with_vision_and_core_ml
	- reinforcement learning:
		* RLax, for reinforcement learning agents, by DeepMind
		* OpenAI Gym: https://github.com/openai/gym
		* RLLib:
			+ https://github.com/ray-project/ray/tree/master/rllib
			+ https://github.com/ray-project/ray/
			+ https://github.com/ray-project
			+ https://docs.ray.io/en/latest/rllib/index.html
		* Stable Baselines 3:
			+ https://stable-baselines3.readthedocs.io/en/master/
			+ https://github.com/DLR-RM/stable-baselines3
			+ https://pypi.org/project/stable-baselines3/
	- for fairness, bias detection and mitigation, and explainability in machine learning:
		* FairLearn: https://github.com/fairlearn/fairlearn/blob/master/README.md
		* AI Fairness 360 (AIF360): https://aif360.mybluemix.net/
		* InterpretML: https://github.com/interpretml/interpret
		* LIME: https://github.com/marcotcr/lime
	- for gradient boosting:
		* LightGBM
		* XGBoost
		* CatBoost (from sanctioned entities)
	- for Python software:
		* PyMC
			+ formerly PyMC3
			+ for Bayesian statistical modeling and probabilistic machine learning
				- Markov chain Monte Carlo
				- variational fitting algorithms
		* TomoPy, tomographic data processing and image reconstruction
	- for C++ software:
		* mlpack
		* OpenNN
	- for Java software:
		* Massive Online Analysis, MOA
			+ SAMOA, derivative of MOA
		* Eclipse Deeplearning4j
	- for distributed machine learning or deep learning:
		* ***Horovod***, open-source software framework for distributed deep learning training
			+ TensorFlow
			+ Keras
			+ PyTorch
			+ Apache MXNet
			+ managed by Linux Foundation AI, LF AI
		* Dask: https://stories.dask.org/
		* Apache Spark: https://spark.apache.org/
	- higher-performance compilation:
		* Numba: from sanctioned entities
	- Orange
	- from sanctioned entities:
		* CatBoost, for gradient boosting
	- ***for MLOps***:
		* MLflow
		* Kubeflow
		* Seldon Core
		* TFServing, TensorFlow Serving
		* MLeap
		* Airflow, but for generic pipelined workflow managemnt
	- ***machine learning and data science pipeline management and version control***
		* goals:
			+ pipeline computation
			+ track data
			+ track machine learning models
				- or track statistical models
			+ track experiments
			+ make machine learning models shareable
			+ make experiments reproducible
			+ track versions of the following:
				- data
				- machine learning models, or statistical models
				- machine learning pipelines, or data science pipelines
		* ***DVC, Data Version Control***
		+ [***MLflow***, An open source platform for the machine learning lifecycle](https://mlflow.org/)
		* Git LFS
		* Dolt
		* lakeFS
		* deep learning models:
			+ ImageNet and VGG
			+ GoogleNet
			+ ResNet
			+ NASNet
			+ DeepSpeech
			+ Large Language Models (LLMs)
		* Data Parallel DNN Training
			+ Basic Solutions for CPU- and GPU-based Training
			+ NVIDIA NCCL, Baidu-allreduce, Facebook Gloo
			+ Co-Designs
			+ Deep Learning and Big Data
		* Model Parallel DNN Training
			+ Out-of-core DNNs
		* Elastic Training
+ data science frameworks, including libraries and tools for data visualization and information visualization:
	- Madagascar
	- Statsmodels, for statistical analysis
	- Dataplot, for statistical analysis and data visualization
	- Fityk, curve fitting and data analysis application
		* fit analytical, bell-shaped functions to experimental data
	- for Python software:
		* ***matplotlib***, for data visualization
		* ***Bokeh***, for data visualization
		* ***Plotly***, for data visualization
		* ***wxPython***, for data visualization
		* ***PLplot***, for data visualization
		* Panel
			+ panel.holoviz.org
		* Voila
			+ voila.readthedocs.io
		* Streamlit
			+ www.streamlit.io
		* Dash
			+ plot.ly/dash
		* HoloViz
		* Gnuplot-py, for data visualization
		* Biggles, for data visualization
		* Chaco, for data visualization
		* MayaVi, for data visualization
		* SQLAlchemy, open-source SQL toolkit and object-relational mapper, ORM
	- PSPP, open-source equivalent of IBM SPSS Statistics (or SPSS Statistics, or Statistical Package for the Social Sciences)
	- other data analytics tools:
		* Apache Arrow
		* Apache Spark, or Spark
		* Baremetrics
		* Chartmogul
		* ***Dask***
			+ "flexible open-source Python library for parallel computing maintained by OSS contributors across dozens of companies"
			+ Scale the Python tools you love
			+ https://www.dask.org
		* Databricks
		* Gephi
			+ for ***graph visualization***
		* Google Analytics
		* Google Data Studio
		* Heap Analytics
		* Jupyter
		* Looker
		* Mesos
		* Mode Analytics
		* Noteable
		* Numba: A High Performance Python Compiler
			- https://numba.pydata.org/
		* Periscope
		* Tableau
			+ alternatives include:
				- Apache Superset
				- Business Intelligence and Reporting Tools, BIRT
				- Domo
				- GoodData
				- Grafana
				- Knime Analytics Platform
				- Looker
				- Metabase
				- Microsoft Power BI???
				- Noteable
				- Oracle Analytics Cloud
				- Pentaho Community Edition
				- Plotly-Dash
				- Qlik Sense
				- QlikView
				- RAWGraphs
				- Redash
				- Retool
				- Sisense
				- SpagoBI
				- Talend
				- ThoughtSpot
				- TIBCO Software
				- Trevor.io
	- for Elasticsearch dashboards
		* Kibana, for data visualization
			+ substitute is: ***Opensearch Dashboards, for Opensearch***
	- for SQL, NoSQL, and NewSQL databases:
		* Amazon DocumentDB
		* Apache Cassandra
		* Apache Hive
		* IBM Db2
		* kSQLdb
			+ database purpose-built to help developers create stream processing applications on top of Apache Kafka
		* large-scale databases
			+ THIN
		* MariaDB
		* massively parallel processing databases, MPP databases
			+ BigQuery
			+ Redshift
			+ Snowflake
			+ Vertica
		* Memcached
		* Microsoft Access
		* Microsoft Azure SQL Database
		* Microsoft SQL Server
		* MongoDB
		* MySQL
		* Oracle Database
		* PostgreSQL
		* Redis
		* Snowflake
		* SQLAlchemy
			+ open-source SQL toolkit and object-relational mapper, ORM
		* SQLite
		* Teradata Vantage
		* Database change management:
			+ Debezium: https://debezium.io/
		* important principles, and properties, to abide by when designing database systems or hardware accelerators for data management (and computation, such as in-memory computing):
			+ common parallel DBMS architectures
				- shared memory architecture
				- shared disk architecture
				- shared nothing architecture
			+ ***CAP theorem, or Brewer's theorem***, in system design and theoretical CS guarantees:
				- consistency: every read receives the most recent write or an error
					* different from consistency definition in ACID properties
				- availability: each request receives a non-error response, without the guarantee that it contains the most recent write
				- partition tolerance: system continues to operate despite an arbitrary number of messages being dropped or delayed by the network between nodes
				- When a network partition failure occurs, it has to do one of the following:
					* cancel the operation and decrease the availability but ensure consistency
					* proceed with the operation and provide availability but risk inconsistency
				- therefore, when a design choice for network partition is made, it has to choose between consistency and availability.
			+ ***ACID = atomicity, consistency, isolation, durability***
				- consistency/correctness: database transactions must change affected data only in allowable ways (as specified by rules):
					* database constraints
					* cascades
					* triggers
					* combination thereof
					* subsequent starts of transactions will have to deal with the effects of past and current transactions
					* database consistency are about transactions
					* atomic consistency refers to the property of each request/response operation sequence
				- isolation is the goal of concurrency control
				- durability guarantees that committed transactions will be completed, even when there is system failure, such as power outage or crash
					* record completed transactions or their effects in NVRAM (or non-volatile memory)
			+ ***CRUD = create, read, update, and delete***
				- essential operations of ***database engine***, or ***storage engine***
				- basic operations of ***persistent storage***
					* data definition, or definition for data organization
						+ creation
						+ modification
						+ removal
					* update (data)
						+ insert data
						+ modify data
						+ delete data
					* retrieval
						+ access data in directly usable format
						+ access data for further processing
					* administration
						- register users
						- monitor users
						- enforce data security
						- monitoring performance
						- maintain data integrity
						- concurrency control
						- recover information corrupted by events, such as unexpected system failure.
				- design for:
					* ***predominantly "persistent data"***, infrequently accessed and not likely to be modified
					* ***predominantly "dynamic data", or predominantly "transactional data"***, asynchronously/periodically update information as new data becomes available
						+ new data can come at any time
						+ ***transaction data***, category of data describing information that refer to ***master data*** and/or ***reference data***, such as dates, times, time zones, and currencies
							- financial transactions
							- work transactions
							- logistics transactions
							- Note: master data and reference data provide context for transaction data (or transactions)
							- Note: reference data also provides information/data for classification and categorization of other data, such as:
								* units of measurement
								* country codes
								* corporate codes
								* fixed conversion rates for mass/weight, temeperature, and length
								* calendar structure and constraints
					* ***streaming data, event stream processing, data stream processing, or distributed stream processing***, constant flow of information
						+ encompasses:
							- dataflow programming
							- reactive programming
							- distributed data programming
						+ solutions:
							- Kafka: https://kafka.apache.org/
							- Flink: https://flink.apache.org/
					* ***static data, or unchanging data***, which does not change
					* ***unstructured data, or unstructured information***
						+ has no pre-defined data model
						+ not organized in pre-defined manner
						+ text heavy
							- can include data about:
								* dates
								* numbers
								* facts
							- can result in irregularities and ambiguities when processed by structured databases
						+ can be ***semi-structured data***, by containing data that has some structure associated with relational databases, RDBMS
							- XML, extensible markup language
								* XML databases
									+ native XML databases
								* XML-enabled databases
								* data-centric XML databases
							- JSON, JavaScript Object Notation
								* supported by:
									+ MongoDB
									+ Couchbase, formerly Membase
										- CouchDB???
							- Object Exchange Model, OEM
						+ can be highly structured, such that the structure is unanticipated and unannounced
						+ periods of inactivity between data arrival can exist
						+ for unstructured data database
					* ***semi-structured database model***
						+ no separation between data and database schema
					* types of database applications:
						+ online transaction processing, OLTP
							- facilitate and manage transaction-oriented applications
							- goals:
								* availability
								* speed
								* concurrency
								* recoverability
							- requirements:
								* high throughput
								* insert- or update- intensive database management
						+ online analytical processing, OLAP
							- multidimensional analysis, MDA
								* MDA queries
							- complex queries
							- small volume
							- for data analytics
								* such as business intelligence or business analytics
							- types:
								* multidimensional OLAP, MOLAP
								* relational OLAP, ROLAP
								* hybrid OLAP, HOLAP
						+ hybrid transactional/analytical processing, HTAP
							- for "in business real time" decision making
					* ***database administration tools***
						+ to manage DBMS such as:
							- MySQL
							- PostgreSQL
							- SQLite
					* relational database model, or relational model or RM
						+ ***relational databases, relational database management systems, RDBMS, or RDB***
							- row-oriented DBMS
							- column-oriented DBMS, columnar DBMS
								* store data tables based on columns rather than rows
					* SQL
						+ applications of SQL:
							- relational databases, relational database management systems, RDBMS, or RDB
							- relational data stream management systems, RDSMS
								* for stream processing
						+ NewSQL
							- extend relational databases, RDBMS, with scalability of NoSQL for online transaction processing, OLTP, while maintaining ACID guarantees of traditional RDBMS (or SQL databases)
							- primarily uses SQL interface
							- distributed computing uses a cluster of shared-nothing nodes, such that each node uses a subset of the data
								* components include:
									+ distributed concurrency control
									+ flow control
									+ distributed query processing
							- uses optimized storage engines for SQL
								* scale better than built-in engines
							- transparent sharding
								* split databases across multiple nodes using consensus algorithms:
									+ Raft
									+ Paxos
					* NoSQL
						+ non-SQL database, or non-relational database, or not only SQL database
						+ database management systems, DBMS, for data storage and retrieval beyond tabular relations in relational databases, relational database management systems, RDBMS, or RDB
						+ can support the following:
							- ACID properties
							- join operations
						+ applications:
							- Big Data applications
							- real-time Web applications
						+ see Wikipedia entry for NoSQL for comparing data models based on:
							- performance
							- scalability
							- flexibility
							- complexity
							- functionality
							- list of data models that are compared:
								+ [x] key-value database, key-value store
								+ [x] document-oriented database, document store
								+ [x] graph database, GDB
								+ relational database model, or relational model or RM
									- [x] relational databases, relational database management systems, RDBMS, or RDB
									- [x] column-oriented DBMS, columnar DBMS
						+ examples:
							- ***HBase***
							- ***Cassandra***
							- ***MongoDB***
							- DynamoDB
					* ***multi-model database***
						+ database management system, DBMS, that is designed to support multiple data models with an integrated back-end
						+ other DBMSes are organized around a data model that determines how data is:
							- organized
							- stored
							- manipulated
						+ examples of supported data models:
							- relational database model, or relational model or RM
								* relational databases, relational database management systems, RDBMS, or RDB
							- key-value database, key-value store
							- graph database, GDB
							- document-oriented database, document store
						+ examples of multi-model databases/DBMS:
							- PostgreSQL:
								* [x] relational database model, or relational model or RM
									+ relational databases, relational database management systems, RDBMS, or RDB
								* [x] key-value database, key-value store
								* [x] graph database, GDB
								* [x] document-oriented database, document store
									+ JSON
									+ XML
								* [x] object database model
									+ object-relational database model, ORD, for object-relational database management systems, ORDBMS
					* navigational databases
						+ navigational databases use references from objects to find records or other objects
						+ hierarchical database model
						+ network database model
						+ graph database, GDB
					* entity relational database models, entity-relationship models, ER models
						+ enhanced entity relational database model, enhanced entity relationship model, EER model
					* entity-attribute-value database model, EAV
						+ or, object-attribute-value data model
						+ or, vertical database model
						+ or, open schema
					* physical database model, physical data model, or physical database design
						+ inverted index, postings list, postings file, or inverted file
						+ flat file, for 2-D arrays of data
							- for flat-file databases
							- examples are:
								* CSV, standard comma-separated-values
								* TSV, standard tab-separated-values
								* Awk, flat-file processor
					* star schema database model
					* semantic database model
					* named graph
					* correlational database model
					* dimensional database model
					* triplestore, or RDF store
						+ semantic triples, RDF triples, or triples
							- atomic data entities in resource description framework, RDF, data model
						+ uses resource description framework, RDF
						+ for storage and retrieval of triples, through semantic queries
					* uncertain databases
						+ includes the following types of uncertain databases:
							- probabilistic databases, probabilistic DBMS
								* possible worlds have associated probabilities
								* types of uncertainties:
									+ tuple-level uncertainty
									+ attribute-level uncertainty
					* non-relational database models:
						+ graph database model
							- ***graph database, GDB***
								* graph database processing is different from graph computing
									+ a separate component for graph databases is needed for graph computing to implement graph algorithms
								* examples:
									+ GraphQL
						+ ***key-value database, key-value store***
							- associative array, map, symbol, dictionary
							- hash table, dictionary
						+ document database model
							- ***document-oriented database, document store***
								* based on semi-structured database model
						+ ***wide-column store, extensible record store***
							- name and format of columns can vary between rows within a table
							- can be interpreted as a 2-D key-value database, key-value store
						+ multidimensional database model
							- resource space database model
							- multivalue database model
							- useful for:
								* online analytical processing, OLAP, applications
									+ multidimensional OLAP, MOLAP
									+ relational OLAP
									+ hybrid OLAP
						+ object database model
						+ object-relational database model, ORD, for object-relational database management systems, ORDBMS
							- object-relational impedance mismatch, can occur when object-oriented software interact with RDBMS
							- includes:
								* terminology-oriented database, or terminology-oriented database management system, or terminology-oriented DBMS
							- or, Object Relational Mapping (ORM)
					* blockchain-based database
						+ combines traditional database with distributed database
						+ supported by multiple layers of blockchains
						+ use features from SQL and NoSQL databases, with blockchain properties
							- data integrity
							- integrity assurance
							- decentralized control
							- Byzantine fault tolerance
							- transaction traceability
					* cloud database
						+ database/DBMS that runs on cloud computing platform
						+ deployment models
							- virtual machine image
								* run databases on the cloud independently, using virtual machine image
							- database-as-a-service, DBaaS
								* purchase/paid access to database service, maintained by cloud database providers
						+ can support SQL and NoSQL databases
						+ *join operations perform poorly*
					* spatial database
						+ usually implemented with relational databases, relational database management systems, RDBMS, or RDB
						include spatial data that represent objects
							- 3-D objects
							- topological coverages
							- linear networks
							- triangulated irregular networks, TINs
						+ includes:
							- geographical database, geodatabase, or georeferenced spatial database
								* "georeferenced" from georeferencing or georegistration
								* applications of coverage data
									+ geographical information systems, GIS
									+ geospatial content and services
									+ GIS data processing
									+ data sharing
								* types of data:
									+ 1-D sensor time series
									+ 2-D satellite images
									+ 3-D x/y/t image time series or x/y/z geo tomograms
									+ 4-D x/y/z/t climate and ocean data
					* temporal database
						+ store data about time instances
							- valid time
							- transaction time
							- decision time
					* real-time database
						+ DBMS that uses real-time processing to handle workloads that can be constantly changing
							- most of the data is not persistent data that is unaffected by time
						+ applications
							- accounting
							- banking
							- law
							- medical records
							- multimedia applications
							- process control
							- reservation systems
							- scientific data analysis
					* ***in-memory database, IMDB***, main memory database system, MMDB, memory resident database
						+ Can support ACID properties: atomicity, consistency, isolation, durability
						+ Can be implemented with NVRAM.
					* ***database security***
					* ***database scalability***
					* ***slowly changing dimension, SCD***
			+ Armstrong's axioms, references to infer functional dependencies on a relational database
			+ Codd's 12 rules, or Codd's twelve rules, for relational database management systems, RDBMS
+ ML/AI conferences
	- AAAI, IJCAI, NeurIPS, ACL, SIGIR, WWW, RSS, NAACL, KDD, IROS, ICRA, ICML, ICCV, EMNLP, EC, CVPR, AAMAS, HCOMP, HRI, ICAPS, ICDM, ICLR, ICWSM, IUI, KR, SAT, WSDM, UAI, AISTATS, COLT, CORL, CP, CPAIOR, ECAI, OR ECML





Companies that have machine learning -centric products
+ OctoML: https://octoml.ai/company/careers/









###	Machine Learning Scientist & Deep Learning Scientist Roles



***Machine Learning Scientist*** and ***Deep Learning Scientist*** roles:
+ machine learning frameworks:
	- JAX
	- TensorFlow
	- Caret
	- H20 3
	- Prophet
	- PyTorch
	- Tidymodels
	- Xgboost
	- MXNet
	- Keras
	- CatBoost
	- LightGBM
	- Scikit-Learn
	- Fast.ai
+ machine learning algorithms:
	- decision trees or random forests
	- evolutionary approaches
	- recurrent neural networks, RNN
	- Bayesian networks
	- linear or logistic regression
	- convolutional neural networks, RNN
	- transformer networks: BERT, gpt-3
	- gradient boosting machines: xgboost, lightgbm
	- dense neural networks: MLPs
	- generative adversarial networks, GANs
+ machine learning products:
	- Google Cloud Vision AI
	- Amazon SageMaker
	- Google Cloud AI Platform / Google Cloud ML engine
	- Google Cloud Natural Language
	- Amazon Forecast
	- Amazon Rekognition
	- Azure Cognitive Services
	- Google Cloud Video AI
	- Azure Machine Learning Studio
+ tools for managing machine learning experiments:
	- Comet.ml
	- Trains
	- Guild.ai
	- Domino Model Monitor
	- Sacred + Omniboard
	- Polyaxon
	- TensorBoard
	- Weights & Biases
	- Neptune.ai
+ categories of automated machine learning tools (or partial AutoML tools):
	- automated data augmentation: imgaug, albumentations
	- automated feature engineering/selection: tpot, boruta_py
	- automated model selection: auto_sklearn, xcessiv
	- automated model architecture searches: darts, enas
	- automated hyperparameter tuning: hyperopt, ray.tune, Vizier
	- automation of full ML pipelines: Google Cloud AutoML, H20 Driverless AI
+ specific automated machine learning tools, or partial AutoML tools:
	- H20 Driverless AI
	- Xcessiv
	- Google Cloud AutoML
	- Auto-Sklearn
	- Tpot
	- Auto-Keras
	- Auto_ml
	- Databricks AutoML
	- MLbox
	- DataRobot AutoML
+ ***Publication in top-tier conferences and journals, such as NeurIPS, ICML, ICLR, CVPR, ICCV, ECCV, AAAI, ACL, STOC, IEEE TPAMI, IEEE TNNLS, IEEE TSP, IEEE TIP, Information Fusion, JAIR, IJRR, IJCV, and JMLR.***
+ If you work on any of these topics, publish in relevant ***conferences (CVPR, ICCV, ECCV, ACCV, NIPS, ICML, BMVC, WACV, ICIP, ICASSP, ICPR, EUSIPCO, MLSP, ICME, ACM Multimedia) and/or journals (IEEE PAMI, TIP, SMC, CSVT, TNNLS, TMM, Pattern Recognition, Information Sciences, Neurocomputing, Neural Networks, Image and Vision Computing, IJCV, ACM Transactions on Intelligent Systems and Technology, ACM Computing Surveys)*** and you want to get relevant regular news or post your own news, you can subscribe as shown above.
	- Ioannis Pitas
		* Professor, PhD, Director of the Artificial Intelligence and Information Analysis Lab, AUTH, Greece
		* IEEE fellow and Distinguished Lecturer
+ platform-agnostic machine learning development
+ Strong understanding of ***Model optimization, Pruning, Tuning, ONNX, Distiller, Quantization***
+ Experience framework such as ***MLflow, Kubeflow, Airflow, Seldon Core, TFServing*** etc
+ Experience with a number of ML techniques and frameworks, e.g. ***data discretization, normalization, sampling, linear regression, decision trees, deep neural networks***, etc
+ tech stack:
	- Research publications at relevant conferences such as ***SIGGRAPH, ACM Trans on Graphics, CVPR, ICCV, ICCP, SPIE, JOSA*** a major plus.
	- Expertise in Deep Learning, Machine learning and familiarity with tools like ***Scipy, Boost, Caffe, TensorFlow, OpenCV, DLIB*** etc. and related areas.
+ tech stack:
	- Publication record in top conferences (***ICML, ICLR, NIPS, KDD, IJCAI, AAAI*** etc )
	- Good knowledge and handson experience in distributed technologies such as ***Hadoop, Hive, Spark*** Experience in Scala programming language.
	- Publications in relevant top venues (e.g., ***KDD, NIPS, ICML, AAAI, IJCAI, ICDM, ACL*** etc.)
	- You have publications in communities such as ***WWW, SIGIR, FAT\*, NeurIPS, WSDM, SIGDIAL, RecSys, CHI, KDD, AAAI, ACL, ICML***, or related.
	- You have hands-on experience implementing production machine learning systems at scale in Java, Scala, Python, or similar languages. Experience with ***XGBoost, TensorFlow*** is also a plus.
	- You preferably have experience with ***data pipeline tools like Apache Beam*** or even our ***open source API for it, Scio*** and cloud platforms like GCP or AWS.
	- Extensive experience manipulating and analysing complex data with SQL, Python and/or R. Knowledge of ***Google BigQuery*** and Java/Scala is a plus.
	- Familiarity with marketing tracking platforms (e.g. ***DoubleClick, Google Tag Manager, Google Analytics***) preferred
	- Become an expert on leveraging existing state-of-the-art tooling into the Spotify eco-system (***TensorFlow, TFX, Kubeflow Pipelines, Cloud Bigtable***)
	- Contribute to new and existing Spotify open source machine learning and data processing products (scio, zoltar)
	- You preferably have experience with data processing and storage frameworks like ***Google Cloud Dataflow, Hadoop, Scalding, Spark, Storm, Cassandra, Kafka***, etc.
	- Extensive publication record at peer-reviewed ML conferences (e.g. ***NIPS, ICML, AISTATS, UAI, COLT, ICLR, AAAI***, etc) as well conferences with applied ML (e.g. ***KDD, WSDM, WWW, CIKM, RecSys***, etc).
+ Publications in top conferences in areas such as MIR, machine learning or similar (e.g. ***ISMIR, ICML, ICLR, NeurIPS***).
+ ***"Knowledge of Bayesian Global Optimization tools and technique"***
+ practical knowledge of machine learning tools (e.g. ***scikit-learn / LightGBM / PyTorch***)
+ Familiarity with neural network framework such as ***Caffe, Torch, Theano, TensorFlow, CNTK***
+ Good knowledge of popular deep learning platforms (***Tensorflow, Pytorch, Paddlepaddle***)
	- https://github.com/PaddlePaddle/Paddle
	- https://www.paddlepaddle.org.cn/
+ skill set:
	- General knowledge in machine learning, natural language processing, knowledge graph, image processing and computer vision, with deep insight in recent progress and practical experience in one of the fields
	- Understanding principles of deep learning, probabilistic inference, graphical models, reinforcement learning, transfer learning and adversarial learning, with extensive knowledge in one of the fields mentioned
+ vw / xgboost
	- vw
		* Vowpal Wabbit (VW) is an open-source fast online interactive machine learning system library and program developed originally at Yahoo! Research, and currently at Microsoft Research.
		* Vowpal Wabbit provides fast, efficient, and flexible online machine learning techniques for reinforcement learning, supervised learning, and more.
		* Vowpal Wabbit provides a fast, flexible, online, and active learning solution that empowers you to solve complex interactive machine learning problems.
	- xgboost
		* XGBoost is a scalable, distributed gradient boosting machine learning library that implements optimized decision tree -LRB- GBDT -RRB- algorithms for regression, classification, and ranking problems.
		* "It aims to provide a "Scalable, Portable and Distributed Gradient Boosting (GBM, GBRT, GBDT) Library". It runs on a single machine, as well as the distributed processing frameworks Apache Hadoop, Apache Spark, Apache Flink, and Dask.
		* "XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples."
		* XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples.
+ Knowledge of sequence models and generative models.
+ skill set:
	- We're looking for a Research Scientist to join Snap Inc! You'll work closely with our Research team to work on innovative problems that unlock new experiences for our users through computer vision, machine learning and graphics. Working closely with researchers and our engineering teams, you will develop technologies empowering our users and creators improving improving the experience on Snapchat for millions of people every day. In addition to impacting the company via products, researchers are encouraged to publish their results in top-tier journals and conferences.
	- Beyond the application and interviews, Research Scientist candidates should prepare to provide detailed supporting materials including a research statement, references, biography, and a 60-minute presentation during the evaluation process.
	- Invent novel technologies that enable new experiences for our users
	- Push the boundaries of what is possible in machine learning, computer vision, and graphics
	- Introduce major innovations that can result in product features or new areas of business
	- Collaborate with research and engineering teams to impact products
	- Contribute to the research community by publishing cutting edge research papers
	- PhD in a technical field such as computer science or equivalent experience
	- Experience in computer vision, machine learning, deep learning, graphics
	- Successful record of publication in top-tier international research venues (e.g. ***ICLR, AAAI, NeurIPS, CVPR, ECCV, ICCV, SIGGRAPH***)
	- Programming experience in one or more of the following: Python, C, C++
	- 1+ years of industrial or academic experience beyond internships or post doctoral positions
	- Efficient and scalable algorithm design and problem solving skills
	- Experience with projects that could impact our products
	- Proven experience as a highly innovative, motivated, and self-directed researcher
	- Ability to perform research that is justified and guided by business opportunities
	- Ability to thrive in a fast-paced, ever-changing work environment
	- Excitement for tough technical challenges
	- Someone with a collaborative, positive, and team-oriented mindset
	- Hands-on experience and fast prototyping skills
	- Demonstrated ability in both research and development
+ skill set:
	- RESEARCH SCIENTIST @ Abacus.AI
	- Responsible for coming up with new techniques in unsupervised learning, dataset augmentation and deep reinforcement learning that can be applied to automating various parts of the AI development workflow.
	- Candidates will need to have a PhD preferably in Artificial Intelligence or Machine Learning. We are looking for people who have done research / published papers in one of the following areas:
		* Auto ML
		* Neural Architecture Search
		* Personalization
		* Forecasting
	- Ideal candidates would be experienced at publishing at top conferences and be able to write code and ideate with the product team.
+ skill set:
	- We're looking for a Research Scientist to join Snap Inc! The mission of the lab is to create hardware and/or software approaches to computational imaging that enable new photographic functionalities and experiences that go beyond what is possible with traditional cameras and image processing methods. Our goal is to empower our users with new tools that allow them to communicate with each other more efficiently and in more creative ways than possible today.
	- We are looking for a highly innovative, motivated, and self-directed researcher. Working from our New York, NY office, you work closely with other researchers and our engineering teams, you will tackle unique technical challenges such as developing techniques to enhance existing products, create new products, deploying algorithms to handle our scale, and improving the experience on Snapchat for millions of people every day. In addition to impacting the company via products, researchers are encouraged to publish their results in top-tier journals and conferences.
	- Beyond the application and interviews, Research Scientist candidates should prepare to provide detailed supporting materials including a research statement, references, biography, and a 60-minute presentation during the evaluation process.
	- Develop new imaging technologies that enhance visual communication on both handheld and wearable devices
	- Develop new technologies that make it easier for users to interact with devices and well as for devices to interact with other devices
	- Introduce major innovations that can result in product features or new areas of business
	- Collaborate with the researchers and engineers to make important product decisions
	- Develop skills to inspire and manage small or large groups of researchers and engineers
	- PhD in a technical field such as computer science, electrical engineering, or equivalent experience
	- 3+ years of research or industry experience
	- 5+ years of research or industry experience
	- Track record of innovative work in the area of computational imaging
	- Experience or familiarity with ***imaging optics, illumination techniques, image processing, computer vision and computer graphics***
	- Ability to perform research that is justified and guided by business opportunities
	- Ability to thrive in a fast-paced, ever-changing work environment
	- Successful record of publication in top-tier international research venues
	- Collaborative, positive, and team-oriented mindset
	- Hands-on research experience and fast prototyping skills
	- Ability to lead small group of talented researchers to deliver on a high-impact research project
+ skill set:
	- SmartNews is a leading mobile app of news aggregation services. It analyzes millions of articles to deliver most engaging information with high quality in near-real time fashion to millions of users around the world. Our AI Foundation team is responsible to research and develop world-class AI algorithms that can be applied at large scale to accomplish our mission. It works on a range of ***content understanding, user modeling and recommendation problems, which include natural language processing tasks of classification, entity recognition, summarization, computer vision of image/video processing, collaborative filtering***, etc. The team generally produce good content/user signals and state-of-art recommendation models to News Ranking/Ads Ranking team to deliver the world's high quality information to the people who need it.
	- Responsibilities
		* Set technical and research roadmap for AI Foundation or even company level machine learning roadmaps (at principal level) and able to lead its implementation
		* The ability to solve hardest issues of AI Foundation team from fundamental algorithm development, implementation and optimization to deliver product metrics
		* Lead cross-organizational projects to improve features/models that benefit company OKR
		* Set visions for company's research direction to be industry leading in areas of personalized discovery and related areas
		* In this position, you are expected to utilize your industry leading expertise on one or more of following R&D areas to provide cutting edge solutions or core technologies for SmartNews recommendation systems (Ads, News, etc). At principal level, you are required to have overall understanding of corporate AI landscape, and set visions/roadmaps in its directions
		* General Machine Learning, Deep Learning
		* Natural Language Processing (entity recognition, categorization, text embedding, etc)
		* Computer Vision, Image Processing
		* Knowledge Graph
		* Recommendation, Collaborative Filtering Algorithms
		* Be great mentor to other machine learning scientists
		* Promote AI first culture and distill AI mindset across engineering teams (principal level)
	- Minimum Qualifications
		* 8+ years of experience in designing and implementing state-of-the-art machine learning algorithms, and applying them to real world problems
		* Industry leading expertise in certain domain of machine learning techniques, especially in deep learning, natural language processing, recommendation systems, computer visions
		* Long term track record of successfully deliver improvement of features/models to production systems with high impact by working across teams and organizations
		* Influential publications at top industry conferences/journals, well recognized in the industry for the domain of expertise
		* Strong mentors of senior machine learning scientists and able to grow them to the next level
		* Good written and spoken communication skills, can work across functional teams
		* Strong coding abilities in multiple programming languages (e.g. Java, C++, Python, Scala)
		* Ph.D in computer science, mathematics, physics or other quantitative fields
	- Preferred Qualifications
		* Strong interest in news media and our mission
		* Strong domain expertise in recommendation algorithms
+ skill set:
	- We use ***regression, Bayesian methods, tree-based learners, SVM, RF, XGBOOST, time series modelling, dimensionality reduction, SEM, GLM, GLMM, clustering*** etc on a regular basis.
	- Ability to deliver AIML based solutions around a host of domains and problems, with some of them being: ***Customer Segmentation & Targeting, Propensity Modelling, Churn Modelling, Lifetime Value Estimation, Forecasting, Recommender Systems, Modelling Response to Incentives, Marketing Mix Optimization, Price Optimization***
	- Experience of ***working on a project end-to-end: problem scoping, data gathering, EDA, modelling, insights, and visualizations***
	- Detailed knowledge of ***XGboost, classification models, RF, understanding of Error metrics (RMSE, MSE, MAE), model fine tuning, feature selection, model selection***
+ skill set:
	- Good knowledge of machine learning algorithms like ***Neural network, CNN, Logistic regression, KNN, Random forest, decision tree, clustering*** etc.
	- Decent depth in understanding ML algorithm concepts like supervised/unsupervised, regression/classification, time series algorithms
+ skill set for ***Deep Learning Research Scientist at DeepScale***:
	- DeepScale was founded by the deep learning researchers from UC Berkeley who created SqueezeNet. DeepScale is developing perception systems that enable automated vehicles to interpret their environment in real-time using low-cost hardware.
	- A PhD in electrical engineering, computer engineering, or computer science.
	- A track record of advancing the state-of-the-art in an application of deep learning (ideally a computer vision or imaging application ... but if you did speech-recognition or text-analysis, that's pretty good too)
	- Published papers that either (a) are in top peer-reviewed conferences such as ***CVPR, NIPS, ECCV, ICCV, or ICML*** ... or ... (b) a ***significant (>100) number of citations on one of your deep learning research publications***
	- ***The ability to design, implement, train and test models in one or more of the leading deep learning frameworks like PyTorch or TensorFlow.***
+ Machine Learning Researcher
	- Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by machine learning and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities.
	- As a Machine Learning Researcher, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors — from fraud detection, to cancer research, to national intelligence — you know the answers are in the data. You'll design and implement machine learning solutions for complex tasks on large datasets, including extracting insights from multiple disparate data sources and types, such as cyber, language, and vision. You'll perform research in machine learning, including adversarial machine learning, algorithmic fairness, and model interpretability. You'll write journal articles, present at academic conferences, and produce whitepapers and briefings to both technical and non-technical audiences. You'll serve as the client interface and maintain responsibility across the entire life cycle, including requirements gathering and analysis, process and systems definition, data analysis, presentation of analysis to clients in a format they can digest, and development of algorithm driven products and solutions.
	- 3+ years of experience with programming in Python and C
	- Experience with functional programming in OCaml
	- Experience with machine learning, including Bayesian machine learning methods
	- Knowledge of adversarial machine learning or differential privacy
	- Knowledge of mathematics and statistics, including coursework in the theory of probability, statistical inference, algorithms, linear algebra, and calculus
	- Ability to derive a variational inference procedure mathematically for a novel model and implement the inference procedure in a framework, including PyTorch or Numpy
	- Ability to communicate results to both technical and non-technical audiences effectively
	- Ability to obtain a security clearance
	- Bachelor's degree in Computer Science, Statistics, Mathematics, Physics, Applied Mathematics, or Engineering
	- Experience with application areas of machine learning, including computer vision, natural language processing, and learning on graphs
	- Experience with Bayesian deep learning and Gaussian processes
	- Experience with building complex data pipelines
	- Experience with using GPUs for machine learning using frameworks, including PyTorch or TensorFlow
	- Knowledge of cloud systems, including AWS, Azure, or GCP
	- Ability to work independently on complex tasks
+ AI Research Scientist
	- AI Research @ Autodesk
	- As an AI Research Scientist at Autodesk Research, you will be doing fundamental and applied research that will help our customers imagine, design, and make a better world. We are a team of scientists, researchers, engineers, and designers working together on projects that range from learning-based design systems, computer vision, graphics, robotics, human-computer interaction, sustainability, simulation, manufacturing, architectural design and construction.
	- As a member of the AI Lab in Autodesk Research you will be an experts in research areas such as ***artificial intelligence, deep learning, generative AI, machine learning, computer vision, reinforcement learning, information retrieval, and natural language processing***.
	- Autodesk's AI Lab is active in the wider research community, targeting publications at ***CVPR, NeurIPS, ICML, ICLR, SIGGRAPH***, and other top-tier conferences. We collaborate with top academic & industry labs, combining the best of an academic environment with product-guided research. We are a global team, located in London, Germany and Italy
	- Location: Flexible EMEA: UK, London, Italy, Germany
	- Explore and develop new ML models and AI techniques
	- Lead and collaborate on research projects within a global team
	- Review relevant AI/ML literature to identify emerging methods, technologies, and best practices
	- Work towards long-term research goals, while identifying intermediate milestones
	- Build relationships and collaborate with academics and institutions
	- Explore new data sources and discover techniques for best leveraging data
	- Publish papers; attend and speak at conferences
	- Think strategically about research directions
	- Minimum Qualifications
		* A Master's or PhD in a field related to AI/ML such as: Computer Science, Mathematics, Statistics, Physics, Linguistics, Mechanical Engineering, Architecture or related disciplines
		* Publication track record in machine learning conferences and/or journals
		* Significant post-graduate research experience, or 5 or greater years of work experience (actual job title/position will be commensurate to experience)
		* Strong background in statistical methods for Machine Learning (e.g. ***Bayesian methods, HMMs, graphical models, dimension reduction, clustering, classification, regression techniques***, etc.)
		* Familiarity with Deep Learning techniques (e.g. ***Network architectures, regularization techniques, learning techniques, loss-functions, optimization strategies***, etc.)
		* Familiarity with ***PyTorch, TensorFlow, JAX*** or similar frameworks
		* Strong coding abilities in Python and/or C++
		* LLMs and Natural Language Processing
		* Reinforcement Learning
		* ***Computational geometry and geometric methods (e.g. shape analysis, topology, differential geometry, discrete geometry, functional mapping, geometric deep learning, graph neural networks)***
		* ***Multi-modal deep learning and/or information retrieval***
		* Architecture, Construction, Manufacturing, Media & Entertainment or other Autodesk domains
+ skill set for Machine Learning Researcher:
	- Specific Skills That Will Set You Apart from the Competition:
		* ***Privacy-preserving machine learning***
		* ***Decentralized machine learning***
		* Deep knowledge of ***adtech***
		* Ph.D. in computer science from a top-tier school
	- Demonstrates a high level of initiative and consistently delivers high-quality answers
	- Has an enquiring mind and a disciplined scientific approach to extracting facts and understanding observed behavior
	- Is excited by the potential of realising high-value commercial outcomes and change the way that the advertising business operates
	- Want to be part of a high-growth startup company with global ambitions
	- Comfortable with JavaScript and C++ so that they can effectively interact with the rest of the team. Knowledge of Python, Java or C# is also strongly encouraged.
	- Has a proven track record implementing data driven products and a broad understanding of the state of the art in machine learning
	- Comfortable working in an open source setting
	- Able to ***create and deploy machine learning pipelines***
	- Has a passion for helping ***protect users' privacy and security***
	- A Ph.D. in computer science is highly preferred, but we may consider some exceptions
	- ***Logistic Regression, Decision Trees, Random Forest, Naive Bayes, Clustering***, etc. and a good grasp of the strengths and weaknesses of specific approaches
	- Basic ***data cleansing and preparation, variable preprocessing/transformation***
	- ***Univariate analysis, performing statistical tests, covariance analysis, multivariate analysis and linear/non-linear regression***
	- ***Preparation of data sets for predictive modelling, robust predictive model building, validation and application***
	- ***Automation of statistical processes and integration into a bigger product***
	- Experience in ***Hadoop technologies such as Hive / Impala and distributed data pipelines such as Airflow / Luigi***
+ skill set for Ph.D.-Level Internships at Brave:
	- San Francisco, CA, or London, U.K..
	- Brave is proud to offer summer internships for Ph.D.-level students that involve working on ground-breaking technologies that make the web faster, safer, and more private for millions of people worldwide. Brave's mission is also to change the way advertising is done on the web. If you are interested in technologies ranging from JavaScript to cutting-edge blockchain, web security, privacy, anonymity, and smart contracts, come and work with us to improve the web for millions of users!
	- You should be ready to tackle hard problems that involve building software that will be shipped to millions of people worldwide. Brave is delving into challenges that are deeply connected to cutting-edge academic research. To address many of these complex issues, we are in touch with several academic groups worldwide and we are excited to offer research internships for students who are currently enrolled in a Ph.D. program.
	- You will be part of Brave, will be paired with a mentor, and will be working alongside a larger Brave team. We offer internships in both the US and Europe. Most internships start in June 2019 and last three months, although there is some amount of flexibility for exceptional candidates.
+ Help the current effort of the AI research community, and contribute to cutting edge research in machine intelligence, starting from areas including:
	- Deep Learning
	- Generative Models
	- Reinforcement Learning
	- Evolutionary Computing
	- ***Sequence Modelling***
	- ***Large-Scale Distributed Optimization***
	- ***Low-Precision Numerical Formats***
+ skills set:
	- ***security of machine learning***
	- ***robustness and reliability of machine learning technologies***
+ skill set:
	- As part of the Advanced Product Development team, immediate responsibilities include:
		* Exploration and development of ***machine learning algorithms for spatiotemporal analysis, including multiclass classification, clustering, temporal segmentation, sequence labeling, and spatial segmentation***.
		* Development of new technologies and digital products to improve surgeon and team performance on robotic surgery platforms.
		* Support clinical and academic collaborations in related fields.
	- Additional responsibilities include:
		* Contributing to multiple areas of research, including but not limited to the following:
		* Designing and applying machine learning algorithms to novel, surgical applications
		* Characterizing surgeon and team behavior and workflow to optimize new technologies
		* Fully integrating machine learning into core digital products and intelligent systems
		* Conducting user studies to evaluate digital product concepts
	- Establishing strong academic collaborations across research disciplines
	- Presenting research at international conferences and publishing research in top academic journals
	- Qualifications... Skill/Job Requirements:
		* Competency Requirements: (Competency is based on: education, training, skills and experience).
		* In order to adequately perform the responsibilities of this position the individual must have:
			+ Doctoral degree in Computer Science, Statistics, Applied Mathematics, or Neuroscience, or Master's degree with minimum (5) years industry experience developing machine learning applications
			+ Demonstrate excellent communication skills both written and verbal
			+ Interested in early research and development through to product roll-out
			+ Solid understanding of statistics, machine learning, and deep learning algorithms and techniques is required
			+ Experience with sequence modeling, image analysis, activity recognition, and/or temporal segmentation on real-world data is required
			+ Experience with Python is required
			+ Hands-on experience with deep learning frameworks such as ***Tensorflow, Theano, Caffe, and/or Torch*** is required
			+ Hands-on experience with ***CNNs, RNNs, and LSTMs*** is ideal
			+ Experience with R, SQL is ideal
			+ Experience with C/C++ is ideal
			+ Experience with clinical studies is a plus
			+ Ability to travel domestically and internationally (10%)
+ skill set for DEEP LEARNING ALGORITHM INTERN
	- Development the deep machine learning models covers computer vision and NLP applications
	- Software performance bottleneck analysis in ***CNN/RNN/LSTM architectures and design***
	- Development of AI profiling tools for neural processor engines to optimize the entire deep neural network architectures
	- Robust learning through minimal data, unsupervised learning, and on-device learning
	- Basic knowledge of leading edge neural network models from ***TensorFlow/Tlite, Keras, Caffe/Caffe2***
	- Bachelor's degree/Master's degree. in Computer Science, Machine Learning, Mathematics, robotics, or similar field (Master's degree is preferred)
	- 1+ years of industry/academia experience with deep learning algorithm development and optimization.
	- Experience in ***deep networks (CNN, DBN, RNN, LSTM, DCN) or reinforcement learning (RL)***
	- Experience with ***classification and regression algorithms (e.g. SVM, MLP)***
	- 2-3 years of software engineering experience in an academic or industrial setting.
	- Excellent Python, C++, and object-oriented programming skills demonstrated through relevant industry experience
	- Hands-on experience in ***computer vision and deep learning frameworks, e.g., OpenCV, Tensorflow, Keras, Pytorch, and Caffe***.
	- Ability to quickly adapt to new situations, learn new technologies, and collaborate and communicate effectively.
	- Location: San Diego, CA.
+ skill set:
	- Descript is offering research internships to PhD and motivated masters students working in machine learning, human computer interaction, natural language processing, computer vision or computer audition. At Descript, we make technology that is transformative for content creation and media editing. Join us and help a passionate cross-disciplinary team of researchers, engineers, and designers build the next generation of media creation tools.
	- As a research intern, you will collaborate with our research and/or engineering teams to develop exciting and novel technology, as well as work closely with researchers who regularly publish in top-tier journals and conferences. We are also interested in fostering ongoing collaborations, and are open to longer term projects that may become part of your PhD thesis, while also having meaningful impact for Descript users. Descript is the perfect vehicle for deploying cutting edge research to real users.
	- Our research team is located primarily in Montreal, with some researchers working from France, as well as the Bay Area. Due to the COVID-19 pandemic, the location of the internship will be flexible, if not remote. You will be paired with a full-time researcher on a project tailored towards your skillset and interests.  The expected duration of the internship is anywhere between 3-6 months, and start dates are flexible.
	- Pursuing a PhD or Master's degree with a focus on one or more of the following research areas: ***computer audition, human computer interaction (with either a video or audio focus), computer vision, deep learning, and computer vision***.
	- Track record of developing new research ideas, as demonstrated by one or more first author publications or projects.
	- Publications at top ML/Audio/HCI conferences is a big plus: ***CHI, UIST, NeurIPS, ICML, ICLR, ISMIR, Interspeech, ICASSP***.
+ ***Distributed Deep Learning***
+ Staff Research Scientist, AI/ML
	- at Chan Zuckerberg Initiative (View all jobs)
	- Redwood City, CA (Open to Flex)
	- We’re on an ambitious mission to solve some of society’s toughest challenges — from eradicating disease to improving education and addressing the needs of our local communities. Join us to build a better future for everyone!
	- The mission of the CZI Science Initiative is to support the science and technology that will help make it possible to cure, prevent, or manage all diseases by the end of the century. We support interdisciplinary teams of physicians, biologists, computational scientists, and engineers to expand our understanding of the human body and illness — the very science behind medicine. CZI fosters collaboration between scientists and engineers, develops tools and technologies, and builds support for basic scientific research. Our current focus is on understanding the mysteries of the cell, the fundamental building block of life. To that end, our approach in the Science Technology group is to digitally model cell function through research, advanced development, collaboration, and funding
	- Building software such as:
		* CZ cellxgene - an easy to use corpus of single-cell transcriptomics data.
		* CZ ID - a metagenomics platform that delivers insights in infectious disease.
	- Funding of:
		* Single cell biology and the application of technologies that enable multi-omics investigation at the level of cells.
		* Imaging and developing tools capable of observing biological processes across spatial scales at the level of tissues, cells, and proteins.
	- Doing science through:
		* The CZ Biohub empowering scientists to work on their riskiest, most exciting ideas.
		* The CZ Imaging Institute and developing technologies to image the molecular architecture of the cell with atomic resolution.
	- As a Staff Research Scientist on the AI/ML team you will develop and apply state-of-the-art methods in artificial intelligence and machine learning to solve important problems in the biomedical sciences aligned with CZI’s mission. You will work as part of a team to leverage CZI’s large open-source biological datasets to create models that transform our understanding of cells. 
	- You will have the opportunity to work closely with teams of scientists, computational biologists, engineers within CZI and to collaborate with CZI grantees, with CZ institutes, and other external labs and organizations. Your work will inspire and enhance the production and analysis of datasets by CZ teams and collaborators. Scientific focus areas could include ***single cell biology, imaging, genomics, and proteomics***.
	- Develop, deploy, and maintain innovative machine learning models, systems, and software tools that enable the analysis and interpretation of complex biology data sets.
	- Solve important problems in biomedical sciences through the application of state-of-the-art methods in artificial intelligence and machine learning.
	- Implement solutions with respect to complex problems/scientific questions on large scale data sets, especially using ***machine learning approaches, predictive models, and statistical analysis, to advance understanding of cell structures, systems, and interactions***.
	- Enjoy working in a ***highly interactive and cross-functional collaborative environment with a diverse team of colleagues and partners in leading-edge cell biology data-driven research***.
	- Have a PhD or Masters in computer science (focus on machine learning & data analytics), computational biology or a related field or equivalent industry experience and at least 6-8 years of experience developing and applying machine learning methods.
	- Have demonstrated experience building and training AI/ML models, ideally but not exclusively to address problems in biology, and developing deep learning methods
	- Experience and technical fluency in AI, machine learning, operations research, data integration, or computer science on varied large scale data sets
	- Have the ability to work independently and as part of a team, and have excellent communication and interpersonal skills.
	- Have a proven track record of relevant research publications, preprints, or software packages
	- The Redwood City, CA base pay range for this role is $270,000.00- $405,000.00.
+ Research Scientist Intern
	- at Chan Zuckerberg Initiative
	- Redwood City, CA (Onsite)
	- We’re on an ambitious mission to solve some of society’s toughest challenges — from eradicating disease to improving education and addressing the needs of our local communities. Join us to build a better future for everyone!
	- The mission of the CZI Science Initiative is to support the science and technology that will help make it possible to cure, prevent, or manage all diseases by the end of the century. We support interdisciplinary teams of physicians, biologists, computational scientists, and engineers to expand our understanding of the human body and illness — the very science behind medicine. CZI fosters collaboration between scientists and engineers, develops tools and technologies, and builds support for basic scientific research. Our North Star objective is on understanding the mysteries of the cell, the fundamental building block of life. To that end, our approach is to digitally model cell function through research, advanced development, collaboration, and funding.
	- Building software such as 
		* CZ cellxgene - an easy to use corpus of single-cell transcriptomics data.
		* CZ ID - a metagenomics platform that delivers insights in infectious disease.
	- Funding of
		* Single cell biology and the application of technologies that enable multi-omics investigation at the level of cells.
		* Imaging and developing tools capable of observing biological processes across spatial scales at the level of tissues, cells, and proteins.
	- Doing science through
		* The CZ Biohub empowering scientists to work on their riskiest, most exciting ideas.
		* The CZ Imaging Institute and developing technologies to image the molecular architecture of the cell with atomic resolution.
		* As a Research Scientist Intern, you will contribute to the development and application of state-of-the-art methods in artificial intelligence and machine learning to solve important problems in the biomedical sciences aligned with CZI’s mission. You will work as part of the ***Single Cell team*** to leverage CZI’s ***large open-source biological datasets*** to create models that transform our understanding of cells. You will have the opportunity to work closely with teams of scientists, computational biologists, and engineers.
	- Develop innovative machine learning models that enable the analysis and interpretation of complex biology data sets.
	- Solve important problems in biomedical sciences through the application of state-of-the-art methods in artificial intelligence and machine learning.
	- Implement solutions with respect to complex problems/scientific questions on large scale data sets.
	- Targeted graduation date December 2024 through Summer 2025
	- Pursuing a MS or PhD degree (Computer Science or related field preferred) and will have time remaining in school after your summer internship
	- Enjoy working in a highly interactive and cross-functional collaborative environment with a diverse team of colleagues and partners in leading-edge cell biology data-driven research.
	- Have ***experience building and training AI/ML models***, ideally but not exclusively to address problems in biology and developing deep learning methods.
	- Experience with ***PyTorch, scikit-learn, and other deep learning frameworks***.
	- Experience using ***collaborative notebook-based workflows (e.g., Jupyter, Databricks) for prototyping and knowledge sharing***.
	- Familiarity with big data technologies
	- The ability to work for 12 consecutive weeks during the Summer 2024
	- Our internship program is designed to give students a meaningful, real-world work experience that complements their academic learnings. While we are not able to offer conversions to full-time positions following our internships, our program is open to a wide range of students at any point in their undergraduate careers that want to develop skills, gain experience, and connect with leaders in their fields.
	- The Redwood City, CA pay for this role is: $56.74/hour for BS candidates; $60.07/hour for MS candidates; $63.61/hour for PhD candidates.
	- The Chan Zuckerberg Initiative was founded in 2015 to help solve some of society’s toughest challenges — from eradicating disease and improving education, to addressing the needs of our local communities. Our mission is to build a more inclusive, just, and healthy future for everyone.
+ Research Scientist, Superalignment
	- OpenAI’s Superalignment Team is working on technical approaches to ensure that superintelligence–an AI system vastly smarter than humans–follows human intent. 
	- Through scientific experimentation, we explore the scalability of alignment techniques and identify potential breaking points. Our approach to alignment research includes a range of different projects; some of these will help us improve the alignment of our models and others will allow us to validate how aligned our models actually are:
		* Scalable oversight: How can we best leverage AI systems to assist evaluation of other AI systems on difficult tasks?
		* Generalization: Can we understand and control how our models generalize from easy tasks that humans can supervise to hard tasks that humans cannot?
		* Automated interpretability: Can we use AI to explain how LLMs work internally?
		* Robustness: How can we train our models to be aligned in worst-case situations?
		* Adversarial testing: If we deliberately train deceptively aligned models as testbeds,  can our oversight techniques, interpretability tools, and evaluations detect this misalignment?
	- We want to figure out how to spend vast amounts of compute to solve this problem, in particular by automating alignment research itself.
	- As a Research Scientist here, you will develop innovative machine learning techniques and advance the research agenda of the Superalignment team, while also collaborating with peers across the organization. We are looking for people who want to discover simple, generalizable ideas that work well even at large scale, and form part of a broader research vision that unifies the entire company.
	- We are seeking Research Scientists to help design and implement experiments for alignment research.
	- Designing experiments to measure the effectiveness of scalable oversight techniques such as AI-assisted feedback and Debate
	- Studying generalization to see when AI systems trained on easy problems can solve hard problems
	- Managing large datasets from interpretability experiments and creating visualizations to explore interpretability data
	- Developing experiments to test how well chain of thought reasoning reflects model cognition
	- Investigating situations when training against a reward signal causes model outputs to deteriorate
	- Exploring methods to understand and predict model behaviors, such as finding inputs causing anomalous circuits or catastrophic outputs
	- Designing novel approaches for using LLMs in alignment research
	- Are excited about OpenAI’s mission of building safe, universally beneficial AGI and are aligned with OpenAI’s charter.
	- Have a track record of coming up with new ideas or improving upon existing ideas in machine learning, demonstrated by accomplishments such as first author publications or projects
	- Possess the ability to own and pursue a research agenda, including choosing impactful research problems and autonomously carrying out long-running projects
	- Possess a strong curiosity about aligning and understanding ML models, and are motivated to use your career to address this challenge
	- Enjoy fast-paced, collaborative, and cutting-edge research environments
	- Have experience implementing ML algorithms (e.g., PyTorch)
	- Can develop data visualization or data collection interfaces (e.g., JavaScript, Python)
	- Want to ensure that powerful AI systems stay under human control
+ Research Scientist
	- By applying to this role, you will be considered for Research Scientist roles across all teams at OpenAI.
	- As a Research Scientist here, you will develop innovative machine learning techniques and advance the research agenda of the team you work on, while also collaborating with peers across the organization. We are looking for people who want to discover simple, generalizable ideas that work well even at large scale, and form part of a broader research vision that unifies the entire company.
	- Have a track record of coming up with new ideas or improving upon existing ideas in machine learning, demonstrated by accomplishments such as first author publications or projects
	- Possess the ability to own and pursue a research agenda, including choosing impactful research problems and autonomously carrying out long-running projects
	- Be excited about OpenAI’s approach to research 
	- Interested in and thoughtful about the impacts of AI technology
	- Past experience in creating high-performance implementations of deep learning algorithms
	- The annual salary range for this role is $200,000 – $370,000.
+ Research Scientist, Machine Learning
	- San Francisco, California, United States — Policy Research
	- The Policy Research team at OpenAI is responsible for understanding our company’s current and potential impact on the world, and using that understanding to recommend the best possible policies at OpenAI and elsewhere (“policies” are defined broadly to include laws, safety requirements, industry norms, etc.). Team members have backgrounds in a wide variety of disciplines, including computer science and engineering, law, philosophy, economics, political science, and more, and we use a wide variety of quantitative and qualitative methods to measure, forecast, and analyze OpenAI’s impacts.
	- We’re seeking an experienced machine learning researcher to shape and lead the ML research agenda for trustworthy AI. 
	- This is an opportunity to pioneer and prototype new approaches for testing and evaluating the most advanced AI systems – and to harness the most advanced AI systems to do so. The role will include research on the development of novel evaluation methods and interventions for things like dangerous model capabilities and existential risks, fairness and representation, as well as untruthful, hallucinatory, or otherwise undesired model behavior. 
	- If you enjoy tackling deep questions in ML research, thrive in roles where ambitious entrepreneurial pursuit of open-ended goals is rewarded, and are strongly motivated to contribute to the roll-out of advanced general AI systems going well, you will find our work here uniquely challenging and rewarding. This role reports to our Trustworthy AI lead.
	- This role is based in our San Francisco HQ. We offer relocation assistance to new employees.
	- Research upstream interventions at the level of training data, pre-training, and training
	- ***Research and prototype novel evaluation methods in areas such as dangerous model capabilities and existential risks, fairness and representation, as well as untruthful, hallucinatory, or otherwise undesired model behavior.***
	- Work with ***downstream product and infrastructure teams*** to ***build and scale effective tools for responsible deployment***
	- Develop and mentor ML Researchers on the ***Deployment Planning team***
	- Architect and develop interventions that improve real world impact
	- Have a track record of coming up with new ideas or improving upon existing ideas in machine learning, demonstrated by accomplishments such as first author publications or projects
	- Possess the ability to own and pursue a research agenda, including choosing impactful research problems and autonomously carrying out long-running projects
	- Have experience developing novel techniques for ML model measurement and mitigation
	- Have experience in research mentorship, leading project teams, and setting technical direction
	- Be comfortable working cross functionally across both research and product teams
	- Past experience in interdisciplinary research collaborations
	- Past experience in creating high-performance implementations of deep learning algorithms
	- Annual Salary Range: $200,000—$370,000 USD
+ Research Scientist, Safety
	- The Safety Systems team is responsible for various safety work to ensure our best models can be safely deployed to the real world to benefit the society. The work encompasses a wide range of research and engineering projects from detection to model training to model evaluation and red-teaming, aiming to reduce unwanted use cases and ensure model behavior within our safety standard and legal compliance. The Safety Systems team is at the forefront of OpenAI's mission to build and deploy safe AGI, driving our commitment to AI safety and fostering a culture of trust and transparency.
	- We seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth. 
	- OpenAI is seeking a senior researcher with passion for AI safety and experience in safety research. Your role will set directions for research to enable and empower safe AGI and work on research projects to make our AI systems safer, more aligned and more robust to adversarial or malicious use cases. You will play a critical role in shaping how a safe AI system should look like in the future at OpenAI, making a significant impact on our mission to build and deploy ***safe AGI***.
	- Set the research directions and strategies to make our AI systems safer, more aligned and more robust.
	- Conduct state-of-the-art research on AI safety topics such as ***RLHF, adversarial training, robustness***, and more.
	- Coordinate and collaborate with cross-functional teams, including T&S, legal, policy and other research teams, to ensure that our products meet the highest safety standards.
	- Actively performing safety audits on AI/ML models and systems, identifying areas of risk and proposing mitigation strategies.
	- Ph.D. in computer science, machine learning, or a related field, with 5+ years of related research experience.
	- Experience in the field of AI safety, working on topics like ***RLHF, adversarial training, robustness, fairness & biases***, is extremely advantageous.
	- Experience in safety work for AI model deployment is a big plus.
	- Care deeply about AI safety and motivated by work to make the cutting edge AI models safer for real world use;
	- In-depth understanding of deep learning research and/or strong engineering skills is critical for the success of the role.
	- Enjoy being a team player.
	- Annual Salary Range: $200,000—$370,000 USD
+ skill set:
	- Intuitive Surgical designs and manufactures state-of-the-art robot-assisted systems for use in minimally-invasive surgery. These systems are revolutionizing the way in which surgery is being done and offer a unique platform that is being used routinely at hospitals worldwide for exploring the potential of digital surgery. Joining Intuitive Surgical means joining a team dedicated to using technology to benefit patients by improving surgical efficacy and decreasing surgical invasiveness, with patient safety as our highest priority.
	- The Applied Research group within Intuitive Surgical has an immediate opening in Sunnyvale, CA for a research scientist with focus on Computer Vision, Deep Learning and Image Analytics, contributing to new technology development in the area of 3D scene understanding/reconstruction and spatial AI systems for next-generation robot-assisted surgery platforms. This role is an exciting opportunity to join a newly formed team and contribute to its growth and it will give you an opportunity to test your knowledge in a challenging problem solving environment.
	- Research, design and implement algorithms in deep learning for computer vision and image analytics
	- Contribute to research projects that develop a variety of algorithms and systems in computer vision, image and video analysis.
	- Advance the state-of-the-art in the field, including generating patents and publications
	- Develop prototypes of 3D recognition models that scale to large clinical datasets
	- Develop prototypes of dense 3D reconstruction systems based on multi-view image sensors
	- Contribute to building new clinical datasets and data pipelines
	- Participate in integration of new ML/CV algorithms into existing and future robotic platforms
	- Experiment with several users and clinical advisors to iterate prototype designs based on feedback and performance.
	- Develop new technologies and digital products to improve surgeon and team performance on robotic surgery platforms.
	- Support academic collaborations in related fields.
	- Contribute to multiple areas of research, including but not limited to the following:
		* Design and apply CV/ML algorithms to novel, surgical applications
		* Design/bring-up of novel sensing technologies
		* Characterize surgeon and team behavior and workflow to optimize new technologies
	- Establish strong academic collaborations across research disciplines
	- Doctoral degree in computer science, electrical and computer engineering, or Master's degree with minimum (5) years industry experience developing computer vision and machine learning applications
	- Strong understanding of machine learning: you should be familiar with the process (data collection, training, evaluation, and making iterative improvements) of building effective learning systems.
	- Strong hands-on experience with at least one of the ***main stream deep learning frameworks such TensorFlow, PyTorch, BLVC Caffe, Theano***
	- Strong hands-on experience with Python (proficiency), C/C++ (proficiency), Shell Script, Matlab
	- Strong engineering practices, debugging/profiling skills, familiarity with multi- threaded programming.
	- Train machine learning and deep learning models on a computing cluster to perform ***visual recognition tasks, such as segmentation and detection***
	- Hands-on experience with GPU accelerated algorithms and implementations
	- Hands-on experience with state-of-the-art models based on ***CNNs, RNNs, and LSTMs***
	- Excellent communication skills both written and verbal
	- Interested in early phases of product exploration and iteration based on incomplete requirements.
	- Solid understanding of computer vision, machine learning, and deep learning algorithms and techniques is required
	- Experience with visualization tools is a plus
	- Self-starter and able to work in a collaborative and results-oriented environment
	- Ability to travel domestically and internationally (5-15%)
	- Able to view live and recorded surgical procedures
+ skill set:
	- Descript is powered by state-of-the-art Deep Learning technology, lowering the barrier to entry for content creation. Our vision is to build the next generation platform to enable easy and fast creation of audio and video content powered by cutting-edge AI. Building a revolutionary way to record, transcribe, edit and mix spoken audio and video comes with a series of unique challenges and requires solving hard and complex problems. This team has pioneered text-based media editing through tools like Overdub and Studio Sound. 
	- Own the ML infrastructure and production pipelines to bring the magic of AI to the end users
	- Collaborate with the engineering team to bring  AI services to life
	- Provide guidance on the performance trade-offs of Deep Learning models in production to the rest of the organization
	- Ability to write flawless, readable and maintainable code in Python. Experience with Go is a plus.
	- Familiarity with ***gRPC*** and Deep Learning model deployments
	- ***Experience in design, development and maintenance of tools for ML data and modeling pipelines, including big data processing, model training and evaluation, continuous integration and development, model quality monitoring and analytics***
	- Previous experience with developing machine learning infrastructure or experience in using GPUs
	- Strong analytical skills and a real passion for efficiency of the data and modeling process
	- Familiarity with ***deep learning frameworks (e.g. Tensorflow, PyTorch)***
	- Preferred: Experience with ***on-device deployment of the deep learning models***
	- Preferred: Ability to deal well with ambiguous problems, and proceed with good judgement
	- Preferred: Knowledge and experience with ***Google Cloud Platform and Kubernetes***
+ Familiar with a certain ***deep learning framework, such as TensorFlow, MXNet, Caffe, Torch***, etc., and have a deep understanding of deep learning
+ skill set for SOFTWARE ENGINEER (INTERN)—DEEP LEARNING/MACHINE LEARNING /COMPUTER VISION
	- ***Software performance bottleneck analysis of frameworks, tools, and run-time to develop and integrate full stack solutions using a variety of neural network architectures.***
	- Development of ***AI profiling tools for neural processor engines to optimize the deep neural network architectures***
	- Bachelor's /Master's degree. in Computer Science, Machine Learning, or similar field (Master's degree is preferred)
	- Basic knowledge on object-oriented software design skills
	- Software engineering experience in an academic or industrial setting.
	- Experience with Python, C++/C, and object-oriented programming skills demonstrated through relevant industry experience.
	- ***Hands-on experience running machine learning toolkits such Caffe/Caffe2, PyTorch, and TensorFlow***
	- Basic knowledge of machine learning concepts, algorithms and architectures, including ***CNNs, LSTM-RNNs***, etc
	- Ability to quickly adapt to new situations, learn new technologies, and collaborate and communicate effectively.
	- Location: San Diego, CA.
+ skill set:
	- At Toyota Research Institute (TRI), we're building a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We're dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life. Through innovations in AI, we'll help...
		* Develop vehicles incapable of causing a crash, regardless of the actions of the driver.
		* Develop technology for vehicles and robots to help people enjoy new levels of independence, access, and mobility.
		* Bring ***advanced mobility technology*** to market faster.
		* Discover new materials that will ***make batteries and hydrogen fuel cells smaller, lighter, less expensive and more powerful***.
		* ***Develop human-centered AI systems to augment (not replace) human decision making to increase the quality of decisions (e.g. mitigate cognitive biases) and/or to facilitate faster innovation cycles.***
	- Our work is guided by a dedication to safety – in both what we research and how we perform our research our goal is to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies.
	- We strive to build a company that helps our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve our goals.
	- ***TRI's Planning and Control team is building the decision-making, planning, and execution technology required to develop the uncrashable Toyota. We are doing cutting edge research in the decision systems required for L5 autonomous cars in addition to the exploration of highly dynamic control regimes and blended driver-machine control techniques to build the ultimate, fun, uncrashable car of the future. We are leveraging advances in AI, Planning, and Control Theory to realize a scalable, verifiable system to solve the L5 driving problem in the long term, while making a difference in society in the short term through our Guardian and Chauffeur systems.***
	- Responsibilities:
		* Develop, deploy and evaluate state of the art algorithms in ***agent behavior prediction***.
		* Closely work together with ***perception and motion planning engineers and research scientists*** to understand needs and develop integrated solutions.
		* ***Maintain and improve the interplay between perception, prediction, and planning to achieve robust and human-like AV behavior.***
		* ***Build software tools to accelerate prediction and planning development.***
		* ***Design reusable software components as part of an integrated system.***
		* ***Understand and fulfill the software practices that produce maintainable code, including automated testing, continuous integration, and code review.***
	- Qualifications:
		* Master's degree or greater in Robotics, Computer Science or equivalent and 3+ years of industry experience, or B.S. and 5+ years of industry experience.
		* ***Strong systems-level thinking and approach to problem solving.***
		* Solid C++ software development skills.
		* Strong understanding of common software performance issues and trade-offs.
		* ***Lifelong learner, interested in tackling new challenges daily.***
		* Familiarity with modern machine learning concepts.
		* Familiarity with ***computational geometry and dynamics***.
		* Good communication and collaboration skills.
		* Experience deploying machine learning models on real-world applications is a plus
		* Experience fielding real-world robotic systems is a plus.
+ skill set for Research Scientist:
	- Responsibilities:
		* ***Perform and publish cutting-edge research in machine intelligence, with special focus on fundamental algorithms and applications for computer vision, language modelling, numerical formats and graph neural networks.***
		* Exploit Graphcore's hardware to develop and deliver models of unprecedented scale and performance.
		* Collaborate with both the research team and other groups within the company, to develop new ideas, identify research opportunities and provide machine learning expertise.
		* Follow the latest developments in the field by attending/presenting at journal clubs and travelling to relevant conferences.
		* Promote the IPU by developing and maintaining collaborations with external institutions and research labs.
	- Essential:
		* MSc or PhD in Machine Learning, Computer Science, Electrical Engineering, Physics, Mathematics or a related field.
		* In-depth understanding of ***modern machine learning algorithms, deep learning architectures and probability theory***.
		* Experience using ***modern machine learning frameworks (e.g., TensorFlow, PyTorch, JAX)***.
		* Proficiency in Python and/or C++.
		* Strong communication skills and willingness to work in a collaborative environment.
	- Desirable:
		* Publications at ***top conference venues (e.g., NeurIPS, ICLR, ICML)***.
		* Contributions to ***open-source software projects in the area of machine intelligence***.
		* Experience in ***using or designing low-precision numerical formats***.
		* Kaggle competitions or other evidence of practical expertise.
+ skill set:
	- At Toyota Research Institute (TRI), we're working to build a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We're dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life. Through innovations in AI, we'll help...
		* Develop vehicles incapable of causing a crash, regardless of the actions of the driver.
		* Develop technology for vehicles and robots to help people enjoy new levels of independence, access, and mobility.
		* Bring advanced mobility technology to market faster.
		* Discover new materials that will make batteries and hydrogen fuel cells smaller, lighter, less expensive and more powerful.
		* ***Develop human-centered AI systems to augment (not replace) human decision making to increase the quality of decisions (e.g. mitigate cognitive biases) and/or to facilitate faster innovation cycles.***
	- Our work is guided by a dedication to safety – in both what we research and how we perform our research our goal is to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies. Over half of our technical team carries PhD degrees. We're continually searching for the world's best talent ‒ people who are ready to define the new world of mobility with us!
	- We strive to build a company that helps our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve our goals. Come work with TRI if you're interested in transforming mobility through designing technology for safer cars, enabling the elderly to age in place, or designing alternative fuel sources. Start your impossible with us.
	- Responsibilities:
		* Research, design, and develop new deep learning algorithms
		* ***Be a leader in high level algorithm decisions to ensure fast and accurate development cycles.***
		* ***Implement and maintain cutting edge deep learning algorithms in object classification, object detection, video understanding, labeling, clustering, segmentation, data association, tracking and prediction***
		* ***Build robust, reliable systems to handle common and long tail problems***
		* ***Embrace self-supervised learning strategies to overcome ever so growing data needs.***
		* As an applied researcher your goal should be to deploy your work onto our test vehicles.
		* ***Develop systems that can run in tightly controlled real-time loops.***
		* ***Collaborate with other perception engineers and scientists to develop perception algorithms, systems, and tools for autonomous driving systems.***
		* Support the ***development of large data sets and data pipelines for system training and evaluation***.
		* Stay up to date on the state-of-the-art in deep learning ideas and algorithms.
	- Qualifications:
		* PhD or MS in CS/CE/EE, or equivalent experience
		* 3+ years of professional experience in related position
		* Extensive experience with ML frameworks such as PyTorch
		* ***Experience with machine learning and classification, tracking or prediction***
		* ***Experience in robotics, AI, tracking, prediction or computer vision applied to autonomous driving.***
		* ***Proficiency in linear algebra, probability, statistics, and differential equations***
		* Strong grasp of current ***ML techniques, especially deep learning for perception, tracking or prediction algorithms.***
		* Strong communication skills. Team player.
		* Strong C++ software development skills.
		* ***Proficient in Python and Unix is a minimum. Additional knowledge of C++ / CUDA is a plus***
+ skill set:
	- At Toyota Research Institute (TRI), we're working to build a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We're dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life. Through innovations in AI, we:
		* ***Develop vehicles incapable of causing a crash, regardless of the actions of the driver.***
		* Develop technology for vehicles and robots to help people enjoy new levels of independence, access, and mobility.
		* Bring sophisticated mobility technology to market faster.
		* ***Discover new materials that will make drive batteries and hydrogen fuel cells smaller, lighter, less expensive, and more powerful.***
	- Our work is guided by a dedication to safety – in how we research, develop, and validate the performance of technology to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies. Over half of our technical team carries Ph.D. degrees. We're continually searching for the world's best talent ‒ people who are ready to define the new world of mobility with us!
	- We strive to build a company that helps our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun start-up environment with forward-thinking people who enjoy solving global problems and the financial backing to successfully achieve our goals. If you're passionate about working with smart people to make cars safer, enable the elderly to age in place, or design alternative fuel sources, TRI is the place for you. ‒ Start your impossible with us.
	- Our Machine Learning (ML) team is looking for Research Scientists in a variety of areas including ***Self-Supervised Learning, Reinforcement Learning (especially Model-based and Offline), Vision-as-Inverse-Graphics (including Differentiable Rendering), and ML Safety (including ML theory, AI ethics, causality)***. We are aiming to make progress on some of the hardest scientific challenges around the ***safe and effective usage of large robotic fleets, simulation, and prior knowledge (geometry, physics, proven experience, behavioral science), not only for automation but also for human augmentation***.
	- As a Research Scientist, you will work with a multidisciplinary team proposing, conducting, and transferring cutting-edge research in Machine Learning. You will use large amounts of sensory data and simulation to solve open problems, publish at top academic venues, and test your ideas in the real world (including our robots (https://www.tri.global/news/virtual-robotics-event/) and test vehicles (https://www.youtube.com/watch?v=0OLcLZwsgzY) of course!). You will also work closely with other teams at TRI to transfer and ship our most successful algorithms and models towards ***world-scale long-term autonomy and advanced assistance systems***. Responsibilities and required qualifications are as follows:
	- Responsibilities:
		* ***Conduct ambitious research in Machine Learning that solves open problems of high practical value and validate it in real-world benchmarks and systems.***
		* ***Push the boundaries of knowledge and the state of the art in ML areas including simulation, perception, prediction, and planning for autonomous driving and robotics.***
		* Partner with a multidisciplinary team including other research scientists and engineers across the ML team, TRI, Toyota, and our university partners.
		* Stay up to date on the state-of-the-art in Machine Learning ideas and software.
		* Present results in verbal and written communications, internally, at top international venues, and via open-source contributions to the community.
		* Lead collaborations with our external research partners (e.g., Stanford, Berkeley, MIT) and mentor research interns.
	- Qualifications:
		* Bachelor's or Master's degree in a quantitative field (e.g. Computer Science, Mathematics, Physics, Engineering, Chemistry). Ph.D. in Machine Learning, Robotics, Computer Vision, or related fields preferred.
		* ***Deep expertise in at least one key ML area among Computer Vision, RL, ML theory, AI ethics.***
		* ***Consistent track record of publishing at high-impact conferences/journals (CVPR, ICLR, NeurIPS, RSS, ICRA, ICCV, ECCV, PAMI, IJCV, etc.) on the aforementioned topics.***
		* ***Proficient at scientific python, Unix, and a common DL framework (preferably PyTorch). Experience with distributed learning (especially on AWS) is a plus.***
		* You can identify, propose, and lead new research projects, working in collaboration with other researchers and engineers to complete it from initial idea to working solution.
		* You are passionate about large-scale challenges in ML, especially in the space of Automated Driving and Robotics and for societal good in general.
		* You are a reliable team-player. You like to think big and go deeper. You care about openness and delivering with integrity.
	- Please add a link to Google Scholar and include a full list of publications when submitting your CV to this position.
+ skill set:
	- The machine learning research scientist's primary role is to work with other R&D team members to imagine, define, and develop ***BrainChip's spiking neural network technology***. This research takes place at the ***interface between machine learning algorithms, event-based algorithms, and neuromorphic hardware***. The research scientist will also be involved in developing commercial applications for BrainChip's Akida Neuromorphic System-on-Chip (NSoC). Target commercial application topics include ***computer vision (object classification/detection and face recognition), audio processing (keyword spotting), and sensor fusion***. Additionally, the team member will support the research team's algorithm development for the next version of the Akida NSoC.
	- Ph.D. in computer science (or equivalent) or MS in computer science with +5 years of machine learning experience
	- 3+ years of machine learning experience using Python
	- Experience with ***supervised, unsupervised, and reinforcement learning***
	- Experience in popular ***Deep Learning/Machine Learning frameworks (Keras, Tensorflow, PyTorch, Scikit-learn, etc.)***
	- Experience in one or more of the following application fields: ***Image Processing/Computer Vision, ADAS, Anomaly Detection, Audio/Speech Processing, or Sensor Fusion***.
	- Experience in ***Neuromorphic Engineering and/or Spiking Neural Networks***
	- Experience with ***event-based algorithms***
	- Experience with Git version control system
+ skill set for Deep Learning Architect Intern:
	- NVIDIA is seeking computer architecture interns to help design processor and system architectures that will enable compelling Deep Learning performance, architecture and efficiency improvements. This role offers the opportunity to directly impact the future hardware and software roadmap in a fast-growing technology company that leads the AI revolution. If you are obsessed with improving deep learning performance beyond anything possible with today's hardware and software, this is the place to be.
	- ***Understand, analyze, profile, and optimize deep learning training workloads on state-of-the-art hardware and software platforms.***
	- Guide development of future generations of deep learning processors and computing platforms.
	- ***Develop detailed performance models and simulators for computing systems accelerating DL training.***
	- Collaborate across the company to guide the direction of machine learning at NVIDIA; spanning teams from hardware to software and research to production.
	- ***Drive HW/SW co-design of NVIDIA's full deep learning platform stack, from silicon to DL frameworks.***
	- You are pursuing a PhD or MS in CS, EE or CSEE.
	- ***Strong background in computer architecture, preferably with focus on high-performance parallel processors.***
	- ***Background in machine learning and neural networks, in particular training.***
	- Experience ***analyzing and tuning application performance***.
	- Experience with ***processor and system-level performance modelling***.
	- Programming skills in C++ and Python.
	- Familiarity with ***GPU computing (CUDA, OpenCL)***.
+ skill set:
	- We are looking for an extraordinary Deep Learning Software Intern to develop NVIDIA's deep learning solutions in autonomous driving vehicles. As a member of our ***Solution Engineering-Automotive Machine Learning team***, you will utilize ground breaking ***NVIDIA deep learning model training/inference software libraries for deployment on NVIDIA's hardware architecture***. You will ***develop new deep learning architectures, deploy deep learning models in low precision, and compile and optimize DNN graphs***. As a part of this role, you will be building a close technical relationship with our internal ***automotive/framework teams during product development and coordinate with the architecture and software teams to develop the best solution on our platforms***.
	- ***Train, fine-tune, optimize and customize perception DNNs in low precision (FP16/INT8)***
	- ***Apply low precision inference, quantization, and compression of DNNs***
	- ***Design and develop robust inferencing software that can be scaled to multiple platforms for functionality and performance***
	- ***Performance analysis, optimization and tuning***
	- You'll collaborate across the company to guide the direction of ***machine learning inferencing***, working with software, research and product teams
	- Pursuing MS or PhD degree from a leading University in a relevant field, e.g. engineering, computer science, or computer engineering or equivalent
	- 2+ years of relevant software development experience
	- Excellent C/C++ programming and software design skills, including debugging, performance analysis, and test design
	- You should display a real passion for artificial intelligence and computer vision, and knowledge of the latest developments in DL and AI
	- Experience working with ***deep learning frameworks like Caffe, TensorFlow and PyTorch***
	- Dedicated and able to work without supervision
	- Experience with ***low precision inference, quantization, compression of DNNs***
	- Experience with ***NVIDIA software libraries such as CUDA and TensorRT***
	- ***Open source project ownership or contribution, healthy GitHub repositories, guiding and/or mentoring experience***
+ skill set:
	- NVIDIA is searching for world-class researchers in deep learning, focused on ***large-scale and high-precision medical imaging analysis, federated learning*** to join our applied research team. We believe that Deep Learning accelerated AI will completely reshape life sciences, medicine, and healthcare as an industry. To foster that transformation, NVIDIA is democratizing deep learning by providing an ***end-to-end AI computing platform*** crafted for the healthcare community.
	- ***GPU-accelerated deep learning solutions*** can be used to craft more sophisticated ***neural networks for healthcare and medical research applications: from real-time pathology assessment to point-of-care interventions to predictive analytics for clinical decision-making***. Innovations in AI are advancing the future of ***precision medicine and population health management*** in spectacular ways. We are passionate about ***applying deep learning to healthcare applications for high-performance preventive/precision medicine, and knowledge mining from very large-scale clinical datasets and resources, to facilitate effective clinical workflows, built upon NVIDIA's hardware/software AI platform***. After building prototypes that demonstrate the promise of your research, you will collaborate with software engineering team to integrate your work into products.
	- Craft DL approaches to solving ***medical imaging analysis, federated learning problems***.
	- ***Construct and curate large problem datasets.***
	- ***Design and implement medical imaging, computer vision, machine learning, federated learning techniques sought at solving specific problems.***
	- Keep up with the latest ***DL research and collaborate with diverse teams, including DL researchers, physicians, hardware architects, and software engineers***, etc.
	- ***Generate high-quality patents and top-tier technical or clinical publications, transfer technology into products.***
	- Pursuing a PhD in Electrical Engineering, Computer Science/Engineering, or related field.
	- ***Relevant work experience in computer vision, medical imaging, deep learning, statistical learning, federated learning.***
	- ***You've produced a track record of research (publication) excellence and/or significant product development. IE 4+ pieces of tier-one publications with substantial deep learning for healthcare applications.***
	- ***Excellent rapid prototyping skills with medical applications using Python.***
	- Excellent knowledge and development experience of ***common deep learning frameworks and packages (Caffe, Tensorflow, PyTorch***, etc.).
	- Excellent communications skills.
	- Prior experience working with physicians to identify (novel) important problems and assessing possible DL solutions is a plus.
+ skill set:
	- Facebook is seeking a Research Scientist to join our AI Research Team, a research organization focused on making significant progress in AI. Individuals in this role are expected to be recognized experts in identified research areas such as ***artificial intelligence, machine learning, computational statistics, and applied mathematics, particularly including areas such as deep learning, graphical models, reinforcement learning, computer perception, natural language processing and data representation***. The ideal candidate will have a keen interest in producing new science to understand intelligence and technology to make computers more intelligent. To learn more about our research, visit https://ai.facebook.com/.
	- ***Lead research to advance the science and technology of intelligent machines***
	- ***Lead research that enables learning the semantics of data (images, video, text, audio, speech and other modalities)***
	- Devise better ***data-driven models of human behavior***
	- ***Work towards long-term ambitious research goals, while identifying intermediate milestones***
	- Influence progress of relevant research communities by producing publications
	- Contribute research that can be applied to Facebook product development
	- Lead and collaborate on research projects within a globally based team
	- Experience holding a faculty, industry, or government researcher position
	- Ph.D. and publications in machine learning, AI, computer science, statistics, applied mathematics, data science, or related technical fields
	- Experience leading a team in solving modeling problems using AI/ML approaches
	- ***Experience in theoretical and empirical research and for addressing research problems***
	- Experience communicating research for public audiences of peers
	- Knowledge in a programming language
	- Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment
	- 1+ year(s) of work experience in a university, industry, or government lab(s), in a role with primary emphasis on AI research
	- Experience driving original scholarship in collaboration with a team
	- ***First-author publications at peer-reviewed AI conferences (e.g. NeurIPS, CVPR, ICML, ICLR, ICCV, and ACL)***
	- Experience in developing and debugging in C/C++, Python, or C#
+ skill set:
	- We are looking for a Research Scientist Intern to join our growing ***Trust & Safety Research & Algorithmic Impact team***. ***Spotify's Algorithmic Responsibility effort*** focuses on empowering Spotify teams to ***assess the algorithmic impact of their products on audio culture, avoid algorithmic harms and unintended side effects, and better serve worldwide audiences and creators***. As an ***Algorithmic Impact research intern***, you will help to ***define, research, and communicate how we assess our impact as a platform and our recommendations across podcasts, music, and user-generated content. We help ensure that Spotify is a safe platform that's true to our values.***
	- Be part of an interdisciplinary team focused on understanding Spotify's impact as a platform, and ***practical implementation and operationalization of Responsible ML activities such as algorithmic impact assessments***. 
	- Contribute to the wider research community by publishing. 
	- ***Develop and iterate policy and auditing processes related to tech responsibility, algorithmic fairness and representation in the music and podcast industry.***
	- Apply your scientific knowledge to ***develop strategy around cultural equity in audio and algorithmic systems, including application-oriented problems in search, recommendation and Machine Learning settings***. 
	- Provide consultative support, guidance on methods, and research-based input for products. For instance, this can include ***algorithmic audits, or analyzing & tracking global and local trends around online abuse, hate content, misinformation, etc., with a particular focus on algorithmic amplification***.
	- Work closely with our team and internal partners to develop, refine, and launch processes that help ensure Spotify is a safe and positive experience. 
	- Be a valued member of an ***autonomous, multi-functional team*** working in collaboration with other scientists, engineers, product managers, policy experts, designers, user researchers, and analysts across Spotify to design creative solutions to exciting problems.
	- You are pursuing a PhD in Social Science, HCI, Computer Science, Information Science, Data Science, Technology Policy, or related areas with a strong computational focus.
	- ***You have publications in communities such as the Web Conference, AIES, FAccT, CSCW, SIGIR, CHI, ACL, NeurIPS, WSDM, EMNLP, RecSys, KDD, ICWSM, ISMIR or related venues.***
	- ***You are curious about how interaction design, data collection strategies, and people's perceptions affect Machine Learning outcomes.***
	- You are a creative problem-solver who is passionate about digging into complex problems and devising innovative ways to reach results.
	- ***You have experience with the complexities of real-world data, and understand the value of both in-depth, qualitative and web-scale, quantitative data working together to build a deep understanding of people's interaction with technology.***
	- Knowledge or ***experience working in emerging markets*** is a plus.
	- You have strong communication skills, both written and verbal. Able to provide concise advice and translate complex challenges clearly. Willing to apply academic knowledge and frameworks into product and practice.
	- You must be comfortable reviewing or being exposed to sensitive content and topics, and having related conversations with teams.
+ skill set:
	- Research Scientist
	- ***Responsible for coming up with new techniques in unsupervised learning, dataset augmentation and deep reinforcement learning that can be applied to automating various parts of the AI development workflow.***
	- Candidates will need to have a PhD preferably in Artificial Intelligence or Machine Learning. We are looking for people who have done research / published papers in one of the following areas:
		* Unsupervised Learning
		* ***Generative Modeling***
		* Deep Neural Networks
		* ***Deep Reinforcement Learning***
		* ***Generative Adversarial Networks***
		* ***Causal Reasoning***
	- Ideal candidates would be able to rapidly iterate on new ideas with engineers, potentially publish at top conferences and be able to write code.
+ skill set:
	- Principal Software Engineer - Applied Machine Learning
	- As the Principal Software Engineer for our Machine Learning team you will be responsible for ensuring that the development of ML systems and services meets all technical and quality standards. You will work with Product Management and other technical teams within Splunk, incorporating new requirements and providing technical information related to this sophisticated ML Platform as needed.
	- work with a team of ***senior ML engineers, applied researchers and security researchers, and experts within their own specialty***. You will set an example for this group, as well as set high standards on quality, communication and ability to deliver with deadlines.
	- contribute to architecture and technical decisions while also mentoring junior members within the team.
	- ***be working in a multi-office, multi-location development environment and prior experience working with local and remote teams or groups will be a plus.***
	- While expertise with ML products and their application within enterprise solutions is highly desirable, it is not required, provided you are willing to quickly come up to speed and you have some prior experience of ML technology and its application.
	- 12+ years software development with focus on large scale distributed systems.
	- Some Machine Learning application development experience, this is NOT a data scientist role, but a ***services/platform development role***.
	- Ability to communicate effectively in conversations with researchers and engineers from academia background.
	- Passionate about building and encouraging good engineering practices and processes such as ***continuous integration and deployment***.
	- ***Experience developing and putting into production test automation and CI/CD systems.***
	- ***Expertise in developing software with container deployment and orchestration technologies at scale, with strong knowledge of the fundamentals including service discovery, deployments, monitoring, scheduling, load balancing.***
	- Strong background in ***building streaming applications or streaming analytics platforms***.
	- Expert in one of the ***streaming platforms, preferably Flink***.
	- Expertise in ***developing software on a public cloud platform (AWS, GCP, Azure)***.
	- Expertise in ***developing software with stream processing technology (Kafka, AWS Kinesis)***.
+ ***Capsule Networks***, or capsule neural networks
+ skill set for ***Autodesk AI Lab, Pier.9 at San Francisco***:
	- [BrickBot](https://www.fastcompany.com/90204615/autodesks-lego-model-building-robot-is-the-future-of-manufacturing)
	- [Auto Sketching and Vectorization](https://canvasdrawer.autodeskresearch.com/)
	- [Topology Optimization for Specific Manufacturing Processes](https://www.autodesk.com/customer-stories/general-motors-generative-design)
	- Exploring and developing new Machine Learning models and techniques
	- Constantly reviewing relevant Machine Learning literature to identify emerging methods or technologies and current best practices
	- Introduces creative approaches to research topics and generates new approaches, perspectives and solutions to research topics
	- Planning and designing research projects: specifying the problem and defining the project scope
	- Connecting with academics and institutions to build relationships and collaborate
	- Realizing solutions through prototypes
	- Exploring new data sources and discovering techniques for best leveraging data
	- Collecting and performing data analysis to validate and further new theories and discoveries
	- Publishing and talking at conferences
	- Working closely with product engineers to design, develop and incorporate AI solutions into new products
	- Meeting with customers to understand how ML could be applied to their problems
	- ***Thinking strategically about research directions***
	- Mentoring more junior researchers and engineers
	- An MS or PhD in a field related to Machine Learning such as: Computer Science, Mathematics, Statistics or Physics
	- Significant doctoral or post-doctoral research experience or 5 or greater years of work experience
	- Truly excited by the pace of advancement in AI research and technology
	- Understanding of fundamental CS algorithms and their scaling behaviors
	- ***Solid background in statistical methods for Machine Learning: Bayesian methods, dimensional reduction, SVD, clustering, classification, forms of regression, etc***
	- ***Strong familiarity with Deep Learning techniques: various network architectures (CNNs, GANs, RNNs, Auto-Encoders, etc.); regularization; embeddings; loss-functions; optimization strategies; etc***
	- ***Familiarity with one or more typical deep learning frameworks: TensorFlow, Caffe, MxNet, TORCH, PaddlePaddle, etc***
	- Experience training and debugging networks
	- Strong coding abilities in: Python and C/C++
	- Good communication skills and an awareness of how to communicate data and results effectively
	- Comfortable working in newly forming ambiguous areas where learning and adaptability are key skills
	- At times, the ability to lead and rally stakeholders and team members
	- ***Reinforcement Learning and other areas of Control Theory***
	- ***Distributed Systems and High Performance Computing methods***
	- ***Geometric Shape Analysis***
	- ***Advanced simulation methods such as: FEA, CFD, Shape and Design Optimization, Photo-Realistic Rendering, etc***
	- ***Knowledge Representation (semantic models, graph databases, etc.)***
+ skill set:
	- Our AI Labs focus on research in: ***deep learning, control systems, simulation and knowledge representation applied to diverse areas such as: geometry, robotics, advanced sensing, design exploration and sustainable engineering or construction practices***. The labs also host product engineers resulting in early productization of our research, so you can see your work in action.
	- You will be a senior researcher focusing on problems related to ***geometry understanding, manipulation and synthesis***.
	- The Lab brings together AI Researchers, Software Engineers and specialists in various problem areas to create novel AI solutions in all the areas mentioned above and more. They work closely with experts in: ***geometric modeling, simulation systems, robotics, knowledge representation, sensing and computer vision, industrial manufacturing and construction techniques***.
	- Explore and develop new Machine Learning models and techniques
	- Constantly review relevant Machine Learning literature to identify emerging methods or technologies and current best practices
	- Introduce creative approaches to research topics and generates new approaches, perspectives and solutions to research topics
	- Plan and design research projects: specifying the problem and defining the project scope
	- Connect with academics and institutions to build relationships and collaborate
	- ***Realize solutions through prototypes***
	- Explore new data sources and discover techniques for best leveraging data
	- Collect and perform data analysis to validate and further new theories and discoveries
	- Publish and talk at conferences
	- Work closely with product engineers to design, develop and incorporate AI solutions into new products
	- Meet with customers to understand how ML could be applied to their problems
	- ***Think strategically about research directions***
	- Mentor more junior researchers and engineers
	- An MS or PhD in a field related to Machine Learning such as: Computer Science, Mathematics, Statistics or Physics
	- Significant doctoral or post-doctoral research experience or 5 or greater years of work experience
	- ***Solid theoretical background in geometry and geometric methods (e.g. shape analysis, topology, differential geometry, discrete geometry, functional mapping, etc.)***
	- ***Good background in statistical methods for Machine Learning (e.g. Bayesian methods, HMMs, Graphical Models, dimensional reduction, clustering, classification, regression techniques, etc)***
	- ***Familiarity with Deep Learning techniques (e.g. Network architectures; regularization techniques; learning techniques; loss-functions; optimization strategies etc)***
	- ***Familiarity with one or more typical deep learning frameworks: TensorFlow, Caffe, MxNet, TORCH, Chainer, etc.***
	- Strong coding abilities in: Python and C/C++
	- Good communication skills and an awareness of how to communicate data and results effectively
	- Comfortable working in newly forming ambiguous areas where learning and adaptability are key skills
	- At times, the ability to lead and rally stakeholders and team members
	- ***Reinforcement Learning and other areas of Control Theory***
	- Distributed Systems and High Performance Computing methods
	- ***Advanced simulation methods such as: FEA, CFD, Shape and Design Optimization, Photo-Realistic Rendering, etc.***
	- ***Knowledge Representation (semantic models, graph databases, etc.)***
+ [Tensorboard](https://www.tensorflow.org/guide/summaries_and_tensorboard)
	- [TensorBoard, TensorFlow's visualization toolkit](https://www.tensorflow.org/tensorboard)
	- https://databricks.com/tensorflow/visualisation
+ skill set:
	- Ideal candidates have a strong background in one or more of the following fields: ***deep learning, machine learning, natural language processing, computer vision, or reinforcement learning***. Additionally, applicants should have in-depth experience with one or more of ***text categorization, text summarization, information extraction, question answering, dialogue learning, machine translation, language and vision, image classification, image segmentation, or object detection***.
	- ***Candidates should have a strong publication record in top-tier conferences or journals (e.g. NIPS, ICML, ICLR, ACL, CVPR, KDD, PAMI, JMLR, TACL, IJCV).***
	- In addition to their own research agenda, senior research scientists will have the opportunity to take on additional responsibilities ***leading project teams, mentoring interns, and advising junior research scientists***.
	- Participate in cutting edge research in machine intelligence and machine learning applications.
	- Develop solutions for real world, large scale problems.
	- Find and build ambitious, long-term research goals.
	- As needed or desired, lead teams to deliver on more complex pure and applied research projects.
	- ***Strong publication record in machine learning, NLP, computer vision, reinforcement learning, or optimization, especially at venues like NIPS, ICML, ICLR, ACL, and CVPR.***
	- ***Experience with one or more deep learning libraries and platforms (e.g., TensorFlow, Caffe, Chainer or PyTorch).***
		* ***Chainer: open-source deep learning framework***
+ skill set:
	- Solid Machine Learning background and familiarity with standard ***speech processing and machine learning techniques***
	- Experience with one or more deep learning libraries and platforms (e.g., ***TensorFlow, Caffe, Chainer or PyTorch***).
	- Industry or academic experience in deep learning research.
	- ***Strong publication record in top-tier conferences or journals (e.g. NIPS, ICML, ICLR, ACL, EMNLP, CVPR, ICCV, KDD, PAMI, JMLR, TACL, IJCV).***
+ skill set:
	- **Salesforce Research and Einstein.AI (formerly MetaMind) are looking for extraordinary deep learning or research engineers.**
	- As a deep learning or research engineer, you will work with research scientists and engineers to ***develop and productize new cutting edge models and associated artifacts such as data preparation pipeline and model characterization logic***. You will ***ensure these models are developed to support accuracy, performance or other specific customer requirements***.
	- You will work with platform team to support deployment of these models. In other words, you are problem solver, a ***deep learning model designer***, and an engineer who makes sure the model is deployed at scale to serve our customers with state-of-the-art ***speech, vision, and language technologies***.
	- You have a strong background in one or more of the following fields: ***deep learning, machine learning, natural language processing, computer vision, voice, or reinforcement learning***. Additionally, applicants should have in-depth experience with problems such as ***text categorization, information extraction, question answering, text summarization, dialogue learning, machine translation, language and vision, image classification, image segmentation, or object detection***.
	- Partner with product managers to understand customer requirements
	- Conduct research (including reviewing relevant literature) and collaborate with our research team to identify appropriate solution candidates
	- ***Develop prototypes, then design and carry out experiments to validate and improve the prototypes***
	- Bring the ideas to production
	- ***Monitor model behaviors in production and iteratively improve quality of services over time***
	- Work on cutting-edge research in machine learning
	- MA/MS or PhD degree in computer science, ***artificial intelligence, machine learning, speech recognition, natural language processing***, or related technical field such as ***operations research, computational mathematics***, etc.
	- Research experience or contributions in ***deep learning, machine learning, NLP, computer vision, reinforcement learning, or optimization***.
	- Solid Machine Learning background and familiarity with machine learning techniques
	- Problem solving and ability to reuse, customize, and implement latest research
	- Experience with one or more general purpose programming languages including but not limited to: Python, Java, C/C++
	- Experience with one or more ***deep learning libraries and platforms (e.g., TensorFlow, Caffe, or PyTorch)***
	- Industry experience in deep learning research
	- Can thrive in team environments; using agile methodology and interacting with Product Leaders, Scientists and Engineers to solve technology's greatest challenges
	- In particular, we are looking for experienced engineers with ***Deep Learning experience and domain expertise around Automatic Speech Recognition (ASR), Natural Language Understanding (NLU), and Vision*** to provide the best possible experience for our customers.
	- ***Experience designing and implementing machine learning pipelines in production environments.***
	- ***Experience in building speech recognition and natural language processing systems (e.g. commercial or government-funded speech products) is a huge plus.***
	- ***We value professional industry experience; advanced degrees alone do not replace real world experience.***
	- Excellent communication, leadership, and collaboration skills.
+ skill set:
	- Ideal candidates have a strong background in one or more of the following fields: ***deep learning, machine learning, natural language processing, computer vision, or reinforcement learning***. Additionally, applicants should have ***in-depth experience with one or more of text categorization, text summarization, information extraction, question answering, dialogue learning, machine translation, language and vision, image classification, image segmentation, or object detection***.
	- ***Candidates should have a strong publication record in top-tier conferences or journals (e.g. NIPS, ICML, ICLR, ACL, CVPR, KDD, PAMI, JMLR, TACL, IJCV).***
	- In addition to their own research agenda, senior research scientists will have the opportunity to take on additional responsibilities leading project teams, mentoring interns, and advising junior research scientists.
	- ***Strong publication record in machine learning, NLP, computer vision, reinforcement learning, or optimization, especially at venues like NIPS, ICML, ICLR, ACL, and CVPR.***
	- Experience with one or more general purpose programming languages including but not limited to C/C++ or Python.
	- Experience with one or more ***deep learning libraries and platforms (e.g., TensorFlow, Caffe, Chainer or PyTorch)***.
+ skill set:
	- Ideal candidates have a strong background in one or more of the following fields: ***deep learning, machine learning, natural language processing, computer vision, or reinforcement learning***. Additionally, applicants should have in-depth experience with one or more of ***text categorization, text summarization, information extraction, question answering, dialogue learning, machine translation, language and vision, image classification, image segmentation, object detection or reinforcement learning***. Our postdoctoral researchers have the ability to give talks, attend conferences and build relationships with academic institutions if desired.
	- Collaborate on research to advance the science and technology of artificial intelligence.
	- ***Contribute to cutting edge research projects in machine intelligence and machine learning applications that can be infused into our world-class CRM.***
	- Develop solutions for real world, large scale problems.
	- Influence progress of relevant research communities by producing publications.
	- Find and build ambitious, long-term research goals.
	- As needed or desired, lead teams to deliver on more complex pure and applied research projects.
	- Create a year long project proposal with research managers.
	- ***First-author publications at AI conferences and journals (e.g. NIPS, ICML, ICLR, ACL, CVPR, KDD, PAMI, JMLR, TACL, IJCV).***
+ skill set:
	- ***Salesforce Research Asia*** is looking for outstanding research interns. Ideal candidates have a strong background in one or more of the following fields:
		* deep learning,
		* machine learning,
		* natural language processing,
		* computer vision,
		* speech recognition, or
		* reinforcement learning
	- Applied to, for example: ***text categorization, text summarization, information extraction, question answering, dialogue systems, language and speech, machine translation, language and vision, image classification, object detection, or image semantic segmentation***, etc.
	- ***Candidates that have published in top-tier conferences or journals (e.g. NIPS, ICML, ICLR, ACL, EMNLP, CVPR, ICCV, ECCV, SIGKDD, PAMI, JMLR, TACL, IJCV) are preferred.***
	- Excellent understanding of deep learning techniques, i.e., ***CNN, RNN, LSTM, GRU, attention models, and optimization methods***
	- Experience with one or more ***deep learning libraries and platforms, e.g. PyTorch, TensorFlow, Caffe, or Chainer***
	- Strong background in ***machine learning, natural language processing, speech, computer vision, or reinforcement learning***
	- Strong algorithmic problem solving skills
	- Programming experience in ***Python, Java, C/C++, Lua***, or a similar language
+ skill set:
	- ***Salesforce Research (previously MetaMind)*** is looking for outstanding research interns. Ideal candidates have a strong background in one or more of the following fields:
		* deep learning,
		* machine learning,
		* natural language processing,
		* computer vision, or
		* reinforcement learning
	- Applied to, for example: ***text categorization, text summarization, information extraction, question answering, dialogue learning, machine translation, language and vision, image classification, image segmentation, or object detection***.
	- ***Candidates that have published in top-tier conferences or journals (e.g. NIPS, ICML, ACL, EMNLP, CVPR, ICCV, SIGKDD, ICDM, ICLR, PAMI, JMLR, TACL, IJCV) are preferred.***
	- As a research intern, you will work with a team of research scientists and engineers on a project that ideally leads to a submission to a top-tier conference.
	- PhD/MS candidate in a relevant research area
	- Excellent understanding of ***deep learning techniques, i.e., CNN, RNN, LSTM, GRU, attention models, and optimization methods***
	-  Experience with one or more ***deep learning libraries and platforms, e.g. Torch, TensorFlow, Caffe, or Chainer***
	-  Strong background in ***machine learning, natural language processing, computer vision, or reinforcement learning***
	-  Strong algorithmic problem solving skills
	-  Programming experience in Python, Lua, Java, or a similar language
+ skill set:
	- ***Salesforce Research (previously MetaMind)*** is looking for an outstanding entry level research scientists focused on ethics in AI. It is our belief in the words of our CEO Marc Benioff, “The business of business is improving the state of the world." The way we behave — with ***integrity, transparency, alignment, and accountability*** — builds trusted relationships. We believe that companies can do well and do good in the world. We know technology is not inherently good or bad. It's what we do with it that matters. With AI, we believe that we can go even further to advance and support its effectiveness by ***ensuring equality, transparency, and accountability in the models we create and how we implement them in our products***.
	- As a research scientist, you discover new research problems, develop novel models, design careful experiments and generally advance the state of the art in AI. At Salesforce, the research team is committed to collaboration with the wider research community. In this unique role, you will have the opportunity to work directly on advancing technologies that nonprofits use to solve problems in the real world that create positive impact for the world while accomplishing publications at major conferences. We believe that making substantive progress on hard problems can drive and sharpen the research questions we study, and, in turn, scientific breakthroughs can spawn entirely new applications. With this in mind, the team maintains a portfolio of projects, some with an immediate path to production, others that may not find an application for several years. Research scientists have the freedom to set their own research agenda and move between pure and applied research.
	- As a research intern, you will work with a team of research scientists and engineers on a project that ideally leads to a submission to a top-tier conference.
	- PhD/MS candidate in a relevant research area (e.g., Machine Learning, AI, AI ethics, law and policy)
	- Excellent understanding of ***deep learning models and techniques (i.e., CNN, RNN, LSTM, GRU, attention models, and optimization methods)***
	- Experience with one or more ***deep learning libraries and platforms (e.g. PyTorch, TensorFlow)***
	- Strong background in ***machine learning, natural language processing, computer vision, or reinforcement learning***
	- Programming experience in Python or a similar language
	- Strong algorithmic problem-solving skills
	- ***Demonstrable experience implementing machine learning models and algorithms, e.g., through open-source implementations, or shareable code***
	- Strong presentation and communication skills
	- ***Experience applying deep learning models to ethical issues in AI or social causes (e.g., racial disparity in facial recognition, explainability of AI for redress and remediation)***
	- ***Experience researching artificial intelligence ethics, including areas such as fairness, safety, privacy and transparency in artificial intelligence***
	- ***Published in top-tier conferences or journals (e.g., FAT\*, NIPS, AIES, ICML, ACL, EMNLP, CVPR, ICCV, SIGKDD, ICDM, ICLR, PAMI, JMLR, TACL, IJCV)***
	- ***Open-source implementations of machine learning research projects.***
	- The ideal candidate will have a keen interest in producing new science to understand intelligence and technology and how to apply it safely and fairly in real-world settings.
+ ***Open-source projects that demonstrate relevant skills and/or publications in relevant conferences and journals (e.g. NIPS, ICML, ICLR, CVPR, ICCV, ECCV, ICASSP)***
+ skill set:
	- Machine Learning Researcher
	- Machine learning is a critical pillar of Jane Street's global business, and our ever-changing trading environment serves as a unique, ***rapid-feedback platform for ML experimentation***. 
	- Researchers at Jane Street are responsible for building models, strategies, and systems that price and trade a variety of financial instruments. As a mix of the trading and software engineering roles, this work involves many things: analyzing large datasets, building and testing models, creating new trading strategies, and writing the code that implements them.
	- We're looking for people to join the research team with ***deep ML experience in either an applied or academic context***. A good candidate should have a ***deep understanding of a wide variety of ML techniques, and a passion for tinkering with model architectures, feature transformations, and hyperparameters to generate robust inferences. We also want people who are good communicators, with the ability to quickly absorb the context of a new problem, carefully consider tradeoffs, and recommend possible solutions.***
	- As an ML researcher, your expertise will also shape the firm's future ML developments including hiring new ML researchers, attending conferences, teaching techniques to teammates, and setting firmwide goals.
	- Base salary is $250,000 - $300,000. Base salary is only one part of Jane Street total compensation, which includes an annual discretionary bonus.
+ skill set:
	- Research Scientist
	- We are looking for Research Scientists in the machine learning discipline who are passionate about ***generative models and creative applications of AI***. In particular, ***we are looking for people who share our mission of open-source research; people who do not believe AI models should be controlled by a centralized gatekeeper behind a closed wall, but rather be truly open and in control by all. We want highly creative researchers who are motivated to push the boundaries of generative models research, not just in state-of-the-art performance, but in pushing the efficient frontier between performance and resource usage. You will have access to state-of-the-art high performance computing resources and you will be able to work alongside top researchers and engineers to truly make an impact in the fast growing world of generative AI.***
	- ***Work with research team to execute research agenda***
	- ***Build the next generation of creative generative AI models***
	- ***Publication of results at top conferences or journals, and blog posts***
	- ***Work with open-source community on model release and tooling***
	- ***Work with engineering / business teams on model deployment and customized training***
	- ***Publication of papers, projects, and blog posts that had a high impact in generative AI***
	- ***Experience with dataset curation, rather than rely solely on spoonfed research datasets***
	- ***Ability to communicate research ideas effectively through writing and visualization***
	- ***Experience with Python scientific stack, PyTorch, creating Jupyter/Colab notebooks***
	- ***Experience with training large models on a compute cluster environment is a plus***
+ skill set:
	- AI/ML Research Scientist
	- Santa Clara Valley (Cupertino), California, United States
	- Apple 3DML team is looking for software engineers to develop and deploy computer vision technologies (2D and 3D) for next generation of Apple products. You'll join a phenomenal team of researchers and engineers with deep experience in deep learning, machine learning, computer vision and software engineering. The team has an outstanding track record in shipping high visibility products empowering Apple new hardwares. More specifically, you will be working closely with ML Applied research scientists in the team to bring CVML prototypes to life and deploy them on shipping frameworks. You'll participate in crafting systems, algorithm, and optimization efforts to ship product with impact. No matter whether you have worked on computer vision and machine learning before, we provide you with the best experience, to learn, grow and contribute.
	- Strong academic and publication record in computer vision.
	- Solid programming skills with Python.
	- Deep understanding large foundation models.
	- Deep understanding of ***multi-task, multi-modal machine learning domain***.
	- Familiarity with ***deep learning toolkits***.
	- Familiar with challenges associated with training large models and working with large data.
	- ***Agile integration of deep learning, data collection and failure analysis.***
	- ***Designing and evaluating experiments monitoring key performance measures.***
	- Visualization and deeper understanding of deep learning networks.
	- Ability to communicate the results of analyses in a clear and effective manner.
	- Are you passionate about building AI/ML products with focus on Augmented Reality (AR) and Virtual Reality (VR) applications? Are you passionate about Generative AI and large foundation models? Are you passionate about solving hard problems? Video Computer Vision org at Apple is looking for machine learning researcher to join the team of highly accomplished and deeply technical scientist. You will design and implement new machine learning algorithms while collaborating with the most innovative product development teams at Apple. We provide the right balance between research and product to deliver Apple quality state of the art experiences on various apple devices. 
	- You will have the opportunity to touch the life of millions of people through amazing products. Our team researches new machine learning algorithm and techniques and has a track record of shipping some of the most impactful CVML products ever shipped by Apple. Examples include ***FaceID, Animoji/Memoji, Scene Understanding, People Understanding and Positional Tracking (VIO/SLAM)***. We want new ambitious team members to join our research ML group. In this role, we create new models and algorithms, and actively engage with the academic community. 
	- You will also have the opportunity to contribute to impactful projects at Apple, and use your machine learning and computer vision skills to transfer your ideas into solutions for some of the most complicated technical problems in the next generation of products that will delight millions of people.
	- M.S. or PhD in Computer Science with relevant publication and research background.
	- At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $116,100 and $208,300 annualized, and your base pay will depend on your skills, qualifications, experience, and location.
+ skill set:
	- Proactive Intelligence, Applied Research Scientist — Generative AI
	- AI represents a huge opportunity to elevate Apple's products and experiences for billions of people globally. We are looking for Applied Research Scientists with a background and interest in Generative AI. You will be leveraging state-of-the-art Generative models to ship extraordinary products, services, and customer experiences for the iPhone, Mac, Apple Watch, iPad and more. 
	- The mission of Proactive Intelligence is to improve Apple platforms by better understanding, anticipating, and adapting to user behavior by using machine learning to build phenomenal features that are built right into Apple platforms. Our team provides an opportunity to be part of an incredible research and engineering organization within Apple. The ideal candidate for this role will have industry experience working on a range of modeling problems e.g., Conversational Agents, Sequential Decision Making, Reinforcement Learning, Autonomous Systems, Human Preference Learning and Large Language Models (LLMs). Working knowledge of large-scale data processing especially with structured data, probabilistic modeling and statistics will broaden your role and effectiveness in this position.
	- Strong programming skills in Python and/or C++ with 5+ years of experience in using these languages for machine learning (ML) modeling and applied research
	- Proficiency in using ML toolkits such as PyTorch, TensorFlow, SkLearn etc.
	- Fundamental knowledge of ML concepts and hands-on experience in building deep-learning systems
	- Strong software engineering skills to create scalable and robust infrastructure for deep learning data, modeling, and evaluation systems
	- Proven ability to train and debug deep learning systems: defining metrics and datasets, performing error analysis and training models in a modern ML framework
	- Familiarity with researching current ML literature and math including optimization methods and modeling techniques
	- Passionate about building extraordinary autonomous systems with Generative AI
	- Creative, collaborative and project focused with an ability to work hands-on in multi-functional teams
	- As an Applied Research Scientist on our team, you will design and implement ML algorithms that process data in different Apple products. You will train Generative AI models and agent behaviors using deep reinforcement learning to solve hard problems/tasks. Where necessary, you will also work on integrating ML/RL frameworks into our products to train large-scale agents and leverage cloud services to enable scalable and distributed training/simulation of agent behaviors. You will communicate advanced ideas to a focused team of researchers in the spirit of developing innovative tools and metrics that change the way we look at problems. You will work closely with other cross-functional teams to align messaging, contribute to roadmaps and contribute software back into different repos for proper integration with core systems. You will write clean, maintainable and production code with appropriate documentation and tests. You will contribute to architecture decisions, design reviews and peer code reviews.
	- M.S. or PhD in Computer Science, or a related fields such as Electrical Engineering, Robotics, Statistics, Applied Mathematics or equivalent experience. A minimum of 5 years of experience in applied ML and/or product development.
	- Publications in top-tier conferences in a plus e.g., ***NeurIPS, ICML, ICLR, ICRA*** etc.
	- Hands-on development experience within OSS Libraries and RL environments such as OpenAI Gym, MuJoCo, RLLib, Stable Baselines 3, Apple Core ML etc.
	- Experience in applying deep learning to robotics problems and predicting multimodal behaviors for agents via-techniques such as MDP, Monte-Carlo methods, TD learning, policy approximations etc.
	- Experience with hardware specific optimization of ML models and deployment
	- Experience developing software for mobile devices and heterogenous compute environments (eg. iOS, watchOS)
+ skill set:
	- Proactive Intelligence, Applied Research Scientist — Generative AI
	- AI represents a huge opportunity to elevate Apple's products and experiences for billions of people globally. We are looking for Applied Research Scientists with a background and interest in Generative AI. You will be leveraging state-of-the-art Generative models to ship extraordinary products, services, and customer experiences for the iPhone, Mac, Apple Watch, iPad and more. 
	- The mission of Proactive Intelligence is to improve Apple platforms by better understanding, anticipating, and adapting to user behavior by using machine learning to build phenomenal features that are built right into Apple platforms. Our team provides an opportunity to be part of an incredible research and engineering organization within Apple. The ideal candidate for this role will have industry experience working on a range of modeling problems e.g., Conversational Agents, Sequential Decision Making, Reinforcement Learning, Autonomous Systems, Human Preference Learning and Large Language Models (LLMs). Working knowledge of large-scale data processing especially with structured data, probabilistic modeling and statistics will broaden your role and effectiveness in this position.
	- Strong programming skills in Python and/or C++ with 5+ years of experience in using these languages for machine learning (ML) modeling and applied research
	- Proficiency in using ML toolkits such as PyTorch, TensorFlow, SkLearn etc.
	- Fundamental knowledge of ML concepts and hands-on experience in building deep-learning systems
	- Strong software engineering skills to create scalable and robust infrastructure for deep learning data, modeling, and evaluation systems
	- Proven ability to train and debug deep learning systems: defining metrics and datasets, performing error analysis and training models in a modern ML framework
	- Familiarity with researching current ML literature and math including optimization methods and modeling techniques
	- Passionate about building extraordinary autonomous systems with Generative AI
	- Creative, collaborative and project focused with an ability to work hands-on in multi-functional teams
	- As an Applied Research Scientist on our team, you will design and implement ML algorithms that process data in different Apple products. You will train Generative AI models and agent behaviors using deep reinforcement learning to solve hard problems/tasks. Where necessary, you will also work on integrating ML/RL frameworks into our products to train large-scale agents and leverage cloud services to enable scalable and distributed training/simulation of agent behaviors. You will communicate advanced ideas to a focused team of researchers in the spirit of developing innovative tools and metrics that change the way we look at problems. You will work closely with other cross-functional teams to align messaging, contribute to roadmaps and contribute software back into different repos for proper integration with core systems. You will write clean, maintainable and production code with appropriate documentation and tests. You will contribute to architecture decisions, design reviews and peer code reviews.
	- M.S. or PhD in Computer Science, or a related fields such as Electrical Engineering, Robotics, Statistics, Applied Mathematics or equivalent experience. A minimum of 5 years of experience in applied ML and/or product development.
	- Publications in top-tier conferences in a plus e.g., ***NeurIPS, ICML, ICLR, ICRA*** etc.
	- Hands-on development experience within OSS Libraries and RL environments such as ***OpenAI Gym, MuJoCo, RLLib, Stable Baselines 3, Apple Core ML*** etc.
	- Experience in applying deep learning to robotics problems and predicting multimodal behaviors for agents via-techniques such as MDP, Monte-Carlo methods, TD learning, policy approximations etc.
	- Experience with hardware specific optimization of ML models and deployment
	- Experience developing software for mobile devices and heterogenous compute environments (eg. iOS, watchOS)
+ skill set:
	- Scientist - Machine Learning
	- The DeepPumas team works on augmenting traditional pharmacological modeling frameworks with seamlessly embedded machine learning algorithms. This enables structural enforcement of prior scientific knowledge through statistical and dynamical modeling while enabling data-driven augmentation. We work with neural networks, universal differential equations, symbolic identification, Bayesian/Convolutional/Graph neural networks and more, all of which are deeply embedded in statistical and dynamical models. Our work is groundbreaking and unprecedented, taking us across the horizontal of basic scientific research to applications in real-world healthcare issues. Throughout the process, we are engaging with and building credibility in the scientific community by publishing papers, presenting (and winning awards) at prestigious international conferences. Our goal is to democratize the resulting methodology through well-crafted software and learning material for widespread use.
	- At DeepPumas, we are currently taking on few but scientifically challenging and long-running consulting projects. These are projects where apply the DeepPumas methodology of augmenting traditional knowledge-based phramacological modelling with data-driven AI. The projects typically involve solving problems that require refinement and further development of our methodology itself – including but not limited to the AI augmentation. As DeepPumas grows and we expand our ability to perform specific analyses quickly, this position might also evolve. Now, however, our projects are similar to post-docs, where we continually update collaborators on our progress but where the project is expected to take more than a year to complete. Every such project needs someone who can take ownership of it. Someone who will be the primary contact to our external partners; who gets to know the biology behind the problem; who charts the course, breaks down the problem into smaller tasks, takes on many of those tasks themselves but outsources the parts that require specific expertise beyond their own. So far, the work is typically done using AI-augmented nonlinear mixed effect models and will thus build on pharmacology, statistics, dynamics and ML.
	- Solve real-world healthcare problems using advanced AI-augmented pharmacological modeling.
	- Develop general theory and methodology needed for the current and future projects to achieve its goals.
	- Establish excellent working relationships with our external partners.
	- Responsibilities
		* Project Owner
			+ Take ownership over specific DeepPumas scientific projects and lead them to successful completion
			+ Communicate internally and acquire the advice and the hands-on help that you need to successfully complete your projects.
			+ Communicate and collaborate internally to successfully meet deliverables.
			+ Interface with our external scientific partners and clients
			+ Research, design, implement, and document methodology
			+ Present your work at scientific conferences and write scientific papers
			+ Mentor interns
		* Company responsibilities
			+ Develop and communicate appropriate project documentation, including project overview, scope, team structure, status reports, issues management reports, change control reports, meeting notes, etc. as required and in a timely manner.
			+ Ensure adherence to company SOPs (Standard Operating Procedures), policies, and guidelines at the project level.
			+ Participate in Pumas-AI's continuous process improvement initiatives by, amongst other activities, assuring that project quality metrics align with company, client, and clinical operations objectives.
			+ Track identified project risks and issues and assist with following up with actions to ensure adherence to contractual agreement.
	- PhD in related field or equivalent experience that satisfies the requirement and responsibilities stated.
	- Effective communication skills.
	- Experience with mathematical modelling.
	- Proficiency in statistical reasoning and modelling
	- Proficiency in dynamical modelling
	- Proficiency with machine learning
	- Proficiency of pharmacology
	- Software development skills
	- Proficiency with the Julia programming language
+ skill set:
	- AI RESEARCH SCIENTIST
	- Two Sigma is a financial sciences company, combining data analysis, invention, and rigorous inquiry to help solve the toughest challenges in investment management, insurance technology, securities, private equity, and venture capital.
	- We are looking for creative experts who are interested in applying general machine learning and specifically deep learning techniques to many types of problems, but particularly those with large amounts of noisy data.
	- Develop effective techniques and infrastructure, from the initial idea to the running prototype and product
	- Similar to a research environment, you will write code, use the latest machine learning tools, run experiments, and generally develop techniques and processes to improve our understanding of how financial data influences the world around us
	- Partner with teams across Two Sigma to implement your ideas into their products
	- Remain connected to the broader research community by partnering with internal and external collaborators and participate in relevant conferences
	- Advanced degree in Computer Science, Engineering, or other STEM field
	- Excellent programming skills in Python, C++, Tensorflow, PyTorch or similar languages
	- Internships/work experience with machine learning, deep learning, reinforcement learning
	- Background in machine learning techniques with large amounts of noisy data, curiosity in applying it to financial problems
	- Relevant research experience (publications at NeurIPS, ICML, ICLR or similar are preferred)
	- Experience with cloud environments and multi-machine setups
	- Participation in open source community
+ skill set:
	- Machine Learning, AI Research Internship (FALL)
	- Our mission is to build the Covariant Brain, a universal AI to give robots the ability to see, reason and act on the world around them. Bringing AI from research in the lab to the infinite variability and constant change of our customer's real-world operations requires new ideas, approaches and techniques.
	- Success in the real world requires a team that represents that world: diversity of backgrounds, points of view, and experiences. Our common denominator: ambitious expectations, love of learning, empathy for those around us, and a team-first mindset.
	- The Covariant Brain is a Universal AI Platform that powers all robotic applications at Covariant. The Brain is a collection of state-of-the-art models, algorithms, and APIs that enable all intelligent behavior of the robot, from perception to 3d object understanding, grasp sampling, motion planning, and control. 
	- We are seeking talented and motivated interns to join our AI Research team. As an AI Research Intern, you will work directly under the guidance of a research mentor, contributing to cutting-edge projects in the areas of artificial intelligence, robotics, and machine learning. This is an opportunity to gain hands-on experience with working on real-world applications and expand your knowledge while having the potential to transform and leave a lasting impact on our company's technology stack.
	- Strong knowledge and experience in any of the following areas: modern computer vision (including but not limited to depth estimation, segmentation, occupancy estimation, NERFs), large language models, motion planning, dynamics modeling, robotics simulation
	- Knowledge and experience in training and analyzing ML models and robotics applications (in simulation, or in the real world)
	- A solid mathematical and statistical foundation with an understanding of how to apply ML concepts (e.g. training, optimizers, regression, classification, etc.)
	- Proficiency in Python and experience with tensor libraries (e.g. NumPy, PyTorch, TensorFlow)
	- Clear communication, organization, and collaboration
+ skill set:
	- AI Software Engineer
	- AlphaICs is looking for a world-class AI/Deep Learning Research Intern to research and develop neural network based learning algorithms. In this role, you will work with algorithm experts to come up with state of the art algorithms in the area of Artificial Intelligence, Computer Vision, natural language processing, including Object detection, and Image recognition. We are looking for candidates who can work with us for more than 3 months.
	- If you are someone with a good understanding of deep learning, reinforcement learning, advanced mathematical concepts and good academic record, we will be happy to talk to you about the work we are doing.
	- 1) Bachelor / Master degree in computer science or AI related field with excellent academic records (Students are also welcome to apply)
	- 2) Strong mathematical foundation and applied research experience in machine learning and deep learning, reinforcement learning.
	- 3) Experience working with deep learning frameworks (Tensorflow, Pytorch, etc.) and related tools in each special field. Solid understanding and hands on experience with C/C++/Python.
	- 4) Publication record in top AI conferences (ACL, CVPR, NAACL, ICML etc) is a plus.
	- 5) Experience with CUDA or GPU computation is a plus.
	- 6) Excellent communication and documentation skills
	- 7) Ability to learn quickly, starting with little information and becoming an expert in your domain.
	- 8) Ability to communicate/collaborate with other researchers/engineers including our team members.
	- 9) Solid Github/ Kaggle profile is a plus.
+ skill set:
	- Artificial Intelligence Intern
	- AlphaICs is looking for a world-class AI/Deep Learning Research Intern to research and develop neural network based learning algorithms. In this role, you will work with algorithm experts to come up with state of the art algorithms in the area of Artificial Intelligence, Computer Vision, natural language processing, including Object detection, and Image recognition. We are looking for candidates who can work with us for more than 3 months.
	- If you are someone with a good understanding of deep learning, reinforcement learning, advanced mathematical concepts and good academic record, we will be happy to talk to you about the work we are doing.
	- 1) Bachelor / Master degree in computer science or AI related field with excellent academic records (Students are also welcome to apply)
	- 2) Strong mathematical foundation and applied research experience in machine learning and deep learning, reinforcement learning.
	- 3) Experience working with deep learning frameworks (Tensorflow, Pytorch, etc.) and related tools in each special field. Solid understanding and hands on experience with C/C++/Python.
	- 4) Publication record in top AI conferences (ACL, CVPR, NAACL, ICML etc) is a plus.
	- 5) Experience with CUDA or GPU computation is a plus.
	- 6) Excellent communication and documentation skills.
	- 7) Ability to learn quickly, starting with little information and becoming an expert in your domain.
	- 8) Ability to communicate/collaborate with other researchers/engineers including our team members.
	- 9) Solid Github/ Kaggle profile is a plus.
+ skill set:
	- Machine Learning Intern, Research (Fall 2023/Winter 2024)
	- Applied Machine Learning Research at Netflix improves various aspects of our business, including personalization algorithms, media and content understanding, search, systems optimization, content valuation, tooling for artists, and streaming video optimization. As such, our research spans many Machine Learning areas, including recommender systems, causal inference, reinforcement learning, computer vision, computer graphics, natural language processing, optimization, operations research and systems. Great applied research also requires great Machine Learning infrastructure,  another large area of emphasis at Netflix.
	- In Fall 2023, Netflix will be hosting a small number of Machine Learning Research internships and Machine Learning Engineering & Infrastructure internships. Applicants are encouraged to express their interest in one or both types of internships.
	- This internship can be remote. We are seeking individuals who are able to work full-time hours (40 hours a week) for 12 weeks between the fall of 2023 and spring of 2024.
	- Currently enrolled PhD in the Machine Learning space, preferably specializing in Natural Language Processing. 
	- Ideally some experience with (controllable) text generation, text generation at scale, or text generation evaluation.
	- Experience programming in at least one programming language (e.g. Python, Scala, Java or C/C++).
	- Curious, self-motivated, and excited about solving open-ended challenges at Netflix.
	- Great communication skills, both oral and written. 
	- Publications in relevant conferences or journals.
	- Comfortable with software engineering best practices (e.g. version control, testing, code review, etc.).
	- You will be sent an Airtable form shortly after you submit your application on our careers site; your application will not be considered complete until you fill out and submit this form.
	- Include a Resume or CV with complete contact information (email, phone, mailing address) and a list of relevant coursework and publications (if applicable). 
	- You will be asked to include a short (max one page) statement describing your research experiences and interests, and (optionally) their relevance to Netflix Research. For inspiration, have a look at the Netflix research site. In this statement, please include the approximate dates you might be able to work full-time hours (40 hours a week) for 12 weeks between the fall of 2023 and spring of 2024.
	- The overall market range for Netflix Internships is typically $40/hour - $110/hour.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
























###	Machine Learning Engineer & Deep Learning Engineer Roles




***Machine Learning Engineer***, and ***Deep Learning Engineer***, roles:
+ ***Take end to end ownership of machine learning systems - data pipelines, candidate extraction, feature engineering, model training, as well as integration into our production systems***
+ Experience implementing ***production-ready machine learning solutions*** is a plus
+ semi-supervised learning
+ Knowledge of ***Apache Spark***
+ Experience with ML frameworks such as ***PyTorch, MxNET, Tensorflow***, etc.
+ Experience with ***distributed analytic processing technologies (Hive, Pig, Presto, Spark)***
+ Machine Learning: build systems and processes that apply ***ML technologies, including ranking, content quality, text understanding, search, ads targeting and CTR prediction***, etc.
+ Experience in neural network frameworks like TensorFlow, ONNX, Caffe, PyTorch etc. is a plus
+ ***Lifelong-DNNTM (L-DNN)*** technology, which reduces the data requirements for AI model development and enables continuous learning in the cloud or at the edge
+ Excellent understanding of machine learning techniques and algorithms, such as ***k-NN, Naive Bayes, SVM, Decision Forests***, etc.
+ Experience working with large data sets and distributed computing tools (e.g. ***Redshift, Presto***)
+ Proficiency with one or more of the following packages: ***HuggingFace, Fastai, scikit-learn, XGBoost, LightGBM, Ray***
+ You have strong coding skills in several of the following languages/libraries: ***Python, NumPy, TensorFlow, PyTorch***.
+ skill set:
	- Experience with advanced ML models and concepts: ***HMMs, CRFs, MRFs, deep learning, regularization*** etc.
	- Experience with ***distributed databases*** such as ***HBase, Redis, CouchBase*** etc.
	- Experience in ***search platform*** such as ***Solr, Elastic Search***
+ tech stack:
	- Python (***numpy, pandas, sklearn, xgboost, TensorFlow***)
	- MySQL, Hive
	- Java
	- Google Cloud Platform
	- Tableau, Looker
+ tech stack:
	- Python (***numpy, pandas, scikit-learn, tensorflow, keras***)
	- Google Cloud Platform
	- ***Machine Learning (e.g. regression, ensemble methods, deep learning, etc.)***
	- ***Statistics (Bayesian methods, experimental design, causal inference)***
	- ***Tableau, Looker***
	- ***Snowflake (SQL)***
+ skill set:
	- extensive experience in ***deep learning, classifiers, clustering algorithms, and anomaly detection***
	- ***highly scalable security tools for exploit and bot detection***
	- ***ML security projects***
	- ***large-scale ML systems***
+ skill set:
	- Technologies : ***AWS Batch,  Spark, Hive, EMR, Presto, Docker, Jenkins, Bitbucket***
	- Databases: ***RDS MySQL, Redshift***
	- Machine Learning: ***Distributed TensorFlow, Keras, PyTorch, Caffe2, scikit-learn, Apache MxNet, SageMaker***
	- ***Developing DAOs (data access objects) and APIs***
	- Extensive practical experience using a wide range of ***AWS technologies, including: S3, EC2s, Lambda, Step Functions, Glue, EMR, API Gateway***
+ skill set:
	- Experience working with modern deep learning software architecture and frameworks including: ***Tensorflow, Pytorch, ONNX, MxNet, Caffe/Caffe2, and/or Torch***;
	- Experience working with modern deep learning models including: ***Resnet, Mask-RCNN, RNN/LSMT, Bert, Transformer*** etc
+ skill set:
	- ***Java, mahout, Hadoop***
	- ***Scala, Spark, SparkML***
	- Spark with ***Python, numpy and pandas***
+ Experience in one application field (***Image processing, ADAS, FinTech, CyberSecurity***)
	- ***ADAS: advanced driver-assistance system***
+ Advanced level programming skills in Python, ideally developed from experience working on long-term commercial projects, including significant experience using ***SciPy and machine-learning packages (Numpy, Pandas, scikit-learn, etc)*** for the development of maintained components. Additional experience using PySpark a big plus.
+ skill set:
	- Design and implement high-performance libraries/APIs for machine learning and statistical techniques.
	- Experience with streaming and event-based programming
	- Experience with continuous integration and deployment workflows
+ skill set:
	- ***Machine learning accelerators such as OpenTPU, NVDLA, Eyeriss, and VTA***.
	- ***Machine learning frameworks such as TensorFlow, PyTorch, Caffe2, Keras, and MXNet***.
	- Common ***DNN models such as AlexNet, ResNet50, Inception, YOLO, RNN, and LSTM***.
	- ***Compilers such as TVM, Glow, Halide, CLANG, LLVM, and GCC***.
+ Design services for performant application of machine-learned models
+ Prior experience is required working with an existing open-source or proprietary machine learning accelerator architecture such as OpenTPU, NVDLA, Eyeriss, or VTA. You must have a background in compiler hacking on one or more of TVM, Glow, Halide, Spatial, XLA, CLANG, LLVM, or GCC. Experience desired with compiler Intermediate Representations (IRs) and back-ends; JIT compilers; kernel-mode and user-mode Windows, Unix, or embedded systems runtime environments and device drivers.
+ Experience in GPU/CUDA/TensorRT
+ skill set:
	- AI Engineer
	- As an AI Engineer (a Member of Technical Staff role on our Forward Deployed team) you will work directly with customers to quickly understand their greatest problems and design and implement solutions using Large Language Models.
	- You’ll apply your problem-solving ability, creativity, and technical skills to close the last-mile gap in Enterprise AI adoption. You’ll be able to deliver products like early startup CTOs/CEOs do and disrupt some of the most important industries and institutions globally!
	- Own and build large new areas within our product.
	- Work across backend, frontend, and customize Large Language Models.
	- Experiment at a high velocity and level of quality to engage our customers and eventually deliver solutions that exceed their expectations.
	- Work across the entire product lifecycle from conceptualization through production.
	- 3+ years of model training, deployment, and maintenance in a production environment.
	- Strong skills in NLP and deep learning.
	- Experience scaling products at hyper-growth startup.
	- Strong written and verbal communication skills.
	- Ability and interest to travel up to 25%, as needed to client sites, but flexible based on personal preferences.
	- Experience improving LLM performance for custom domains via fine tuning or RLHF.
	- Experience in Information Retrieval systems for document question answering.
	- Experience in day-to-day NLP for industry using Python and related toolchains (SpaCy, HuggingFace, NLTK, etc.).
	- Published research in areas of machine learning at major conferences and/or journals.
+ Machine Learning Platform Engineer
	- Are you prepared to join the X team and help build the ultimate real-time information-sharing app, revolutionizing how people connect? At X, we're on a mission to become a trusted global digital public square, committed to minimal censorship within legal boundaries. Our goal is to empower every user to freely create and share ideas, fostering open public discourse without barriers. Join us in shaping this thrilling journey where your contribution will be invaluable to our success!
	- Location: San Francisco or Seattle
	- Base Salary Range: $127,000 USD - $297,000 USD
	- At X, we’re pioneering the frontier of technology with our innovative Everything App. Our mission is to revolutionize how people connect, share ideas, and engage in meaningful conversations. We champion freedom of speech and strive to create a platform that embraces diverse perspectives. Our commitment is to foster open dialogue and empower individuals to express themselves freely.
	- We value:
		* Writing code rather than documents
		* Shipping products rather than talking about roadmaps
		* Big features rather than changing button colors
	- Build large-scale distributed machine learning systems which are scalable, performant, efficient and reliable.
	- Design and evaluate novel approaches for handling high-volume real-time data streams in a machine learning environment. 
	- Participant in design and code reviews, team processes, and technical decisions. 
	- Work on ML frameworks such as Pytorch, Tensorflow, and/or feature management and vector databases such as Qdrant.
	- Learn new machine learning, deep learning, and/or natural language processing techniques for a variety of modeling and relevance problems involving users, their tweets, their interests, twitter ads, and relationships among entities. 
	- Conduct online A/B testing, interpret and understand algorithm performance
	- Shape the future of development of Machine Learning Platform at X.
	- We're looking for exceptional engineers who are passionate about our mission and have a strong desire to make a meaningful impact. The ideal candidate will have:
		* Bachelor, Master, Post-graduate or PhD in computer science, computing engineering, machine learning, information retrieval, recommendation systems, natural language processing, statistics, math, engineering, operations research, or other quantitative discipline; or equivalent work experience
		* 2+ years of industry experience working with high traffic or large ML production environments, distributed systems, backend infrastructure, recommender systems and/or deep learning applications
		* 2+ years experience with ML problems and platform tools either through first-hand modeling or close collaboration with modeling engineers or data scientists
		* Programming experience in Python, Rust or C / C++ or Java.
	- Nice to haves
		* You are comfortable with Linux systems.
		* You have worked with Vector databases, GPU / CUDA programming.
	- At X, our small but fast-paced team values innovation, creativity, and a strong commitment to our mission. As a Senior/Staff ML Platform Engineer, you'll have the opportunity to make a significant impact on the future of X and our aspiration to build the Everything App.
	- If you're an exceptional engineer who shares our passion for freedom of speech, we'd love to hear from you.
	- If you thrive in a dynamic, high-growth tech environment and relish the opportunity to collaborate with passionate, driven over-achievers, your career with us here at X will be both exhilarating and fulfilling!
+ Machine Learning Engineer - Core Product
	- Are you prepared to join the X team and help build the ultimate real-time information-sharing app, revolutionizing how people connect? At X, we're on a mission to become a trusted global digital public square, committed to minimal censorship within legal boundaries. Our goal is to empower every user to freely create and share ideas, fostering open public discourse without barriers. Join us in shaping this thrilling journey where your contribution will be invaluable to our success!
	- Location: San Francisco or London
	- Base Salary Range: $127,000 to $297,000 USD; 56,000 - 169,000 GBP 
	- At X, we’re pioneering the frontier of technology with our innovative Everything App. Our mission is to revolutionize how people connect, share ideas, and engage in meaningful conversations. We champion freedom of speech and strive to create a platform that embraces diverse perspectives. Our commitment is to foster open dialogue and empower individuals to express themselves freely.
	- Writing code rather than documents
	- Shipping products rather than talking about roadmaps
	- Big features rather than changing button colors
	- Designing and architecting recommendation algorithms across various product surfaces in X 
	- Collaborating with cross-functional teams to integrate machine learning models into our platform
	- Iterating and improving the algorithm by gathering user feedback in real time through experimentation
	- Ensuring scalability and efficiency of machine learning systems
	- Mentoring junior engineers and contributing to the team's growth
	- Staying updated on Machine Learning and Deep Learning industry trends
	- Master, Post-graduate or PhD in computer science, machine learning, information retrieval, recommendation systems, natural language processing, statistics, math, engineering, operations research, or other quantitative discipline; or equivalent work experience
	- 2+ years of industry experience working with recommender systems and/or deep learning applications (note - we are open to hiring for this role at all levels)
	- Good theoretical grounding in core machine learning concepts and techniques
	- Ability to perform comprehensive literature reviews and provide critical feedback on state-of-the-art solutions and how they may fit to different operating constraints
	- Experience with a number of ML techniques and frameworks, e.g. data discretization, normalization, sampling, linear regression, decision trees, SVMs, deep neural networks, bandits, reinforcement learning, etc.
	- Familiarity with one or more DL software frameworks such as Tensorflow, PyTorch.
+ ML Infrastructure Engineer
	- Location: San Francisco or New York
	- Base Salary Range: $127,000 USD - $297,000 USD
	- Writing code rather than documents
	- Shipping products rather than talking about roadmaps
	- Big features rather than changing button colors
	- Enabling teams to quickly test and iterate on their ML hypotheses via ML training capabilities, reliable GPU compute infrastructure and experimentation tools such as distributed deep learning libraries and Python notebooks
	- Integrating X’s GPU compute environment with large scale data and inference pipelines
	- Collaborating with cross-functional teams to integrate machine learning models into our platform
	- Ensuring scalability and efficiency of machine learning systems
	- Work across the stack to solve problems independently
	- Mentoring junior engineers and contributing to the team's growth
	- Bachelor, Master, Post-graduate or PhD in computer science, computing engineering, machine learning, information retrieval, recommendation systems, natural language processing, statistics, math, engineering, operations research, or other quantitative discipline; or equivalent work experience
	- 2+ years of industry experience (4+ for Senior) working with high traffic or large data production environments, distributed systems, backend infrastructure, recommender systems and/or deep learning applications
	- 2+ years experience (4+ for Senior) with ML problems and platform tools either through first-hand modeling or close collaboration with modeling engineers or data scientists
	- Working knowledge of Jupyter notebooks and Python, plus experience with a compiled language, such as Scala, Java or C++
	- You stay up-to-date on Machine Learning and Deep Learning industry trends
	- You have low level understanding of compute systems such as distributed storage, NVIDIA drivers and CUDA toolkits
	- You are comfortable with Linux systems
	- You have worked with Slurm scheduler, Puppet or Ansible
+ Machine Learning Engineer - Community Notes
	- Location: San Francisco, San Jose, Seattle, Los Angeles, New York City
	- Base Salary Range: $127,000 to $297,000 USD
	- X serves our community of users and customers by working tirelessly to preserve free expression and choice, create limitless interactivity, and create a marketplace that enables the economic success of all its participants.
	- We are the Community Notes team — empowering the people to keep each other better informed, with a fully open source algorithm and data. Community Notes is constantly advancing the state-of-the-art in improving the quality of information on the internet and we employ an experimental, fast-moving, iterative approach to find product solutions that work for people of all different points of view.
	- Design and build improvements to our unique machine learning algorithm that improve Community Notes’ helpfulness, accuracy, scale, speed, and manipulation resistance
	- Work in public: contribute to our open source code base, supporting external researchers and people working with our public data . For (example).
	- Build efficient, scalable internal production machine learning systems and infrastructure
	- Contribute to the entire product via tight cross-functional collaborations with product/eng/etc
	- Experience developing and shipping high-impact ML solutions end-to-end: from getting your hands dirty creating training data pipelines, to developing novel model architectures, to deploying to production at scale reliably
	- Demonstrated ability to work with real-world data to extract insights, inform product roadmap and develop guiding metrics in situations that lack cut-and-dry evaluation criteria
	- Familiarity with one or more deep learning software frameworks, e.g. PyTorch
	- Enjoy working in a 0-to-1 space with no known machine learning or product solutions, and trailblazing to build novel solutions that work
	- Love doing whatever work is needed to get things done, enabling rapid iteration on the product
	- Join our small and fast-paced team and empower the people to keep each other better informed.
	- If you thrive in a dynamic, high-growth tech environment and relish the opportunity to collaborate with passionate, driven over-achievers, your career with us here at X will be both exhilarating and fulfilling!
+ skill set:
	- Machine Learning Intern/Co-op (Winter 2024)
	- Ship state of the art models to production.
	- Design and implement novel research ideas.
	- Build elegant training/deployment pipelines.
	- Join us at a pivotal moment, shape what we build and wear multiple hats as an intern!
	- Please Note: To be eligible for this position you should be a student currently enrolled in a post-secondary program, available for a full-time 3-6 month internship, co-op, or research work term (January - April). We have offices in Toronto, Palo Alto, and London but embrace being remote-first! There are no restrictions on where you can be located for this role.
	- Design, train and improve upon cutting-edge models
	- Help us develop new techniques to train and serve models safer, better, and faster
	- Train extremely large-scale models on massive datasets
	- Explore continual and active learning strategies for streaming data
	- Publish your work in top-tier conferences and journals
	- Learn from experienced senior machine learning technical staff
	- Work closely with product teams to develop solutions
	- Proficiency in Python and related ML frameworks such as Tensorflow, TF-Serving, JAX, and XLA/MLIR
	- Experience using large-scale distributed training strategies
	- Familiarity with autoregressive sequence models, such as Transformers
	- Strong communication and problem-solving skills
	- A demonstrated passion for applied NLP models and products
	- Bonus: experience writing kernels for GPUs using CUDA
	- Bonus: experience training on TPUs
	- Bonus: papers at top-tier venues (such as NeurIPS, ICML, ICLR, AIStats, MLSys, JMLR, AAAI, Nature, COLING, ACL, EMNLP)
+ AI/ML Search Architect
	- We seek a seasoned AI/ML Architect with expertise in Neural Information Retrieval (IR) technology to lead the design, development, and implementation of machine learning models for search and recommendation systems. Your focus will be on retrieval and ranking/reranking infrastructure and pipelines, collaborating with cross-functional teams, and maintaining awareness of the latest technological advancements. This is a unique opportunity to impact and contribute to our cutting-edge products significantly.
	- Led the Design, Development, and Implementation: Spearheaded machine learning models for search and recommendation systems, focusing on retrieval, ranking/reranking infrastructure, and pipelines.
	- Collaborate with Cross-Functional Teams: Work closely with product management, engineering, and business development to understand and translate product requirements into robust technical solutions.
	- Monitor and Optimize Infrastructure: Regularly evaluate performance, adjusting algorithms and methodologies for continuous improvement.
	- Manage End-to-End Pipeline: Supervise the complete machine learning pipeline, including data collection, preprocessing, feature engineering, modeling, and deployment.
	- Stay Ahead of the Curve: Maintain awareness of the latest ML and search technologies to keep our systems at the cutting edge.
	- Contribute to Strategic Decisions: Provide valuable insights into product direction through technical expertise.
	- Educational Background: A Master’s or Ph.D. in Computer Science, Electrical Engineering, or a related field.
	- Experience: Minimum seven years of professional experience in search, retrieval, and ranking, focusing on building search ML-based pipelines.
	- Programming Languages and Frameworks:
		* Proficiency in Deep Learning Frameworks: Knowledge of popular deep learning frameworks like TensorFlow, PyTorch, or Keras would be essential for implementing complex neural models.
		* Proficient Programming Skills: Expertise in programming languages such as Python and C++ to write and optimize algorithms and machine learning models.
	- Multimodal Search Algorithms: Deep understanding of search algorithms and methods across different data types (text, image, etc.).
	- Architecting Neural Models for Information Retrieval: Develop and implement neural network architectures tailored for complex information retrieval tasks.
	- Ranking Systems and Recommendation Models: Knowledge in designing and optimizing ranking/reranking systems and recommendation models for improving search functionality.
	- Large-Scale Distributed Systems: Experience handling large-scale distributed systems is crucial for managing big data and ensuring the models run efficiently.
	- Cloud Computing Platforms: Familiarity with popular cloud platforms like AWS, Azure, or Google Cloud for deploying and managing models.
	- End-to-End Machine Learning Pipeline Management: Skills in managing the complete machine learning pipeline, including data collection, preprocessing, feature engineering, modeling, and deployment.
	- Optimization Techniques: Ability to evaluate performance and apply optimization techniques for continuous model improvement.
	- Collaborative Skills: Ability to work closely with cross-functional teams, including product management, engineering, and business development.
	- Agile Methodologies: Familiarity with Agile methodologies for iterative development and collaboration in team environments.
	- Research and Innovation: Collaborate with the research team to keep abreast of the latest developments in neural IR and drive innovation through prototyping.
	- Publications/Contributions: Though not mandatory, contributions to scientific and tech communities can be a valuable addition.
	- Technical Leadership: Guide less experienced engineers and researchers, actively contribute to technical documentation, and promote best practices in machine learning.
+ Software Engineer, AI Frameworks
	- We believe that AI is a net positive force in the world. Our vision and mission are to help rebuild AI infrastructure to advance humanity and our environment. We will do whatever it takes to empower our customers, team, and company to benefit from that pursuit. You can read about our culture and careers here to understand how we work and what we value.
	- We are owners and advocates for the underlying technologies, developer platforms, product components, and infrastructure. These essential building blocks form the high-quality and coherent experiences our users expect. We aim to drive the pace of innovation for every AI/ML developer.
	- Within the Frameworks and Engagement team, we are focused on building software that helps drive Modular product adoption while engaging with our customers. We work heavily with compiler, performance and kernel teams to fully understand events, metrics, logs and traces for customers and our production systems. We are looking for candidates based on both their breadth and depth of experience in software engineering, compiler, hardware, machine learning and more.
	- We are a growing team who collaborate across disciplines on a day to day basis. A strong cross-collaborator is a must. If solving customers problems excites you, come and be part of our team and architect our client side infrastructure at Modular. Join our world-leading AI infrastructure team and help drive our AI infrastructure stack forward.
	- Build monitoring, alerting and observability for Modular services.
	- Collaborate with open source engineers to help facilitate the future of ML software stacks
	- Work with compiler, performance, and kernel teams providing API’s to fully integrate the events, metrics, logs and traces and build corresponding dashboards to analyze today’s complex server, mobile, and other production systems.
	- Ensure that existing and up-and-coming accelerators are high performing and work with ML frameworks inside the Modular runtime.
	- 4+ years of systems design experience such as distributed systems, high-performance concurrency, etc.
	- Ability to create durable, reusable software frameworks that are leveraged across teams and functions
	- In-depth knowledge of modern C++ is required.
	- Develops secure and high-quality production code, and reviews and debugs code written by others
	- Experience with one or more cloud application programming languages (C, C++, Java, C#, Go etc.) and modern scripting languages (Bash, Python, etc).
	- Strong collaboration skills, ability to share information with internal and external engineering and product teams.
	- Experience, or deep interest, in machine learning technologies and use cases.
	- Creativity and curiosity for solving complex problems, a team-oriented attitude that enables you to work well with others, and alignment with our culture.
	- Experience using open source software components in production.
	- Devotion to quality and engineering excellence.
	- Strong written and verbal communication skills.
	- Strongly identifies with our core company cultural values.
	- LLVM, MLIR, or Python experience is a bonus.
	- Experience with working on or contributing to a major machine learning framework such as TensorFlow, PyTorch, and/or ONNX/ONNXRuntime is a bonus.
	- The estimated base salary range for this role to be performed in the US, regardless of the state, is $166,500.00 - $286,000.00 USD. The salary for the successful applicant will depend on a variety of permissible, non-discriminatory job-related factors, which include but are not limited to education, training, work experience, business needs, or market demands. This range may be modified in the future. The total compensation for a candidate will also include annual target bonus, equity, and benefits, with equity making up a significant portion of your total compensation.
+ Research Engineer, Superalignment
	- OpenAI’s Superalignment Team is working on technical approaches to ensure that superintelligence–an AI system vastly smarter than humans–follows human intent. 
	- Through scientific experimentation, we explore the scalability of alignment techniques and identify potential breaking points. Our approach to alignment research includes a range of different projects; some of these will help us improve the alignment of our models and others will allow us to validate how aligned our models actually are:
		* Scalable oversight: How can we best leverage AI systems to assist evaluation of other AI systems on difficult tasks?
		* Generalization: Can we understand and control how our models generalize from easy tasks that humans can supervise to hard tasks that humans cannot?
		* Automated interpretability: Can we use AI to explain how LLMs work internally?
		* Robustness: How can we train our models to be aligned in worst-case situations?
		* Adversarial testing: If we deliberately train deceptively aligned models as testbeds,  can our oversight techniques, interpretability tools, and evaluations detect this misalignment?
	- We want to figure out how to spend vast amounts of compute to solve this problem, in particular by automating alignment research itself.
	- We are seeking Research Engineers to help design and implement experiments for alignment research.
	- Writing performant and clean code for ML training.
	- Independently running and analyzing ML experiments to diagnose problems and understand which changes are real improvements.
	- Writing clean non-ML code, for example when building interfaces to let workers interact with our models or pipelines for managing human data.
	- Collaborating closely with a small team to balance the need for flexibility and iteration speed in research with the need for stability and reliability in a complex long-lived project.
	- Understanding our high-level research roadmap to help plan and prioritize future experiments.
	- Implement experiments to measure the effectiveness of scalable oversight techniques such as AI-assisted feedback and Debate
	- Studying generalization to see when AI systems trained on easy problem can solve hard problems
	- Managing large datasets from interpretability experiments and creating visualizations to explore interpretability data
	- Investigating situations when training against a reward signal causes model outputs to deteriorate
	- Exploring methods to understand and predict model behaviors, such as finding inputs causing anomalous circuits or catastrophic outputs
	- Designing novel approaches for using LLMs in alignment research
	- Are excited about OpenAI’s mission of building safe, universally beneficial AGI and are aligned with OpenAI’s charter
	- Want to use your engineering skills to push the frontiers of what state-of-the-art language models can accomplish
	- Possess a strong curiosity about aligning and understanding ML models, and are motivated to use your career to address this challenge
	- Enjoy fast-paced, collaborative, and cutting-edge research environments
	- Have experience implementing ML algorithms (e.g., PyTorch)
	- Can develop data visualization or data collection interfaces (e.g., JavaScript, Python)
	- Want to ensure that powerful AI systems stay under human control
+ skill set:
	- Software Engineer Intern/Co-op (Winter 2024)
	- This role is for students who are excited about building the next generation of machine learning models and NLP products. Our SWE roles can cover creating datasets for machine learning, scaling the pods to serve our API, or even building out new security features on our platform. We don't distinguish much between interns and full-time employees, and you’ll have plenty of opportunities to push code to production. You'll have full autonomy and ownership over high-impact work, and will be backed by the support of an incredible team or leaders & mentors. Join us at a pivotal moment, shape what we build, and wear multiple hats!
	- We're currently hiring for multiple teams and roles, including Frontend, Backend, Full-stack, and Infrastructure roles. We'll take your interests & experience into account throughout the application process.
	- Please Note: To be eligible for this position, you should be currently enrolled in a post-secondary program and available for a full-time 3-6 month internship, co-op, or research work term (January - April). We have offices in Toronto, Palo Alto, and London but embrace being remote-first! There are no restrictions on where you can be located for this role.
	- Ship delightful experiences for our user-facing products, meticulously crafting code for browsers or server code
	- Build features for the API platform that directly impact users
	- Design and implement robust data pipelines (crawlers, storage, filters)
	- Design and implement scalable services or infrastructure for machine learning development
	- Build internal tooling (CI/CD, dev utilities) to move faster together
	- Build tech writing skills through maintaining and contributing to technical documentation, both internal and external facing
	- Keep up with the cutting edge and adopt new technologies to improve performance and reliability across Cohere
+ Distributed Systems/ML Engineer
	- The Platform ML team builds the ML side of our state-of-the-art internal training framework used to train our cutting-edge models.  We work on distributed model execution as well as the interfaces and implementation for model code, training, and inference.  Our priorities are to maximize training throughput (how quickly we can train a new model) and researcher throughput (how quickly we can develop new models) with the goal of accelerating progress towards AGI.  We frequently collaborate with other teams to speed up the development of new capabilities.
	- As a Distributed Systems/ML engineer, you will work on improving the training throughput for our internal training framework, while enabling researchers to experiment with new ideas.  This requires good engineering (for example designing, implementing, and optimizing state-of-the-art AI models), writing bug-free machine learning code (surprisingly difficult!), and acquiring deep knowledge of the performance of supercomputers. In all the projects this role pursues, the ultimate goal is to push the field forward.
	- We’re looking for people who love optimizing performance, understanding distributed systems, and who cannot stand having bugs in their code.  Since our training framework is used for large runs with massive numbers of GPUs, performance improvements here will have a large impact.
	- This role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.
	- Apply the latest techniques in our internal training framework to achieve impressive hardware efficiency for our training runs
	- Profile and optimize our training framework
	- Work with researchers to enable them to develop the next generation of models
	- Have run small scale ML experiments
	- Love figuring out how systems work and continuously come up with ideas for how to make them faster while minimizing complexity and maintenance burden
	- Have strong software engineering skills and are proficient in Python
	- Annual Salary Range: $245,000—$385,000 USD
+ ML User Experience Engineer
	- The Platform ML team builds the ML side of our state-of-the-art internal training framework used to train our cutting-edge models.  We work on distributed model execution as well as the interfaces and implementation for model code, training, and inference.  Our priorities are to maximize training throughput (how quickly we can train a new model) and researcher throughput (how quickly we can develop new models) with the goal of accelerating progress towards AGI.  We frequently collaborate with other teams to speed up the development of new capabilities.
	- As a ML User Experience Engineer, you will work on our training framework to create the abstractions that allow researchers to perform experiments using cutting-edge models with impressive ease-of-use.  Many of our research teams build on our framework for running their experiments, and they should be able to write their experiments such that they get both flexibility and high scalability.
	- We’re looking for someone who wants to work at the interface between research and compute and who loves building a great experience for researchers designing their next experiment. This is a high leverage area due to the large algorithmic gains that can be achieved when research productivity is increased.
	- This role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.
	- Build out our internal training framework to make research with large distributed models easy and fun
	- Work closely with researchers to ensure that the framework meets their needs and enables the next generation of experiments
	- Design and build the next generation of training infrastructure at the forefront of language model research
	- Have worked on ML tools that researchers love
	- Have a good understanding of current models and training algorithms
	- Are a strong software engineer and proficient in Python
	- Are obsessed with correctness and beautiful interfaces
	- Annual Salary Range: $245,000—$385,000 USD
+ Research Engineer
	- By applying to this role, you will be considered for Research Engineer roles across all teams at OpenAI.
	- As a Research Engineer here, you will be responsible for building AI systems that can perform previously impossible tasks or achieve unprecedented levels of performance. We're looking for people with solid engineering skills (for example designing, implementing, and improving a massive-scale distributed machine learning system), writing bug-free machine learning code, and building the science behind the algorithms employed. 
	- The most outstanding deep learning results are increasingly attained at a massive scale, and these results require engineers who are comfortable working in large distributed systems. We expect engineering to play a key role in most major advances in AI of the future.
	- Have strong programming skills
	- Have experience working in large distributed systems
	- Be excited about OpenAI’s approach to research 
	- Interested in and thoughtful about the impacts of AI technology
	- Past experience in creating high-performance implementations of deep learning algorithms
	- Annual Salary Range: $200,000—$370,000 USD
+ Software Engineer – Model Inference
	- Our team brings OpenAI’s most capable technology to the world through our products. Most recently, we released ChatGPT, GPT-4, the Whisper API, and DALL-E. We empower consumers and developers alike to use and access our start-of-the-art AI models, allowing them to do things that they’ve never been able to before.
	- Across all product lines, we ensure that these powerful tools are used responsibly. This is a key part of OpenAI’s path towards safely deploying broadly beneficial Artificial General Intelligence (AGI). Safety is more important to us than unfettered growth.
	- We're looking for an engineer to join our team at OpenAI to help us scale up our critical inference infrastructure, which efficiently services every customer request to use our state-of-the-art AI models, including GPT-4 and Dall-E. 
	- Improve the reliability, security, scalability, and observability of our distributed inference infrastructure.
	- Build tools to give us visibility into our bottlenecks and sources of instability and then design and implement solutions to address the highest priority issues.
	- Ensure the most efficient use of a constellation of different state-of-the-art AI models deployed on a large, heterogeneous fleet of Azure VMs under Kubernetes.
	- Have experience with high-throughput scheduling as a service, particularly at supercomputing scale.
	- Are proficient in testing, debugging, and maintaining systems written in low-level systems languages, particularly C++ or Go.
	- Either know or can quickly learn the fundamentals of modern AI architectures.
	- Have at least 3 years of professional software engineering experience.
	- Know network technologies inside and out from L1 to L7.
	- Own problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done.
	- Have a good intuition for when off-the-shelf solutions will work, and build tools to accelerate your own workflow quickly if they won’t.
	- Have the ability to move fast in an environment where things are sometimes loosely defined and may have competing priorities or deadlines.
	- Annual Salary Range: $200,000—$370,000 USD
+ skill set:
	- Member of Technical Staff
	- Design and implement novel research ideas. 
	- Ship state of the art models to production.
	- Deep connections to academia.
	- We do not delineate strongly between engineering and research. Everyone will contribute to writing production code and conducting research depending on individual interest and organizational need.
	- Design, train and improve upon cutting-edge models
	- Develop new techniques to train and serve models safer, better, and faster
	- Train extremely large scale models on massive datasets
	- Engage in research collaborations with our partner organizations and academic affiliations
	- Publish your work in top-tier conferences and journals
	- Work closely with product teams to develop solutions
	- Assist our legal teams with preparation of patents on developed IP
	- Join us at a pivotal moment, shape what we build and wear multiple hats!
	- Proficiency in Python and related ML frameworks such as Tensorflow, TF-Serving, JAX, and XLA/MLIR
	- Experience using large-scale distributed training strategies
	- Familiarity with autoregressive sequence models, such as Transformers
	- Strong communication and problem-solving skills
	- A demonstrated passion for applied NLP models and products
	- Bonus: experience writing kernels for GPUs using CUDA
	- Bonus: experience training on TPUs
	- Bonus: paper at top-tier venues (such as NeurIPS, ICML, ICLR, AIStats, MLSys, JMLR, AAAI, Nature, COLING, ACL, EMNLP)
	- This is neither an exhaustive nor necessary set of attributes. Even if none of these apply to you, but you believe you will contribute to Cohere, please reach out. We have a wide variety of backgrounds at Cohere.
+ skill set:
	- Collaborate within the team across product, design, product, infrastructure, strategy and engineering.
	- Mentor, learn and share knowledge with others along the way.
	- Have impact and have fun
	- Working outside your comfort zone
	- MS/PhD degree in Computer Science or related technical field or equivalent practical experience.
	- Experience with one or more general purpose programming languages including but not limited to: Java, C/C++ or Python.
	- Develop scalable solutions based on state-of-the-art machine learning and AI methodologies.
	- Develop prototypes and conduct experiments to evaluate the performance of ML/AI architectures/algorithms in large-scale industrial applications.
	- Have strong familiarity with leading machine learning and deep learning such as libraries such as TensorFlow, Caffe, Scikit-Learn, Scipy, Pandas, PyTorch and others.
	- You should be able to develop your own algorithms, loss functions, network architectures.
	- Prior publication record in top tier conferences in computer vision / machine learning is a major plus.
	- Write well-structured and re-usable code, design experiments and integrate solutions in larger production systems.
	- Experience shipping products strongly preferred
+ skill set:
	- Collaborating with business stakeholders to understand requirements and socialize solutions
	- Designing and implementing novel machine learning methods
	- Evaluating new paradigms for deploying machine learning models
	- Staying atop the most recent developments and best practices in a quickly changing field
	- A deep understanding of machine learning algorithms and statistics
	- Scientific or quantitative computing experience (Python, R, Spark)
	- Experience working with distributed datasets (Hadoop, Hive, Spark, SQL)
	- The ability to tell a story with data (large scale analysis, data visualization)
	- Experience writing production code (such as Python, Java, or Scala)
	- An understanding of best practices in software engineering (git, CI/CD, etc)
	- We strongly believe in being an active part of our community. We teach, write, give tech talks, release open source projects, and would love it if you also shared these passions. Take a look at a few of our recent blog posts to get an idea:
		* https://tech.iheart.com/mapping-the-world-of-music-using-machine-learning-part-2-aa50b6a0304c
		* https://tech.iheart.com/a-generative-model-for-track-playlists-4dba8b8515c
		* https://tech.iheart.com/ihrpi-a-simple-solution-to-python-package-management-874e373f5838
		* https://tech.iheart.com/real-time-music-recommendations-for-new-users-with-amazon-sagemaker-364b346d07db
+ skill set:
	- We're looking for a Research Engineer - Deep Learning  to join Team Snapchat! As a member of the Augmented Reality team, you will train state of the art Machine Learning models. Working closely with the Research team, you will collaborate with engineers and designers and find new ways to apply machine learning to create exciting products and breakthrough interactive experiences for millions of Snapchatters around the world.
	- Design and implement machine learning and computer vision solutions to be used by millions of Snapchatters
	- Develop deep architectures and optimization techniques for cutting-edge solutions
	- Write production software used by millions of Snapchatters
	- Learn new techniques and stay on the cutting edge
	- Introduce major innovations that can lead to new product features or new areas of business
	- Work closely with other Snap teams to explore and prototype new product features
	- Master's degree in a technical field such as computer science or equivalent experience
	- Industry experience with applied machine learning
	- Experience of deep learning research
	- Experience with any one of segmentation, object detection, image classification, GANs, monocular depth estimation or a related field
	- Experience with a deep learning framework (e.g. TensorFlow, Caffe2, PyTorch)
	- Software engineering skills (Python)
	- A passion for machine learning; you stay up-to-date with research and are excited about prototyping new ideas quickly
	- Great communication, presentation, and interpersonal skills
+ skill set:
	- We're looking for a Machine Learning Research Engineer to join Team Snapchat! As a member of the Augmented Reality Team, you will train state-of-the-art machine learning models. You will collaborate with researchers, engineers, and designers and find new ways to apply machine learning to create exciting products and breakthrough interactive experiences for 100s of millions of Snapchatters around the world.
	- Design and implement machine learning and computer vision solutions to be used by millions of Snapchatters
	- Develop deep architectures and optimization techniques for cutting-edge solutions
	- Create products that are used by millions of Snapchatters
	- Learn new techniques and stay on the cutting edge
	- Introduce major innovations that can lead to new product features or new areas of business
	- Work closely with other Snap teams to explore and prototype new product features
	- A proven passion for machine learning; you stay up-to-date with research and are excited about prototyping new ideas quickly
	- Knowledge of mathematics and deep learning foundations
	- Knowledge of basic computer vision algorithms
	- Communication, presentation, and interpersonal skills
	- Bachelor's Degree in a technical field such as computer science (or equivalent experience)
	- 3+ years of research or engineering experience in one or more of the following: generative models (GANs, VAE, Glow), segmentation, object detection, classification, tracking, or other related applications of machine learning
	- Industry or project experience with deep learning frameworks (e.g. PyTorch, TensorFlow, Caffe2)
	- Strong track record of software development in Python or C++
	- Master's degree or PhD in a related technical field
	- Experience developing real-time software for mobile applications
	- Examples of your work such as open source projects, blog posts, Kaggle contests, top conference or journal publications, etc.
	- Excitement about Snapchat and our products
+ skill set:
	- Software development with innovative deep learning and machine learning algorithms
	- Exploring immense data sets of information from images, videos, music, customer interactions, and marketing
	- Selecting features, building and optimizing classifiers using machine learning techniques
	- Enhancing data collection procedures to include information that is relevant for building analytic systems
	- Processing, cleansing, and verifying the integrity of data used for analysis
	- Analyze data from across Shutterstock including behavioral data with state of the art techniques to provide a better experience to customers
	- Creating automated anomaly detection systems and constant performance tracking
	- Working with data engineers, analysts and business partners to drive ideas from the rapid prototyping phase all the way through to serving and learning from live traffic at scale
	- 1+ years of experience with common toolkits, such as TensorFlow, Caffe, Torch/PyTorch
	- 1+ years of industry experience creating, deploying, and learning from production algorithm analysis
	- Experience in one or more areas: computer vision, information retrieval, natural language processing, or recommendation systems
	- Experience with software development best practices (version control, testing, code review, etc.)
	- Fluent in one or more general purpose programming languages including but not limited to Python, Spark, C, Java, Scala
	- Proficiency in using query languages such as SQL, Hive, Pig
	- Excellent applied statistics skills, such as distributions, statistical testing, regression, etc.
	- Complete understanding of common frameworks/models such as Inception, Faster R-CNN, YOLO, ELMo or BERT
	- BS or MS in Computer Science or equivalent experience
	- Notebook experience (Jupyter, Zeppelin, Databricks, etc.) to perform data analysis and algorithm development using Python
	- Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
	- Experience with graphics/visualization programming (CUDA, cuDNN)
	- Cloud computing experience
	- Experience with ML collaborative platforms/pipelines (MLflow, Neptune, Kubeflow, etc.)
	- Docker and/or Kubernetes exposure
	- Ph.D. in a related scientific field: Computer science, Physics, Math
+ skill set:
	- There has never been a better time to indulge in the science and technology of Artificial Intelligence. Join a high performing, elite, well experienced team (worked at Google, Amazon, Uber and Facebook; key developers of BigQuery, GMail, Amazon Personalize; come from CMU, MIT, IIT, Stanford, Cal and Cornell), working on some holy grail problems in Machine Learning Systems (a next generation enterprise AI/ML platform that can automatically build custom models for a variety of business problems).
	- We are looking for talented backend software engineers, machine learning software engineers and research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you will own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.
	- SOFTWARE ENGINEER - BACKEND SYSTEMS @ Abacus.AI
	- Responsible for building out a cloud runtime for an AI engine that automates various aspects of an ML/AI system workflow including feature pipelines, model training and a real-time multi-tenant inference system.
	- Candidates will need to have a BS or MS from top notch CS programs with over 4 years of industry experience. We are looking for excellent backend / systems software engineers who have experience building at least one of the following:
		* Large scale backend systems used by consumer or high volume enterprise services
		* Cloud data processing platforms in production
		* Large scale machine learning pipeline infrastructure
	- Experience building production applications which use ML/AI is a plus.
+ skill set:
	- SOFTWARE ENGINEER 1 - MACHINE LEARNING @ Abacus.AI
	- Responsible for implementing various algorithms to do automated feature extraction and dataset augmentation, optimizing runtimes of neural network algorithms and building higher-level abstractions for various common AI/ML techniques. As an ML engineer, they will also work cross functionally amongst other engineers, on common ML operation tasks such as ML data management and training and model deployment, as well as build systems that are scalable.
	- Candidates will need to have a BS in computer science from an accredited university. In addition, we're looking for engineers who have the following:
		* Working knowledge of software engineering - through job experience or coursework. Experience with Python preferred
		* Have at least 6 months of professional work experience in one of the following: ML/AI models in production, neural network algorithms, performance optimization of deep learning systems.
		* Coursework or work experience with machine learning algorithms such as classifiers, anomaly detection, and clustering
+ skill set:
	- SENIOR SOFTWARE ENGINEER - MACHINE LEARNING @ Abacus.AI
	- Responsible for implementing various algorithms to do automated feature extraction and dataset augmentation, optimizing runtimes of neural network algorithms and building higher-level abstractions for various common AI/ML techniques. As an ML engineer, they will also work cross functionally amongst other engineers, on common ML operation tasks such as ML data management and training and model deployment, as well as build systems that are scalable.
	- Candidates will need to have a BS in computer science from an accredited university OR have 5 years of professional work experience. In addition, we are looking for software engineers who have the following:
		* 5 years of professional software engineering experience. Some experience with Python is required.
		* Have at least 1 year of professional work experience in one of the following: data infrastructure, ML/AI models in production, neural network algorithms, performance optimization of deep learning systems.
+ skill set:
	- The Think Tank Team is an interdisciplinary collective of researchers, designers, scientists and engineers located in Mountain View, CA. Our mandate is to explore what's next for Samsung by applying bleeding-edge advances in software, machine learning, computer-human interaction, sensor and display technologies to solve real-world challenges that will transform users' experiences in ways we can only just glimpse on the horizon today.
	- TTT began as a small team in 2012 and brought its first concept -- the Samsung Gear watch -- to market one year later. Since then we have released several projects such as the Beyond 3D/360/4k camera for AR/VR cinematography, the BotChef cooking robot, the Ballie personalized companion, and others. We work on a wide variety of time scales, advancing science and applying it to create new products and experiences that will impact the lives of millions.
	- Our team members represent a diverse skillset, including electrical engineering, computer engineering, signal processing, machine learning, computer vision, visual design, interaction design, industrial design, optics, physics, and more from institutions such as MIT, Caltech, Stanford, CMU, Oxford and others. We believe that the best way to show is to design and build prototypes, and that the best products come from teams collaborating to understand and solve a problem from multiple perspectives. We believe that design and creativity are core duties of every member of our team.
	- You must be passionate about creating new devices and technologies, and ready to learn on the fly, solve complex problems, work closely with others, and creatively approach design and engineering tasks at all scales. We believe a person's work speaks for itself, and welcome everyone with the right drive, attitude, and skills.
	- BS/MS/PhD degree in Computer Science or related technical field or equivalent practical experience.
	- 2 years of work experience in Machine Learning or Artificial Intelligence in real-world settings.
	- Strong C++ and/or Python skills.
	- Ability to rapidly prototype with leading ML frameworks.
	- Experience with current state-of-the-art methods from machine learning & deep learning libraries such as TensorFlow, Caffe, Scikit-Learn, Scipy, Pandas, Torch and others.
	- Experience with a multitude of machine learning methods such as SVMs, logistic regression, boosting, decision trees, clustering, HMMs etc.
	- Experience with CV libraries such as OpenCV
	- Experience in multiple forms of machine leaning, from the very simple to the most complex.
	- Experience in creation of novel custom features and pre-processing approaches to improve baseline algorithms. Work should go beyond using standard libraries.
	- Solid understanding of proper evaluation including folds, cross-validation and metrics.
	- Experience with one or more of the following: Natural Language Processing, GANs, autoencoders, Reinforcement Learning, CNNs, and others.
	- Flexibility to deal with rapidly changing environment.
	- Prior experience with signal processing from sensor data is a plus.
	- Participate in cutting edge research in machine intelligence and machine learning applications. Leverage expertise from ML research and develop novel predictive models/algorithms
	- Develop solutions and algorithms that can be applied in variety of real-world applications and devices.
	- Work closely with researchers and engineers from variety of disciplines to develop new algorithms, product concepts and core-technologies that will bring new business opportunities to Samsung.
+ skill set:
	- Our Acoustic Modeling team is collaborating closely with our Machine Learning Engineering team to train, test, and deploy a state-of-the-art, deep-learning based system to transcribe voice into text. This critical work will add to our customers' ease of use and control as we continue to differentiate an end-to-end Sonos experience for them.
	- Train state of the art acoustic models
	- Minimize the model footprint while keeping high performance in both noisy and far field conditions
	- Manage, scale and optimize our Kaldi training pipeline (data management, infrastructure and metric tracking)
	- Experience with machine learning models applied to speech recognition (GMM-HMM, DNN-HMM, E2E models) and related algorithm (forward-backward, viterbi search, backprop, etc)
	- Python, C++
	- Good knowledge of Kaldi, and at least one other deep learning framework (Tensorflow, PyTorch)
	- MS / PhD in Computer Science or Machine Learning
	- At least two years of experience in deployment of machine learning models in production
	- Excellent verbal and written communication skills (English)
	- Experience using Docker
	- SQL, noSQL database
	- Rust
+ skill set:
	- Responsibility: This is a hybrid of system engineering and machine learning role:
		* Write server-side production code for applications that are robust and efficient
		* Develop machine learning algorithms, combining with rule-based optimization to deliver improvement in product metrics
		* Build recommendation and ranking algorithms for news articles
		* Develop internal analytics tools
		* Rapid prototyping
	- Minimum Qualifications
		* 2+ yrs. experience in designing and implementing machine learning algorithms, and applying them to real world problems
		* Solid Machine Learning background and deep understanding of certain domain of machine learning techniques, especially in natural language processing, recommendation systems, computer visions
		* Solid software development skills with proven record of shipping changes to production that improved product metrics with machine learning technologies
		* Good written and spoken communication skills, can work across functional teams
		* Expert coding abilities in multiple programming languages (e.g. Java, C++, Python, Scala)
		* MS or BS in computer science, mathematics, physics or other quantitative fields
	- Preferred skill/experience
		* Experience with cloud based architecture (e.g. Amazon Web Services)
		* Strong interest in news media and our mission
+ skill set:
	- Senior Staff Software Engineer, Model Serving
	- We're a team of engineers, thinkers, and champions whose aim is to give technology language. Every day our team is breaking new ground, as we build transformational AI technology and products for enterprise and developers that wish to harness the power of Large Language Models.
	- We're driven by ambition, as we firmly believe that our technology has the potential to revolutionise the way industries engage with natural language. Our strong technical foundation speaks for itself, with our team composed of world-class experts who have collectively accumulated hundreds of thousands of citations in academia.
	- The Cohere team is a collective of college dropouts, PhDs, alumni of big tech and scrappy start-ups, new grads and career pivots, who believe a diverse team is the key to a safer, more responsible technology. At Cohere, work isn't the opposite of play, as we build the future of language AI with team members on almost every continent in the world, working from high rises, cabins, tour buses, and dog-friendly offices.
	- There's no better time to herald the next step with us as we shape the future of Generative AI.
	- Are you energized by building high-performance, scalable and reliable machine learning systems? Do you want to help define and build the next generation of AI platforms powering advanced NLP applications?  We are looking for Senior Staff Software Engineers to join the Model Serving team at Cohere. The team is responsible for developing, deploying, and operating the AI platform delivering Cohere's large language models through easy to use API endpoints. In this role, you will work closely with many teams to deploy optimized NLP models to production in low latency, high throughput, and high availability environments. You will also get the opportunity to interface with customers and create customized deployments to meet their specific needs.
	- We are looking for candidates with a range of experiences for multiple roles, from senior to staff-level engineers.
	- Please Note: We have offices in Toronto, Palo Alto, and London but embrace being remote-first! There are no restrictions on where you can be located for this role.
	- Experience with serving ML models
	- Experience designing, implementing, and maintaining a production service at scale
	- Familiarity with inference characteristics of deep learning models, specifically, Transformer based architectures.
	- Familiarity with computational characteristics of accelerators (GPUs, TPUs, and/or Inferentia), especially how they influence latency and throughput of inference.
	- Strong understanding or working experience with distributed systems
	- Experience in performance benchmarking, profiling, and optimization.
	- Experience with cloud infrastructure (e.g. AWS, GCP)
	- Experience in Golang (or, other languages designed for high-performance scalable servers)
	- If some of the above doesn’t line up perfectly with your experience, we still encourage you to apply! If you consider yourself a thoughtful worker, a lifelong learner, and a kind and playful team member, Cohere is the place for you.
	- We value and celebrate diversity and strive to create an inclusive work environment for all. We welcome applicants of all kinds and are committed to providing an equal opportunity process. Cohere provides accessibility accommodations during the recruitment process. Should you require any accommodation, please let us know and we will work with you to meet your needs.
+ skill set:
	- Responsibility
		* Research and core technology development for machine learning
		* The ability to solve issues ranging from fundamental algorithm development, implementation and optimization to deliver product metrics
		* In this position, you are expected to utilize your expertise on one or more of following R&D areas to provide cutting edge solutions or core technologies for SmartNews recommendation systems (Ads, News, etc)
		* General Machine Learning, Deep Learning
		* Natural Language Processing (entity recognition, categorization, text embedding, etc)
		* Computer Vision, Image Processing
		* Knowledge Graph
		* Recommendation, Collaborative Filtering Algorithms
		* Rapid prototyping and iterating
	- Minimum Qualifications
		* 2+ yrs. experience in designing and implementing machine learning algorithms, and applying them to real world problems
		* Solid Machine Learning background and good understanding of certain domain of machine learning techniques, especially in natural language processing, recommendation systems, computer visions
		* Good written and spoken communication skills, can work across functional teams
		* Strong coding abilities in multiple programming languages (e.g. Java, C++, Python, Scala)
		* MS in computer science, mathematics, physics or other quantitative fields
	- Preferred skill/experience
		* Ph.D Degree in computer science, mathematics, physics or other quantitative fields
		* Strong interest in news media and our mission
+ skill set:
	- Contribute to designing, building, evaluating, shipping, and refining Neural Magic's machine learning product including libraries, demos, and notebooks
	- Prototype and iterate on state of the art research against proprietary, in-house software
	- Work closely with customers to understand specific needs, implementation details, and successful deployment using Neural Magic's engine
	- Collaborate with a cross functional team about market requirements, best practices and how machine learning is deployed in the wild
	- Be a trusted advisor and partner, providing deep analysis of deep learning approaches, helping to define and conduct pilot tests
	- Master's or PhD degree in computer science or math, or equivalent experience. Prefer a focus on machine learning.
	- Solid knowledge of machine learning and deep learning fundamentals, in particular MLPs and CNNs
	- Experience with taking deep learning models from conception to production: writing, training, testing, and deploying machine learning models
	- Proficient with Python and one or more deep learning frameworks such as Pytorch, Tensorflow, Caffe, MXNet, Keras, etc
	- Experience working with large data pipelines for analyzing and training
	- Self-directed individual who learns quickly and is comfortable operating in a blank slate environment
	- Excellent communication skills, ability to tailor technical information for different audiences
	- Strong sense of project ownership and personal responsibility
+ skill set:
	- You have a proven track record of statistical modeling / applied machine learning with a focus on churn prediction, LTV prediction, and customer behavioural clustering.
	- You have experience with A/B and Multivariate test design and implementation.
	- You're pragmatic. You value simple and effective solutions over complicated brain-melters.
	- You can take a complex concept and make it sound simple, using clear visual references to help.
	- You like taking on big challenges—given the appropriate time and resources.
	- You're hungry to learn and embrace healthy debate.
	- You're empathic, enthusiastic, and collaborative.
	- You've are proficient building queries with SQL.
	- You have experience with AWS or other cloud systems.
	- You are an expert in Python or R, and have some experience in implementation (Scala/Java).
	- Having a working knowledge of Big Data technologies (e.g. Spark or Redshift) is a plus.
	- You're fluent in English and eager to work in a multicultural, international environment.
+ skill set:
	- Design, build, evaluate, ship, and refine Neural Magic's machine learning product including libraries, demos, and notebooks
	- Prototype and iterate on state of the art research against proprietary, in-house software
	- Work closely with customers to understand specific needs, implementation details, and successful deployment using Neural Magic's engine
	- Collaborate with a cross functional team about market requirements, best practices and how machine learning is deployed in the wild
	- Be a trusted advisor and partner, providing deep analysis of deep learning approaches, helping to define and conduct pilot tests
	- Several years of experience working with Machine Learning in industry. Master's or PhD degree in ML, computer science or math preferred.
	- Solid knowledge of machine learning and deep learning fundamentals, in particular MLPs, Recommendation Systems, and CNNs
	- Full stack experience of taking deep learning models from conception to production: writing, training, testing, and deploying models
	- Proficient with Python and one or more deep learning frameworks such as Pytorch, Tensorflow, Caffe, MXNet, Keras, etc
	- Experience working with large data pipelines for analyzing and training
	- Self-directed individual who learns quickly and is comfortable operating in a blank slate environment
	- Excellent communication skills, ability to tailor technical information for different audiences
	- Strong sense of project ownership and personal responsibility
+ skill set:
	- Advanced understanding of SQL, Python, PySpark, Scala, Hive, h2o, as well as machine learning techniques and algorithms, such as linear / logistic regression, tree-based learners, Gradient boosting, SVM, NLP, time series modeling, clustering, etc.
+ skill set:
	- https://scale.ai/careers/5d709886-b586-44c7-b112-4e04501a4ca0
	- Create optimized and efficient tooling, like [Guided Automatic Segmentation](https://scale.ai/blog/automatic-segmentation), for taskers to complete complex tasks with speed and accuracy.
	- Reliably evaluate data quality at scale.
	- Intelligently route tasks from customers to specialized taskers for low turnaround and high accuracy.
	- Automatically hire, train and onboard taskers.
	- Deep Learning: building CNNs.
	- Classical Machine Learning: non-deep learning methods (random forests, collaborative filtering, HMMs, etc.)
	- Applied ML Engineering: building large-scale data and machine-learning pipelines.
	- Experience with TensorFlow and/or Pytorch.
+ skill set:
	- Machine learning areas of special interests include: CNNs, RNNs, distributed GPU computing, detection, prediction, motion planning, mapping and localization
	- Work with lidar sensor firmware and low level signal processing
	- Perform Multi-Object Tracking & Multi-Sensor Fusion
	- Sensor calibration & Perception algorithms (all types and flavors)
+ skill set:
	- Hadoop, HDFS, Hive, HBase, MapReduce, and Mahout.
	- Large-scale graph algorithms, clustering, page-rank, and community detection.
	- Apache Spark, SparkSQL, MLlib, and Scala Actors.
	- Ensemble Methods, Deep Learning, and other trendy topics in the Machine Learning community.
+ Familiarity with neural network framework such as TensorFlow, PyTorch, Caffe, Theano
+ Develop runtime API for custom NN accelerator hardware in C/C++ environment
+ Help developers, marketers, and product managers understand how to access, implement, and rigorously evaluate and optimise ML-based interventions.
+ Working with Big Data, ML, AI. Keras, TensorFlow, Python, Redshift, S3, Spark, Random Forests and Vowpal Wabbit
+ Strong hands-on experience with at least one of the main stream deep learning frameworks such ***TensorFlow, PyTorch, BLVC Caffe, Theano***
+ skill set:
	- You will be responsible for the training, the validation and the deployment of state-of-the-art speaker validation systems based on the most recent machine learning techniques. Since our speaker verification system must run locally on resource-constrained hardware, you will be faced with the challenging task of minimizing the system footprint while retaining high performance in both noisy and far field conditions. Additionally, you will work closely with the embedded software team to continuously improve optimization and inference strategies to contrast the prevailing cloud computing paradigm.
	- Experience in development, validation and implementation of deep learning models in either the acoustic or visual domains.
	- Experience with one or more general purpose programming languages (C++, Python etc) and with version control.
	- Knowledge of deep learning framework (TensorFlow or PyTorch)
	- MS / PhD in Computer Science or related technical field.
	- 2+ years of experience in deployment of machine learning models in production.
	- Ability to formalize, analyze and solve complex problems.
	- Excellent verbal and written communications skills in English.
	- Experience with face, speaker or landmark recognition
	- Experience in deploying machine learning for embedded systems
	- Previous experience working on verification or authentication tasks
	- Track record of published papers in peer-reviewed journals or conferences
	- Knowledge of Rust and/or Docker
+ skill set:
	- Every day, SmartNews analyzes millions of URLs to deliver the top articles that matter in near-real time to millions of users around the world. Our News Ranking team, along with our AI Foundation team, works on a range of recommendation and optimization problems, e.g. news feed ranking, push recommendation, search ranking/discovery, collaborative filtering, personalized recommendation, diversification to deliver the world's quality information to the people who need it.
	- Responsibilities: This is a hybrid of system engineering and machine learning role:
		* Propose machine learning initiatives to fuel our business growth, build end to end machine learning framework/solution to improve our KPI/metrics
		* Write server-side production code for applications that are robust and efficient
		* Develop machine learning algorithms, combining with rule-based optimization to deliver improvement in product metrics
		* Build recommendation and ranking algorithms for news articles
		* Develop toolings to make ML engineers to be more productive
		* Lead medium/large sized projects to improve news ranking
	- Minimum Qualifications
		* 3+ years of experience in designing and implementing machine learning algorithms, and applying them to real world problems
		* Solid Machine Learning background and deep understanding of certain domain of machine learning techniques, especially in natural language processing, recommendation systems, computer visions
		* Strong software development skills with proven record of shipping changes to production that improved product metrics with machine learning technologies
		* Able to have deep end-to-end understanding of sophisticated ranking systems and can proactively detect problems and make improvement suggestions
		* Good written and spoken communication skills, can work across functional teams
		* Expert coding abilities in multiple programming languages (e.g. Java, C++, Python, Scala)
		* MS or BS in computer science, mathematics, physics or other quantitative fields
	- Preferred Qualifications
		* Experience with cloud based architecture (e.g. Amazon Web Services)
		* Strong interest in news media and our mission
+ skill set:
	- Develop highly scalable machine learning models to solve problems such as image/video classification, image/video content understanding and recommendation
	- Develop in-house machine learning tools and pipelines to support fast experimentation of machine learning models
	- Work with other engineers to identify and solve machine learning problems
	- Minimum Qualifications
		* Experience in one or more of the following areas: deep learning, computer vision, recommendation systems, and data mining
		* Experience with machine learning frameworks such as TensorFlow, PyTorch or MXNet
		* Expert knowledge in C/C++ and Python
	- Preferred Qualifications
		* MS degree in Computer Science or related quantitative field with 3+ years of machine learning related work or research, or PhD degree in Computer Science or related quantitative field
		* Industry experience with developing and deploying machine learning models in production
		* Contributions to research communities/efforts, including publishing papers in machine learning (AAAI, ICLR, NeurIPS, ICML, KDD, CVPR)
+ skill set:
	- Develop highly scalable tools leveraging machine learning models to solve problems such as classification, clustering, topic modeling, natural language processing and recommendation
	- Develop in-house machine learning tools and pipelines to support fast experimentation of machine learning models
	- Work with other engineers to identify and solve machine learning problems
	- Minimum Qualifications
		* Experience in one or more of the following areas: machine learning, data mining, computer vision, and natural language processing
		* Experience with machine learning frameworks such as TensorFlow, PyTorch or MXNet
		* Expert knowledge in C/C++ and Python
	- Preferred Qualifications
		* MS degree in Computer Science or related quantitative field with 3+ years of machine learning related work or research, or PhD degree in Computer Science or related quantitative field
		* Industry experience with developing and deploying machine learning models in production
		* Contributions to research communities/efforts, including publishing papers in machine learning (AAAI, ICLR, NeurIPS, ICML, KDD, CVPR)
+ skill set:
	- Immuta's Data Platform
	- Python, Pandas, PySpark
	- Various Machine Learning Frameworks
	- Snowflake
	- Databricks
+ skill set:
	- Responsibilities
		* Responsible to set technical direction of most impactful areas of news ranking team and drive its major projects as tech lead
		* Able to work across product and platform teams to orchestrate large scope projects that significantly improve news ranking and achieve key engagement KPIs
		* Design and develop frameworks to make ranking engineers of news ranking team to be productive
		* Lead design and implementation of machine learning algorithms, combining with rule-based optimization to deliver significant improvement in product metrics
	- Minimum Qualifications
		* 6+ years of experience in designing and implementing machine learning algorithms, and applying them to real world problems
		* Solid Machine Learning background and deep understanding of certain domain of machine learning techniques, especially in natural language processing, recommendation systems or computer visions
		* Have proven track record of hands-on design and coding experience in building and deploying multi-tier recommendation systems at scale
		* Able to have deep end-to-end understanding of sophisticated ranking systems and can proactively detect problems and make/implement improvement suggestions
		* Able to distill and solve hardest problems of news ranking team in expertise areas
		* Good written and spoken communication skills, can work across functional teams
		* Expert coding abilities in multiple programming languages (e.g. Java, C++, Python, Scala)
		* MS or BS in computer science, mathematics, physics or other quantitative fields
	- Preferred Qualifications
		* Strong interest in news media and our mission
		* Experience with news ranking
+ Senior Machine Learning Engineer, Science
	- at Chan Zuckerberg Initiative (View all jobs)
	- Redwood City, CA (Open to Flex)
	- We’re on an ambitious mission to solve some of society’s toughest challenges — from eradicating disease to improving education and addressing the needs of our local communities. Join us to build a better future for everyone!
	- Learn more about our work modes, benefits, and interview process at www.chanzuckerberg.com/careers.
	- The mission of the CZI Science Initiative is to support the science and technology that will help make it possible to cure, prevent, or manage all diseases by the end of the century. We support interdisciplinary teams of physicians, biologists, computational scientists, and engineers to expand our understanding of the human body and illness — the very science behind medicine. CZI fosters collaboration between scientists and engineers, develops tools and technologies, and builds support for basic scientific research. Our current focus is on understanding the mysteries of the cell, the fundamental building block of life. To that end, our approach in the Science Technology group is to digitally model cell function through research, advanced development, partnerships, and funding.
	- Building software such as 
		* CZ CELLxGENE - a rich data platform with interfaces that enable any computational or biological expert to understand the molecular function of cells and tissues.
		* CZ ID - a metagenomics platform that delivers insights in infectious disease.
		* napari-hub - a site to discover image analysis methods.
	- Funding of
		* Single cell biology and the application of technologies that enable multi-omics investigation at the level of cells.
		* Imaging and developing tools capable of observing biological processes across spatial scales at the level of tissues, cells, and proteins.
		* Neurodegeneration and bringing new ideas and new people into the field, to look at this problem from a cross-disease perspective.
	- Doing science through
		* The CZ Biohub empowering scientists to work on their riskiest, most exciting ideas.
	- The CZ Imaging Institute and developing technologies to image the molecular architecture of the cell with atomic resolution
	- As an Engineer on the  AI/ML team you will apply and optimize state-of-the-art models in artificial intelligence and machine learning to solve important problems in the biomedical sciences aligned with CZI’s mission. You will work as part of a team responsible for developing and deploying ML models that use data developed by CZI and research partners all for the purpose of contributing to greater understanding of human cell function.
	- You will have the opportunity to work closely with teams of scientists, computational biologists, engineers within CZI and to collaborate with CZI grantees, with CZ institutes, and other external labs and organizations. Your work will inspire and enhance the production and analysis of datasets by CZ teams and collaborators. Scientific focus areas could include single cell biology, imaging, genomics, and proteomics.
	- Working with the ML Research Scientists, iterate on, optimize, deploy, and maintain innovative machine learning models, systems, and software tools that enable the analysis and interpretation of complex biology data sets and natural language.
	- Work with the cross-functional team members to quickly iterate on system performance to meet/stay ahead of users’ needs - e.g. we get feedback that the model doesn't scale to X million so working with our user researcher/scientist/product team to iterate on the solution. 
	- May be involved in data pipelining work to clean, manage, and version data to ensure that the Research Scientist has access to reproducible data. 
	- Serve as an interface to product teams to understand how models may need to evolve to support multiple use cases.
	- Enjoy working in a highly interactive and cross-functional collaborative environment with a diverse team of colleagues and partners in leading-edge cell biology data-driven research.
	- A track record and expertise in developing AI/ML models for large scale  clusters of CPUs and GPUs, using techniques of distributing load, scheduling computation, optimizing AI/ML code, fine tuning models,  deploying for batch/endpoint inference, and generally taking full advantage of the computational infrastructure.
	- A good working knowledge of Python-based ML  libraries and frameworks such as PyTorch, TensorFlow, NumPy, Pandas, and Scikit-learn.
	- Expertise in using modern frameworks for distributed computing and infrastructure management, particularly as related to ML models, (e.g. Apache Spark, High Performance Compute (HPC), Distributed Tensorflow, etc)
	- Have a Masters in computer science with a focus on machine learning & data analytics, or equivalent industry experience and at least 3-5 years of experience developing and applying machine learning methods.
	- A good working knowledge of general software engineering practices in a production environment.
	- The ability to work independently and as part of a team, and have excellent communication and interpersonal skills.
	- The Redwood City, CA base pay range for this role is $190,000- $285,000.00.
+ skill set:
	- Building descriptive or predictive models using Python, PySpark, Spark ML, Scala
	- Building and deploying models in a Big Data environment; comfort with using Hive, MapReduce, Kafka, Spark Streaming, Spark SQL, JavaScript, Sqoop to run data processing tasks
	- Building AI/ML models using techniques such as Regressions, Random Forest, Gradient boosting, neural networks, such as ANN/CNN, Hidden Markov, NLP, SVM, Bayesian techniques, etc.
	- Experience in a Linux computing environment and use of command-line tools including knowledge of shells. Python scripting for automating common tasks is a plus
	- Working knowledge of AIML packages such as Keras, Theano, TensorFlow. Software such as H2O is a plus
	- Working knowledge of cloud infrastructures such as AWS, Azure or GCP is a plus
+ skill set:
	- Drawing on recent advances in Deep Imitation Learning and Deep Reinforcement Learning, covariant.ai is developing AI software that makes it easy for robots to learn new, complex skills.
	- As a part of a rapidly growing startup, you will have the rare opportunity to build and develop software that mimics human behavior without the help of engineers, while also growing and developing your own skills and passions as the company expands. Join us on an exciting journey as we bring the latest breakthroughs in artificial intelligence to the future of robotics.
	- Work side-by-side with the top talent in industry and academia in the field of AI + robotics.
	- Implement mission-critical software in a reliable and sustainable manner.
	- Evolve best practices for traditional software development to address the needs of cyber-physical systems and deep-learning-based software -- including scalability, maintainability, and security.
	- Collaborate with and support a diverse team, which includes software engineers, mechanical and electrical engineers, roboticists, and ML researchers.
+ machine learning:
	- Develop backend services and infrastructure to expand our answer engine to support 10M+ documents and 100K+ QPS
	- Ship web applications and APIs using Python, Flask, MongoDB, MySQL, Lucene, Spark, React, Go, and/or TensorFlow
	- Optimize the performance of our indexing, processing, and query pipelines
	- Take product ideas from ideation to implementation
	- Implement state-of-the-art algorithms in Question Answering, Machine Reading Comprehension, Text Summarization, in a scalable, production-ready fashion using Tensorflow and Spark
	- Build systems to evaluate and tune performance of a real world deep learning system, from data collection to processing to model implementation to post-processing and visualization
	- modern Big Data stack (Spark or Hadoop, Kafka or RabbitMQ, ZooKeeper, Redis, Memcache, Lucene, MongoDB, MySQL)
	- Familiarity with containerization and dev-ops (Docker, Kubernetes, Docker Swarms, Jenkins, Phabricator, Continuous Integration, Continuous Delivery) is a plus
	- Familiarity with modern Deep Learning and Natural Language Processing / Natural Language Understanding (NLP, NLU), including Neural Networks, RNNs, seq2seq models, and real world machine learning in TensorFlow (incl. regularization, cross-validation, dropout) are a huge plus
	- Adaptable, humble, and interested in pushing the boundaries of what's possible
	- Work with world class talent (our team consists of former Facebook, Palantir, Dropbox, and LinkedIn Engineers; we have 2 ACM ICPC World Finalists)
+ skill set:
	- Vicarious aims to transform robotics by creating robots with human level performance on real-world manipulation tasks. We are passionate about changing the world with science and software, and we are looking for exceptional people to join us in that mission.
	- Our long term goal is to build machines that exceed human intelligence. We are passionate about changing the world with science and software, and we are looking for exceptional people to join us in that mission. Vicarious is working on solving the problems that will take us from the current state of the art to human-level AGI. We work on all components of the AI problem, including perception, concept learning, reasoning, and sensory motor systems, and beyond. Our underlying framework is a probabilistic graphical model that is inspired by the structure of the neocortex. You will join a small, tightly knit collective of extraordinary engineer scientists. Everyone works on our full stack, from algorithms to low level optimizations to GUI code and back.
	- Put your algorithm and math skills to work in solving the hardest problems in learning and inference in hierarchical models.
	- Make decisions about how to translate complex ideas to working solutions while keeping a keen eye for computation/accuracy/memory tradeoffs.
	- Design controlled experiments to show particular performance aspects of the systems and large scale experiments to show statistical robustness.
	- Write infrastructure software to scale our systems and data visualization routines to understand what is happening inside.
	- Keep yourself updated with advances in the field of machine learning and neuroscience.
	- The craftsmanship of building elegant algorithms and tight implementations are part of our company DNA. We work hard to maintain a codebase and a culture that are a joy to work in.
	- PhD or Masters in CS/EE or a related discipline or Masters in CS/EE with relevant research experience.
	- Strong machine learning fundamentals, including probabilistic graphical models
	- Experience building hierarchical vision systems and publishing relevant papers in CVPR/NIPS/ICML is a big plus.
	- Extensive programming skills, ideally in Python and C, and a track record of translating ideas into prototypes quickly.
	- Solid fundamentals in linear algebra, probability theory, signal processing, and optimization.
	- Experience developing and testing ideas in a large scale setting.
	- Experience with belief propagation and approximation methods.
	- Knowledge of biologically inspired models of vision.
	- Interest in neuroscience a plus.
	- Experience working in an interpreted environment like MATLAB or Mathematica also a plus.
	- Desired personal qualities:
		* Integrity
		* Ability to admit when wrong
		* Altruism
		* Fearlessness working outside your comfort zone
		* Patience with others
		* Described by others as the best researcher / engineer / thinker they know
		* Intellectual breadth
		* Sense of humor
+ skill set:
	- Ursa Labs's work is focused on the Apache Arrow open source project, a cross-language development platform for in-memory analytics. Within the Arrow project, most of our time is spent on the C++, Python, and R libraries. It is our goal to make everyday tools for data access, cleaning, wrangling, analytics, and visualization a great deal more powerful and interoperable than they are now.
	- We are looking for an experienced engineer to take a lead role in the build and testing systems of the Apache Arrow project, including automated building (continuous integration), testing, and benchmarking on a range of architectures and operating systems. The ideal candidate should have experience playing a significant role in shipping software with high technical complexity.
	- Help maintain the Apache Arrow open source project: code review, documentation, and mentor junior contributors.
+ machine learning engineer:
	- Experience in modern Deep Learning and Natural Language Processing / Natural Language Understanding (NLP, NLU), including Neural Networks, RNNs, seq2seq+attention models, and real world machine learning in TensorFlow (incl. regularization, cross-validation, dropout)
	- Experience building production-ready NLP systems
	- Familiarity with non-standard machine intelligence models (Reinforcement Learning, Hierarchical Temporal Memory, Capsule Networks) is a plus
	- Familiarity with Distributed systems (Docker, Kubernetes, Kafka, Spark, Redis, AWS S3/EC2/RDS/KMS, MongoDB, or Lucene) is a plus
	- Adaptable, humble, and interested in pushing the boundaries of what's possible
	- Proficiency in Python, R, or Java
+ skill set for Deep Learning Research Engineer at Crossing Minds:
	- San Francisco, CA.
	- At Crossing Minds we are building a future where AI-powered software helps maximize human happiness. Currently, we are creating the continuous recommendation experience that provides personalized recommendations for all the things you love but haven't discovered yet.
	- Crossing Minds incubates artificial intelligence products and services, enriching the human experience using deep learning. Our first product, Hai, is a universal recommendation engine that maps taste across categories (music, movies, games, etc.) to help find more of what you love. Through our website, app, and messenger interaction, Hai syncs with other platforms to serve as a cultural home and launchpad for personal exploration.
	- Sponsored by Nvidia, GCP and Stanford's StartX program, we're looking for a deep learning expert to help our product understand tastes and help our growing team develop the heart of AI.
	- Collaborate with our agile team of researchers and engineers.
	- Design and implement efficient systems to understand users textual queries in real time.
	- Elaborate algorithms to extract relevant informations from text reviews or descriptions.
	- Elaborate algorithms to extract relevant informations from images data.
	- You want to join a small team of hard-workers, to build an awesome product that'll help everyone you know.
	- You have a PhD in Deep Learning, with focus on Computer Vision and/or Natural Language Processing.
	- You have strong knowledge on Computer Science, Computational Learning and HPC fundamentals: algorithms, systems, linear algebra, numerical methods, statistics.
	- You have at least two years of experience in Theano, TensorFlow or PyTorch.
	- You used CUDA on clusters of GPUs professionally.
	- Python, Machine Learning, Natural Language Processing, Deep Learning, theano, Convolutional Neural Networks, Machine Learning Data Science Python
	- Compensation: $140k – $170k, 0.0% – 1.0% of stock options.
+ (applied) machine learning and data science skill set:
	- Google Cloud ML Engine
	- spaCy / Prodigy
	- scikit-learn
	- H2O
	- Amazon SageMaker
	- Azure ML Studio
	- RISELab Ray
	- OpenAI Gym
	- PyTorch
	- Spark NLP
	- BigDL and Analytics Zoo
	- TensorFlow
	- Keras
	- AllenNLP
	- Other cloud-based services
	- Other open source tools
	- AutoML tools/technologies:
		* Google Cloud AutoML
		* Azure AutoML
		* Amazon SageMaker
		* IBM Watson AutoAI
		* DataRobot
		* H2O
	- data versioning:
		* Weights & Biases
		* Pachyderm
		* DVC
		* Homegrown
	- model and experiment tracking:
		* Neptune
		* MLflow
		* Polyaxon
		* Replicate
		* Weights & Biases
		* Kubeflow
		* Comet
		* Homegrown
	- categories of ML tools to incorporate into ML workflows:
		* Automated model search and hyperparameter tuning
		* Model monitoring
		* Support for notebooks
		* Support for IDEs
		* Model visualization
		* Feature store
		* Data lineage or data catalog
	-  bottlenecks holding back further AI adoption:
		* Lack of data or data quality issues
		* Company culture doesn't yet recognize the needs for AI
		* Lack of skilled people or difficulty hiring the required roles
		* Efficient tuning of hyperparameters
		* Difficulties in identifying appropriate business use cases
		* Legal concerns, risks, or compliance issues
		* Technical infrastructure challenges
		* Workflow reproducibility
	- skills gaps related to machine learning and AI adoption within your organization
		* Understanding and maintaining a set of business use cases
		* Data engineering
		* Compute infrastructure
		* ML modelers and data scientists
+ skill set:
	- Software Development at Rasa is not only about writing Code. You'll have to come up with good architectural designs, quality code, and break an ambitious long-term vision down into milestones and issues.
	- We don't draw a hard line between our engineering and research teams, we all work on the same stack and share work, knowledge, and tools. A lot of the code we create is open source and used by a large community of developers. The driver for our development efforts is this: what would help developers build great conversational software? What can we enable them to build that they couldn't do currently?
	- We do fundamental machine learning research, and we ship commercial quality software that puts it to use. We mostly work in Python, but dip into other languages when it makes sense to. Because engineering is so close to research, you'll quickly learn a lot about Machine Learning, Model Management, Data Analysis workflows, and what it takes to ship machine learning applications into production.
+ skill set:
	- Google Dialogflow
	- The Visual Fusion Engine, VFE
	- algolia - Search Made Powerful
	- Cruzr - Humanoid service robot
	- Descartes Labs
	- Blue River Technology - Smart Agricultural Machines
	- NLPBOTS - Intelligent Chat-bots
	- BrainShop - AI for developers
	- Flyr
	- Sisense
	- Mookkie
	- NanoNets
	- Workfusion - Rpa Express
	- MSG.AI
	- Keepers - Advanced Child Monitoring
	- Neura - User Awareness with AI
+ skill set:
	- Software Engineer, Model Inference
	- Lamini AI is at the forefront of bringing LLMs to production.  We are on a mission to help every company unlock the power of generative AI, by putting their own data to work. Our team is made up of highly experienced ML engineers and tech industry veterans and we're backed by leading computing and technology companies.
	- We are looking for a systems expert to be one of our founding engineers, who's excited to reinvent programming languages with AI and enable a software engineering revolution powered by AI. We can teach you the AI part, as we've taught over 100k people around the world.
	- You'll be working directly with the founders, influencing the product direction, and playing a key role in leading and growing our team. 
	- Most of all, we're looking for someone who is eager to iterate fast on building new ML cloud systems, and is hungry to build and own enormous contributions.
	- 2+ Experience building and rapidly prototyping production cloud based software
	- 2+ years of experience in researching or contributing to ML/DL systems and frameworks
	- Strong coding skills (in at least one of Python and C++)
	- Solid fundamentals in machine learning and deep learning topics
	- Demonstrated fluency with data structures, algorithms, architecture, and agile software best practices in any language
	- Desire to work in an inclusive and collaborative environment
	- An interest in continually learning from others, teaching others, and digging into new challenges
	- Desire to create speed of light training and inference systems for next-generation AI
	- Deep technology expertise in machine learning systems, e.g. TinyML, Triton, CUDA, ROCm, Exo, MLIR, Halide, etc
	- Software architect of a programming system or language
	- Solid fundamentals in other computer science and computer engineering topics: algorithms and data structures, operating systems, computer architecture, etc.
	- Experience with GPU architecture and programming: CUDA and its related libraries and toolkits (e.g., cuDNN, cuBLAS, CUTLASS, nvprof, Nsight Compute, Nsight Systems, etc.); ROCm and its related libraries and toolkits.
+ skill set:
	- Advanced understanding of SQL, Python, PySpark, Scala, Hive, h2o, as well as machine learning techniques and algorithms, such as linear / logistic regression, tree-based learners, Gradient boosting, SVM, NLP, time series modeling, clustering, etc.
+ skill set:
	- Machine Learning Engineer
	- Lamini AI is at the forefront of bringing LLMs to production.  We are on a mission to help every company unlock the power of generative AI, by putting their own data to work. Our team is made up of highly experienced ML engineers and tech industry veterans and we're backed by leading computing and technology companies.
	- We are looking for exceptionally talented Machine Learning Engineers to join our small team. You will be responsible for end-to-end ownership of scalable Machine Learning systems — from data pipelines, to training, to analyzing performance in a production environment. Since you'll be joining an early-stage startup at the ground level, you'll need to be able to wear multiple hats and thrive while working in a dynamic environment. 
	- Design and train new production-ready machine learning models. You will lead the development of new machine learning models and data pipelines. You will apply fundamental machine learning concepts to quickly iterate and debug model related issues and develop new techniques to handle unique cases with each customer. 
	- Collect, process and analyze data. A big part of our machine learning projects is understanding and analyzing the data. You must build pipelines and processes for cleaning and organizing data as well as build tools to help analyze data. You must also understand what types of data models are struggling with and use this analysis to propose solutions.
	- Analyze and improve existing models. You will also be responsible for analyzing performance of our existing models and work to improve their accuracy by applying the latest published research, feature engineering and tuning of hyperparameters.
	- At least 3 to 5+ years of professional experience designing, training, and deploying machine learning models
	- Strong computer science foundation, including data structures, algorithms, and design patterns
	- Expertise in Python demonstrated by implementing multiple medium to large-scale projects
	- Proven ability to implement and debug machine learning models
	- Excellent communication skills and the ability to have in-depth technical discussions with both the engineering team and business people
	- Familiarity with machine learning frameworks and libraries (e.g., scikit-learn, Keras, TensorFlow, PyTorch)
	- Industry experience with relational databases and SQL-based tools
	- BSc in Computer Science, Mathematics or similar field; Master's or Ph.D. degree is a plus
	- Self-starter and comfortable working in an early-stage environment
	- Experience with big data pipeline technologies such as BigQuery, SnowFlake, Spark, Kafka
	- Research experience in machine learning or artificial intelligence related field
	- Contributions to open source ML projects
	- Experience working on logistics or shipping-related products
	- Experience with Agile development 
+ skill set:
	- MACHINE LEARNING PLATFORM SOFTWARE ENGINEER
	- Collaborate with data engineers, data scientists, and product teams to guide the translation of R&D prototypes into stable, testable, and maintainable production services
	- Develop and deploy tools and services for our team to accelerate the production lifecycle and assessment of production readiness
	- Help lead team members in executing continuous integration and continuous delivery (CI/CD) activities to release code into a Production environment
	- Act as a consultant within the Science Organization on software engineering principles, code quality, and performance optimization techniques
	- Apply software engineering rigor and best practices to machine learning, including CI/CD and automation
	- Build model performance monitoring capabilities and data monitoring tools
	- MS Computer Science, Engineering, Technology, Mathematics, Statistics, or related field with 3+ years of industry experience or BS + 5 years' experience
	- Hands on coding experience with Python building end-to-end systems as an MLOps Engineer, Machine Learning Engineer, Software Engineer, or equivalent
	- Experience in ML model development, orchestration, deployment, monitoring, support and creating and maintaining deployment pipelines with CI/CD tools
	- Experience with cloud computing platforms like AWS, GCP, or other cloud providers developing with containers (e.g., Docker, Kubernetes) in cloud computing environments
	- Experience with database, such as SparkSQL, MongoDB, SQL, and SQLite
	- Exposure to deep learning approaches and modeling frameworks (Py Torch, TensorFlow, Keras, etc.)
	- Experience building ML web service, such as Flask, JavaScript, HTML, and Django.· Familiarity with Kubeflow or similar platforms like MLflow or SageMaker
	- Experience building and evaluating machine learning models
	- Strong understanding of software testing, benchmarking, and continuous integration
	- Experience mentoring and teaching software development best practices to data scientists
	- Ability to translate complex technical concepts to collaborations, decision makers, and non-technical audiences
	- The ideal candidate will have a passion for generating new ideas, be a proactive and quick learner, and be able to demonstrate creativity and innovation.
+ skill set:
	- ALGORITHM ENGINEER (DEEP LEARNING)
	- You will be responsible for research, development and deployment of real world deep learning solutions while building Computer Vision, Speech, Machine Learning, and Robotics
	- Drive end to end data collection/annotation, model training and model evaluation
	- Optimizing and accelerating deep learning algorithms on various Kneron platforms (SOC, edge, server etc) and accelerators (DSP, NPU etc).
	- Improving model accuracy by understanding failures, finding redundancies in data and staying on top of the latest in model architectures and training algorithms.
	- Contributing to the backend or edge infrastructure to scale model training and inference workload including training pipelines, evaluation, and model deployment
	- MS or PhD in Computer Science/Engineering with 2+ years of professional experience or equivalent experience
	- Strong background in at least one of area of machine learning, such asgenerative models (GANs, VAE, etc.), segmentation, object detection, human tracking
	- Strong programming skills in Python and C/C++; strong software design skills
	- Experience working with modern deep learning frameworks including OpenMMlab, Keras, Tensorflow, PyTorch, MXNet
	- Experience with improving efficiency of AI algorithms for deployment
	- Ability to multitask effectively in a dynamic environment
	- Strong debugging, problem-solving and analytical skills
	- Excellent interpersonal, written and oral communications skills
	- Familiarity with building DL algorithms (neural architecture search, active learning, pruning, quantization etc) and working with data pipelines (ETL, data lake etc).
	- Familiarity with scene understanding, learning 3D representations, synthetic data, temporal data in computer vision.
	- Demonstrated software engineer experience via an internship, work experience, coding competitions, or widely used contributions in open-source repositories (e.g., GitHub)
	- The ideal candidate will have a passion for generating new ideas, be a proactive and quick learner, and be able to demonstrate creativity and innovation.
+ skill set:
	- Good working knowledge in a wide range of machine learning methods and algorithms for classification, regression, clustering, and others – a must.
	- Good Statistical analysis, e.g. hypothesis testing, estimation theory and mathematical skills.
	- Experience dealing with end to end machine learning projects: data exploration, feature engineering/definition, model building, performance evaluation and help in implementation.
	- The ideal candidate should be able to use his/her experience in implementing advanced analytical methods (machine learning, statistical/mathematical modeling) on large amounts of raw data – dealing with all parts of modeling workflow (from data extraction, feature engineering to model building and implementation) and should be able to clearly present and communicate the findings.
	- As a Data Scientist at Playtika you will take part in projects in which analytical solutions are used for solving and/or optimizing business/product problems like user experience modeling, churn prediction, advanced segmentation and others.
	- Experience working with big data tools e.g. pySpark.
	- DL toolbox (e.g. pyTorch, Tensorflow etc. it a plus).
	- Knowledge in Deep learning models (CNN, RNN, etc ...)
	- Reinforcement Learning
+ Strong understanding of machine learning algorithms & principles (regression analysis, time series, probabilistic models, supervised classification and unsupervised learning), and their application
+ skill set for Machine Learning/Deep Learning Algorithm Engineer:
	- Conduct research and development on machine learning, deep learning, and reinforcement learning models, including but not limited to basic algorithms and models, such as CNN, RNN, DNN, and DQN.
	- Provide basic algorithms or operator optimization such as model compression and convolution acceleration for the above models and support performance improvement.
	- Conduct research on algorithms for convex optimization and non-convex-optimization and high performance telecom technologies to make full use of software and hardware and build leading AI frameworks and platforms in the industry.
	- Develop one-stop end-to-end AI platforms including intelligent labeling, feature engineering, model development, automated learning, training, and reasoning.
	- Proficiency in one of the following programming languages: C, C++, and Python; ability to implement self-designed algorithms
	- Knowledge of common machine learning algorithms, including cluster, decision tree, regression, and recommendation
	- Proficiency in the establishment and training of common deep learning networks such as CNN, RNN, and GAN
	- Experience in machine learning/AI engineering and at least one of the mainstream machine learning platforms, including PyTorch and TensorFlow
	- Experience in open source AI platforms including TensorFlow, MXNet, PyTorch, and Caffe (preferred)
	- Knowledge of the transportation, finance, industrial control, and environment protection industries (preferred)
+ skill set for EI Algorithm Expert (for Enterprise Intelligence):
	- Ensure the application of algorithms for one of the following industry solutions: intelligent transportation, smart medical, smart finance, Internet, and IoT.
	- Drive the evolution of system architecture and iterated product development and resolve engineering and optimization issues during algorithm application.
	- Consider the positioning, development strategies, and business models of AI solutions and formulate long-term development plans.
	- Bachelor's degree or higher (PhD preferred); proficient in Java, C, or C++; in-depth knowledge of algorithms and data structures
	- Understanding of at least one of the mainstream deep learning tools, including Caffe, TensorFlow, Keras, MXNet, and so on  
	- Proficiency in deep learning technologies, especially in research on applications of the computer vision technology, including model acceleration, model encryption, and model quantification
	- Distributed system architecture design abilities; knowledge of mainstream technologies including fault tolerance, distributed cache, and high concurrency solutions; experience in multi-threaded and high performance system design and in coding and performance tuning
	- Good communication and coordination skills and dedication to work
+ skill set:
	- Help the current effort of the AI research community, and contribute to cutting edge research in machine intelligence, starting from areas including Deep Learning, Generative Models, Reinforcement Learning, Evolutionary Computing, Sequence Modelling, Large-Scale Distributed Optimization and Low-Precision Numerical Formats.
	- Prototype efficient implementations for training of novel deep learning optimization algorithms and model architectures of increasing complexities.
	- Contribute to the design of efficient software implementation of the experimental setup required to evaluate novel machine learning algorithms and models at scale.
	- Participate to work to identify new directions of AI research, with the aim of contributing to new groundbreaking approaches to computational intelligence. The position will involve the possibility of attending the main research conferences in the field of machine intelligence.
	- Contribute to investigations in specific areas of fundamental and applied research, aiming at publishing the work for discussion within the wider AI research community.
	- Take responsibility for the software implementation of experimental setup critical for investigation of new research directions.
	- Collaborate with the rest of the team and with other groups within the company, to develop new ideas and identify research opportunities.
	- Interact and work with external institutions and research labs. 
	- MSc or PhD in Computer Science, Machine Learning, Mathematics, Physics, Electrical Engineering or related fields, with a strong basis in numerical methods and probability theory.
	- In-depth understanding of modern machine learning algorithms and deep learning architectures.
	- Strong software engineering and coding skills (Python, C/C++) and experience of algorithm implementation in modern machine learning frameworks (TensorFlow, PyTorch). 
	- Strong communication skills, and willingness to work in a collaborative environment.
	- Publications and/or open-source implementations in the area of machine intelligence will be a plus.
+ skill set:
	- If you would like to build computational machines that are solving problems in ways that have never been done, we are looking for software engineers with strong problem-solving skills to help us build an SDK for our optical hardware accelerators. 
	- This SDK converts a trained neural network into a binary we can run on our custom hardware. The SDK imports neural networks from popular frameworks (e.g., TensorFlow, PyTorch) and runs a series of transformations on those neural networks. These transformations include things like quantizing certain parts of the graph and partitioning subgraphs that can run on our device. The SDK also includes a compiler and runtime library to run the transformed neural network on both a simulator and our actual hardware. 
	- Create a customer portal to help keep track of bugs in the SDK 
	- Write documentation and literature for customers to learn how to use the SDK 
	- Debug and refactor parts of the SDK based on customer feedback  
	- Work with electrical engineers to update compiler and runtime libraries
	- Create profiling and debugging tools for both internal and customer use 
	- Bachelor's degree in computer science or related fields 
	- 2+ years of experience writing industry standard code 
	- Proficient in at least one object-oriented programming language (i.e., Python, Java, C++) 
	- Familiarity with Python and C++ 
	- Experience with software testing and building robust software systems 
	- Strong debugging and problem-solving skills  
	- Experience with different build tools (e.g., CMake, Bazel)  
	- Familiarity with Protocol Buffers  
	- Highly proficient in deep learning frameworks (e.g., TensorFlow, PyTorch) 
	- Understanding of machine learning concepts like quantization, pruning, sparsity, etc. 
	- Strong skills with graph algorithms  
	- Experience with Jira, Azure Boards, and Sphinx 
	- Substantial experience with Python and C++ 
	- Proficient with Linux, Bash, and Git  
	- Experience publishing and maintaining open-source packages
+ skill set:
	- The use of machine learning to reimagine software applications and service development is exploding.  Companies from every corner of the industry -- the biggest cloud service providers to corporate industrials to financial services to healthcare to retailers -- are exploring new ways of building products and services using data-centric learning models in place of traditional explicit programming.  The drive to deliver more timely and more accurate results is compelling an ever greater need for specialized computing power. GPUs have been hailed as the solution to those computing needs but the industry is actively searching for a better, more efficient solution.  Graphcore has that solution. 
	- Graphcore's Intelligence Processing Units, or IPUs, are specifically designed for artificial intelligence and compute-dense graph applications.  These are not GPUs, Graphics Processing Units, but rather graph processors especially adept at the kinds of computations used in understanding relationships within a sea of data.  Architecturally, IPUs looking nothing like GPUs.  They offer performance, latency, and power efficiency advantages a GPU will be unable to match.  Graphcore offers support for popular industry ML frameworks and a full tool suite for developers to innovate both within and outside those frameworks. 
	- As a Machine Learning Engineer, you will work to port and optimize machine learning and artificial intelligence applications using Graphcore's Poplar™ software and IPU processors, enabling breakthroughs in this rapidly moving field.
	- You will work on AI and ML applications, create application notes and blog content, and work closely with Graphcore's field teams, customers and partners to help them in understanding and getting the most from our Intelligence Processing Unit (IPU) technology. Having access to world leading compute resources, you will develop applications that push the boundaries of what is possible with machine learning today. You will also act as a senior technical figure within our product support organization, debugging customer issues and providing concise summaries and recommended fixes to our core engineering teams.
	- In your work you will support some of the world's top machine learning innovators at deep learning research groups, at academic institutions, at innovative machine learning start-ups, at leading automotive companies, and at some of the world's largest cloud and internet companies. You will need to develop a deep understanding of the IPU architecture and the associated Poplar™ tools and become familiar with leading machine learning frameworks. 
	- You will need to develop a deep understanding of the state-of-the-art in artificial intelligence & machine learning domains and work with our customers to develop new techniques which exploit the unique features of our IPU architecture.  We want you to become an industry thought leader on Graphcore technology and machine learning applications in the cloud, in automotive and in embedded applications. You should be interested and keen to present at industry conferences and will be able to back this up with written blogs and compelling content.
	- Responsibilities
		* Develop strong technical relationships with researchers and engineers at our customers and partners and help them to develop new algorithms and achieve breakthroughs in artificial intelligence
		* Become a recognized expert on Graphcore's IPU technology and Poplar™ tools and deliver compelling training to our customers and partners
		* Field & resolve challenging/complex customer support issues
		* Shepherd critical customer issues and provide timely advance warning of critical issues that need attention
		* Become a thought leader on machine learning and advocate for Graphcore's IPU technology
		* Work with the Product Management and Engineering to ensure a good flow of customer feedback that can be incorporated into future products
	- Requirements
		* Demonstrable machine learning development experience or related experience writing and optimizing applications in HPC, scientific libraries, compilers, digital signal processors or GPUs.
		* Deep experience with C++ and in-depth knowledge of computer architectures, high performance programming and parallel programming
		* Ability to multitask effectively in a fast-paced environment
		* Action-oriented with strong analytical and problem-solving skills
		* Keen interest to learn about the exciting new field of AI
		* Comfortable in a customer-facing environment
		* Strong written and oral communications skills with the ability to effectively interface with management and engineering
		* Strong team-working and excellent interpersonal skills
	- Differentiators
		* Masters or PhD in related computationally intensive science or engineering field
		* Experience with C/C++, parallel programming and knowledge of computer architectures
		* Experience working with modern deep learning software architecture and frameworks including: Tensorflow, MxNet, Caffe and/or PyTorch
		* Excellent communication & presentations skills and comfortable in a customer-facing environment
		* Experience working with accelerators such as GPUs, DSPs or FPGAs
		* Experience in the AI/machine learning, cloud or automotive space
+ skill set for AI/ML Application Framework Engineer:
	- SiFive is proud to take a software-first approach to develop tools and frameworks that achieve cutting-edge performance without compromising quality. SiFive's Intelligence processors leverage and extend RISC-V Vectors to accelerate AI applications for the edge and beyond. Our Core IPs navigate tradeoffs between performance, power, and area, but do not sacrifice flexibility or programmability. Our software stack is co-designed with the hardware and developed with scalability and quality in mind. Join us to create revolutionary software from the ground up.
	- We are looking for an experienced AI/ML application frameworks engineer passionate about deploying AI inference and end to end enablement, AI framework integration, model accuracy, and performance analysis and tuning. You might be an ideal candidate if you are seeking to develop high quality, innovative, and scalable software that enables state of the art AI inference models to run efficiently and accurately on the SiFive Intelligence processors.
	- Bringing up AI/ML model including model deployment and accuracy verification/tuning.
	- AI/ML model end to end performance analysis and tuning.
	- Quantized ML model development and retraining.
	- Deep learning application and flow implementation and integration.
	- Working closely with Software and Hardware team members for performance exploring and tuning.
	- 3+ years experience working in AI/ML model deployment, verification, tuning and quantization.
	- 3+ proven years of experience in developing high quality production software in C/C++/Python.
	- Experience in AI frameworks: Tensorflow/Tensorflow-Lite/Pytorch/Tensor-RT/CUDA, etc.
+ skill set:
	- Research and develop algorithms /system for given problem independently
	- Provides solutions to a diverse range of moderately complex problems
	- Development of medium sized product features
	- Create rapid prototyping, generating quality wireframes and mockups – a portfolio of recent or salient work is required
	- Works independently and uses judgment within defined policies and practices to influence others in technical directions.
	- Expected to interface with colleagues outside of engineering and may mentor less experienced engineers (NCGs).
	- Sets task level goals and may set project level schedules.
	- Extensive expertise in a any/all below technical domain
		* CV,ML,DL (Un/semi/supervised /reinforcement)
		* Research/Develop CV/ML/DL algorithms using historical (training) data
		* Expertise in rapid DL/ML/CV/RL/NLP POC development using python, Tensorflow, Pytorch,Keras,Matlab,TensorRT,ONNX etc·
		* Expert knowledge of research methodologies in ML/DL domain·
		* Model compression
		* Model Pruning, sparsity, Model Decomposition, Mixed precision, Quantization, sensitivity analysis, Tuning
		* Transfer learning
	- User experience background is a plus·
	- Experience with usability and evaluation is a plus·
	- Experience working within Agile framework is a plus.
	- Experience in conceiving and delivering fantastic end-to-end cross-channel experiences with appreciation of flow, context, micro-interactions, multi -modal possibilities, performance, and tone for multiple customers·
	- Analytical skills, conceptualize ideas, POC, understand and implement literature 
	- Implement given task in C++, MATLAB, Python and design/code DL model using TensorFlow
	- Strong experience in CV, ML, DNN, RNN, RL, Linear Algebra & AI
	- Strong experience in C++, MATALB, Python, TensorFlow, PyTorch,Keras,ONNX,Pytorch
	- Hands on Experience in rapid DL/ML/CV/RL/NLP POC development
	- Very good Knowledge on Model optimization, Pruning, Tuning, ONNX, Distiller, Quantization
	- Very good Knowledge on Object-Oriented Design & System Integration
	- Very good knowledge on Code Optimization, Implement & Adapt Complex Algorithms (E.g. from literature, from other teams, etc.)
	- Work Independently without supervision
	- Work under aggressive schedules towards world-class solutions
	- Ability to deliver exceptional results in challenging tasks
	- Experience in conceiving and delivering fantastic end-to-end cross-channel experiences with appreciation of flow, context, micro-interactions, multi -modal possibilities, performance and tone for multiple customers
	- Ability to consolidate, distill, and incorporate diverse ideas quickly
	- Experience with usability and evaluation is a plus
	- Experience working within Agile framework is a plus
	- CV, ML, CNN, DNN, RNN, Linear Algebra, Pattern Recognition, DSA, OOPS,Model compression
	- C++, MATALB, Python, TensorFlow Pytorch ,Cuda basic, ONNX,Keras
	- Hands-on experience on NLP - NLTK,Padna ,spacy
	- Hands-on experience of AWS (Amazon Web Services) & IoT (Internet of Things).
	- Hands-on experience with Databases.
	- Unity, C#
+ skill set for Machine Learning and Deep Learning Algorithm Engineer
	- Lead R&D for models such as machine learning, deep learning, and reinforcement learning, including CNN, RNN, DNN, and DQN.
		* DQN
	- Optimize basic algorithms or operators of the preceding models, such as model compression and convolution algorithm acceleration, to achieve ultimate performance.
	- PhD in computer science, electrical engineering, or related field
	- Extensive knowledge of deep learning and classical machine learning. Field application experience, such as computer vision, NLP, or intelligent control. Practical experience preferred
	- Proficient in a least one mainstream deep learning tool such as Caffe, TensorFlow, Keras, or MXNet
	- At least one paper published in a top-level conference in a related field preferred
	- Excellent learning ability, communication skills, strong sense of responsibility, and good teamwork. Ability to continually learn and embrace change
+ skill set for Data Mining and Machine Learning Algorithm Engineer:
	- Use data mining and machine learning to study and analyze HUAWEI CLOUD products in the aspect of data monitoring.
	- Use machine learning frameworks to process massive amounts of monitoring data, develop intelligent resource monitoring services, use machine learning algorithms to provide intelligent recommendation for customers, and optimize customers' cloud resource monitoring.
	- Expertise in common data mining technologies and machine learning algorithms, and related practical experience
	- Continuous study of the latest research directions and achievements in machine learning, and exploration of big data applications in cloud monitoring
	- Sensitive to data, strong analysis capability, and creative thinking
	- Solid knowledge of open source components related to data mining and machine learning, such as TensorFlow, Caffe, Spark, and Flink
		* Flink
		* Spark
+ skill set:
	- AI Data Algorithm Engineer
	- Research cutting-edge AI data reduction technologies, including data reduction, deduplication, serialized data compression, video compression, and model compression.
	- Use AI algorithms to analyze problems and model them, design algorithms, and develop and verify prototypes.
	- Lead research of AI technology innovation applications, innovative exploration, and high-value patent incubation, to cement HUAWEI CLOUD's innovation lead.
	- Proven research background and experience in machine learning, deep learning, reinforcement learning, and theoretical information technology preferred. At least one paper published in a top-level AI conference such as ICML, IJCAI, ICLR, AAAI, or KDD preferred
	- Expertise with data storage, data arrangement, data coding, and data reduction preferred
	- Skilled at using machine learning, deep learning, or reinforcement learning frameworks and platforms or tools, such as TensorFlow, Keras, and Caffe
+ skill set:
	- We are looking for a highly motivated ML Frameworks engineer to develop deep learning network models and applications in tensorFlow and pyTorch, that would run on Blaize's massively parallel graph streaming processors. The role provides an opportunity to work on cutting edge technologies in AI and to closely collaborate with the rest of the software stack at Blaize to achieve peak performance on Blaize's graph streaming processors
	- Design and develop state-of-the art machine learning models in Image Classification, Object Detection, NLP, autonomous driving etc
	- Translation of network models in different ML frameworks to MLIR based graphs
	- Closely collaborate with MLIR graph compiler and the rest of the software stack to run the application end-to-end.
	- Enable inference and network training on Blaize's processors with close collaboration with other teams
	- Analyze/Profile various ML workloads and report performance improvement opportunities
	- Develop end to end demo applications to show-case Blaize's capabilities
	- Follow agile software development methodology, unit testing and continuous integration
	- Quantising the ML models for the edge to improve performance with minimal loss of accuracy
	- B.Tech/M.Tech ECE or CS
	- 2 to 12 years of relevant experience working with various ML frameworks.
	- Strong programming skills in python
	- Strong hands-on knowledge of tensorFlow and pyTorch
	- Knowledge of network training and distributed algorithms
	- Familiarity with compute kernels for various network layers is a plus but not mandatory
	- Experience of developing end-to-end applications using camera and display is a plus
	- Good knowledge of various quantisation techniques. Prior work with tensorFlow to tensorFlow-lite conversion is a plus
	- Familiarity with ONNX is good to have
	- Familiarity with Graph Compilers is an added advantage but not mandatory
+ skill set:
	- Senior Deep Learning Software Engineer, Algorithmic Model Optimization
	- Join our team of algorithmic model optimization experts and take part in unlocking the biggest potential for AI with generative models such as large language models (LLM) and diffusion models. As a Senior Deep Learning Software Engineer, you will be at the forefront of pushing the boundaries of these models and enabling their deployment at a larger scale with unmatched efficiency. We are developing an innovative software platform that will not only be utilized internally but also have a significant impact externally by enabling the creation of groundbreaking AI products. This is an exceptional opportunity for passionate software engineers like you, who have a strong background in Deep Learning, to join us in solving the most significant challenges in the field.
	- Your role will be pivotal in our mission to maximize the potential of our rapidly expanding data center deployments. Additionally, you will play a crucial part in adopting a data-driven approach to hardware design and system software development. Collaboration is at the heart of what we do, and you will have the chance to work closely with a diverse range of teams at NVIDIA, including the Applied Deep Learning Research teams, CUDA Kernel and DL Framework development teams, and the Silicon Architecture Team. In this position, you will actively engage with internal stakeholders, users, and members of the open-source community. Your input will be vital in defining and implementing cutting-edge model optimization algorithms. The scope of your work will encompass researching and developing highly efficient search algorithms, defining public APIs, implementation, and various other software engineering tasks. We are seeking individuals who are as enthusiastic as we are about pushing the boundaries of AI and contributing to groundbreaking advancements in the field. If you are passionate about innovation, tackling complex DL problems, and working in a collaborative environment, this is the perfect opportunity for you. Join us, and together, we will shape the future of AI model optimization and its impact on the world.
	- Prototype and develop model optimization methods, and build a most impactful model optimization platform
	- Collaborate with internal and external partners to accelerate the adoption of deep learning model optimization
	- Stay up to date with the latest research and innovations in generative AI and model optimization techniques
	- Analyze and optimize the theoretical and practical performance of DL models generated
	- Publish findings in top AI conferences, and create Intellectual Property
	- Masters, PhD, or equivalent experience in Computer Science, AI, Applied Math, or related field.
	- 6+ years of relevant work or research experience in Deep Learning.
	- Excellent software design skills, including debugging, performance analysis, and test design
	- Strong algorithms and programming fundamentals
	- Ability to work independently, define project goals and scope, and run your own development effort
	- Good communication, documentation habits, and interpersonal skills
	- Experience with one or more: Python, C++, performance tuning
	- Contributions to PyTorch, JAX, or other Machine Learning Frameworks
	- Knowledge of GPU architecture and compilation stack, and capability of understanding and debugging end-to-end performance
	- Familiarity with Nvidia's deep learning SDK such as TensorRT
	- Strong understanding of deep learning algorithms and solutions
	- Strong understanding of ML model optimization techniques such as quantization, pruning, distillation.
	- Increasingly known as “the AI computing company” and widely considered to be one of the technology world's most desirable employers, NVIDIA offers highly competitive salaries and a comprehensive benefits package. Are you creative, motivated, and love a challenge? If so, we want to hear from you! Come, join our model optimization group, where you can help build real-time, cost-effective computing platforms driving our success in this exciting and rapidly growing field.
	- The base salary range is $176,000 - $333,500.
+ skill set:
	- You will be working on cutting edge problems in Deep Learning for Deeplite optimization software stack.
	- Work on architecture-specific neural network optimization algorithms for high performance computing.
	- Design and develop a lightweight and high-performance inference engine for CPUs and microcontrollers.
	- In this role you will have opportunity to develop an inference engine running on many devices.
	- Bachelors, Masters or Ph.D. or equivalent in Computer Science, Computer Engineering, or related field.
	- 4+ years of relevant work or research experience in high performance computing and compiler optimizations.
	- Excellent C/C++ programming and software design skills, including debugging, performance analysis, and test design.
	- Excellent Python skills, and a dedication to writing clean, understandable, testable code with an eye towards maintainability.
	- Experience with optimizing compiler, programming low-level hardware and microcontrollers.
	- Development or research experience in a production compiler (preferably LLVM or [TVM/Apache TVM](https://tvm.apache.org/))
	- Familiarity with ARM, RISC-V and/or x86 architectures is highly preferred
	- Experience with deep learning runtime frameworks such as ARM-NN, CMSIS-NN, TensorRT, XLA, ONNX Runtime, OpenCL, MLIR is a huge plus
+ Knowledge of machine learning frameworks such as scikit-learn, SparkML, or Tensorflow.
+ skill set:
	- Deeplite's revolutionary platform “Neutrino” is being used and/or evaluated by many customers, including top consumer and automotive OEMs, semiconductor companies and computer vision pioneers, globally. As a member of the customer success team, you will be the bridge between our product team and our customers to enable them to optimize and run their Artificial Intelligence (AI) solutions on eco-friendly, small footprint devices for everyday use. 
	- In this role, you will act as an external champion of our platform and work closely with our customers to solve issues and/or educate them to speed up their projects. You will also get an opportunity to work on development of faster & smaller models for small footprint devices.
	- Undergraduate in Computer Science or related field (master's degree is a plus). 
	- More than 2 years' experience with the following skills 
	- Hands on experience with Deep Learning frameworks like PyTorch, TensorFlow.
	- Proficiency in programming languages like Python and C/C++
	- Fundamentals of deep learning (CNN)
	- Experience with runtime environments (OpenVINO, ONNX runtime, TVM etc.) would be a huge plus.  
	- Experience with deep learning model compression, speedup related project is a huge plus 
	- Experience building systems based on machine learning and/or deep learning (Experience with embedded boards is a plus) 
	- Customer facing skills. 
	- 2 years of industry experience working with clients for technical collaboration.
	- Willingness to work on multiple projects concurrently.
	- Opportunity to advance state-of-the-art software in the fields of DNN model compression, AutoML, Neural Architecture Search (NAS) and more!
+ skill set:
	- Our platform is in the development phase, and we're implementing academic works and our patent portfolio into our technology. In this role, you will be immersed in core concepts of deep neural networks and their low-level implementations, closely follow academic works in the field of deep learning and collaborate and increase productivity on existing research projects.
	- Post-secondary education in a related field.
	- Strong working knowledge of deep learning, and experience utilizing theoretical and empirical research to solve real-world problems.
	- Must have at least 1 year of experience with Deep Learning frameworks like PyTorch or TensorFlow.
	- Must have at least 3 years of industry experience with C/C++, Python coding or other high-level languages.
	- Experience building systems based on machine learning and/or deep learning.
	- An understanding of low-level implementation of neural networks.
+ skill set:
	- Post-secondary education in a related field.
	- Must have at least 1 year of experience with Deep Learning frameworks like PyTorch or TensorFlow.
	- Must have at least 1-3 years of experience with C/C++, Python coding or other high-level languages.
	- A strong publication record or alternative relevant innovation experience.
	- As an intern, you will be tasked to advance the science and technology of Deeplite's engine. You'll interact with both leading academics and industry to create new advancements in the field of deep learning alongside top academic partners, and you'll have the opportunity to define and lead research directions and contribute to the AI research community by publishing papers, securing patents, collaborating with leading academic institutions, and speak and participate at international conferences.
+ skill set:
	- Machine Learning Engineer
	- In order to execute our vision, we need to grow our team of best-in-class machine learning engineers. We are looking for developers who are excited about staying at the forefront of deep learning technology, prototyping state-of-the-art neural net models and launching these models into production. We value hard workers who have no qualms working with terabyte-scale datasets, who are interested in learning new technologies at all levels of the machine learning stack, and who move fast and take ownership of their projects. Our ideal candidate has experience creating a working machine learning-powered project from the ground up, contributes innovative ideas and ingenious implementations to the team, and is capable of planning out scalable, maintainable data pipelines.
	- Everything involved in applying a ML model to a production use case, including, designing and coding up the neural network, gathering and refining data, training and tuning the model, deploying it at scale with high throughput and uptime, and analyzing the results in the wild in order to continuously update and improve accuracy and speed
	- Interface closely with the Backend and DevOps teams as well as with our internal data labeling services
	- Utilize OWASP top 10 techniques to secure code from vulnerabilities
	- Maintain awareness of industry best practices for data maintenance handling as it relates to your role
	- Adhere to policies, guidelines and procedures pertaining to the protection of information assets
	- Report actual or suspected security and/or policy violations/breaches to an appropriate authority
	- You have an undergraduate or graduate degree in computer science or similar technical field, with significant coursework in mathematics or statistics
	- You have 1-2 years industry machine learning experience
	- You have successfully trained and deployed a deep learning machine model (image, NLP, video, or audio) into production, with measurably improved performance over baseline, either in industry or as a personal project
	- You have strong experience with a high-level machine learning frameworks such as ***Tensorflow, Caffe, or Torch***, and familiarity with the others
	- You know the ins and outs of Python, especially as it applies to the above ML frameworks
	- You are capable of quickly coding and prototyping data pipelines involving any combination of Python, Node, bash, and linux command-line tools, especially when applied to large datasets consisting of millions of files
	- You have a working knowledge of the following technologies, or are not afraid of picking it up on the fly: ***C++, Scala/Spark, SQL, Cassandra, Docker***
	- You are up-to-date on the latest deep neural net research and architectures, both in understanding the theory and motivations behind the techniques, as well as how to implement them in the ML framework of your choice
	- You have great communication skills and ability to work with others
	- You are a strong team player, with a do-whatever-it-takes attitude
	- The current expected base salary for this position ranges from $120,000 - $180,000.
+ skill set for SOFTWARE ENGINEER
	- A Software Engineer is sought by a company providing custom Deep Learning software for image and video analytics in San Diego, CA to perform the following duties:·
	- Design neural network structures optimized for mobile and edge hardware.·
	- Develop and Design Face Recognition Platform including model training for face detection, alignment, and feature extraction.·
	- Implement novel deep neural network architectures and learning techniques to solve a variety of computer vision tasks and push the State of Art in performance.·
	- Build and maintain the infrastructure for training and deploying models, including massive data pipelines, experiment management platform, and visualization tools, etc.·
	- Integrate model components with the product stack.·
	- Research and develop State of Art model compression techniques including model distillation, pruning, quantization, model binarization, and others for CNN, RNN, and LSTM models.·
	- Implement novel deep neural network architectures and develop advanced training algorithms to support model structure training, auto applications, and others.·
	- Research and optimize model compression techniques for CNN accelerator and jointly optimize hardware architecture for compressed models.·
	- Develop a deep learning compiler stack that interfaces frameworks such as TensorFlow, CAFFE2, and KERAS, etc.· Convert neural nets (CNN/RNN) into internal representations suitable for optimization.
	- Must have a Master's Degree in Computer or Computational Science.·
	- Proficient in C, C++/STL, PYTHON, MATLAB, JAVA Programming.·
	- Knowledge in compute algorithms and data structure.·
	- Familiar with software development process.
	- Note: This is a full-time position.
	- Location: San Diego, CA.
+ skill set for AI Algorithm Expert/Data Scientist:
	- Network Energy Advanced Technology Research, Architecture Evolution Design and Strategic Technology Planning
	- Huawei's German Research Center in Nuremberg (Nuremberg Research Center) is responsible for Network Energy Advanced Technology Research, Architecture Evolution Design and Strategic Technology Planning.
	- Responsible for exploring and breeding of the AI/Big Data algorithms and their application in on-board energy, data center energy, telecom energy and PV energy field, etc.
	- Responsible for technology insight and planning, algorithm research and design, technology development and architecture maintaining of AI technology in energy field.
	- Supervising a team of AI engineers to solve complex industrial and technical problems using advanced mathematical modeling and optimization technique, including but not limited to, big data pre-processing, problem formulation, feature engineering, algorithm selection, hyper parameters tuning and deployment. You will not only supervise the team but should also be able to code and deploy on your own
	- Analyzing the latest development of industry and academia on industrial AI/Big Data field, participate in open communities and further organizations in industrial AI/Big Data, promote industrial AI/Big Data ecosystem construction and external cooperation, and increase the overall influence of Huawei energy.
	- Lead the design and subsequent verification and validation of AI/Big Data algorithm concepts in the R&D laboratories.
	- Essential:
		* You hold an Master Degree in AI, software development, applied mathematics, statistics, control science or any related field
		* You provide more than 10 years of experience in AI algorithm, research design ant it's application. In addition you have experience in Data Mining in an energy related industry
		* You hold successful AI and Big Data related project experience in an energy related industry
		* In-depth knowledge of AI/Big Data, Digital Twin and Operational Optimization algorithm, etc.
		* Good grasp of at least one or more of the following languages such as Python, Matlab, R, C/C++, Java
		* In-depth knowledge in at least one or more mainstream algorithm development frameworks such as TensorFlow, Caffe, MXNet, Scikit-Learn.
		* You have initial experience in leading a development team and have certain encoding capability.
		* Very good English skills in written and spoken (working language)
		* Strong learning ability, passion for technology, good communication and coordination skills.
	- Preferred:
		* Doctor degree in AI, software development, applied mathematics or any related field with 5 years of experience in AI algorithm and Data Mining in an energy related industry
		* Further language skills are an plus
+ skill set for SOFTWARE RESEARCH ENGINEER (SAN DIEGO, CA)
	- A Software Research Engineer is sought by a company providing custom Deep Learning software for image and video analytics in San Diego, CA to perform the following duties:· 
	- Design software architecture to improve software data training and machine learning framework;· 
	- Examine current state-of-the-art AI systems and investigate new approaches and methods to increase the speed of software solutions;· 
	- Investigate the quality of database elements/data editing and research new validation methods and procedures;· 
	- Investigate systems and software issues affecting company's research efforts and investigate possible solutions;· 
	- Examine current research database and explore new ways to modify, test, verify, and analyze category and pre-processing of image data labeling;· 
	- Prepare research manuscripts and presentations based on the company's research discoveries;· 
	- Examine current performance measures and investigate new, more effective methods to evaluate energy efficiency, and time and space complexity of algorithms;· 
	- Design and conduct tests to troubleshoot and validate software for performance, reliability, and robustness; and· 
	- Design key performance testing models and procedures to measure the efficiency and accuracy of new and existing software.
	- Must have a master's degree in computer engineering.
	- Location: San Diego, CA.
+ skill set for SENIOR AI AND DEEP LEARNING ARCHITECT – MODEL COMPRESSION AND QUANTIZATION
	- Research and develop state of art model compression techniques including model distillation, pruning, quantization, model binarization, and others for CNN, RNN, LSTM models.
	- Implementing novel deep neural network architectures and develop advanced training algorithm to support model structure training, auto pruning and low-bit quantization.
	- Apply and optimize model compression technique to variety of models in computer vision applications, audio applications, and others.
	- Research and optimize model compression technique for Kneron CNN accelerator and jointly optimize hardware architecture for compressed model.  
	- M.S./PhD in Computer Science, Machine Learning, Mathematics or similar field (Ph.D. is preferred)
	- 3+ years of industry/academia experience with deep learning algorithm development and optimization.
	- 3-5 years of software engineering experience in an academic or industrial setting.
	- Holistic understanding of deep learning concepts, state of the art in model compression research and the mathematics of machine learning.  
	- Solid understanding of CNN, RNN, LSTM, variety of training method, learning rate choice, hyper-parameter tuning.
	- Research experience on any model compression technique including model distillation, pruning, quantization, model binarization.
	- Strong experience in C/C++ programing.
	- Hands-on experience in computer vision and deep learning frameworks, e.g., OpenCV, Tensorflow, Keras, Pytorch, and Caffe.
	- Experience on hardware architecture design is a plus.  
	- Ability to quickly adapt to new situations, learn new technologies, and collaborate and communicate effectively.
	- Experience with parallel computing, GPU/CUDA, DSP, and OpenCL programming is a plus.
	- Top-tier conference publication records, including but not limited to CVPR, ICCV, ECCV, NIPS, ICML, is a strong plus.
	- Location: Taipei/Hsinchu/USA_San Diego/Shenzhen/Zhuhai
+ skill set:
	- Research and develop algorithms /system for given problem independently
	- Provides solutions to a diverse range of moderately complex problems
	- Development of medium sized product features
	- Create rapid prototyping, generating quality wireframes and mockups – a portfolio of recent or salient work is required
	- Works independently and uses judgment within defined policies and practices to influence others in technical directions.
	- Expected to interface with colleagues outside of engineering and may mentor less experienced engineers (NCGs).
	- Sets task level goals and may set project level schedules.
	- Extensive expertise in a any/all below technical domain
		* CV,ML,DL (Un/semi/supervised /reinforcement)
		* Research/Develop CV/ML/DL algorithms using historical (training) data
		* Expertise in rapid DL/ML/CV/RL/NLP POC development using python, Tensorflow, Pytorch,Keras,Matlab,TensorRT,ONNX etc·
		* Expert knowledge of research methodologies in ML/DL domain·
		* Model compression
		* Model Pruning, sparsity , Model Decomposition , Mixed precision ,Qunatization ,sensitivity analysis , Tuning
		* Transfer learning
	- User experience background is a plus·
	- Experience with usability and evaluation is a plus·
	- Experience working within Agile framework is a plus.
	- Experience in conceiving and delivering fantastic end-to-end cross-channel experiences with appreciation of flow, context, micro-interactions, multi -modal possibilities, performance, and tone for multiple customers·
	- Analytical skills, conceptualize ideas, POC, understand and implement literature 
	- Implement given task in C++, MATLAB, Python and design/code DL model using TensorFlow
	- Strong experience in CV, ML, DNN, RNN, RL, Linear Algebra & AI
	- Strong experience in C++, MATALB, Python, TensorFlow, PyTorch,Keras,ONNX,Pytorch
	- Hands on Experience in rapid DL/ML/CV/RL/NLP POC development
	- Very good Knowledge on Model optimization, Pruning ,Tuning ,ONNX, Distiller , Quantization
	- Very good Knowledge on Object-Oriented Design & System Integration
	- Very good knowledge on Code Optimization, Implement & Adapt Complex Algorithms (E.g. from literature, from other teams, etc.)
	- Work Independently without supervision
	- Work under aggressive schedules towards world-class solutions
	- Ability to deliver exceptional results in challenging tasks
	- Experience in conceiving and delivering fantastic end-to-end cross-channel experiences with appreciation of flow, context, micro-interactions, multi -modal possibilities, performance and tone for multiple customers
	- Ability to consolidate, distill, and incorporate diverse ideas quickly
	- Experience with usability and evaluation is a plus
	- Experience working within Agile framework is a plus
	- CV, ML, CNN, DNN, RNN, Linear Algebra, Pattern Recognition, DSA, OOPS,Model compression
	- C++, MATALB, Python, TensorFlow Pytorch ,Cuda basic, ONNX,Keras
	- Hands-on experience on NLP - NLTK,Padna ,spacy
	- Hands-on experience of AWS (Amazon Web Services) & IoT (Internet of Things).
	- Hands-on experience with Databases.
	- Unity ,C#
+ skill set:
	- Do you want to be in the forefront of Deep Learning innovation? Training extremely large models at a fraction of time compared to other solutions? Helping companies and labs around the world solving a real impactful problem? Working with the latest Deep Learning Architecture (i.e. Transformer, GNN...etc)? If so, then we need you!!!
	- Cerebras is developing a radically new chip and system to dramatically accelerate deep learning applications. Our system runs training and inference workloads orders of magnitude faster than contemporary machines, fundamentally changing the way ML researchers work and pursue AI innovation.
	- We are innovating at every level of the stack – from chip, to microcode, to power delivery and cooling, to new algorithms and network architectures at the cutting edge of ML research. Our fully-integrated system delivers unprecedented performance because it is built from the ground up for deep learning workloads.
	- Cerebras is building a team of exceptional people to work together on big problems. They aren't afraid of taking risk and thinking outside of the box to solve fun and challenging problems.
	- As an ML Software Engineer on our team, you will work with leaders from industry and academia at the intersection of hardware and software, to develop state-of-the-art solutions for emerging problems in AI compute.
	- The Cerebras software platform is designed to be targeted by today's most relevant machine learning frameworks such as TensorFlow, PyTorch, JAX, and MXNet.  Our ML software engineers are responsible for the backend of these frameworks and the integration with our own highly optimized software stack.
	- Fundamentally, you will be enabling ML researchers to use the software tools and workflows of today to unlock the advanced hardware capabilities of tomorrow.
	- This role includes our ML framework backend and frontend stack, you will be involved in the frontend workflow for development, training and inference on our new hardware system. And the backend runtime that map the abstract computation expressed via third-party ML frameworks computation graph into our own representations that can then be compiled into highly optimized executables that target Cerebras's system.
	- The role includes cross team collaboration with the applied science and ML application team in one hand, and the compiler and hardware team on the other hand.
	- Understanding of state-of-the-art deep learning model architectures and training protocols.
	- Strong Python and C++ development skills.
	- Experience with at least one deep learning framework internals (i.e. TensorFlow, PyTorch, JAX, Caffe 2, MXNet, PaddlePaddle, CNTK, Caffe, Theano, Chainer...etc) is strongly preferred.
	- Experience with GPU programing such as CUDA, shading language...etc.
	- Experience with deep learning distributed training.
	- Familiar with compiler IR stack such as LLVM and MLIR.
+ skill set for Research Engineer
	- Responsibilities:
		* Perform and publish cutting-edge research in machine intelligence, with special focus on fundamental algorithms and applications for computer vision, language modelling, numerical formats and graph neural networks.
		* Exploit Graphcore's hardware to develop and deliver models of unprecedented scale and performance.
		* Collaborate with both the research team and other groups within the company, to develop new ideas, identify research opportunities and provide machine learning expertise.
		* Follow the latest developments in the field by attending/presenting at journal clubs and travelling to relevant conferences.
		* Promote the IPU by developing and maintaining collaborations with external institutions and research labs.
	- Essential:
		* MSc or PhD in Machine Learning, Computer Science, Electrical Engineering, Physics, Mathematics or a related field.
		* In-depth understanding of modern machine learning algorithms, deep learning architectures and probability theory.
		* Experience using modern machine learning frameworks (e.g., TensorFlow, PyTorch, JAX).
		* Proficiency in Python and/or C++.
		* Strong communication skills and willingness to work in a collaborative environment.
	- Desirable:
		* Publications at top conference venues (e.g., NeurIPS, ICLR, ICML).
		* Contributions to open-source software projects in the area of machine intelligence.
		* Experience in using or designing low-precision numerical formats.
		* Kaggle competitions or other evidence of practical expertise.
+ skill set:
	- Contribute to open-source with guidance from MIT PhDs who are prominent in ML research.
	- Develop large-scale web applications for data-centric AI. Our tools enable data scientists/engineers (across all industries) to effectively diagnose/fix issues in their datasets thus improving the quality of their business's core asset.
	- Get paid a Silicon Valley engineer salary but have the ability to work remotely with flexible hours.
	- Work on interesting challenges (massive datasets, scaling systems, security/privacy, novel interfaces for data editing, etc.) using modern tech stack at a dynamic startup operating in one of the fastest growing subfields of data science & AI.
	- As a Cleanlab software engineer, you will be responsible for building Cleanlab Pro, a user-friendly web app built on our ML algorithms. You'll work on scalable backend code for data ingestion, model training, and data analysis, and you'll help design beautiful and easy-to-use interfaces for data visualization, interpretation, and correction.
	- We encourage applications from full-stack software engineers who have some familiarity with machine learning and are interested in furthering their skills in building MLOps applications. Your contributions to our SaaS tool will be used by data scientists/engineers across all industries to improve the quality of their data and reliability of ML models produced from this data. Come help us build the next generation of data-centric AI!
	- Developing a SaaS data and machine learning pipeline.
	- Design, develop, test, deploy, maintain, and improve software, using a modern tech stack.
	- Write server and client-side code for web applications, optimizing for speed, scale, and ease-of-use.
	- Collaborate with other engineers to build large-scale systems and help establish a strong engineering culture across the company.
	- We select candidates based on strengths, not based on weaknesses. Candidates should have at leat 3+ years experience developing web apps using a modern tech stack and shipping code to production.
	- Experience with the following is recommended (but not necessarily required):
		* Python, Flask
		* Relational databases (e.g. PostgreSQL)
		* JavaScript + React, HTML, CSS (and SCSS)
		* AWS (or other similar cloud tools like Azure, GCP)
	- Bonus points if you have experience with some of the following:
		* Docker, Kubernetes, sklearn, pandas
		* Distributed computing (Ray, Spark, etc.)
		* Model serving, deployment, sharing (Sagemaker, Triton, gradio, etc.)
+ skill set:
	- At Cleanlab you'll get to
		* Spend 100% of your time writing open-source ML, with guidance from MIT PhDs who are prominent in ML research. Get paid a Silicon Valley engineer salary but have the ability to work remotely from wherever you want. And the cherry on top? You get to work with a modern tech stack (the latest tooling and ML models) at a dynamic startup to pioneer the rapidly growing field of data-centric AI.
	- What we're looking for
		* First and foremost, strong software engineering skills and experience productionizing your code. You should be comfortable with large software systems and love building applications.
		* Contributed to the open-source community for more than 4 years, either via your own open-source package or via substantial contributions to existing open-source repositories, written blog posts, and tutorials.
		* Experience working in ML: processing data, deploying models, etc. We do not require deep theoretical ML expertise, but practical experience in ML projects is desired.
	- Responsibilities
		* Develop and contribute novel data-centric AI algorithms to Cleanlab's open-source projects, via high quality implementations and maintaining the highest coding standards.
		* Be a good member of the open-source community (address Github issues and queries, review PRs, write crisp documentation/tutorials, help integrate with other packages).
		* Work on applied ML projects with Cleanlab enterprise customers.
		* Collaborate with other engineers to build large-scale systems and help establish a strong engineering culture across the company.
	- Qualifications
		* We select candidates based on strengths, not on weaknesses. Experience with the following is highly recommended, but not required:
			+ Python, NumPy
			+ pandas, scikit-learn
			+ ***PyTorch/PyTorch Lightning or TensorFlow + Keras***
		* Bonus:
			+ ***MLOps Experience with model deployment and monitoring (MLflow, Sagemaker, etc.)***
			+ Databases and ETL (Postgres, etc.)
			+ Cleanlab or other data-centric AI tools
			+ ***AutoGluon, H2O, or other AutoML tools***
			+ ***Tableau, DataBricks, Alteryx, Trifacta***
			+ ***Hugging Face, Snorkel, Weights and Biases, Gradio, Streamlit***
	- Working at Cleanlab is awesome! Beyond the opportunity to work at a well-funded (backed by Bain Capital Ventures) early stage AI tech company with an incredible, friendly founding team of MIT, Stanford, and Harvard graduates, all full-time employees receive the following:
		* $9,000 per year travel benefit
		* Travel enhances our empathy with different cultures and enables us to work together more effectively. It's how we grow and learn: traveling is an essential part of what makes us human. At Cleanlab, every two months you will receive a $1500 reimbursable travel benefit (resets on Jan 1, March 1, May 1, July 1, Sep 1, Nov 1). This is a unique benefit that lets you work from Paris for a week in February, then take a backpacking trip in the Andes for a weekend in March. Cleanlab will cover the flight for your partner or friend, too, as long as you attend and its within the $1500 / two-month period. For remote employees, you can use this benefit to come work with us in Boston/SF from time to time (encouraged, but not required).
		* Premium health insurance
			+ We provide a fantastic $4 (we cover the rest) health insurance option. We also provide a $0 deductible 100% coverage premium health care option for those who prefer the best health insurance.
		* Stipend for attending conferences to keep up with the latest innovations in ML and software.
		* Competitive salary (+ equity offering for certain roles), with regular opportunities for a raise if things are going well.
	- Cleanlab is focused on data-centric AI (DCAI), providing algorithms/interfaces to help companies (across all industries) improve the quality of their datasets and diagnose/fix various issues in them. We develop next-generation DCAI algorithms that are publicly contributed via open-source (github.com/cleanlab), as well as SaaS enterprise products with interfaces for data scientists/engineers to effectively improve their data quality and produce more reliable ML models.
	- Founded by 3 ML PhDs from MIT and engineers/scientists from Stanford & Harvard, Cleanlab is a well-funded early-stage startup that is rapidly growing to transform the future of DCAI. Some of Cleanlab's early work (while the company was still in stealth-mode) has been featured in various media such as: Wired, MIT Technology Review, and VentureBeat.
	- While many companies can help store/manage data or develop ML models, there exist few solutions today to improve the quality of existing data, which is the core asset of the modern enterprise. This is where you come in. At Cleanlab, you'll be able to take ownership of critical projects that pioneer the future of data-centric AI.
	- We are a remote-first company, with roughly half of our team located near Boston, MA (EST time) and the other half located near San Francisco, CA (PST time).
+ skill set:
	- As an ML Engineer on our team, you will work with leaders from industry and academia at the intersection of hardware and software to develop state-of-the-art solutions for emerging problems in AI compute.
	- The Cerebras software platform is designed to be targeted by today's most relevant machine learning frameworks such as TensorFlow, PyTorch, and JAX. Our ML software engineers are responsible for integrating these frameworks to work with our own highly optimized software stack. Fundamentally, you will be enabling ML researchers to use the software tools and workflows of today to unlock the advanced hardware capabilities of tomorrow.  
	- In this role, you will create tools and design workflows that enable the development, training, and deployment of machine learning models on our new hardware system. The workflow covers from a small to an extremely large models with trillion of parameters. Furthermore, you will be lowering abstract computations expressed via third-party ML frameworks into representations that can be compiled into highly optimized executables that target the Cerebras system, and help us design a general backend that can accommodate most advance deep learning models. You will also have the opportunity to participate and contribute to open-source projects that we depend on. 
	- Work on the end-to-end training, eval, and inference workflow with customer-facing API
	- Distributed training both via data and model parallelism
	- Scale and optimize the data pipeline
	- Lower Deep Learning framework graph presentation into our internal IR and add any missing OPs
	- Compiler optimization such as graph rewrite, constant folding, common expression elimination, and canonization
	- Lower high-level OPs to low-level OPs such as affine dialect
	- Handle both static and dynamic computational graph
	- Bachelor's, Master's, or foreign equivalent in Computer Science, Engineering, or related
	- 5+ years software development experience
	- Understanding of state-of-the-art deep learning model architectures and training protocols
	- Strong Python and C++ development skills
	- Direct experience with at least one Deep Learning framework internals is strongly preferred
	- Contributed to a deep learning framework
	- Experience with distributed training algorithm
	- Familiar with deep learning model architecture
	- Experience with MLIR, LLVM, or TVM
+ skill set:
	- The junior machine learning engineer's primary role is to support the research team in developing commercial applications for BrainChip's Akida Neuromorphic System-on-Chip (NSoC). Some of the target applications include work in computer vision (object classification/detection and face recognition), audio processing (keyword spotting), and sensor fusion. Additionally, this team member will support the research team's algorithm development for the next version of the Akida NSoC.
	- B.S. in Computer Science or equivalent
	- Course work in machine learning and computer vision
	- Strong programming skills in Python
	- 1 year experience developing ML applications in either TensorFlow/Keras and/or PyTorch
	- Excellent communication skills
	- The ability to read, understand, and implement algorithms from technical ML journals
	- 2+ years experience developing ML applications in TensorFlow/Keras and PyTorch
	- Multi-project experience in object classification, object detection, face recognition, and/or keyword spotting
	- Knowledge of deep learning quantization techniques
	- Experience with Docker and Git
	- Experience with Scrum/Agile software development (e.g. Jira)
+ skill set:
	- The machine learning engineer's primary role is to support the research team in developing commercial applications for BrainChip's Akida Neuromorphic System-on-Chip (NSoC). Some of the target applications include work in computer vision (object classification/detection and face recognition), audio processing (keyword spotting), and sensor fusion. Additionally, this team member will support the research team's algorithm development for the next version of the Akida NSoC.
	- B.S. in Computer Science or equivalent
	- Course work in machine learning and computer vision
	- Strong programming skills in Python
	- 3 years' experience developing ML applications in either TensorFlow/Keras and/or PyTorch
	- Excellent communication skills
	- The ability to read, understand, and implement algorithms from technical ML journals
	- Master's in computer science of equivalent
	- 4+ years experience developing ML applications in TensorFlow/Keras and PyTorch
	- Multi-project experience in object classification, object detection, face recognition, and/or keyword spotting
	- Knowledge of deep learning quantization techniques
	- Experience with Docker and Git
	- Experience with Scrum/Agile software development (e.g. Jira)
+ skill set:
	- Work on exciting Proof of Concept projects with using GrAI VIP
	- Train Deep Learning models that work on Real-World Scenarios.
	- Develop and optimize AI training pipelines.
	- Use different sensors to acquire data.
	- Create applications using AI and robotics.
	- You will work closely with the Customer's Solutions Architect Team to deliver contents that drive results.
	- You are in your last year of your engineering School.
	- Pursuing a master's degree program in Computer Science, or related technical field.
	- Programming experience in Python. Experience in C/C++ is a plus.
	- Good Understanding of Deep Learning fundamentals.
	- Experience using one or more of the Machine Learning Libraries (TensorFlow, Keras, PyTorch).
	- Experience working in Linux environments.
	- Team Player.
	- Problem-solver keen to find innovative solutions in any situation.
	- Super enthusiastic, and you like to be challenged!
	- Fluent in English and willingness to work in an international context.
+ skill set:
	- GrAI Matter Labs is a young and vibrant high-tech company, which aims to revolutionize artificial intelligence for everyone. Our unique machine learning technology will drive the next generation of computer chips to power many future products. This way, we contribute to making robots, cameras, and transportation smart, safe, and power-efficient. GML is an international company, with highly motivated teams in offices in France (Paris), Netherlands (Eindhoven), and USA (San Jose).
	- At GML, we develop new technologies for efficient low-latency and low-power processing of neural networks, for training neural networks, and for neuromorphic computing. And we are looking for talented MSc candidates to help us in this research.
	- If you are an MSc candidate with a background in electrical engineering, computer science, or computer architecture, and you are looking for a cutting-edge environment to perform your MSc thesis project, then you should certainly consider applying at GML!
	- You will be embedded in a team of highly trained and highly motivated architects, scientists, and engineers. In your assignment, you will work with experts in the fields of processor architecture, computer architecture, compiler construction, neural network and neuromorphic processing. These are some of the topics we are currently working on:
		* Retraining neural networks for imposed temporal sparsity;
		* Improving input signal sparsity;
		* Mixed-precision training;
		* LIDAR-based neural network applications;
		* Bayesian machine learning on neuromorphic architectures;
		* Neural-networks mapper algorithms for massive-multicore Systems;
		* Auto-tuners for efficient neural-network mapping for massive multicore systems;
		* NoC architectures for neuromorphic massive multicore systems;
		* Low-power techniques for neuromorphic massive multicore systems.
		* AI solutions for [ANDANTE project](https://www.andante-ai.eu/) use cases, together with partners such as ST Microelectronics, Philips, Boeing, Thales, Valeo, CEA, and Fraunhofer.
		* AI solutions for medical sensor systems in the [pAvIs project](https://penta-eureka.eu/project-overview/penta-call-5/pavis/), together with partners such as Philips, Cochlear, and InBrain.
	- Responsibilities:
		* Determining the scientific contributions of your project, and advancing the state-of-the-art in neural network processing;
		* Providing GML with new technologies for neural network processing and neuromorphic design;
		* Defining your project goals, deliverables, and plans, to fit the timeframe of your assignment;
		* Running and managing your project, together with your GML advisors, university supervisors, colleagues, and co-students;
		* Delivering a final report for your MSc graduation.
	- Requirements:
		* Master student with a background in Electrical of
		* Strong mathematics, computer science, and/or computer architecture background
		* Strong machine-learning background, and hands-on experience with neural network frameworks, such as Tensorflow
		* Strong programming skills (e.g. Python, C, C++)
		* "Can-do" mentality, excellent problem-solving skills
	- GrAI Matter Labs is a dynamic organization which employs some of the brightest minds in the industry and is known for the great care we take with clients and employees alike. We believe we will win as a close-knit team that converts a strong vision into products that solve use cases which our customers truly value. We also hold to the highest standards of inclusion, team spirit, and cooperation. This position is based at GrAI Matter Labs offices at the High Tech Campus in Eindhoven, The Netherlands. The High Tech Campus houses 160 companies, employing a total of 11,000 entrepreneurs and R&D employees. To our interns, we offer a nice compensation, in line with what is customary around the Eindhoven area.
+ skill set:
	- Master's degree in software development, computer science, algorithm design, artificial intelligence, or machine learning or equivalent experience
	- 5 years of experience as a machine learning engineer and using libraries, such as Scikit-learn, TensorFlow, Caffe, Keras, etc.
	- Experience with Microsoft Azure platform – Azure ML Services, Databricks, AKS, etc.
	- Experience with the Hadoop ecosystem (e.g., Apache Hive, Pig, HBase and Kafka)
	- Experience with distributed computing platforms, such as Spark, and user interface frameworks, such as Angular or React
	- Ph.D. in software development, computer science, algorithm design, artificial intelligence, or machine learning or equivalent experience
	- Strong object-oriented programming skills, including proficiency in Java, Scala, C/C++ or Python
	- Strong SQL skills
	- Proficiency in the Microsoft Office suite
	- The Machine Learning Engineer designs and develops the platform and frameworks that facilitate automated data-driven decision-making, gathers data, and determines statistical algorithms and models that a system can use to learn from experience, predict outcomes and make decisions.
	- Collaborate with data scientists to develop algorithms and tools for training and running simulations
	- Build services to interact with machine learning models through simulations
	- Participate in code reviews to ensure code quality and share best practices
	- Develop services that host the trained models and work with other application teams to integrate them into business processes
	- Gather and analyze large datasets and develop data model pipelines
	- Develop algorithms that drive automated data-driven decision-making
	- Build the tools for monitoring the performance of machine learning applications
+ skill set:
	- We are looking for Machine Learning Engineering Interns to help drive a data-led culture across Spotify. You will apply machine learning methods to extensive data sets to extend improve Spotify's means of understanding and engaging users across various contexts and modalities. You will build upon Spotify's deep understanding of our content, users, and artists to develop rich analytics, engagement, and business applications. Above all, your work will impact the way the world experiences audio.
	- Contribute to designing, building, evaluating, shipping, and refining Spotify's product by hands-on ML development
	- Collaborate with a cross functional agile team spanning user research, design, data science, product management, and engineering to build new product features that advance our mission to connect artists and fans in personalized and relevant ways
	- Assist in prototyping new approaches and product-ionize solutions at scale for our hundreds of millions of active users
	- Help drive optimization, testing, and tooling to improve quality
	- Be part of an active group of machine learning practitioners across Spotify) collaborating with one another
	- You are pursuing a Bachelor's or Master's degree in Machine Learning, Computer Science, Computer Engineering or a related field of study
	- You have dabbled in ML engineering practices via prior internships, coursework, and/or projects
	- You have experience in working with Scala and/or PythonYou have an understanding of system design, data structures, and algorithms
	- You care about quality and you know what it means to ship high-quality code
	- You are currently in your final or penultimate year of your studies
+ skill set:
	- We are looking for Machine Learning Interns to \#JoinTheBand and help drive a data-first culture across Spotify.  You will work on a variety of problems such as content recommendation, personalization, optimization, user intelligence, and content classification. You will work with a team to come up with new and interesting hypotheses, test them, and scale them up to huge data sets with hundreds of billions of data points. Above all, your work will impact the way the world experiences music.
	- Apply machine learning, collaborative filtering, NLP, and deep learning methods to massive data sets
	- Prototype new algorithms, evaluate with small scale experiments, and later productionize solutions at scale to our 140 million active users
	- Collaborate with a cross functional agile team of software engineers, data engineers, ML experts, and others to build new product features
	- Help drive optimization, testing and tooling to improve data quality
	- Iterate on recommendation quality through continuous A/B testing
	- You are pursuing a Ph.D. or Master's degree in Machine Learning, Statistics or related field preferred
	- You have a graduation date of 2022 or 2023
	- You currently have valid work authorization to work in the country in which this role is based that will extend from June to August 2022
	- You have experience implementing machine learning systems at scale in Java, Scala, Python or similar (not just R or Matlab)
	- You have a strong mathematical background in statistics and machine learning
	- You care about agile software processes, data-driven development, reliability, and responsible experimentation
	- You preferably have experience with data processing and storage frameworks like Hadoop, Scalding, Spark, Storm, Cassandra, Kafka, etc.
	- You preferably have machine learning publications or work on open source to share with us
	- We are a distributed workforce enabling our band members to find a work mode that is best for them!
	- Where in the world? For this role, it can be within the Americas region in which we have a work location.
	- Prefer an office to work from home instead? Not a problem! We have plenty of options for your working preferences. Find more information about our Work From Anywhere options here.
	- Working hours? We operate within the Eastern Standard time zone for collaboration.
+ skill set:
	- Kiwibot is looking for a Senior Machine Learning Engineer role and it could be a great opportunity to join us. You should have the right technical knowledge and understanding of common and novel computer vision, and machine learning techniques to support and develop new algorithms, and create solutions. You should also have proven experience designing, developing and deploying machine learning solutions on real world applications.
	- As a Machine Learning Engineer : You will report directly to our Head of AI & Robotics.
	- Implement, train and iterate vision based deep learning models.
	- Train models on Cloud on single and multiple GPUs. 
	- Design and implement data pipelines for storing and processing thousands of images and videos.
	- Design and integrate with third party labeling company API for upload and ingestion of data and labels. 
	- Design and implementation of data harvesting from current fleet operations. 
	- Create data visualization tools for data analysis and debugging. 
	- Evaluate the quality of labeling of data.
	- Design and iterate labeling instructions that produce high quality labels.
	- Implement, design and manage databases of images, videos and metadata associated with them.
	- Optimize models for performance on constrained environments.
	- Deploy trained models on-premise integrated with the rest of the robot's software stack.
	- Report of training procedures, error analysis, data review.
	- Offline database analysis for getting insights, generating labels automatically, doing anonymization, etc. 
	- You have knowledge of Python and scripting (advanced) 
	- Git (intermediate/advanced) 
	- Docker, docker-compose (advanced) 
	- Scrum and agile methodologies 
	- Vast experience with deep learning frameworks like pytorch/tensorflow 
	- Experience with one or more cloud providers (advanced), GCP is a plus 
	- Deep understanding of DL techniques like CNN, LSTM, RNN, Transformers
	- Hands on with semantic segmentation algorithms, object detection or depth estimation.
	- Experience using and implementing RESTFULs services 
	- Terraform/pulumi knowledge for deploying solutions 
	- Experience with some MLOps, MLFlow is a plus 
	- SQL and no SQL databases (advanced). BigQuery is a plus 
	- ROS or ROS2 (basic) is a plus 
	- C++ (intermediate) is a plus 
	- Experience with sensor technologies is a plus (Lidars 2D, 3D, Stereo Cameras, Cameras, IMU, GPS) 
	- Strong English level, both written and spoken.
+ skill set:
	- We are looking for a Machine Learning Engineer with expertise in NLP who can join our AI research and development efforts with a direct impact on our core platform. You will work with both engineering and business teams to best understand design requirements. Then, your role is to design and build practical high performance machine learning solutions.
	- In this role, you will work on some of the latest cutting edge applications of machine learning applied to critical problems that affect businesses, governments and society. You will directly work with top management and key stakeholders to define solutions to critical problems that will have immediate impact and value at the platform and client levels. If you are passionate to work on massive, unstructured problems that can be solved using data, we are looking for you.
	- Contribute to research and development focusing on the following areas: information extraction, multilingual NLP, automated summarization and graph network analysis.
	- Manage the collection and annotation of large custom datasets for text classification, unsupervised pre-training, translation, tagging, and other related problems.
	- Capable of understanding and implementing state-of-the-art methods based on research papers and/or open source libraries, and push beyond the state-of-the-art.
	- Experience with implementing efficient and scalable software systems in Python.
	- Ability to integrate implemented software components into a fully functional software pipeline, and provide verification and validation against requirements.
	- Knowledge of machine learning evaluation techniques, failure modes, and limitations.
	- Requirements
		* Minimum 2 years of professional experience working in Natural Language Processing or closely related field, with demonstration of successful delivery of novel research and/or product offerings.
		* Masters degree or PhD from an accredited college/university in Computer Science, Computational Linguistics, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields (strong mathematical/static background with ability to understand algorithms and methods from a mathematical and intuitive viewpoint). Some exceptions can be made depending on exceptional past accomplishments/references.
		* Experience with command-line scripting, data structures and algorithms, and the ability to work in a Linux environment, processing large amounts of data in a cloud environment.
		* Highly skilled in Python development, as well as: Tensorflow, Pytorch, Keras and Scikit-Learn.
		* Able to communicate scientific concepts to both technical and non-technical audiences.
	- Nice to Have:
		* Working knowledge of AWS and other cloud services.
		* Experience creating novel datasets for scientific analysis or benchmarking.
		* Capability to contribute at the system architecture level to enhance scalability, testability, robustness.
		* Experience with generative models of fake text or images.
		* Experience and top performances in online competitions / hackathons, such as, kaggle.
		* Published research in areas related to machine learning, NLP, or its applications.
		* Record of contributions to open-source machine learning projects, or related endeavors.
		* Experience writing detailed documentation of machine learning systems.
+ skill set:
	- Anyscale is looking to hire strong individuals to develop open source machine learning libraries.
	- The software industry largely operates on a messy zoo of specialized distributed systems such as Spark, Horovod, and TensorFlow Serving. These systems cannot easily be composed together and used as elements of a larger application. On the Machine Learning Ecosystem team at Anyscale, we are developing a rich ecosystem that will allow developers to import powerful distributed libraries and compose them together to build new applications.
	- Part of this work will be open source as part of Ray, which is a distributed Python execution engine as well as an ecosystem of libraries for scalable machine learning.
	- The ML Ecosystem team's mission is to make it really easy to do distributed machine learning on Ray and Anyscale. Specifically, our team maintains and develops features for a broad number of libraries — including RaySGD (distributed deep learning), Ray Tune (distributed hyperparameter tuning), RLlib (reinforcement learning), and XGBoost-on-Ray.
	- Our team is the most user-facing engineering team on the open source side, collaborating with ML engineering teams at organizations like Shopify, Uber, and Bytedance.
	- Build elastic, scalable, fault-tolerant distributed machine learning libraries that power the next generation of machine learning platforms around the world
	- Benchmark and improve performance and scalability of different machine learning libraries
	- Work closely with other engineers developing Ray to build core abstractions and simplify machine learning services for open source users
	- Work closely with the open source community (with ML researchers, ML engineers, data scientists) to scope and build new abstractions for scalable machine learning
	- Solid background in algorithms, data structures, system design
	- Experience with machine learning frameworks and libraries (PyTorch, Tensorflow)
	- At least 1 year of relevant work experience (new grads should apply to a separate job posting)
	- Experience working with a cloud technology stack (AWS, GCP, Kubernetes)
	- Experience building machine learning training pipelines or inference services in a production setting
	- Experience with big data tools (Spark, Flink, Hadoop)
	- Experience in building scalable and fault-tolerant distributed systems
+ skill set:
	- RLlib is an open-source library for reinforcement learning that offers both high scalability and a unified API for a variety of applications. We're looking for software engineers with existing machine learning experience that are interested in continuing to improve RLlib.
	- We are looking for senior hires as well as less experienced but motivated individuals.
	- About the ML Ecosystem team:
		* The ML Ecosystem team's mission is to make it really easy to do distributed machine learning on Ray and Anyscale.Specifically, our team maintains and develops features for a broad number of libraries — including RaySGD (distributed deep learning), Ray Tune (distributed hyperparameter tuning), RLlib (reinforcement learning), and XGBoost-on-Ray.Our team is the most user-facing engineering team on the open source side, collaborating with ML engineering teams at organizations like Shopify, Uber, and Bytedance.
	- As part of this role, you will:
		* Develop high quality open source software to simplify reinforcement learning (RLlib)
		* Identify, implement, and evaluate promising new RL algorithms from the literature
		* Improve the testing process for RLlib to make releases as smooth as possible
		* Communicate your work to a broader audience through talks, tutorials, and blog posts
	- We'd love to hear from you if you:
		* Have relevant experience using RLlib or developing RL algorithms
		* Have strong proficiency in Python and Tensorflow or Pytorch
		* Are excited about working with customers who are applying RL to their own use cases
		* Are excited about working on open source and broadcasting new features to the community
	- About Anyscale:
		* Anyscale provides an application development platform for developers to build distributed applications. We're commercializing a popular open source project called Ray, which is a framework for distributed computing as well as an ecosystem of libraries for scalable machine learning. Our goal is to build a standardized platform for distributed computing. Ray was developed at UC Berkeley by Robert Nishihara and Philipp Moritz, under the guidance of Ion Stoica and Michael Jordan, and the four of them have co-founded Anyscale. The company raised a $20.6M Series A and a $40M Series B funding from Andreessen Horowitz (a16z), NEA, Foundation Capital, Intel Capital, Ant Financial, Amplify Partners, 11.2 Capital, and The House Fund.
		* With Ray, we're making it easy to program at any scale (from your laptop to the datacenter) by providing easy-to-use, general-purpose, and high-performance tools. In addition, we are building a rich ecosystem of libraries (for reinforcement learning, hyperparameter search, experiment management, machine learning training, prediction serving, and more) on top of the core distributed system so that users can rapidly build sophisticated applications. Help us build the future of software development.
+ skill set:
	- Software Runtime Principal Engineer (CA, TX or ON)
	- Provide technical guidance and direction to junior staff member
	- Work closely across teams to discover the hardware and software requirements of current and future machine learning applications
	- Develop performance analysis and debug tools
	- Develop firmware for Tenstorrent hardware
	- Develop highly optimized kernels in C++ and assembly to implement complex ML operations
	- Analyze, optimize, and fine-tune performance of key machine learning applications on various configurations of Tenstorrent hardware
	- Extensive working experience with one or more: firmware, low-level programming, optimizing kernels, hardware debug
	- Close familiarity with computer architecture, comfortable working with hardware
	- 7+ years of experience working with algorithms, data structures, and software development
	- C/C++, Python
	- Bachelors in Computer Science or Electrical/Computer Engineering or Engineering Science
	- Excellent verbal and written communication skills
	- Ability to work across multiple teams
	- 2+ years of experience as a technical lead, developing and mentoring a team
	- Masters/PhD in Computer Science or Electrical/Computer Engineering or Engineering Science
+ skill set:
	- Hardware and system knowledge including bare metal compute, colocation centers, and cloud
	- ML frameworks and workloads
+ Experience in Deep Learning and Deep Learning development frameworks
+ Proficiency in programming languages such as Python, Java and C++, and experience with machine learning libraries (e.g., TensorFlow, PyTorch, scikit-learn)
+ You will be expected to have a good understanding of a broad range of traditional supervised and unsupervised techniques (e.g. logistic regression, SVMs, GBDTs, Random Forests, k-means and other clustering techniques, matrix factorization, LDA . . .) as well as be up to date with latest ML advances (e.g. Deep Neural Networks, or non-parametric Bayesian methods).
+ skill set:
	- Tenstorrent is looking for an experienced Machine Learning engineer to support our growing customer base as they build Deep Learning models on Tenstorrent hardware. If you're enthusiastic about Machine Learning, are a competent software engineer, and enjoy working with other people, this is your opportunity to be at the bleeding edge of AI processing. You'll get exposure to a broad array of problem types from different industries and be at the forefront of our customer engagements.
	- Work with the customer-facing team to support clients with their ML models on Tenstorrent hardware
	- Designing and developing demonstration machine learning and deep learning systems
	- ***Model benchmarking***
	- Running machine learning tests and experiments on behalf of customers
	- Implementing appropriate ML algorithms
	- Select appropriate datasets and data representation methods
	- ***Run machine learning tests and experiments***
	- ***Perform statistical analysis and fine-tuning using test results***
	- ***Train and retrain systems when necessary***
	- ***Extend existing ML libraries and frameworks***
	- ***Develop novel ML models and primitives that take advantage of Tenstorrent's breakthrough architecture to deliver orders of magnitude performance & efficiency improvements***
	- Student in Electrical/Computer Engineering, Computer Science, Machine Intelligence, Engineering Science, or Math;
	- 5 years of experience as a Machine Learning Engineer or similar role (a fleshed out GitHub repo a plus)
	- Experience with algorithms, data structures, and software development in Python and C/C++.
	- Deep knowledge of math, probability, statistics and algorithms
	- Experience in solving business problems with Machine Learning models
	- Familiarity with and passion for any of the following -- machine learning, compilers, parallel programming, high-performance and massively parallel systems, processor and computer architecture -- is a plus
	- Travel at 15% to 25% will be required.
+ tech stack:
	- Experience with Deep Learning frameworks, e.g., PyTorch, DeepLearning4J, TensorFlow
	- Experience in SPARK (using Python or Scala). Knowledge of AWS services will be appreciated.
+ skill set:
	- 3+ years of experience in machine learning, data mining, natural language processing, information retrieval, or statistical analysis
	- Experience working with large data sets using open source technologies such as Spark, Hadoop, and NoSQL
	- Experience developing and productizing real-world AI/ML applications such as prediction, personalization, recommendation, content understanding and NLP
	- Experience working with at least 3 of the following popular machine learning frameworks/libraries: sklearn, tensorflow, pytorch, caffe, keras, theano, cntk, mxnet, spark mllib
	- Experience developing and deploying deep learning NLP models is a plus
	- Experience working with a knowledge graph is a plus
+ skill set:
	- Senior Sotware Engineer - Machine Learning
	- Responsible for implementing various algorithms to do automated feature extraction and dataset augmentation, optimizing runtimes of neural network algorithms and building higher-level abstractions for various common AI/ML techniques. As an ML engineer, they will also work cross functionally amongst other engineers, on common ML operation tasks such as ML data management and training and model deployment, as well as build systems that are scalable.
	- Candidates will need to have a BS in computer science from an accredited university OR have 5 years of professional work experience. In addition, we are looking for software engineers who have the following:
	- 5 years of professional software engineering experience. Some experience with Python is required.
	- Have at least 1 year of professional work experience in one of the following: data infrastructure, ML/AI models in production, neural network algorithms, performance optimization of deep learning systems.
+ skill set:
	- Sotware Engineer 1 - Machine Learning
	- Responsible for implementing various algorithms to do automated feature extraction and dataset augmentation, optimizing runtimes of neural network algorithms and building higher-level abstractions for various common AI/ML techniques. As an ML engineer, they will also work cross functionally amongst other engineers, on common ML operation tasks such as ML data management and training and model deployment, as well as build systems that are scalable.
	- Candidates will need to have a BS in computer science from an accredited university. In addition, we're looking for engineers who have the following:
	- Working knowledge of software engineering - through job experience or coursework. Experience with Python preferred
	- Have at least 6 months of professional work experience in one of the following: ML/AI models in production, neural network algorithms, performance optimization of deep learning systems.
	- Coursework or work experience with machine learning algorithms such as classifiers, anomaly detection, and clustering
+ skill set:
	- 7+ years of industry/academic experience in Machine Learning or related field
	- You will be expected to have a good understanding of a broad range of traditional supervised and unsupervised techniques (e.g. logistic regression, SVMs, GBDTs, Random Forests, k-means and other clustering techniques, matrix factorization, LDA . . .) as well as be up to date with latest ML advances (e.g. Deep Neural Networks, or non-parametric Bayesian methods).
	- Previous experience building end to end scalable Machine Learning systems
	- Software engineering skills. Knowledge of Python and C++ is a plus.
	- Knowledge of existing open source frameworks such as scikit-learn, Torch, Caffe, or Theano is a plus
+ skill set:
	- Individuals in this role should be experts in machine learning and NLP and have experience working on problems such as language models, discourse analysis, question-answering, word-sense disambiguation, automatic summarization etc.
	- Improve our existing NLP and Machine Learning systems using your expertise
	- Identify new opportunities to apply NLP and Machine Learning to different parts of the Quora product
	- Work with other engineers to implement algorithms, abstractions and systems in an efficient way, with strong positive impact on our user-facing products
	- Take end to end ownership of Machine Learning systems - from data pipelines and training to realtime prediction engines
	- Good mathematical understanding of popular NLP and Machine Learning algorithms
	- Experience building production-ready NLP or information retrieval systems
	- Hands-on experience with NLP tools, libraries and corpora (e.g. NLTK, Stanford CoreNLP, Wikipedia corpus, etc)
	- Knowledge of Python or C++, or the ability to learn them quickly
+ skill set:
	- At Quora, we use Machine Learning in almost every part of the product - feed ranking, answer ranking, search, topic and user recommendations, spam detection etc.
	- Take end to end ownership of Machine Learning systems - from data pipelines and training, to realtime prediction engines.
	- Previous experience building internet applications and large systems
	- General understanding of Machine Learning at the level of a semester-long ML class (college or multiple MOOCs)
	- Passion for learning
+ skill set:
	- We use a variety of algorithms — everything from linear models to decision trees and deep neural networks.
	- To that end, we are looking for engineers to help us build our company-wide ML development platform. In this role, you will be the part of a small team solving very interesting technical problems at the intersection of various exciting domains like Machine Learning, Distributed Systems and High Performance Computing.
	- Build and maintain large scale distributed systems to support the whole pipeline from data collection and training to deployment
	- Write efficient implementations of ML algorithms over CPUs & GPUs
	- Integrate our in-house systems with open source libraries like Spark and Tensorflow
	- Build abstractions to automate various steps in different ML workflows
	- Build tools to debug, visualize and inspect various features and models
	- Work with the engineers who use the platform, and help them be more impactful by improving the platform
	- Experience with designing large-scale distributed systems
	- Experience with building end-to-end machine learning systems
	- Take end to end ownership of Machine Learning systems - from data pipelines and training, to realtime prediction engines.
	- Previous experience building end to end Machine Learning systems
+ ***Capsule Networks***, or capsule neural networks
+ skill set:
	- Experience working with relational SQL and NoSQL databases
	- Experience working with big data platforms (Hadoop, Spark, Hive)
	- Fluency with one or more programing language: Python, Java, Scala, etc
	- Good understanding of CS fundamentals, e.g. algorithms and data structures
	- Experience with data science tools and libraries, e.g. R, pandas, Jupyter, scikit-learn, TensorFlow, etc
	- Familiarity with statistical concepts and analyses, e.g. hypothesis testing, regression, etc
	- Familiarity with machine learning techniques, e.g. classification, clustering, regularization, optimization, dimension reduction, etc
	- Guide the utilization or development of a robust CI/CD capability.
	- Identify key performance & effectiveness metrics, monitor & adjust to goals
	- Work with test automation team to lay the groundwork for automated API testing framework and test cases
	- Prioritize backlog & drive product releases
	- Distill strategic intent into structured product release roadmaps that are compelling and achievable
	- Ability to execute and manage performance and expectations within a cross-functional, matrix management environment
+ A background in machine learning and related sub-areas including ranking, personalization, search, recommendation, explore/exploit, causal learning, reinforcement learning, deep learning and probabilistic modeling.
+ skill set:
	- As a Deep Learning Engineer at Simbe Robotics, you will be part of a talented team designing and training state of the art deep learning algorithms to identify placement, presentation, pricing, and availability of products in retail stores across the globe.  
	- In this role you will lead various initiatives designing, developing, and training in-house character recognition and image caption algorithms powered by deep learning.
	- Participate in planning and prioritizing, write functional specifications and lead design reviews for our character recognition and image caption algorithms.
	- Generate, clean, and curate real world training datasets
	- Create photorealistic synthetic training data for augmentation
	- Develop, test, tune, and deploy character recognition and image caption systems across a wide variety of customers
	- Evaluate existing character recognition and image caption methods for speed and accuracy performance improvements
	- Collaborate with other developers, quality engineers, product managers, and documentation writers
	- Ph.D. or M.S. preferred
	- Strong machine learning background, with 2+ years of hands-on experience in building real systems
	- Deep understanding of state of the art machine learning and deep learning algorithms, techniques and best practices
	- Solid understanding of linear, non-linear, and dynamic programming
	- Experience using or building synthetic image generation systems, data augmentation pipelines, and OCR/image caption systems
	- Proficient in at least one of the following: Tensorflow, Keras, PyTorch. Tensorboard knowledge is a plus
	- Must be fluent in Python, other languages are a plus
	- Should be familiar with training and running deep learning models on GPUs (both commodity and otherwise)
	- A good understanding of recurrent neural networks (including LSTMs and GRUs)
	- Experience in debugging and diagnosing performance problems with ML algorithms
	- Must have excellent written and verbal communication skills
	- Experience with attention models, text localization, Google Cloud Platform, AWS, and serverless is a plus
	- Strong Linux & Command Line background
	- Ability to work hands-on in cross-functional teams with a strong sense of self-direction
+ skill set:
	- You have industry experience with writing code (e.g., Python, Scala, PySpark, Java) and taking ML models/ algorithms to production. Preference for 5+ years of industry experience (without PhD); at least 2-3+ years of industry experience with PhD. This is not an entry level / new college graduate role.
	- Experience with Apache Spark platform (including Datasets, SparkML) and/or experience with one or more deep learning libraries and platforms (e.g., TensorFlow, Caffe or PyTorch).
+ skill set:
	- As a research engineer at Salesforce Research, your role will be at the intersection of software engineering and research, and may range from implementing novel research models to rapid-prototyping demos that show off applications of deep learning on production data. You will work closely with research scientists to develop models, prototypes, and experiments that push the state of the art in AI research, paving the way for innovative products for the Einstein AI Platform. You will have the opportunity to take on real-world problems from Salesforce's enterprise customers with the latest deep learning models.
	- You have strong programming skills and a background in one or more of the following domains: deep learning, machine learning, natural language processing, or computer vision, with applications such as: text categorization, text summarization, sentiment analysis, information extraction, question answering, dialogue learning, language and vision, image classification, image segmentation, and object detection.
	- Knowledge of linear algebra, calculus, statistics, and machine learning.
	- Practical experience in natural language processing, computer vision, crowdsourcing, or information retrieval.
	- Exposure to industry or academic research, particularly in deep learning, neural networks, or related fields.
	- Experience with one or more deep learning libraries and platforms (e.g., TensorFlow, Caffe, Chainer or PyTorch).
	- Experience with Amazon Web Services and Mechanical Turk.
	- Strong computer systems experience in topics such as filesystems, server architectures, and distributed systems.
	- Experience in GPU programming, data visualization, or web development.
+ skill set:
	- Machine learning. You should be able to understand and apply major machine learning methods, such as logistic regression, SVM, Decision Trees, Principal Component Analysis and K-means. Completion of Andrew Ng's Machine Learning course on Coursera is sufficient to meet this criterion.
	- Deep learning. You should be able to understand and apply major deep learning methods, including neural network training, regularization, optimization methods (gradient descent, Adam), and be familiar with major neural network architecture types such as Convolutional Networks, RNN/LSTM. Completion of the deeplearning.ai specialization is sufficient to meet this criterion.
	- Implementation. You should have prior experience taking a dataset, cleaning it if necessary, and applying a learning algorithm to it to get a result. You should be able to implement a learning algorithm “from scratch” using a framework such as NumPy, Tensorflow, Pytorch, Caffe, etc.
	- General coding. You should be able to code non-trivial functions in object-oriented programming, such as popular sorting or search algorithms.
	- Mathematics (including probabilities and statistics.) You should be able to use mathematical notations and linear algebra (matrix/vector operations, dot products, etc.), and understand basic probability theory (distributions, independence, density functions, etc.) as well as statistics (mean, variance, median, quantiles, covariance, etc.)
	- Software Engineering. You should know how to use your terminal, work with version control systems (Git), relational databases, APIs, and build the back-end of web or mobile applications.
	- Mean Stack
		* MEAN is a free and open-source JavaScript software stack for building dynamic web sites and web applications.
		* The MEAN stack is MongoDB, Express.js, AngularJS (or Angular), and Node.js.
+ skill set:
	- The steps of an end-to-end machine learning project. This includes, but is not limited to:
		* Conducting a structured and deep literature review of a specific field.
		* Strategizing your machine learning project end-to-end.
		* Collecting, cleaning, labeling, and augmenting your own dataset.
		* Training a model for a real-world application.
		* Setting-up an efficient and organized experimentation process.
		* Defining task-specific metrics to optimize in your experiments.
		* Performing error analysis to improve your models.
		* Deploying an AI product.
		* Exposure to real-world problems that multiple AI teams in our community work on.
	- Hands-on experience in designing, building, and deploying end-to-end AI solutions through curated content and instructor-led workshops.
	- Career mentorship and connections with teams aligned with your career aspirations.
	- Meet and share experiences with other machine learning engineers and data scientists.
	- Everyone who successfully completes the Bootcamp will be awarded a certificate of completion and join the AI Bootcamp Alumni community.
	- Machine learning Engineers and Data Scientists who have already worked on Machine Learning projects and want to get exposed to different Machine Learning problems.
	- Demonstrated AI, data science and/or data analysis experience from previous work experience or publications.
	- Demonstrated strong coding from previous work experience or publications. This means you're able to write a non-trivial program in Python, Java, or C++.
	- Solid CS foundation (including but not limited to Operating Systems, Computer Networks, Database, etc.)
+ Experience working with modern deep learning software architecture and frameworks including: Tensorflow, MxNet, Caffe, Caffe2, Torch, and/or PyTorch.
+ experience creating machine learning products
	- deploy model
	- MLOps
+ skill set for machine learning architect:
	- optimize workflows and solve problems using a data-driven approach
	- provide machine learning as a service (MLaaS) for users
	- co-develop machine learning as a service (MLaaS) platform, with the following features:
		* data ingestion
		* data indexing
		* data labeling
		* visualization
		* dashboards
		* data viewers
	- collaborate with team on production quality service development with:
		* unit testing, integration testing for MLaaS
		* CI/CD for MLaaS
		* DevOps for MLaaS
	- develop and maintain services with:
		* high production quality standards
		* components for feature data storage
		* ML model training and inferencing
		* ML model storage and management
		* model evaluation metrics
	- demonstrate experience in MLOps and deep learning related infrastructure
	- solid foundation for machine learning, deep learning architecture and service development experience
	- provide capacity to use and fine-tune latest state-of-the-art machine learning and deep learning models, depending on the use cases
		* develop lifecycle management tool for these machine learning and deep learning models to be deployed as a service and made available for inferencing
	- detailing processes and workflows
	- Programming skills in:
		* Java
		* Python
		* Web service development, using REST API
			+ front-end Web development
				- React
				- Ember.js
	- object-oriented design patterns
	- ability to learn quickly and adapt to different platforms as per the need of the project
	- crafted/developed production quality microservices
	- knowledge of:
		* Hadoop
		* Hive
		* Spark
		* Kafka
		* cloud/distributed infrastructure
		* SQL and NoSQL data platforms
+ skill set:
	- deep knowledge of distributed training concepts and frameworks, such as Megatron and Deepspeed
		* Megatron-Turing Natural Language Generation model, MT-NLG,
	- design and develop analysis tools to drive efficient research, such as:
		* deep cleaning
		* analysis of training dynamics
		* grdient quality
	- design and develop software for scaling models and large-scale experimentation
	- design and develop ML workflows and user interfaces for novel algorithms
	- deep knowledge of machine learning framework, such as TensorFlow and PyTorch
+ skill set:
	- wafer scale engine, WSE
	- NLP models:
		* BERT
		* GPT
	- computer vision models:
		* ResNet
		* Vision Transformer
	- sparse and low-precision training algorithms for reduced training time and increased accuracy
	- compute- and memory- efficient training techniques, such as reversibility and low-rank
	- Scaling laws for increasing model size: accuracy/loss, architecture scaling, hyperparameter transfer 
	- Optimizers, initializers, normalizers to improve distributed training on large scale clusters 
	- Develop novel training algorithms and demonstrate on state-of-the-art large DNNs 
	- Develop novel network architectures and layers such as normalization, activation functions, optimizers, and parameter layers 
	- Design and run research experiments to prove novel algorithms are effective and robust 
	- Analyze results to gain research insights, including training dynamics, gradient quality, and dataset cleaning techniques 
	- Publish and present research at leading machine learning conferences 
	- Collaborate with engineers in co-design of the product to bring the research to customers 
	- Strong grasp of machine learning theory, fundamentals, linear algebra, and statistics 
	- Experience with state-of-the-art DNNs models, such as BERT and GPT 
	- Experience with machine learning frameworks, such as TensorFlow and PyTorch
	- Experience with distributed training concepts and frameworks such as Megatron and Deepspeed 
	- Fluency in a programming language, such as Python 
	- Strong track record of relevant research success through relevant publications/patents at top conferences or journals (e.g. ***ICLR, ICML, NeurIPS***)
+ experience with modern compiler frameworks:
	- TVM
	- LLVM
	- MLIR
	- GLOW
	- XLA
+ skill set:
	- ***deep learning runtimes: ONNX Runtime, TensorRT***
	- ***inference server or model serving frameworks***
		* ***Triton***
		* ***TFServe***
		* ***KubeFlow***
	- distributed systems collective
		* NCCL
		* OpenMPI
	- deploy ML workloads on distributed systems, in a multitenancy environments
	- MLOps, from definition to deployment, including training, quantization, sparsity, model preprocessing, deployment
	- training, tuning, and deploying ML models for:
		* computer vision, such as ResNet
		* natural language processing, such as BERT, GPT
		* recommendation systems, DLRM
+ machine learning model compression techniques, such as quantization or pruning
+ skill set:
	- Machine Learning Research Engineer, Generative AI
	- Performant model code, high quality data, and robust evaluation methods form the foundation of an AI system. Scale's leading end-to-end solutions for the ML lifecycle based on real-world data will continue to set the bar for the data-centric AI movement. Scale's Generative AI team focuses on building models to accelerate AI adoption for some of the largest companies in the world. 
	- Your focus will be on developing Models as a Service using a variety of Machine Learning techniques. You will be involved end-to-end from coordinating with operations to create high quality datasets to productionizing models for our customers. If you are excited about shaping the future of the data-centric AI movement, we would love to hear from you!
	- Apply state of the art models, developed both internally and from the community, in production to solve problems for our customers and data labelers. 
	- Work with product and research teams to identify opportunities for ongoing and upcoming services.
	- Explore approaches that integrate human feedback and assisted evaluation into existing product lines. 
	- Work closely with customers - some of the most sophisticated ML organizations in the world - to quickly prototype and build new deep learning models targeted at multi-modal content understanding problems.
	- At least 3 to 5 years of model training, deployment and maintenance experience in a production environment.
	- Strong skills in NLP, LLM and deep learning.
	- Solid background in algorithms, data structures, and object-oriented programming.
	- Experience working with cloud technology stack (eg. AWS or GCP) and developing machine learning models in a cloud environment.
	- Experience in dealing with large scale AI problems, ideally in the generative-AI field. 
	- Demonstrated expertise in large vision-language models for diverse real-world applications, e.g. classification, detection, question-answering, etc. 
	- Published research in areas of machine learning at major conferences (***NeurIPS, ICML, EMNLP, CVPR***, etc.) and/or journals. 
	- Strong high-level programming skills (e.g., Python), frameworks and tools such as ***DeepSpeed, Pytorch lightning, kuberflow, TensorFlow***, etc. 
	- Strong written and verbal communication skills to operate in a cross functional team environment. 
	- The base salary range for this full-time position in our hub locations of San Francisco, New York, or Seattle, is $176,000 - $240,960. Compensation packages at Scale include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Scale employees are also granted Stock Options that are awarded upon board of director approval. You'll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.
+ skill set:
	- Scale Spellbook is a developer platform for prompt engineering, evaluation, deployment, knowledge retrieval and more. We are looking for a strong product engineer to join our team and help us scale and grow our product. The ideal candidate will have a strong understanding of software engineering principles and practices, as well as experience with large-scale distributed systems. You will be responsible for owning large new areas within our product, working across backend, frontend, and interacting with LLMs and ML models. You will solve hard engineering problems in scalability and reliability.
	- Own large new areas within our product
	- Work across backend, frontend, and interacting with LLMs and ML models
	- Deliver experiments at a high velocity and level of quality to engage our customers
	- Work across the entire product lifecycle from conceptualization through production
	- Be able, and willing, to multi-task and learn new technologies quickly
	- 5+ years of full-time engineering experience, post-graduation
	- Experience scaling products at hyper growth startups
	- Experience tinkering with or productizing LLMs, CV, vector databases, and the other latest AI technologies
	- Proficient in Python or Javascript/Typescript, and Sql database
	- The base salary range for this full-time position in our hub locations of San Francisco, New York, or Seattle, is $212,800-$258,121.
+ skill set:
	- Experience  in using the following systems in production: AWS, Typescript, Node, MongoDB, MLflow, Python (note that we are mostly language-agnostic and are open to using whatever is the best tech for the problem at hand)
	- Experience working with Docker, Kubernetes, and Infrastructure as code (eg terraform); bonus points for running GPU/ML workloads
	- Experience building systems that process large volumes of data.
	- Experience with core AWS technologies such as VPC, EC2, ALB, ASG, Spot Instances
	- Experience in operating or managing Infrastructure such as Spark, Presto, Hive
+ skill set:
	- Staff Machine Learning Research Engineer, Generative AI
	- Scale's Generative AI Data Engine powers the most advanced LLMs and generative models in the world through world-class RLHF/RLAIF, data generation, model evaluation, safety, and alignment.
	- As the Lead of the Generative AI team, you will be responsible for managing and leading a group of talented researchers and engineers. Your primary focus will be to leverage your expertise in LLMs, generative models, and other foundational models to create and execute an AI roadmap which will help Scale accelerate our customers' Generative AI initiatives forward. This is an exciting opportunity to work on cutting-edge technologies and collaborate with industry-leading professionals.
	- We are building a large hybrid human-machine system in service of ML pipelines for dozens of industry-leading customers. We currently complete millions of tasks a month and will grow to complete billions monthly.
	- Led a team of highly effective researchers and engineers. Provide guidance, mentorship, and technical leadership to a team of researchers and engineers working on Generative AI projects. Develop and evaluate methods for integrating machine learning into human-in-the-loop labeling systems to ensure high-quality and throughput labels for our customers.
	- Implement and improve on state-of-the-art models developed internally and from the community and put them into production to solve problems for our customers and taskers.
	- Work with product and research teams to identify opportunities for improvement in our current product line and for enabling upcoming product lines.
	- Work with massive datasets to develop both generic models as well as fine-tune models for specific products.
	- Work with customers and 3rd party research groups to understand their goals and define how we can enable them.
	- Build a scalable ML platform to automate our ML services, including automated model retraining and evaluation.
	- Be able and willing to multi-task and learn new technologies quickly.
	- Must be able to commute to the San Francisco Office 1-2x weekly. 
	- 7+ years of full time work experience using LLM, deep learning, deep reinforcement learning, or natural language processing in a production environment. Especially training foundational AI models through pre-training, fine-tuning, and RLHF.
	- A vision for where the field should go and what Scale should do to enable it.
	- Strong programming skills in Python, experience in PyTorch or Tensorflow
	- Experience with MLOps and the automation of model training & evaluation
	- Experience working with cloud technology stack (eg. AWS or GCP) and developing machine learning models in a cloud environment
	- Solid background in algorithms, data structures, and object-oriented programming
	- Deep appreciation for building high-quality, robust, reusable machine-learning software
	- Degree in computer science or related field
	- Graduate degree in Computer Science, Machine Learning or Artificial Intelligence specialization
	- Publication experience in the field or related topics.
	- Experience with model optimization techniques for both training and inference
	- The base salary range for this full-time position in our hub locations of San Francisco, New York, or Seattle, is $176,000 - $250,000.
+ Experience working fluently with standard orchestration & deployment technologies like Kubernetes, Temporal, Terraform, Docker, etc in multiple clouds
+ skill set:
	- Senior Software Engineer, AV / CV
	- At Scale AI, we are building tools to across the AI development lifecycle. Data is the new code, and Scale AI helps companies get the data they need, whether it's for self-driving vehicles, artificial general intelligence, or robotics. The AV-CV Team (Autonomous Vehicles / Computer Vision) builds the infrastructure for labeling Lidar, Mapping, and Camera data. If seeing autonomous vehicles excited you, you'll be seeing a lot of that on the AV-CV team. The team builds the tools for labeling Lidar pointclouds, annotating image and video feeds, and linking them together to build perception models.
	- Own large new areas within our product
	- Become an expert in working closely with customers across many CV industries
	- Build technologies ranging from frontend and backend to automated ML systems
	- Work deeply with sales and marketing to run demos and increase customer engagement
	- Work across the entire product lifecycle from conceptualization through production
	- Be able, and willing, to multi-task and learn new technologies quickly
	- 5+ years of full-time engineering experience
	- 2+ years working with TypeScript/JavaScript, HTML, CSS, and related web technologies (React, Next.js, Webpack)
	- Experience working with distributed systems and cloud environments
	- Experience working with a production database (Postgres, MongoDB, MySQL, MS SQL) and schema migrations
	- Solid background in algorithms, data structures, and object-oriented programming.
	- Excitement to work with AI technologies
	- Strong written and verbal communication skills
	- Strong problem-solving skills, and be able to work independently or as part of a team.
	- The base salary range for this full-time position in our hub locations of San Francisco is $153,000 - $215,000.
+ skill set:
	- Familiar with CUDA ecology, experience in NCCL and RDMA development is preferred;
	- Understand common large-scale distributed training optimization strategies, familiarity with fsdp/deepspeed/accelerate/galvatron is preferred.
+ skill set:
	- Familiarity with distributed training, NCCL communication library, etc. is preferred; familiarity with large model training frameworks such as DeepSpeed, Megatron, etc. is preferred;
	- Proficiency in CUDA and other heterogeneous programming is preferred; familiarity with GPU/GPGPU architecture is preferred;
	- Familiar with CNN, RNN, Transformer and other deep neural networks is preferred;
	- Familiarity with AI compilation technologies such as TVM and MLIR is preferred.
+ skill set:
	- Proficient in Gtest or Pytest framework, and be familiar with Jenkins, K8s and Docker environment.
	- Experience in PyTorch/TensorRT/Tensorflow programming is a big plus.
	- Experience in KMD/UMD/Operator development is a big plus.
+ Familiar with and have used one or more mainstream deep learning frameworks (Tensorflow/PyTorch/PaddlePaddle/MindSpore, etc.);
+ skill set:
	- Research and analyze common algorithm models (CNN/RNN/Transformer, etc.) in scenarios such as computer vision, speech recognition, natural language processing, and advertisement recommendation, and analyze their implementation, performance, and accuracy on mature GPUs;
	- Based on Biren's chip products (GPGPU), participate in the transplantation, acceleration, precision tuning of deep learning algorithm models on Biren GPU, and performance tuning of application pipelines;
	- Closely track industry trends and technology trends, focusing on hot algorithms/models that will be applied in the industry.
	- Master's degree or above in EECS or related majors, with more than 5 years of relevant work experience;
	- Proficiency in operating Linux system, proficiency in C/C++/Python/Shell, solid programming foundation and debugging experience;
	- Familiar with and have used one or more mainstream deep learning frameworks (Tensorflow/PyTorch/PaddlePaddle/MindSpore, etc.);
	- Familiar with the principles of deep learning algorithms, have experience in precision and performance tuning, and be familiar with the application of algorithms in business scenarios;
	- Diligent in thinking, willing to solve problems, and have the spirit of cooperation.
	- Have a developer's perspective understanding of one or more mainstream deep learning frameworks, and have certain insights and experience in framework design or tuning;
	- Familiar with large-scale distributed training, understand the principle and implementation of large models such as GPT;
	- Have experience in algorithm and engineering collaborative optimization, and be able to make a reasonable trade-off between accuracy and performance;
	- Experience in GPGPU programming, experience in domestic GPGPU/AI chips;
	- Have experience in AI compiler.
+ skill set:
	- System Architect - HW/SW Architecture - Apple Vision Pro
	- Apple is where individual imaginations gather together, committing to the values that lead to great work. Every new product we build, service we create, or Apple Store experience we deliver is the result of us making each other's ideas stronger. That happens because every one of us shares a belief that we can make something wonderful and share it with the world, changing lives for the better. It's the diversity of our people and their thinking that inspires the innovation that runs through everything we do. When we bring everybody in, we can do the best work of our lives. Here, you'll do more than join something — you'll add something.
	- Apple Vision Pro is a revolutionary spatial computer that seamlessly blends digital content with your physical space. It will allow us to do the things we love in ways never before possible — all while staying connected to the people around us.
	- 6+ years of working experience
	- Strong system / SoC architecture background with deep understanding of low power processing.
	- Experience in development of SoC Power and Performance simulation models for use case level analysis and optimization.
	- Strong coding skills in Python, C/C++, SystemC.
	- You have background on NN algorithms and Neural HW architecture.
	- You have background on HW acceleration for image / display / audio signal processing workloads.
	- Ability to drive HW / SW partition and co-optimization in a data driven way.
	- Strong verbal communication skills across organizations and at the executive level.
	- Excellent written skills for clear reporting of data analysis and conclusions.
	- We are seeking a highly motivated, system architect to define compute acceleration strategy into our products. You must have excellent understanding of computer architecture (CPU, GPU, Neural Processing), System / SoC level power architecture, emerging compute engines RISC-V, Low power neural processing architecture. You will be mapping system level use cases to the SoC and system and identify HW/SW partitioning opportunities. With this knowledge you are able to apply it to analyzing requirements tradeoffs impacting system performance and product experience. 
	- The job will have a focus on use case level analysis and development of system level models for power, performance and latency to drive overall product architecture.
	- This cross-functional role requires excellent interpersonal skills, working with camera module, architecture, system EE, and product development teams and communicating across teams and to leadership.
	- MS/PhD in relevant field (EE, CS, Computer Eng)
	- At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $138,900 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location.
+ ***Experience with metrics systems such as Grafana.***
+ skill set:
	- ML Systems & Performance Engineer - SPG
	- The key to successful Machine Learning Teams is an efficient, robust, flexible and scalable architectural foundation. The Apple Special Projects Group on Autonomous Systems is looking for a talented, dedicated and result oriented software engineer to help build and improve our Machine Learning Systems. This fundamental and highly impactful work enables us to architect, train, evaluate and deploy state of the art machine learning models for Autonomous Systems.
	- You will be part of a world class team with a highly diverse skillsets. From implementing CUDA kernels, optimizing cache coherency of complex algorithms, reducing memory footprints all the way to optimizing distributed training setups and implementing efficient large scale cloud compute schedules, ML Systems & Performance engineers are taking a holistic view at the whole stack to eliminate bottlenecks resulting in a lean and optimally efficient implementation.
	- 3+ years of professional software development experience.
	- Familiarity with modern Machine Learning frameworks like PyTorch.
	- Familiarity with optimization techniques like Quantization, sparsity and/or pruning.
	- Experience in architecting and implementing large-scale cloud pipelines., e.g using spark, kafka, kubeflow, postgres
	- High proficiency in Python, C++ and/or CUDA.
	- Passion for optimizations and efficient implementations.
	- High software engineering standards: desire to write clean, well-tested and well-structured code.
	- Track record of collaborations across teams, including requirement specifications and successful project delivery.
	- Excellent communication and presentation skills.
	- Curiosity to learn new things and push the boundary towards new approaches without fear of changing existing paradigms.
	- Improve ML Training efficiency to models train faster by scaling out and scaling up.
	- Develop strategies for training distributed models to accommodate model growth beyond state-of-the-art.
	- Design and implement a highly scalable inference pipelines for large scale evaluation.
	- Architect a data processing framework training data preparation and auto-labeling.
	- Collaborate with ML engineers to remove bottlenecks and improve turn-around times.
	- Build visualizations and dashboards to monitor cloud resource utilization.
	- At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $138,900 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location.
+ ***Good experience with applying Big Data tools (MapReduce, Hadoop, Hive and/or Pig, Spark) to large quantities of textual data***
+ skill set:
	- AIML - Software Engineer, Machine Learning Platform & Technologies
	- The Machine Learning Platform Team at Apple is looking for a Senior Engineer who has extensive experience in CI/CD, orchestration pipelines, build, release, and code management to manage critical parts of our development lifecycle. You will work with a dedicated team of engineers that will deliver the tooling and pipelines that enable consistent development of a high performance search stack, ensuring high quality delivery and enabling fast engineering turnaround.
	- 5+ years of experience in developing developer tooling, pipelines, automations and API
	- Thorough understanding of software development lifecycle, DevOps (build, continuous integration, deployment tools) and best practices.
	- Strong programming skills in Go, Python, or other language
	- Strong experience with Spinnaker and/or other delivery platforms
	- Strong experience with workflow platforms (Argo, Jenkins, or other)
	- Solid Kubernetes, AWS or other cloud experience
	- Strong communications and collaboration skills required
	- We design and build infrastructures to support features that empowers billions of Apple users. Our team processes trillions of links to find the best content to surface to users through search. We also analyze pages to extract critical features for indexing, ranking. We apply statistical analysis to improve link selection, freshness, retrieval rates, extraction quality, and many others. You'll have the opportunity to work with large scale systems with trillions of rows and many petabytes of data and incredible complexity.
	- Work in a team of engineers to deliver core tooling and pipelines for builds, validation, and deployment
	- Build tooling and SCM integrations that ensures code consistency, test coverage, and reliability
	- Develop pipelines for continuous, incremental delivery to preproduction environments
	- Extend tooling that helps engineers test, maintain, and deploy solutions across multiple repos and languages
	- Collaborate with DevOps and Release Engineering to enhance release speed and reliability
+ skill set:
	- On the GPGPU-based heterogeneous system, research and implement distributed core modules such as tensorflow/pytorch/horovod for scenarios such as voice/image/NLP, and research multiple hybrid parallel strategies such as data parallelism/model parallelism/pipeline parallelism to improve the scalability of large-scale distributed training;
	- On the heterogeneous system based on GPGPU, research large-scale sparse model training framework for scenarios such as search/advertising/recommendation, support TB-level models, and support multi-machine efficient expansion;
	- Participate in MLPerf rankings to enhance the international influence of domestic GPU chips.
	- Computer, electronics, mathematics and related majors, more than 2 years of relevant work experience;
	- Proficiency in C++/Python programming;
	- Experience in developing Tensorflow/pytorch/horovod and other domestic frameworks;
	- Proficiency in NCCL, RDMA and other communication technologies is preferred;
	- Familiar with data parallel/model parallel/pipeline parallel, familiar with Deep Speed, etc. is preferred;
	- Familiar with CNN/ RNN such as Bert/GPT and other networks is preferred;
	- Familiarity with advertising/recommendation scene algorithms such as Wide&Deep/DLRM/DeepFM/DIEN is preferred, and familiarity with large-scale sparse model training frameworks such as AIBox/HugeCTR/XDL is preferred.
+ skill set:
	- Biren-based chip products (GPGPU), responsible for the implementation of customer applications, including the transplantation and acceleration of the customer's algorithm model on the Biren chip, as well as the performance tuning of the application pipeline;
	- Have certain insights and experience in AI models (CNN/RNN/Transformer, etc.) and pipelines corresponding to scenarios such as computer vision, speech recognition, search advertisement recommendation, and natural language processing;
	- Closely track industry trends and technology trends, and participate in the exploration of new technology solutions.
	- Bachelor degree or above in EE, CS or related majors, more than 5 years of work experience;
	- Proficiency in operating Linux system, proficiency in C/C++/Python/Shell, solid programming foundation and debugging experience;
	- Familiar with and have used one or more mainstream deep learning frameworks (Tensorlow / PyTorch / MXNet, etc.);
	- Familiar with heterogeneous computing systems, and have at least participated in the model transplantation and optimization of one or more AI chips;
	- Diligent in thinking, willing to solve problems, and have the spirit of cooperation.
	- Bonus points: 1. For one or more mainstream deep learning frameworks (Tensorflow/PyTorch/MXNet, etc.) have developers; understanding of perspective, certain insights and experience in framework design or tuning;
	- Familiar with and like performance optimization, have certain development experience in CUDA/OpenCL/OpenMP, etc. or have certain insights and experience in performance distributed solutions such as MPI/CCL;
	- Familiar with GPGPU/AI ASIC/CPU micro-architecture, have certain insights and experience in joint optimization of software and hardware;
	- Experience in compiler, video codec, GPU virtualization, K8s cluster management and scheduling is preferred.
+ skill set:
	- AI Software Library Senior Development Engineer (C++).
	- Participate in the design, implementation, testing, performance optimization and problem fixing of deep learning acceleration library
	- Participate in the design, implementation, testing, performance optimization and problem fixing of AI compilation module
	- Participate in the design, development and continuous optimization of the basic framework for AI operator development
	- Participate in the interface design of AI operator docking with the upper framework, and the design and development of debugging tools
	- Proficient in C++11/14/17/20, proficient in STL
	- Proficient in commonly used data structures and algorithms, it is best to have your own implementation
	- Proficient in C++ multi-thread development under multi-platform, have a deep understanding of thread safety, anti-deadlock, thread-related design patterns and functional programming and the ability to get started immediately
	- Proficient in Python
	- Those who have studied the source code of the deep learning framework (Caffe/Tensorflow/PyTorch/MXNet) and have done relevant development are preferred
	- Must have excellent programming style
	- Familiar with deep learning framework (Caffe/Tensorflow/PyTorch/MXNet) or experience in using TensorRT is preferred
+ skill set:
	- Intelligent Platform Inference Engine R&D Engineer
	- Responsible for the design and implementation of the programming model of the intelligent processor reasoning optimization engine;
	- Responsible for the function realization and performance optimization of the intelligent processor reasoning optimization engine;
	- Responsible for the implementation of the intelligent processor reasoning optimization engine, including function realization, performance optimization and problem repair;
	- Participate in the design, development and continuous optimization of deep learning-related solutions;
	- Continue to carry out intelligent processor compilation optimization and integration work.
	- Bachelor degree or above, computer, mathematics, software engineering, automation, communication, microelectronics and other related majors, more than three years of relevant work experience;
	- Familiar with object-oriented programming methods, familiar with C++ programming development, compilation and debugging process in Linux environment, familiar with python, have a solid programming foundation, good programming style and working habits;
	- Familiar with deep learning algorithms, familiar with at least one deep learning programming framework (one of caffe/tensorflow/pytorch/mxnet), familiar with or have experience in using TensorRT is preferred;
	- Have good learning and understanding ability, strong logical thinking;
	- Possess a good teamwork spirit, strong sense of responsibility, do things practically and conscientiously, be able to actively complete relevant work, and have certain ability to resist pressure.
+ skill set:
	- Math Library Development Engineer
	- Participate in the hardware implementation and performance optimization of common neural network models, such as ResNet, BERT, EfficientNet, DLRM, etc., and propose architecture and microarchitecture improvements based on various neural network model architectures;
	- Participate in the development and performance optimization of AI operator libraries and other mathematical libraries;
	- Participate in the function and performance verification of the chip, and propose architecture and micro-architecture changes according to the verification results;
	- Participate in the development and improvement of various tools, which will be used to support the development and verification of AI operators and other mathematical libraries;
	- Cooperate with the hardware design department to support hardware verification;
	- Cooperate with the software department to support the development of AI framework/software/compiler.
	- Master degree or above, major in computer science, applied mathematics, etc.;
	- Proficient in using Python, familiar with algorithms and data structures;
	- Understand computer architecture, familiar with CPU/GPU architecture is preferred;
	- Understand the basic principles of neural networks, experience in the development and use of neural networks is preferred;
	- Good communication skills and teamwork skills.
+ Experience in ***PyTorch/TensorRT/Tensorflow*** programming is a big plus.
+ Experience in ***CUDA/cuDNN*** programming is a big plus
+ skill set:
	- Inference Engine Architect
	- On the heterogeneous system based on GPGPU, research and realize the reasoning engine for voice/image/NLP and other scenarios, and be responsible for related architecture design, performance optimization and business implementation;
	- On the heterogeneous system based on GPGPU, research and realize the prediction engine for search/advertising/recommendation and other scenarios, and be responsible for related architecture design, performance optimization and business implementation;
	- Responsible for the integration of Biren's self-developed reasoning/estimation engine and third-party frameworks such as TF or the reasoning/estimation engine of major Internet customers, to strengthen ecological construction and promote business implementation;
	- Participate in MLPerf rankings to enhance the international influence of domestic GPU chips.
	- Computer, electronics, mathematics and related majors, more than 5 years of relevant work experience;
	- Proficiency in C++/Python programming;
	- Experience in open source framework or engine architecture design such as ***Tensorflow/Pytorch/Paddle/TensorRT/TNN/MNN/OpenPPL/HugeCTR***;
	- Familiar with AI compilation technology such as TVM/MLIR/XLA is preferred;
	- Familiar with CNN/ RNN and other network reasoning optimization / landing priority;
	- Familiarity with Wide&Deep/DeepFM/DIN and other advertising recommendation scene models is preferred, and familiarity with sparse model estimation engine architecture design and implementation is preferred.
+ skill set:
	- Deep Learning Framework Engineer
	- On the heterogeneous system based on GPGPU, research and implement the core module of the deep learning programming framework;
	- Algorithm research and framework implementation of large-scale cluster distributed training.
	- Computer, mathematics and related majors, more than 1 year of relevant work experience, doctor is preferred;
	- Master at least one language (C++/Python);
	- Mastering a mainstream deep learning framework (Tensorflow, PyTorch, MXNet, NNVM/TVM, etc.) is preferred;
	- Familiar with CUDA, OpenCL, OpenMP and other heterogeneous programming is preferred;
	- Familiarity with CNN, BERT, RNN and other networks is preferred; 6. Familiarity with compilation principles and LLVM is preferred.
+ skill set:
	- Deep Learning Framework Architect
	- On the GPGPU-based heterogeneous system, research and implement the core module of tensorflow;
	- According to the characteristics of the model and hardware, optimize the calculation graph, as well as optimize the memory and synchronization scheduling.
	- Computer, mathematics and related majors, more than 5 years of relevant work experience, doctorate is preferred (more than 3 years);
	- Familiar with C++/Python;
	- More than 2 years of experience in the development of mainstream deep learning frameworks, including Tensorflow, PyTorch, Mindspore, PaddlePaddle, Oneflow, MegEngine, MXNet, NNVM/TVM, etc.;
	- Proficiency in heterogeneous programming such as CUDA/OpenCL/Vulkan/OGL/DX Compute is preferred;
	- Familiar with GPU/GPGPU architecture;
	- Familiar with CNN, BERT, RNN and other networks is preferred;
	- Familiar with compilation principles and LLVM is preferred.
+ skill set:
	- Deep Learning Framework Engineer
	- Research and implement the core modules of the deep learning programming framework on the heterogeneous system based on GPGPU;
	- Algorithm research and framework implementation of large-scale cluster distributed training.
	- Computer, mathematics and related majors, with more than 1 year of relevant work experience, doctor is preferred;
	- Master at least one language (C++/Python);
	- Mastering a mainstream deep learning framework (Tensorflow, PyTorch, MXNet, NNVM/TVM, etc.) is preferred;
	- Familiar with CUDA, OpenCL, OpenMP and other heterogeneous programming is preferred;
	- Familiarity with CNN, BERT, RNN and other networks is preferred; 6. Familiarity with compilation principles and LLVM is preferred.
+ skill set:
	- Chip System Architecture Engineer
	- Responsible for driving the architectural design of our general computing/AI processors based on the latest general computing and AI accelerator applications, providing new technologies for products in new markets and existing markets
	- Participating in the development of modeling tools and infrastructure needed to facilitate exploratory design and performance studies;
	- Promote the development of new GPGPU/AI technologies to improve the user experience of various products and applications.
	- Bachelor degree or above in computer science/electronic engineering/applied mathematics, master/doctorate preferred;
	- More than 7 years of experience in general computing/AI hardware architecture, microarchitecture and design;
	- Have a deep understanding of modern general-purpose computing application programming interfaces, such as Cuda, OpenCL;
	- Have a deep understanding of deep learning technology, with artificial neural network framework;
	- Familiar with C/C++, Python, excellent software development skills;
	- Excellent teamwork skills, self-motivation and focus on results.
+ skill set:
	- Senior Software Library Engineer/Architect
	- Design and develop general basic mathematics library;
	- Discuss and implement possible optimization methods for specific hardware implementations;
	- Coordinate with other software engineers to provide solutions to problems and performance tuning in various general purpose platforms.
	- Master degree or above, more than 3 years of work experience;
	- Proficient in C/C++ programming, experience in Python programming is preferred;
	- Understand computer architecture;
	- Understand compute shader programming;
	- Experience in one or more common platforms or mathematical libraries is preferred: such as ***CuFFT, CuBlas, CuDNN, Tensorflow, TensorRT***, etc.;
	- Have a strong ability to analyze and solve problems;
	- Possess strong communication skills, independent working ability and team driving ability, and can coordinate all relevant teams to promote the completion of the plan.
+ skill set:
	- AI/GPU Heterogeneous Platform Software Development Engineer
	- Parallel algorithm implementation and high-performance template library development in AI/GPU software framework;
	- Analyze and research open source machine learning and deep learning training engines, optimize and improve the implementation of operators and models;
	- Participate in the architecture design, key technology research and core code development of heterogeneous computing framework;
	- Development of test cases in general computing and heterogeneous computing programming models.
	- Computer, mathematics and related majors, master degree or above or more than 3 years of relevant work experience, doctor is preferred;
	- Proficient in C/C++ and open source project development tools under Linux; familiar with heterogeneous programming models such as CUDA/HIP/cupy;
	- Strong learning ability, familiar with compilation principles and architecture is preferred;
	- Familiarity with deep learning frameworks, accelerator cards, and typical deep learning networks is preferred.
+ skill set:
	- GPU application optimization engineer
	- Biren-based chip products (GPGPU), responsible for the transplantation and acceleration of deep learning algorithm models on Biren GPU, and performance tuning of application pipelines;
	- Have certain insights and experience in AI models (CNN/RNN/Transformer, etc.) corresponding to scenarios such as computer vision, speech recognition, search advertisement recommendation, and natural language processing;
	- Closely track industry trends and technology trends, and participate in the exploration of new technology solutions.
	- Master degree or above in EECS or related majors;
	- Proficiency in operating Linux system, proficiency in C/C++/Python/Shell, solid programming foundation and debugging experience;
	- Familiar with and have used one or more mainstream deep learning frameworks (Tensorlow / PyTorch / MXNet, etc.);
	- Familiar with heterogeneous computing systems, experience in cuda or parallel computing is preferred;
	- Diligent in thinking, willing to solve problems, and have the spirit of cooperation.
	- Have a developer's understanding of one or more mainstream deep learning frameworks (Tensorlow / PyTorch / MXNet, etc.), and have certain insights and experience in framework design or tuning;
	- Familiar with GPGPU/AI ASIC/CPU micro-architecture, have certain insights and experience in joint optimization of software and hardware;
	- Experience in compiler, video codec, GPU virtualization, K8s cluster management and scheduling is preferred.
+ skill set:
	- Machine Learning Engineer - SIML, ISE
	- Would you like to help shape the next set of ML features of iPhone? Would you like to contribute to the field of generative AI? Want to contribute to transforming how people interact with AI technologies?
	- The System Intelligence and Machine Learning team is in charge of creating datasets that power many of Apple's intelligent software. Our datasets range from very small targeted sets to Petabyte scale datasets. As a data scientist on our team you will be in charge of selecting the right assets, removing harmful and toxic assets and extracting insights from the datasets, assessing & reducing harmful biases, and maximizing fairness and inclusion of various ML features.
	- We are looking for an experienced Machine Learning Engineer who can help create and improve the datasets used in Generative AI through solid understanding and usage of ML and stats. You will be using Apple technologies to refine our datasets, remove toxicity and select the right images, videos or texts through active selection and model-in-the-loop methodologies. Focus areas range from text processing across many languages (toxic language detection and removal, identification of colloquial vs formal language) to image and video understanding, deduplication and processing.
	- Familiarity with a broad range of Machine Learning techniques and relevant statistical packages to engineer Machine Learning solutions end-to-end.
	- Experience in contributing to production code bases. Ability to rapidly prototype algorithmic ideas in notebook environments and translate them into production code.
	- Proficient in state-of-the-art ML techniques particularly in the field of Generative AI and Large Language Models (Transformer architecture, CLIP and various visual and text embedding models, GPT and BERT style language models).
	- Exceptional communication and presentation skills and the ability to explain difficult technical topics to everyone from data scientists to engineers to business partners.
	- Strong proficiency with Python (Scikit learn, Jupyter), PyTorch, SQL-based languages. Working proficiency with Git.
	- As a Machine Learning Engineer on the Data Team, you will be working to deepen our understanding of how various datasets can improve the quality of Apple's ML models on a range of products. You will particularly help shape Apple's Datasets that are used for generative AI by removing irrelevant or toxic assets, selecting the right assets by employing various asset selection algorithms, utilizing Apple proprietary ML models. For this, you will also use your stats and ML background to build models and algorithms that can select the right assets for ML experiences from a large pool of available assets. And you will work with our data engineers to put your models in data pipelines to run on large scale datasets.
	- In our team, you are expected to collaborate with other AIML product stakeholders and partners to understand needs, design Machine Learning models that help us better understand our data and automatically pick the right assets for ML training. Our Data Scientists actively evaluate and present the progress of their work. Your creative problem solving skills will be used daily.
	- Masters or Phd degree in Computer Science, Engineering; or equivalent practical experience. 
	- Strong analytical product intuition: able to understand the user experience and use data to guide the development of products.
	- 2+ years of experience in an Applied Scientist role, preferably in a technology company.
	- Ability to understand a technically complex product, and work with engineering leads and data engineers.
	- Proficiency in data science and analytics, including statistical data analysis and machine learning. Experience crafting, conducting, analyzing, and interpreting experiments and deep-dive investigations.
	- Ability to build relationships across multiple functions and establish strong partnerships.
+ Proficiency ***in building end-to-end ML pipeline from data ingestion to feature engineering to model training to deploying and scaling the model in production***.
+ Experience ***in building end-to-end ML pipeline from data ingestion to feature engineering to model training to deploying and scaling the model in production***.
+ skill set:
	- Bonus if you have prior data analysis experience (SQL, Python/Jupyter Notebooks, Tableau, Superset)
	- Bonus if you have prior experience exploring data formats and tools for big data systems (e.g. Parquet, Avro, Protobuf).
	- Bonus if you have prior experience working with data engineers (e.g. engineers who use tools such as ***Airflow, Luigi, Jenkins, MapReduce, Pig, Spark, Hadoop, Hive, HBase, Greenplum, Vertica***, etc.)
+ skill set:
	- 2+ years of experience in developing end to end machine learning pipelines on distributed systems.
	- You have experience in deploying machine learning solutions on marketplaces. Any previous experience in advertising technology in areas such as conversion modeling, automatic bidding, keyword/bid/budget recommendation, creative optimization, advertiser churn prediction, automatic targeting and auction design will be a plus.
	- You can drive multi-functional collaboration with product, data engineering, experimentation and machine learning operations.
	- You can actively participate in investigations into multiple streams of ads quality data, draw conclusions from data, and recommend actions.
	- You are comfortable with alternative experiment designs such as budget splitting, switch backs, interleaving in addition to traditional a/b testing.
	- You have extensive experience developing in Python.
	- You are familiar with databases, SQL, and scripting languages.
	- You have a practical understanding of some of the modern machine learning applications to rare events modeling, natural language processing, ranking, clustering and embedding generation.
	- You enjoy working closely with operational teams on deployment, monitoring, and management concerns.
+ skill set:
	- Senior Software Engineer, Autonomous Systems - SPG
	- Apple SPG (Special Projects Group) is seeking an experienced software engineer to work on developing and implementing high-quality software for autonomous systems. Our organization is engaged in conducting world-changing research that requires the development of novel algorithms that need to run in real-time.
	- Proficient in C++ and Python. Language-agile.
	- Experience with building production code.
	- Strong understanding of scientific and numerical programming in domains such as robotics, controls, computer graphics.
	- Familiarity with code developer workflows and tooling.
	- Strong interest in engineering problem solving.
	- Help design and build production-grade software to solve historically difficult problems in the field of autonomous systems under strong engineering constraints
	- To be experienced in designing and building production-grade software in C++
	- Have deep understanding of patterns (and anti-patterns) of architecture
	- Familiarity with scientific programming and numerical techniques
	- A minimum of a BS in Computer Science or related fields.
	- 10+ years of experience on working on production software in scientific and numerical domains.
+ skill set:
	- Perception System Engineer - SPG
	- As Perception System Engineer on a revolutionary Apple project, you will be working on an autonomous system built on state of the art sensing technologies and ground breaking machine learning algorithms. The Perception team provides sense capabilities such as detection, classification, tracking, and observed maps in complex environments using a range of sensing modalities. You will play a key role in measuring end-to-end system performance, identifying key issues and provide detailed feedback for performance improvement. You will engage cross functionally with a wider range of experts to build a robust and scalable triage and measurement system. You will use statistical modeling and develop expertise in Perception system performance trends, forecasting methodologies, and synthesize key findings for leadership reviews.
	- 5+ years of experience in testing, QA or algorithm development for Autonomous Perception systems
	- A deep understanding of perception functions its impact on motion planning
	- Knowledge of machine learning models and deep learning fundamentals
	- A background in statistical analysis, system-level triage of complex systems
	- Proficient in data analysis, scripting and automation using python
	- Familiarity with data products from optical sensors like lidar and camera is desired
	- You will be developing and maintaining a Perception performance measurement pipeline that provides continuous feedback to developers for performance improvement and debugging. The work involves significant cross functional interaction with system test engineers, model, and tooling developers.
	- Defining procedure and tooling requirements for a triage and test pipeline that identifies, classifies, and measures perception failure rates.
	- Engaging with relevant partners to ensure timely implementation and delivery. 
	- Synthesize failure rate data to derive meaningful trends and sensitivities, and track measured improvements and regressions over time. 
	- Create and own dashboards for leadership reviews and develop expertise in observed system performance. 
	- Root causing and failure analyses in partnership with deep learning model developers will be essential to be effective in this role. 
	- You will also have opportunities to develop statistical models to forecast full system performance using developer metrics, critical scenario testing, and past performance.
	- Masters degree in engineering, data science, statistics, or mathematics
	- 5+ years of relevant Industry experience in robotics or autonomous systems
+ skill set:
	- Computer Vision Architect
	- Apple is looking for a computer vision architect with exceptional technical and communication skills to contribute on high-impact projects that will enable game-changing future Apple products. The role requires deep knowledge of image processing and ability to define, analyze and optimize the architecture of video pipelines. Successful candidate must possess good understanding of both hardware and software solutions used in battery operated devices, including tradeoffs in optimal performance vs. power consumption.
	- Ability to evaluate existing and emerging imaging systems against use case requirements, including, understanding of hardware engines (CPU, GPU, Neural Network Accelerator, DSP, etc.) and how to choose the right one for a given application.
	- Understanding of difference between classes of algorithms and how to optimize their efficiency on available hardware engines (Computer Vision vs DeepLearning) as well as resource sharing and arbitration.
	- Understanding of the impact processing flow selection will have on overall system performance, power consumption and resource sharing by various algorithms.
	- Deep knowledge of sensors and camera technologies, including, image acquisition (sensor+lensing+ISP), rolling vs global, color vs monochrome, rectilinear vs equidistant and their impacts on algorithms, color management, performance optimization in low light conditions, etc.
	- Understanding of system resources supporting image collection and camera calibration in multi-camera systems and ability to define common system pre-processing blocks for camera streams.
	- Demonstrated proficiency in system architecture and performance analysis, including, input interface definition/optimization of image streams serving multiple algorithms, estimation of system compute requirements based on required performance.
	- Ability to define system-wide policies optimizing resources in multi-sensor streaming systems with memory constraints as well as estimation of system responsiveness based on latency analysis and system margins.
	- Ability to translate product goals to feature level architectures and the ability to derive for each feature the end-to-end requirements (with rationale) and decompose them down to module/component specific requirements.
	- Ability to work cross-functionally (Algorithms, Embedded, ML, Mechanical, Electrical, Optical, Human Factors, Vision science etc.) with stakeholders to define CV features, understand trades, sensitivities, risks and perform budgeting across full system.
	- Ability to effectively communicate and align with peers while navigating complex trade-spaces and the ability to summarize learnings, take-aways and recommendations in a succinct way to executive leadership.
	- Ideal candidate must have proven track record of having participated in the development of multiple consumer electronic products. Should have broad understanding of hardware and software technologies that are employed in low-power hand-held / wearable devices. Must be a self-starter who is highly-motivated and an organized thinker with excellent communication and presentation skills.
	- BE + 15 yrs of relevant industry experience.
	- Masters/PhD + 10yrs of relevant industry experience
+ skill set:
	- Robotics Software Engineer, Autonomous Systems - SPG
	- Apple SPG (Special Projects Group) is looking for talented robotics and software engineers to join our team to push the boundaries of autonomous planning algorithms (behavior, predictions, motion planning, and architecture).
	- Background in any of the following areas: behavior planning/decision-making, predictions, machine learning, motion planning (sampling, search based planning, optimization), estimation, control, and/or high-performance real-time algorithms.
	- Experience programming autonomous robots, modeling multi-agent systems, and developing algorithms for them.
	- Strong C++ and/or Python development skills.
	- Solid understanding of advanced algorithms and data structures.
	- 2+ years of professional or equivalent experience.
	- You must be hands-on, eager, curious and never satisfied with the status quo.
	- You must love learning and being challenged.
	- You will develop cutting edge robotics technology at the intersection of machine learning, AI, and classical robotics. This involves the design and implementation of algorithms that run on a robot in real-time in a safety critical application that involves autonomous interactions with the surrounding world in an uncontrolled environment. You will test and deploy your work in simulation and in the real world on state-of-the-art robotics hardware. You will contribute to the development of an ambitious and innovative projects as part of a dedicated team of world-class engineers.
	- M.Sc., or Ph.D. in computer science, engineering, or equivalent professional experience.
	- Designed one or more machine-learned approaches to solve a robotics problem.
	- Experience with cloud-based tools to automate experiments and analysis at scale.
	- Familiarity with real-time, multi-process, multi-threaded coding.
	- Comfort using the command line in Linux.
	- Experience with 3D geometric math.
	- Comfortable with collaboration tools for programming
+ skill set:
	- Data Collections Lead - SIML, ISE
	- Would you like to help shape the next set of ML features of iPhone? Would you like to contribute to the field of generative AI? Want to contribute to transforming how people interact with AI technologies? 
	- The System Intelligent and Machine Learning team is in charge of creating datasets that power many of Apple's intelligent software. Our datasets range from very small targeted sets to Petabyte scale datasets. As part of the Data Collection team, you will be managing end-to-end data collection projects for a wide variety of features. Our data team is responsible for designing and building high quality datasets at scale. At the heart of machine learning, data defines how Apple features and products operate and what is the final user experience that will impact millions of our customers. This is an exciting time to join us: grow fast and have an impact on multiple key features on your first day at Apple!
	- Excellent project management, communication, interpersonal, analytical, and organizational skills
	- Passion for creating great products and understanding the challenges associated with building datasets for machine learning features; while addressing the challenges of inclusion, bias removal, and fairness.
	- Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
	- Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
	- Problem solving & critical thinking capacities, with an eye for innovation and continuous optimization (improving the diversity and quality of assets, reducing time to delivery and cost)
	- Ability to understand data needs and define concrete project deliverables
	- Our SIML Data team focuses on data acquisition, data science, annotation, data QA and robustness analysis. We utilize generative AI tools to help generate and evaluate data. Each year, we power dozens of features and work closely with ML teams across the entire company. Apple's commitment to deliver incredible experiences to a global and diverse set of users with a full respect of their privacy leads our team to explore innovative data collection processes.
	- In this position, you will be responsible for leading and managing data collection projects end-to-end and ensuring the quality of the data delivered to R&D. 
	- Connect with R&D teams to understand expectations and define specs of data collection efforts, with a constant focus on fairness and on potential biases
	- Co-define a data collection workflow with the partners, in accordance with Apple values
	- Coordinate the efforts of internal teams (privacy, legal, procurement, security) and own the administrative setup
	- Lead the data collection project, including working with internal and external teams
	- Define and dynamically adapt the data collection methodology to foster efficient quality analysis and annotation
	- Track quantities and quality delivered
	- A strong understanding of applied machine learning concepts is desired
	- Formal or informal experience working with generative AI tools (including personal projects) is desired
	- Experience in data operations supporting R&D work related to generative AI is a strong plus
	- Ability to maintain and develop relationships with multi-functional teams
+ skill set:
	- Generative AI Applied Researcher - SIML, ISE
	- Are you excited about Generative AI? We are looking for experts in this space to join our applied ML R&D team at Apple! You will be inventing and shipping the next generation of these core technologies with a focused team. Our purpose is to surprise and delight users and developers worldwide.
	- The team comprises domain experts in Computer Vision & Natural Language Processing (NLP) who contribute to a variety of shipping workflows you may already regularly use, including: Photos Search, Curation, Memories, Intelligent Auto-crop, Visual Captioning for Accessibility, Federated Learning on visual content, Real-time Classification & Saliency in Camera, Semantic Segmentation in Camera, and several on- device feature extractors across the system. Further, several of our projects are surfaced to third party developers through Vision & CoreML. Shipping APIs include image tagging, image similarity, saliency estimation and prints for transfer learning. The team collaborates extensively with various teams across Apple in bringing experiences to life across our devices, services and 1st/3rd party APIs. 
	- Selected references to our team's work:
	- https://machinelearning.apple.com/research/stable-diffusion-coreml-apple-silicon
	- https://machinelearning.apple.com/research/on-device-scene-analysis
	- https://machinelearning.apple.com/research/panoptic-segmentation
	- 5+ years of industry experience with strong ML fundamentals
	- Hands-on experience with building Deep Learning applications
	- Proficiency in using ML toolkits, e.g., PyTorch
	- Strong analytical and problem solving skills
	- Strong programming skills in Python, C and C++
	- You're aware of the challenges associated to the transition of a prototype into a final  product
	- You're familiar with the challenges of developing algorithms that run efficiently on  resource constrained platforms
	- You've demonstrated leadership in both applied research and development
	- Excellent written and verbal communications skills, be comfortable presenting  research to large audiences, and have the ability to work hands-on in multi-functional teams
	- We are looking for a candidate with a proven track record in applied ML research. Responsibilities in the role will include training large scale multimodal (vision-language) models on distributed backends, deployment of compact neural architectures such as transformers efficiently on device, and learning adaptive policies that can be personalized to the user in a privacy preserving manner. Ensuring quality in the field, with an emphasis on fairness and model robustness would constitute an important part of the role. You will be interacting very closely with a variety of ML researchers, software engineers, hardware & design teams cross functionally. The primary responsibilities associated with this position range from algorithm design and implementation, ability to integrate research into production frameworks, and collaborating closely with product teams before and after feature launch.
	- M.S. or PhD in Electrical Engineering/Computer Science, or a related field (mathematics, physics or computer engineering), with a focus on computer vision and/or machine learning or comparable professional experience; or equivalent experience.
	- Familiarity with Multi-modal ML, Graph ML and/or Reinforcement Learning (RL) in a distributed large-scale training environment is desirable.
	- Experience in neural network deployment optimizations is desirable.
+ skill set:
	- Software Engineer - Apple Vision Pro
	- Apple Vision Pro is a revolutionary spatial computer that seamlessly blends digital content with your physical space. It will allow us to do the things we love in ways never before possible — all while staying connected to the people around us.
	- Passionate about Spacial Computing
	- Passionate about working with hardware architectures
	- Great interest or background in Computer Vision and/or Machine Learning
	- Solid fundamentals in Linear Algebra
	- Strong proficiency in C/C++
	- Performance and optimization oriented
	- Self-motivated and great teammate
	- VPG (Vision Product Group) is the group that is responsible for many of the key algorithms for Apple Vision Pro. We are looking for versatile engineers who are passionate about building products for millions of customers around the world. You'll be working on cutting-edge technology and develop algorithms that enable a high-quality user experience across a range of tentpole use cases and applications. As a part of our team, you will closely collaborate with HW engineers (cameras, silicon, electrical engineering, product design) and other technology development software teams (computer graphics, video engineering, data generation/annotation, drivers/OS). You can make a difference by researching and prototyping novel deformable object tracking algorithms beyond the state of the art and/or by optimizing the performance of real-time algorithms running on Apple silicon.
	- M.Sc. or B.Sc. degree in Computer Science or similar, alternatively a comparable industry career with a consistent track record of successful projects.
+ Familiarities with Knowledge Graph and Traversal Algorithms
+ skill set:
	- Machine Learning Engineer — NLP
	- Superior verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
	- Thorough understanding of common machine/deep learning algorithms and practical experience in one or more of the following areas: prompt-based learning, reinforcement learning, BERT, GPT, T5, transformers, conversational models, large-scale NLP model training and fine-tuning
	- Working knowledge of distributed training and parallel computing on machine learning tools, such as AWS SageMaker
	- Working knowledge of relational databases, including SQL, and large-scale distributed systems such as Hadoop and Spark
	- Ability to implement data intensive pipelines and applications in a general programming language such as Python, Scala, Java or C++
	- Ability to comprehend and debug complex systems integrations spanning toolchains and teams
	- Ability to extract meaningful business insights from data and identify the stories behind the patterns
	- Creativity to engineer novel features and signals, and to push beyond current tools and approaches
	- Excellent verbal and written communication skills, in both Mandarin Chinese and English
	- Engage with others to find opportunities, understand requirements, and translate those requirements into technical solutions 
	- Design internal search and conversational system concerning business and sales topics
	- Design machine learning approach, applying tried-and-true techniques or developing custom algorithms as needed by the business problem 
	- Collaborate with data engineers and platform architects to implement robust production real-time and batch decisioning solutions 
	- Ensure operational and business metric health by monitoring production decision points
	- Investigate adversarial trends, identify behavior patterns, and respond with agile logic changes
	- Communicate results of analyses to business partners and executives 
	- Research new technologies and methods across data science, data engineering, and data visualization to improve the technical capabilities of the team
	- Ph.D. in Computer Science, Machine Learning, Statistics, Operations Research or related field; or 
	- Ph.D. in Math, Engineering, Economics, or hard science with data science fellowship; or 
	- M.S. in related field with 3+ years experience applying deep learning to real business problems
+ Deep technical knowledge in classic Computer Vision (pixel processing and geometry) or Machine Learning are a must. Bayesian filtering, Signal processing, Optics, Camera calibration and/or Mathematics expertise is desirable as well.
+ skill set:
	- Algorithm & Performance Engineer - SPG
	- The Apple Special Projects Group, working on autonomous systems, we are implementing highly complex algorithms. We are looking for a talented, dedicated and result oriented C++ Software Engineer to help improve, expand and further optimize our stack.
	- You will be part of a world class team with a highly diverse skillsets. Implementing complex numerical algorithms in a well designed, testable manner is as much part of an Algorithm & Performance Engineer's day-to-day as optimizing cache coherency of existing implementations, applying SIMD optimization or reducing memory footprint of modules. You will be addressing a vast variety of challenges from implementing GPU kernels over deploying and optimizing machine-learned models all the way to architecting, implementing and testing a complex software stack.
	- 3+ years of professional software development experience.
	- Expert knowledge in Modern C++.
	- Experience in either ComputerVision, High Performance Computing or Numerical Algorithms.
	- Familiarity with SIMD, concurrency and/or GPU kernels.
	- Passion for optimizations and efficient implementations.
	- High software engineering standards: desire to write clean, well-tested and well-structured code.
	- Excellent communication and presentation skills.
	- Track record of collaborating across teams, gathering requirements and delivering results.
	- Efficient, correct, clean C++ implementation of complex numerical algorithms using efficient data structures.
	- Low-level optimization, for example using SIMD, concurrency, cache optimizations, GPU kernels
	- Design, implementation, testing and maintenance of a complex software stack.
	- Implement visualization tooling to enable insights into complex algorithms.
	- Collaborate with testing and verification teams to ensure correctness and reliability of our stack.
+ skill set:
	- AIML - Engineering Manager, Machine Learning Data Platform
	- The Machine Learning Data Platform group builds cloud-native systems that enable customers across all Apple to design, build and innovate with ML-driven product features rapidly and at scale. These systems provide cloud-native solutions for data exploration, data pre-processing, ETL, ML fine-tuning, and large-scale batch inference for ML models including LLMs. We are looking for an experienced leader who wants to bring their passion for infrastructure & distributed systems to build world-class data platforms/products at a very large scale across cloud environments.
	- 5+ years of experience building, influencing, and growing successful infrastructure teams that consist of senior software engineers and first-line managers.
	- Strong experience in strategizing, planning, and delivering very large-scale cloud-native distributed systems and data infrastructure.
	- Experience managing expectations and relationships with multiple collaborators and project teams across various functional areas.
	- Excellent communication and leadership skills. Ability to influence across the organization and customer leadership.
	- Demonstrated ability to partner with recruiting to grow technical teams.
	- Experience with building production Machine Learning inference pipelines is a plus.
	- Experience building GPU cost/performance observability systems and optimizing them for cost and speed is a plus
	- Our platform is built using a variety of systems and services, from bare metal to managed infrastructure services, and everything in between. We use existing and open-source systems when possible, but do not shy away from building new products ourselves. As the Engineering Leader, you will work closely with customers, and cross-functional teams and lead the planning, execution, and success of technical projects. You also take full ownership of the strategic direction of products and solutions and influence customers, executives, and tour teams. This role requires technical expertise, experience in driving strategy, influence across the leadership stack, growing and mentoring senior engineers and first-time managers, relationship management, and multi-functional coordination.
	- Work closely with customers, cross-functional teams and lead the planning, execution, and success of technical projects. 
	- Lead, mentor, and grow a team of senior software engineers and first-line managers
	- Foster a healthy and collaborative culture as well as a high-output group 
	- Strategize, plan, and execute technical and cross-functional projects and provide leadership in an innovative and fast-paced environment 
	- Measure and improve the reliability and security of data infrastructure systems
+ skill set:
	- State Estimation Engineer — World Representation / Localization
	- Apple is looking for passionate, talented, and results-oriented robotics / state-estimation engineers to join our team and work on exciting technologies for autonomous systems. In this position, you will have the opportunity to work with a cross-functional team on innovative hardware/software technologies, enabled by the systems you build.
	- Joining our team, you will get to work with a fantastic group of talented and dedicated engineers and researchers. We hope you're excited about the values that drive us: 
		* Passion for the mission:  we're here to make something great. We take on whatever work is right for the mission and strive for the best possible results. 
		* Humility:  the right answer is more important than being right. We search for solutions as a team and value clear-eyed feedback. 
		* Lean habits:  you can't grow without limits. Time constraints and big goals encourage us to sharpen our focus and learn to make great decisions.
	- Experience developing and integrating state estimation algorithms for localization, calibration, mapping, or SLAM applications in robotic systems.
	- Experience developing algorithms which fuse many sensor modalities is a plus.
	- Very strong background in C++ development for Linux. Ability to understand and prototype in a python codebase is a plus.
	- Excellent communication: strong interpersonal, verbal and written skills.
	- Experience with machine learning and recent literature is a plus.
	- Develop, deploy, and scale both online and offline state-estimation algorithms for real-world robotic systems.
	- Build software, tools, and processes that accelerate your rate of experimentation, monitor performance, and inform what to try next.
	- Work with large quantities of sensor data on challenging real-world problems.
	- Collaborate with the team to deploy your work in a mission critical environment.
	- Masters or PhD in Computer Science, Robotics, Machine Learning, Engineering or equivalent professional experience.
	- The base pay range for this role is between $138,900 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location.
+ skill set:
	- AIML - Machine Learning Engineer - Machine Learning Platform Technology (MLPT)
	- Want to build the training platform that engineers rely on to develop next-generation Apple products and services?  As a machine learning engineer on our team, you will create software systems and algorithms to enable performant, scalable training for Apple's AI-driven experiences.  Join our team of highly skilled, impact-focused engineers!  This role also includes opportunities to open source your work and publish at top ML conferences.
	- Strong Python programming skills
	- Understanding of data structures, software design principles, and algorithms
	- Experience with deep learning frameworks, such as PyTorch, JAX, or TensorFlow
	- Experience developing model parallel and data parallel training solutions and other training optimizations
	- Experience building large-scale deep learning infrastructure or platforms for distributed model training
	- Experience with parallel training libraries such as torch.distributed, DeepSpeed, etc.
	- We're looking for strong machine learning engineers to help build next-generation tools for training deep learning models at scale. You'll be part of a small team of training technology experts, focusing on training speed and scalability. We're looking for candidates with polished coding skills as well as passion for machine learning and computational science. 
	- Design and develop components for our centralized, scalable ML platform. Help push the limits of existing solutions for large-scale training. Develop novel techniques to circumvent the limitations of these solutions. Deploy your techniques on high-impact tasks from our partners across the company building new Apple products and services. 
	- We encourage publishing novel work at top ML conferences such as ***MLSys or NeurIPS*** and releasing contributions as open source. 
	- In exchange, we offer a respectful work environment, flexible responsibilities, and access to world-class experts and growth opportunities—all at one of the best companies in the world.
	- PhD or Masters in the area of Computer Science or equivalent years of industry experience
+ skill set:
	- AIML - Machine Learning Engineer, Siri and Information Intelligence
	- The Siri information intelligence team is creating groundbreaking technology for artificial intelligence, machine learning and natural language processing! The features we create are redefining how hundreds of millions of people use their computers and mobile devices to search and find what they are looking for. Siri's universal search engine powers search features across a variety of Apple products, including Siri, Spotlight, Safari, Messages and Lookup. As part of this group, you will be doing large scale machine learning and deep learning to improve Query Understanding and Ranking of Siri Search and developing fundamental building blocks needed for Artificial Intelligence. This involves developing sophisticated machine learning models, using word embeddings and deep learning to understand the quality of matches, online learning to react quickly to change, natural language processing to understand queries, taking advantage of petabytes of data and signals from millions of users and combining information from multiple sources to provide the user with results that best satisfies their intent and information seeking needs.
	- 5+ years of experience in machine learning, information retrieval, indexing and retrieval
	- Mastery of two of following languages: Python, Go, Java, C++
	- Excellent knowledge and good practical skills in major machine learning algorithms
	- Excellent data analytical skills
	- Experience with large scale search and machine learning systems is highly desired
	- ***Experience with Hadoop, Hive, and/or Impala is a plus***
		* https://en.wikipedia.org/wiki/Apache_Impala
	- Good interpersonal skills
	- Good team player
	- Analyzing search suggestion ranking and relevance requirements, issues and opportunities
	- Understanding product requirements, translate them into modeling tasks and engineering tasks
	- Building machine learned models for search relevance, ranking and query understanding problems
	- Integrating search functions into Apple products, such as Siri, Spotlight, Safari, Messages, Lookup, etc.
	- Building end-to-end production system including query understanding, ranking and recommendation to power search
	- Utilizing Spark, Hadoop MapReduce, Hive, Impala to perform distributed data processing
+ skill set:
	- AIML - Software Engineer, Machine Learning Platform & Technologies
	- Imagine what you could do here. At Apple, great ideas have a way of becoming great products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish.
	- The Machine Learning Platform Team at Apple is looking for a Senior Engineer who has extensive experience in CI/CD, orchestration pipelines, build, release, and code management to manage critical parts of our development lifecycle. You will work with a dedicated team of engineers that will deliver the tooling and pipelines that enable consistent development of a high performance search stack, ensuring high quality delivery and enabling fast engineering turnaround.
	- 5+ years of experience in developing developer tooling, pipelines, automations and API
	- Thorough understanding of software development lifecycle, DevOps (build, continuous integration, deployment tools) and best practices.
	- Strong programming skills in Go, Python, or other language
	- Strong experience with Spinnaker and/or other delivery platforms
	- Strong experience with workflow platforms (Argo, Jenkins, or other)
	- Solid Kubernetes, AWS or other cloud experience
	- Strong communications and collaboration skills required
	- We design and build infrastructures to support features that empowers billions of Apple users. Our team processes trillions of links to find the best content to surface to users through search. We also analyze pages to extract critical features for indexing, ranking. We apply statistical analysis to improve link selection, freshness, retrieval rates, extraction quality, and many others. You'll have the opportunity to work with large scale systems with trillions of rows and many petabytes of data and incredible complexity.
	- Work in a team of engineers to deliver core tooling and pipelines for builds, validation, and deployment
	- Build tooling and SCM integrations that ensures code consistency, test coverage, and reliability
	- Develop pipelines for continuous, incremental delivery to preproduction environments
	- Extend tooling that helps engineers test, maintain, and deploy solutions across multiple repos and languages
	- Collaborate with DevOps and Release Engineering to enhance release speed and reliability
+ skill set:
	- AIML - Senior Data Infrastructure Software Engineer, Machine Learning Platform and Technology
	- The Data Infrastructure group within the AI/ML organization powers the analytics, experimentation and ML feature engineering that powers the Machine Learning technologies we all love in our Apple devices. Our mission is to provide cutting edge, reliable and easy to use infrastructure for ingesting, storing, processing and interacting with data while keeping Apple's users' data private and secure.
	- Are you a passionate about building scalable, reliable, maintainable infrastructure and solving data problems at scale? Come join us and be part of the Data Infrastructure journey.
	- 5 years of experience in software engineering with deep knowledge in computer science fundamentals.
	- Strong in data structures and algorithms. Must write good quality code with test cases and review PR's in fast faced environment.
	- Expert in one or more functional or object-oriented programming languages (Scala, Java)
	- Fluent in at least one scripting or systems programming language (Python, Bash and Go etc.)
	- ***Experience or knowledge in distributed data systems like Hadoop, Spark, Kafka or Flink.***
	- Experience or knowledge in public cloud is a big plus, preferably AWS.
	- Strong collaboration and communication (verbal and written) skills to work with diff
	- The role involves managing petabytes of data for machine learning applications and designing and implementing new frameworks to build scalable and efficient data processing workflows and machine learning pipelines. The successful candidate will be responsible for ensuring complete data lineage and legal workflow integration while optimizing performance and scalability. You will also be responsible for monitoring the performance of the system, optimizing it for cost and efficiency, and solving any issues that arise. This is an exciting opportunity to work on cutting-edge technology and collaborate with cross-functional teams to deliver high-quality software solutions. The ideal candidate should have a strong background in software development, experience with public cloud platforms, and familiarity with distributed databases.
	- ***Familiarity with distributed databases, such as DynamoDB, MongoDB, or Cassandra.***
	- ***Experience with containerization and orchestration technologies, such as Docker and Kubernetes.***
+ skill set:
	- AIML - Sr Product Manager, Siri Knowledge
	- Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Do you love taking on challenges that create a positive impact? Here, you could play a leading part in revolutionizing how people use their computers and mobile devices by empowering many ground-breaking intelligent experiences.
	- The Siri team is crafting innovative technology for virtual assistants, knowledge graph, and algorithmic search using machine learning, natural language processing, and artificial intelligence. We're looking for someone to lead product management efforts for Search and Knowledge in Siri, Spotlight, and Safari. You would work with top tier engineering and product teams to serve over 1 billion customers, crafting the type of magnificent user experiences that Apple customers expect and love. As a PM for Siri Knowledge and Search, you would drive search relevance, machine learning, and user experience improvement projects to build and improve end-to-end knowledge products on all major Apple platforms including iPhone, CarPlay, macOS, AppleTV and HomePod.
	- 5+ years experience as a Product Manager, Software Engineer, Engineering Manager, or similar role leading cross-functional product or software engineering teams.
	- 2+ years experience bringing a product from concept to completion, ideally related to joining together sophisticated backend and front-end systems with the user experience in mind
	- Experience driving large cross-functional projects with multiple workstreams
	- Self-motivated and proactive, with demonstrated creative and critical thinking capabilities
	- Self-sufficient in analyzing and drawing conclusions about the quality and product opportunity from raw and refined product data
	- Ability to, directly and indirectly, lead large teams for success
	- Experience shipping machine-learned products
	- Lead roadmap planning and detail execution of Siri Knowledge and Search in Siri, Spotlight, and Safari
	- Lead cross-functional teams from the product ideation/creation to full-stack delivery to our customers
	- Keep teams focused on the right priorities to meet aggressive deadlines; clearly communicate project progress to leads and executive team.
	- Collaborate with engineering, product, and executive leadership to drive outstanding year over year product delivery across large product areas at Apple.
	- Analyze product metrics to measure performance and plan the evolution of search and knowledge for immediate impact and longer-term (5+ years)
	- Be the voice for our customers; do whatever it takes to deliver the highest quality experience to our customers
	- Lead machine learning best practices in Siri team
	- Collaborate with other Apple teams to promote cross-team technology sharing
+ skill set:
	- Machine Learning Engineer
	- Machine learning is a critical pillar of Jane Street's global business, and our ever-changing trading environment serves as a unique, rapid-feedback platform for ML experimentation. 
	- Our ML Engineers develop the infrastructure that makes all of that possible. The work is wide-ranging, including things like:
		* Developing libraries for automating ML workflows and experiment evaluation, and helping us evaluate and onboard existing open-source tools
		* Digging in to the internals of open-source ML tools to extend their capabilities and fix fundamental bugs
		* Optimizing our systems to match the needs of our trading systems, whether that be for efficient training or low-latency inference
		* Building tools to train and evaluate models in parallel over large datasets
	- And much more besides. As an ML Engineer, you'll help drive the direction of an ML platform that is used daily by traders and researchers across every corner of the firm.
	- We're looking for accomplished and disciplined software engineers with deep experience in machine learning techniques and the software systems that power them. A good candidate will be curious, with a wide-ranging understanding of the open-source ML ecosystem, and an interest in the latest advances in ML, in both academic and industrial contexts.
	- Base salary is $250,000 - $300,000. Base salary is only one part of Jane Street total compensation, which includes an annual discretionary bonus.
+ skill set:
	- Senior Video Processing Algorithm Engineer
	- As a Senior Video Processing Algorithm Engineer, you will explore opportunities to research and develop video process algorithms in order to both improve real-time video quality & performance, and add new features on Zoom video products. 
	- Work across our stack, developing software ranging from Web Server to business application layer for our distributed, cloud-hosted backend. You will work alongside fellow experts in the field, you will deliver happiness to our users, and grow your knowledge base each and every day.  
	- Conduct performance research evaluations on image/video processing algorithms 
	- Perform feasibility analysis and validation, develop corresponding demos, and cooperate with team members for feature deployment on various platforms
	- Develop and prototype innovative algorithms in Zoom's video processing pipeline
	- Design new video features to tackle new and existing problems on Windows, macOS, IOS, Android and Linux systems
	- Collaborate with internal stakeholders across the business to drive the delivery of features, processes and happiness
	- PhD degree or Master degree with 4 years of working experiences in Computer Science, Electrical Engineering, or a related STEM field
	- Excellent C++/C and Python programming skills 
	- Strong experiences with libraries for deep learning, such as TensorFlow, PyTorch, Keras, Caffe, etc.
	- Solid knowledge of math, including linear algebra, numerical optimization, calculus, etc.
	- Hands-on experiences with video processing techniques (traditional method and deep learning method), such as image/video synthesis and generation, image enhancement, etc.
	- Hands-on experiences in ***deep learning (neural network, neural rendering, generative model, discriminative model, transfer learning, one-shot or few shot learning, Neural Architecture Search, etc.)***
	- Experience on deep learning structure (Transformer, CNN, RNN, etc.) optimization and acceleration
	- Ability to crystallize vague concepts into concise plans with clear documentation
	- Detail oriented, organized, ethical, responsible, and self-motivated
	- Strong communication skills and a desire to learn something new 
	- Basic understanding of Mandarin
+ skill set:
	- Video Processing Algorithm Engineer
	- Conduct research on image/video processing algorithms. Conduct performance evaluations on image/video processing algorithms. Leverage signal processing, machine learning and deep learning techniques to solve computer vision problems. Possess strong skills in the areas of development and real-time implementation of video processing system. Analyze factors that impact algorithm runtime on various platforms and come up with solutions for real-time implementation without sacrificing algorithm performance. Analyses at both algorithm level and coding level (x86/x64/Arm neon assembly optimization, data structure optimization, multiple thread, GPU acceleration, etc.) are conducted to achieve the goal. Develop and prototype innovative algorithms in Zoom's video processing pipeline. Develop a deep understanding of Zoom's video processing architecture and develop new features on top. Design new video features to tackle new and existing problems on Windows, macOS, IOS, Android and Linux systems. Perform feasibility analysis and validation, develop corresponding demos and cooperate with team members for feature deployment on various platforms. 
	- Master's degree in Electrical/Computer Engineering, Computer Science, a related field, or foreign equivalent and 1 year of post-baccalaureate experience in job offered or related. Applicants must have 1 year of experience with the following (1) C++/C and Python programming skills to develop computer vision/video processing features; (2) deep learning frameworks including TensorFlow, PyTorch, Keras, and Caffe; (3) video/image processing including semantic segmentation, object detection, object tracking, and image enhancement (traditional method or deep learning method); (4) Convolutional Neural Networks or (CNN) structure optimization and acceleration; and (5) project development skills including build and release, quality assessment, third party SDKs integration. Telecommuting Permitted.
+ skill set:
	- Machine Learning Engineer
	- You will be part of a team whose focus is to solve cutting edge AI problems and deploying models that constantly advance the state-of-the-art. You will be working across various Natural Language Processing (NLP) areas like summarization, topic segmentation, language modeling, coreference resolution and other interesting challenges that are challenging at Zoom's scale.
	- A person in this role is expected to able to carry out independent research without much supervision, collaborate with other researchers on larger scale projects, and provide directions to junior engineers on their research/engineering tasks.
	- Build and scale Machine Learning (ML) services which enable Zoom's products.
	- Research, build and deploy state-of-the-art Machine Learning models for Natural Language.  
	- Processing use cases – mostly in the conversational domain.
	- Take ML models from research all the way to production.
	- Integrate and support the ML services with product and operations teams.
	- PhD degree in Computer Science, Machine Learning, or related degree, or Masters with 3+ years of relevant experience
	- Strong expertise in NLP
	- Experience with one or more of the following: text summarization, natural language understanding, natural language generation, conversational AI, and multimodal AI modeling
	- Experience with deep learning modeling
	- Experience in machine learning toolkits (TensorFlow, PyTorch, Scikit, etc.)
	- Experience with large-scale data processing.
	- Strong coding skills in Python
	- Experience in distributed training and performance optimization on GPU's
	- Experience working on multi-modal ML
	- Familiarity with large-scale data processing and distributed systems.
	- Microservice, Docker, Kubernetes, REST API, AWS
+ skill set:
	- Research Scientist / Research Engineer
	- MosaicML is a deep learning startup with a mission to make ML training more efficient for everyone through fundamental innovations in algorithms, systems, and platforms. We believe that large scale training should be available beyond the well-resourced companies, and bridging the gap between research and industry is core to our success. Our products will enable our customers to train the best neural networks efficiently as possible within given time, cost, or other resource constraints – and to do so with a great user experience.
	- Develop methods for efficient neural network training. You will survey ideas in the literature and develop ideas of your own to change the way neural networks are trained to improve efficiency. This involves exacting scientific inquiry, rigorous empirical analysis of large-scale experiments, and building high-quality research artifacts.
	- Systematize knowledge and adjudicate scientific truth. At MosaicML, we are focused on transforming scientific knowledge into practical efficiency improvements. To do so, we navigate the messy machine learning literature, determine what holds up under scrutiny, and use that knowledge to build better models.
	- Advance the frontier of deep learning. You will drive ambitious research projects that push the limits of existing technology and explore new approaches that go beyond the state of the art.
	- Love our customers. Our goal is to make our customers successful when they train large deep learning models. We seek to encode our scientific expertise in our tools for the benefit of our customers. We love our customers, and we expect you to love them too!
	- Experience training large models. We're looking to hire researcher scientists and research engineers who have experience training modern neural networks for computer vision, natural language processing, and multimodal settings. Ideally, you will have experience training at large scales (100M+ parameters, and ideally 1B+ parameters) and conducting multi-node training. 
	- Extensive experience with NLP for deep learning. We are looking to hire research scientists who specialize in natural language processing.
	- Experience with data preparation and data quality for deep learning. We are looking to hire research scientists who have experience cleaning and curating large-scale data corpora (1B-100B examples) and using those corpora for deep learning.
	- Experience with deep generative model evaluation and improvement. We are looking to hire research scientists with experience evaluating generative models and using those insights to improve the models. 
	- A PhD is NOT required for this role. We are open to hiring candidates with bachelor's and master's degrees and to new graduates. We are open to hiring candidates who are currently in "research engineer" roles at other companies.
	- Keeping up to date with the research literature and thinking beyond the current state of the art.
	- Developing and implementing methods that improve the efficiency and efficacy of deep learning.
	- Rigorously evaluating these methods and communicating the results of your findings.
	- Proficiency with the fundamentals of deep learning.
	- Proficient software engineering skills and proficiency with PyTorch.
	- Knowledge of the systems aspects of how neural networks train and the resources used in the process of doing so.
	- Research experience in deep learning.
	- US work authorization required
	- Salary Range: $145K - $295K
	- Also includes equity (stock options) and benefits
+ skill set:
	- Principal Software Engineer
	- MosaicML is hiring a Principal Software Engineer to play a key role in building our product and in developing our team of software engineers.
	- Serve as a technical lead, overseeing and supervising projects and engineers on the team.
	- Play a leading hands-on role in the design and implementation of ML infrastructure and cloud platform software technologies
	- Drive our technology vision and roadmap
	- Establish software development best practices, and lead by example in applying them
	- Develop our engineering organization and culture through hiring, mentoring, and feedback.
	- ***8+ years of hands-on programming experience with at least one modern language such as Python, Go, or C++***
	- 8+ years of experience contributing to the architecture and design of large scale distributed systems and/or ML systems and tools
	- Strong sense of software design and usability of ML systems
	- Experience applying software engineering methodologies and best practices including coding standards, code reviews, build processes, testing, and security.
	- Prior experience in developing public cloud services or open source ML software is an advantage.
	- We value candidates who are curious about all parts of the company's success and are willing to learn new skills and technologies along the way.
	- Salary Range: $200K - $300K
+ skill set:
	- (Senior) Julia machine learning specialist
	- You love applying mathematical models to real data? You are expert about how to automatically learn from data?
	- What we offer
		* you will be part of an inspiring team of Julia professionals
		* every Friday is time for knowledge sharing, SDGs or generally trying out new product ideas
		* an open, reflective, and caring environment where you can feel like among friends
		* fair salary
	- What you will do
		* understand the kind of machine learning the customer needs
		* communicate with the customer
		* implement the models
		* connect the machine learning part with given data sources and sinks
		* build dashboard solutions
		* present results to the customer
		* give workshops and trainings about Julia, data science and machine learning
		* use your Fridays to empower SDGs (Sustainable Development Goals) with Julia
	- What you bring
		* completed Bachelor or Master or PhD in data science, statistics, computer science, mathematics, physics or a comparable education
		* programming experience in Julia
		* knowledge about Databases and SQL
		* expertise in two fields of machine learning
		* generic strategies for problem solving
		* good soft skills
		* enthusiasm about Julia
+ skill set:
	- (Senior) Julia machine learning engineer
	- You love to see machine learning models in production? You care more about the infrastructure than about the actual model itself?
	- What you will do
		* understand the production demands of the customer
		* communicate with the customer
		* setup appropriate architectures (e.g. for DevOps & MLOps)
		* setup monitoring and alerting
		* automatize training and evaluation of machine learning models
		* present results to the customer
		* give workshops and trainings about Julia and MLOps
		* use your Fridays to empower SDGs (Sustainable Development Goals) with Julia
	- What you bring
		* completed Bachelor or Master or PhD in data science, statistics, computer science, mathematics, physics or a comparable education
		* experience with DevOps & MLOps
		* expertise with docker and kubernetes
		* cloud knowledge, including infrastructure-as-code
		* generic strategies for problem solving
		* good soft skills
		* enthusiasm about Julia
+ We have built and contributed to foundational AI technologies like TensorFlow, PyTorch, TF Lite, XLA, TPUs, ONNXRuntime, Android, Apple Neural Engine, MLIR, LLVM, Clang, Swift and more. We are world-leading experts in compilers, runtimes, distributed computation, and hardware, and have deployed production workloads to billions of users and devices.
+ skill set:
	- Mojo Kernel Engineer
	- We believe that AI is a net positive force in the world. Our vision and mission are to help rebuild AI infrastructure to advance humanity and our environment. We will do whatever it takes to empower our customers, team, and company to benefit from that pursuit. You can read about our culture and careers here to understand how we work and what we value.
	- We are owners and advocates for the underlying technologies, developer platforms, product components, and infrastructure. These essential building blocks form the high-quality and coherent experiences our users expect. We aim to drive the pace of innovation for every AI/ML developer.
	- ML developers today face significant friction in taking trained models into deployment. They work in a highly fragmented space, with incomplete and patchwork solutions that require significant performance tuning and non-generalizable/ model-specific enhancements. At Modular, we are building the next generation AI platform that will radically improve the way developers build and deploy AI models.
	- A core part of this offering is providing a platform that allows developers reuse deployment specific tuning and enhancements across model families and frameworks. As an AI Kernel Engineer you will own developing and tuning performance libraries for AI models. You will develop kernels and algorithms to increase performance of kernels, reduce the activation volumes, speedup data pre- and post-processing, and in general increase the end-to-end performance of the model.
	- Design and optimize high-performance ML numeric and data manipulation kernels/operators.
	- Utilize low-level C/C++/Assembly programming to achieve state of the art performance. Your work will also entail potentially introducing new novel compiler and tools support.
	- Work with compiler, framework, runtime and performance teams to deliver end-to-end performance that fully utilizes today's complex server and mobile systems.
	- Collaborate with architects and hardware engineers to co-design future accelerators, including ISA for new hardware features and evolving ISA.
	- Collaborate with machine learning researchers to guide system development for future ML trends.
	- 6+ years of relevant work experience.
	- In-depth knowledge of C++ and low-level (micro)architectural performance is required.
	- 2+ years of experience working on complex code and systems.
	- Experience with HPC programming and accelerator languages such as CUDA, OpenCL, SYCL, etc.
	- Experience with performance modeling and performance data analysis.
	- Understanding of Parallelization techniques for ML / HPC Acceleration.
	- Deep interest in machine learning technologies and use cases.
	- Creativity and curiosity for solving complex problems, a team-oriented attitude that enables you to work well with others, and alignment with our culture.
+ skill set:
	- Machine Learning Engineer, Beijing, China
	- Research and develop key technologies of AI compilers and automatic optimization tools
	- Research and develop software and hardware co-design methods and related tools
	- For the IPU chip architecture, develop new AI compilation optimization methods
	- Participate in the work of the AI compiler open source community
	- Strong background in computer architecture, in-depth understanding of at least one AI chip architecture
	- Experience with assembly-level performance tuning on AI chips (including GPUs or other AI chips)
	- Solid C++ system development ability
	- Understand the basic principles of deep learning training/inference framework
	- Experience with AI processor adapting mainstream deep learning framework is preferred
	- Bachelor degree or above in computer, electronics, communication or mathematics
	- Excellent teamwork ability, self-motivation and results-driven
+ skill set:
	- Lead ML & AI Engineer
	- Develop a Tech driven innovation strategy for TIL based on the principles of Design Thinking.
	- Identify and Define relevant channels of engagement across HERE for TIL to expand the impact footprint of the business vertical
	- Define IP monetization strategy that will enable HERE to earn revenue /enter new market
	- Define startup/university engagement framework for successful collaboration with these bodies, in line with HERE's business strategy.
	- Identify the domains in technology where TIL and HERE should engage and defining a strategy for realization of same through development of disruptive prototypes in line with HERE business strategy
	- Enabling invention of new frameworks /solutions in the domain of AIML, Blockchain, Location intelligence, distributed computing,quantum computing, tinyML, etc
	- Improving the innovation index of HERE, by getting research papers published in ***NeurIPS, IEEE***, and awarded recognition in international forums like CES, Stevie ,etc
	- Enabling y-O-y increase in number of patents being filed by the team
	- Work with the Manager to Identify and Define lead KPIs related to effective assessment of performance at individual level and impact assessment of innovation implementation at business unit level
	- Support team to design experiments and stay up to date with industry inventions in AIML(esp Computer Vision), blockchain, quantum computing, Location Intelligence , distributed computing LiDAR and Drone processing, 3D modelling , AR/VR
	- Identify relevant research papers in above mentioned tech domains and enable team to design solutions for the same
	- MS/ MSc/ PhD in the field of Computer Science, Machine Learning, Mathematics, Location Intelligence , Signal Processing or related quantitative field
	- Understanding of statistical analysis of data and mathematical modeling
	- Knowledge of Clustering, Regression, Decision Trees, Forecasting, RandomForest, XGBoost, SVM, Deep Neural Networks (CNN, GRU, LSTM, Activation and Pooling layers), GAN, Encoders, Transformers, BERT, Graph Neural Network , diffusion models
	- Experience in Object Detection, Localization, Segmentation using Computer Vision and Deep Learning
	- Ability to handle large datasets and images of high resolution (4K) using Scala, Hadoop, Pyspark
	- Candidates with MSc/MS in Mathematics/Computer Science, Machine learning and AI or related quantitative needs 10yrs of experience. Candidates with PhD in related fields may have 5 yrs of experience
	- The candidate should possess a certified degree in the field of quantum physics and other related fields.
	- Should have adequate knowledge about machine learning and artificial intelligence.
	- Prior experience through internships and volunteering with professionals will also be needed to apply for the quantum engineer profile.
	- Should possess in-depth knowledge about the emerging and simulating fields and approach challenges with unique perspectives.
	- The candidates should also possess a basic knowledge of the different programming language
	- 8 or more years of experience in research and/or corporates with multi tech domain exposure
	- Demonstrated experience in setting up new business verticals and leading them to success
	- Demonstrated experience in successful team and performance management
	- Demonstrated experience in designing business strategy and successful execution of the same
	- Have prior experience in designing innovation strategy with organization wide impact
	- Have minimum 10 patents/ international publications in high impact factor journals like ***NeurIPS, IEEE***, etc
	- Shows a combined experience in both research and business field
	- Startup experience is advantageous and highly desirable
+ skill set:
	- A data scientist experienced with using real-world data to analyze and develop algorithms that are incorporated into commercially profitable product lines. Someone who can leverage clustering algorithms to model non-Gaussian statistics;  who is able to study the physical characteristics of a problem and design mathematical models that solve problems from first principles;  has a desire to learn, develop, and keep up to pace with the state-of-the-art machine learning based algorithms; has the ability to be a subject matter expert on HERE's technologies and product lines and leverage that knowledge to identify derivative algorithms to create new growth opportunities.
	- Knowledge of data mining and analytic methods.
	- Perform your day-to-day work by programming in Python and work with associated statistical and analytics packages in python.
	- Leverage AWS technologies and use them to develop modelling pipelines.
	- Proficiency with statistical analysis packages.
+ Experience tinkering with or productizing LLMs, CV, vector databases, and the other latest AI technologies
+ skill set:
	- Software Engineer, Generative AI
	- Software is eating the world, but AI is eating software. We live in unprecedented times – AI has the potential to exponentially augment human intelligence. Every person will have a personal tutor, coach, assistant, personal shopper, travel guide, and therapist throughout life. As the world adjusts to this new reality, leading platform companies are scrambling to build LLMs at billion scale, while large enterprises figure out how to add it to their products. To make them safe, aligned and actually useful, these models need human eval and reinforcement learning through human feedback (RLHF) during pre-training, fine-tuning, and production evaluations. This is the main innovation that's enabled ChatGPT to get such a large headstart among competition.
	- At Scale, our Generative AI Data Engine powers the most advanced LLMs and generative models in the world through world-class RLHF, human data generation, model evaluation, safety, and alignment. The data we are producing is some of the most important work for how humanity will interact with AI.
	- We're looking for entrepreneurial Software Engineers to join our team. In this role, you'll be given the opportunity to build any of these products to meaningfully drive millions of dollars in revenue. You'll also get widespread exposure to the forefront of the AI race as Scale sees it in enterprises, startups, governments, and large tech companies.
	- The ideal person is a natural entrepreneurial engineer who can take an ambiguous scope and lead the execution of outcomes, doing what it takes to hit them incl coding, talking to customers, defining requirements, etc. We strongly believe the best engineers own outcomes and deeply understand customer problems. This tweet by Greg Brockman summarizes it well: https://twitter.com/gdb/status/1514291063233474560
	- You're excited about solving customer problems, and you pick the technologies and tactics that balance speed, function, and long-term robustness.
	- Own large new areas within our product
	- Work across backend, frontend, and interacting with LLMs and/or other ML models
	- Deliver experiments at a high velocity and level of quality to engage our customers
	- Work across the entire product lifecycle from conceptualization through production
	- Be able, and willing, to multi-task and learn new technologies quickly
	- Collaborating with cross-functional teams to define, design, and ship new product features and experiences.
	- 5+ years of full-time engineering experience, post-graduation
	- Proficiencies in one or more of Python, Node, React, Next.js and MongoDB
	- Solid background in algorithms, data structures, and object-oriented programming.
	- Experience scaling products at hyper-growth startups
	- Excitement to work with AI technologies
	- Strong written and verbal communication skills
	- Strong problem-solving skills, and be able to work independently or as part of a team.
	- Strong knowledge of software engineering best practices.
	- Have experience with AI platforms and technologies, including generative models and LLMs.
	- Experience building ML infrastructure and AI-powered solutions.
+ skill set:
	- Senior Software Engineer, AV-CV
	- At Scale AI, we are building tools to across the AI development lifecycle. Data is the new code, and Scale AI helps companies get the data they need, whether it's for self-driving vehicles, artificial general intelligence, or robotics. The AV-CV Team (Autonomous Vehicles / Computer Vision) builds the infrastructure for labeling Lidar, Mapping, and Camera data. If seeing autonomous vehicles excited you, you'll be seeing a lot of that on the AV-CV team. The team builds the tools for labeling Lidar pointclouds, annotating image and video feeds, and linking them together to build perception models.
	- Own large new areas within our product
	- Become an expert in working closely with customers across many CV industries
	- Build technologies ranging from frontend and backend to automated ML systems
	- Work deeply with sales and marketing to run demos and increase customer engagement
	- Work across the entire product lifecycle from conceptualization through production
	- Be able, and willing, to multi-task and learn new technologies quickly
	- 5+ years of full-time engineering experience
	- 2+ years working with TypeScript/JavaScript, HTML, CSS, and related web technologies (React, Next.js, Webpack)
	- Experience working with distributed systems and cloud environments
	- Experience working with a production database (Postgres, MongoDB, MySQL, MS SQL) and schema migrations
	- Solid background in algorithms, data structures, and object-oriented programming.
	- Excitement to work with AI technologies
	- Strong written and verbal communication skills
	- Strong problem-solving skills, and be able to work independently or as part of a team.
+ skill set:
	- Machine Learning Research Engineer - Public Sector
	- The goal of a Machine Learning Engineer at Scale is to bring techniques in the fields of computer vision, deep learning and deep reinforcement learning, or natural language processing into a production environment to improve Scale's products and customer experience. Our research engineers take advantage of our unique access to massive datasets to deliver improvements to our customers.
	- We are building a large hybrid human-machine system in service of ML pipelines for Federal Government customers. We currently complete millions of tasks a month, and will grow to complete billions of tasks monthly.
	- Take state of the art models developed internally and from the community, use them in production to solve problems for our customers and taskers.
	- Take models currently in production, identify areas for improvement, improve them using retraining and hyperparameter searches, then deploy without regressing on core model characteristics
	- Work with product and research teams to identify opportunities for improvement in our current product line and for enabling upcoming product lines
	- Work with massive datasets to develop both generic models as well as fine tune models for specific products
	- Build the scalable ML platform to automate our ML service
	- Be a representative for how to apply machine learning and related techniques throughout the engineering and product organization
	- Be able, and willing, to multi-task and learn new technologies quickly
	- US citizenship and US Government Security Clearance is a requirement (TS/SCI preferred)
	- Extensive experience using computer vision, deep learning and deep reinforcement Learning, or natural language processing in a production environment
	- Solid background in algorithms, data structures, and object-oriented programming
	- Strong programing skills in Python or Javascript, experience in Tensorflow or PyTorch
	- Graduate degree in Computer Science, Machine Learning or Artificial Intelligence specialization
	- Experience working with cloud technology stack (eg. AWS or GCP) and developing machine learning models in a cloud environment
	- Experience with generative AI models
+ skill set:
	- Machine Learning Research Engineer, Generative AI
	- Performant model code, high quality data, and robust evaluation methods form the foundation of an AI system. Scale's leading end-to-end solutions for the ML lifecycle based on real-world data will continue to set the bar for the data-centric AI movement. Scale's Generative AI team focuses on building models to accelerate AI adoption for some of the largest companies in the world. 
	- Your focus will be on developing Models as a Service using a variety of Machine Learning techniques. You will be involved end-to-end from coordinating with operations to create high quality datasets to productionizing models for our customers. If you are excited about shaping the future of the data-centric AI movement, we would love to hear from you!
	- Apply state of the art models, developed both internally and from the community, in production to solve problems for our customers and data labelers. 
	- Work with product and research teams to identify opportunities for ongoing and upcoming services.
	- Explore approaches that integrate human feedback and assisted evaluation into existing product lines. 
	- Work closely with customers - some of the most sophisticated ML organizations in the world - to quickly prototype and build new deep learning models targeted at multi-modal content understanding problems.
	- At least 3 to 5 years of model training, deployment and maintenance experience in a production environment
	- Strong skills in NLP, LLM and deep learning 
	- Solid background in algorithms, data structures, and object-oriented programming
	- Experience working with cloud technology stack (eg. AWS or GCP) and developing machine learning models in a cloud environment
	- Experience in dealing with large scale AI problems, ideally in the generative-AI field
	- Demonstrated expertise in large vision-language models for diverse real-world applications, e.g. classification, detection, question-answering, etc. 
	- Published research in areas of machine learning at major conferences (***NeurIPS, ICML, EMNLP, CVPR***, etc.) and/or journals
	- Strong high-level programming skills (e.g., Python), frameworks and tools such as ***DeepSpeed, Pytorch lightning, kuberflow, TensorFlow***, etc. 
	- Strong written and verbal communication skills to operate in a cross functional team environment
+ skill set:
	- Stability AI is a community and mission driven, open-source artificial intelligence company that cares deeply about real-world implications and applications. Our most considerable advances grow from our diversity in working across multiple teams and disciplines. We are unafraid to go against established norms and explore creativity. We are motivated to generate breakthrough ideas and convert them into tangible solutions. Our vibrant communities consist of experts, leaders and partners across the globe who are developing cutting-edge open AI models for Image, Language, Audio, Video, 3D and Biology.
	- We are looking for a versatile Software Engineer who will do anything it takes to design and implement our projects for Japanese partners, clients, and the community. We will focus on projects related to image/video models, large language models, and chatbots.
	- You will adapt quickly as we try various approaches to various industries in a fast-changing environment. You will have access to state-of-the-art high-performance computing resources, and you will be able to work alongside top researchers and engineers to truly make an impact in the fast-growing world of generative AI. 
	- Lead efforts to drive the design, development, and productionization of ML systems, and present the solutions to partners and clients in Japan
	- Work on the commercial side - productionizing generative models and building the infrastructure to serve them at scale; collaborate with ML Engineers to deploy customized models for commercial applications
	- Be a strategic thought partner both internally and externally on driving business impact through machine learning
	- Build pipelines to ingest and process data (e.g. images and text) for feeding into ML models
	- Provide technical advice to partners/clients on the integration of generative models into their products
	- Good communication skills with fluency in Japanese and business-level English proficiency
	- 5+ years of software development experience with high proficiency in 2 or more languages (Python required, Go is a plus) across a variety of projects
	- Experience with MLOps
	- Experience with data engineering (data pipelines for ML projects)
	- Experience with Linux and command line tools
	- Experience with cloud computing and APIs
	- Experience with web scraping/crawling is a plus
	- Experience with Tensorflow/PyTorch is a plus
	- Experience with Kubernetes and containers is a plus
+ skill set:
	- Research Engineer, Music
	- We are looking for ML Research Engineers who are passionate about generative models for music creation. In particular, we are looking for people who can explore new ideas and architectures for music generation models; highly creative people who straddle research and engineering and who are motivated to push the boundaries of generative music research, not just in state-of-the-art performance, but also in balancing performance and resource usage. You will have access to state-of-the-art, high-performance computing resources, and you will work alongside top researchers and engineers to truly make an impact in the fast growing world of generative AI.
	- Work with the rest of the research team and the open-source community on developing the next generation of generative audio models
	- Prototype and productionize model architecture improvements and new features
	- Maintain and innovate on open-source code repositories for generative AI audio models, including custom model code, training code, and fine-tuning code
	- Work with Product, Engineering and Commercial teams on model deployment and customized training
	- Create interactive demos and interfaces for generative models, demonstrating simple use cases in an intuitive and fun way
	- Optimize model architectures and inference code for performance on consumer devices
	- Publish results at top conferences, in journals, and in blog posts
	- Keep up to date with the latest research advancements in the field and work them into open-source repos, reimplementing as needed to ensure an open license
	- 3+ years working on machine learning projects, including training, fine tuning and refining models
	- Publication of papers, projects, and blog posts that had a high impact in generative AI
	- Experience maintaining high-quality, well-documented open-source code repositories for AI models
	- Experience with music generation models, preferably working in the time domain (Jukebox, SampleRNN, RAVE, etc.)
	- Ability to iterate quickly on public code-bases with attention to backwards compatibility, usability, and readability
	- Experience with Python scientific stack, PyTorch, and creating Jupyter/Colab notebooks
	- Ability to communicate machine learning concepts and results effectively through writing and visualization
	- Experience training and/or deploying ML models with Amazon AWS (Sagemaker a plus) or Google Cloud
	- Experience with data engineering, including cleaning and maintaining large heterogeneous datasets
	- Experience building interactive web demos that serve generative ML models
	- Experience with the open-source ML ecosystem (HuggingFace, W&B, etc.)
	- Experience with Linux and command line tools
	- Familiarity with digital signal processing and audio engineering concepts
	- Experience with Python audio processing libraries such as librosa, torchaudio, or similar
+ skill set:
	- Machine Learning Engineer, Audio
	- We are looking for Machine Learning Engineers to work on our audio team who are passionate about generative models and creative applications of AI. In particular, we are looking for people who have experience of developing model serving pipelines to operate at scale and have knowledge of state of the art techniques for optimisation and feature development. We want highly creative ML engineers who are motivated to push the boundaries of generative audio models. You will have access to state-of-the-art high performance computing resources and you will be able to work alongside top researchers and engineers to truly make an impact in the fast growing world of generative AI.
	- Lead efforts to drive the design, development and production of customer-facing ML music, speech and audio generation systems, with specific reference to inference and API environments
	- Work with the Audio, Platform and Inference teams on building pipelines for the next generation of models, where you may assist with areas such as optimization, model tuning and deployment, HPC clusters, and tooling
	- Be a strategic thought partner for leaders across the organization on driving business impact through machine learning
	- Work on the commercial side - productionizing generative models, and building the infrastructure to serve them at scale
	- Produce events and metrics in our data warehouse so that we can analyze critical business metrics like cost, performance, reliability, etc.
	- Be part of the team that brings new Stability audio models and pipelines into existence for API customers
	- Prototype and productionize inference platform improvements and new features 
	- 5+ years working on machine learning projects, including inference and pipeline development
	- Solid knowledge of Python scientific stack, PyTorch and at least one high-performance inference framework (e.g. ***TensorRT***)
	- Experience profiling and optimizing deep neural networks, including knowledge of GPU profiling tools such as NVIDIA Nsight
	- Experience with Python audio processing libraries such as librosa, torchaudio, or similar
	- Experience with cloud orchestration systems such as Kubernetes and cloud providers such as AWS, GCP, and Azure
	- Ability to rapidly prototype solutions and iterate on them with tight product deadlines
	- Experience with training and/or deploying ML models with Amazon AWS (Sagemaker a plus) or Google Cloud
	- Strong communication, collaboration, and documentation skills
	- Experience with Linux and command line tools
	- Evidence of interest in music / audio projects is valued
+ skill set:
	- Machine Learning Engineer, 3D Research
	- We are looking for experts in Machine Learning and 3D Graphics, who are passionate about generative models and creative applications of AI. In particular, we are looking for people who share our mission of open-sourcing machine learning models; people who do not believe AI models should be controlled by a centralized gatekeeper behind a closed wall, but rather be truly open and in control by all. You will have access to state-of-the-art high performance computing resources and you will work alongside other creative, hard-working top researchers and engineers, to make a lasting, positive impact in the fast-growing world of generative AI.
	- Contribute to the creation and improvement of applications and use cases such as text-to-3D, 2D-to-3D, text-to-4D, simple and fast 3D editing… and make systematic progress towards enabling anyone to easily and quickly create complex, animated and interactive 3D characters and environments
	- Take ownership of ML and 3D graphics new and existing features, across the whole product lifecycle, from developing prototypes, to assisting the teams charged with production and maintenance - with minimal supervision
	- Collaborate within Stability and in the open-source community on developing the next generation of 3D-aware neural models, where you may assist with areas such as optimization of model training, model tuning, dataset engineering, automation of processes, tooling, data translation, integration in game engines, etc.
	- Always look for opportunities to delight our customers and improve their life through AI
	- ***If you want: publish new ideas on arxiv and in major conferences***
	- 3+ years working on state-of-the-art ML or 3D graphics projects (ideally both), including training, fine-tuning ML models, neural graphics, raytracing, etc.
	- Experience researching and implementing SOTA algorithms related to ML or 3D, e.g Neural Radiance Fields, real-time 3D graphics, diffusion models, 3D file format conversion, etc.
	- Experience with Python scientific stack, PyTorch or similar ML frameworks
	- Communicate ML insights and results effectively: verbally, in writing and through visualization
	- Self-motivated, well-organized (e.g. keep track of your own priorities and refine the plan according to new insights), self-reliant (able to debug complex issues with minimal supervision)
	- ML and 3D open-source projects or influential publications
	- Performance optimization, such as profiling shaders and/or ML systems, C++/CUDA, algorithmic improvements, ML quantization and distillation
	- 3D graphics and game development, e.g. OpenGL, DirectX, Vulkan, Unreal Engine, Unity, Godot
	- JAX, TPUs, compiler development
+ skill set:
	- Machine Learning Engineer
	- We are looking for a versatile ML Engineer who will train and deploy generative models for Japanese partners, clients, and the broader community.  You will adapt quickly as we try various approaches to various industries in a fast-changing environment. We will focus especially on image/video models, large language models, and chatbots. 
	- You will have access to state-of-the-art high-performance computing resources and you will be able to work alongside top researchers and engineers to truly make an impact in the fast-growing world of generative AI.
	- Lead efforts to drive the design, development, and productionization of ML models and systems, and present the solutions to partners and clients in Japan
	- Work on the commercial side - productionizing generative models and building the infrastructure to serve them at scale; collaborate with other engineers and researchers to build customized models for commercial applications
	- Be a strategic thought partner both internally and externally on driving business impact through machine learning
	- Conduct experiments on e.g. fine-tuning image generation models or LLMs for the Japan market
	- Prototype and productionize model architecture improvements and new features
	- Provide technical advice to partners/clients on generative models
	- Good communication skills with fluency in Japanese and business-level English proficiency
	- 5+ years working on machine learning projects, including training, fine tuning and refining models
	- Familiarity with recent, important papers and projects in the generative machine learning space
	- Experience with Python scientific stack, PyTorch, creating Jupyter/Colab notebooks
	- Experience with the open-source ML ecosystem (HuggingFace, W&B, etc.)
	- Experience with training and/or deploying ML models with Amazon AWS (Sagemaker a plus) or Google Cloud
	- Experience with Linux and command line tools
+ skill set:
	- Machine Learning Engineer, Research
	- We are looking for Machine Learning engineers who are passionate about generative models and creative applications of AI. In particular, we are looking for people who share our mission of open-source machine learning models; people who do not believe AI models should be controlled by a centralized gatekeeper behind a closed wall, but rather be truly open and in control by all. We want highly creative ML engineers who are motivated to push the boundaries of generative models. You will have access to state-of-the-art high performance computing resources and you will be able to work alongside top researchers and engineers to truly make an impact in the fast growing world of generative AI.
	- Lead efforts to drive the design development and production of ML systems, and  present the solutions to customers 
	- Work with Research team on developing the next generation of models, where you may assist with areas such as optimization of model training, model tuning, dataset engineering, HPC clusters, tooling, and work on open-source efforts
	- Be a strategic thought partner for leaders across the organization on driving business impact through machine learning
	- Work on the Commercial side - productioning generative models, and building the infrastructure to serve them at scale, or work to build customized models for commercial applications
	- Prototype and productionize model architecture improvements and new features 
	- 3+ years working on machine learning projects, including training, fine tuning and refining models
	- Experience with Python scientific stack, PyTorch, creating Jupyter/Colab notebooks
	- Experience with JAX / TPUs / CUDA-level / JavaScript (TensorFlow.js etc) a plus
	- Ability to communicate machine learning concepts and results effectively through writing and visualization
	- Experience with training and/or deploying ML models with Amazon AWS (Sagemaker a plus) or Google Cloud
	- Experience with building interactive web demos that serve generative ML models
	- Experience with the open-source ML ecosystem (HuggingFace, W&B, etc.)
	- Experience with Linux and command line tools
+ skill set:
	- Machine Learning Engineer [Dept: Business Analytics]
	- Master's degree or foreign equivalent in Operation Research, Machine Learning, Industrial Engineering or related field and 3 years of experience in the job offered or related occupation.
	- 1 year of experience with each of the following skills is required:
	- Statistics
	- Machine Learning
	- Linear and convex optimization
	- Convex and Stochastic Optimization
	- Large scale mixed integer Optimization
	- Metaheuristics
	- Python
	- Multiple positions available in Cupertino, California and various unanticipated locations throughout the USA. Design Apple's future supply chain and planning processes leveraging linear, mixed-integer and stochastic optimization, machine learning and statistics. Collaborate with business teams to find opportunities, understand requirements, prepare technical solutions and drive critical projects. Design data science approach, applying tried-and tested techniques or developing custom algorithms as needed by the business problem. Collaborate with data engineers and infrastructure partners to implement robust solutions and operationalize models. Enhance and evolve solutions to meet changing business needs with agility. Work collaboratively across teams and present results of analyses and models to partners and senior leaders. Research new technologies and methods across data science, data engineering, and data visualization to improve the technical capabilities of the team. 40 hours/week.
+ skill set:
	- AIML - Software Engineer, MLR
	- As part of Apple's Machine Learning Research organization, we do world-class scientific research and build the technologies that will power future products at Apple.  The techniques and tools we create will impact ML solutions across Apple, which in turn power most of the features we deliver to billions of consumers worldwide.  We are looking for highly motivated, result-oriented engineers with a strong background in system engineering and software development to join our team. In this position, you will work with researchers across the Machine Learning Research group to build scalable, distributed training and research pipelines in the latest and greatest generative models.
	- Expert in Python programming
	- Expert in at least one ML framework (PyTorch preferred but tensor flow or jax are ok as well).
	- Experience with CUDA programming, and/or High-Performance Computing and/or distributed computing.
	- Experience with open-source projects and collaborative software development.
	- Excellent communication skills.
	- Experience and passion to circumvent unexpected roadblocks
	- Past research experience is a plus
	- Work with researchers on the team to build high-performance and scalable software addressing novel ML research algorithms - Apply solid software engineering skills, leverage experience to deal with the unexpected, explore research software solutions and pave the way to future Machine Learning toolboxes. Be part of a small team dedicated to advancing ML algorithms and techniques - Is this you? If so we'd love to hear from you.
	- M.S. or PhD in Computer Science (or related fields) or related fields or equivalent experience.
+ skill set:
	- AIML - Machine Learning Engineer, Siri Information & Intelligence (SII)
	- Search ranking is the technology that presents the most relevant results to a search query, giving the user a rewarding experience with Apple's search products. The Siri Information Intelligence teams are building groundbreaking technology using algorithmic search, machine learning, natural language processing, and artificial intelligence.
	- The features we build are redefining how hundreds of millions of people interact with their favorite devices. Siri's universal search engine powers search features across a variety of Apple products, including Siri, Spotlight, Safari, Messages and Lookup. As a part of this group you will have an opportunity to contribute to on-device search technologies and imagine and build products that delight our customers every single day.
	- Strong problem-solving skills, ability to abstract out details and simplify a problem
	- Strong programming skills, e.g. C/C++, python
	- Strong background in computer science: algorithms and data structures.
	- Knowledge of data mining and machine learning
	- Strong interpersonal skills; able to work independently as well as in a team
	- Our team builds the technology for search ranking that brings the “ideal” search results to the top. In pursuit of this, we are interested in ways to rank search results in a way that is sensitive to user-privacy, and in ways to evaluate the quality of answers that are being returned to user queries. This leads us to different adventures, ranging from building indexes for very fast retrieval and search, reimagining query processing using state-of-the-art text processing methods, statistical methods for result evaluation, and many more.
	- BMS, Ph.D. in a related field , or equivalent experience
+ skill set:
	- Machine Learning Engineer - Apple Vision Pro
	- Apple Vision Pro is a revolutionary spatial computer that seamlessly blends digital content with your physical space. It will allow us to do the things we love in ways never before possible — all while staying connected to the people around us.
	- Our team builds technology that defines industry standards, and we are seeking people who thrive to innovate and strive to build best-in-class high-impact products. We value passion for excellence and a deep commitment to excellence, and if you want to impact millions of customers by working on the most advanced technology solutions, we want to talk to you.
	- Strong programming skills in Python and/or C++ with 5+ years of demonstrated ability in using these languages for machine learning (machine learning) modeling and applied research
	- Hands-on experience with building deep learning applications
	- Expertise in using machine learning toolkits such as PyTorch, TensorFlow, etc
	- Experience developing and optimizing algorithms that run efficiently on resource constrained platforms
	- Ability to drive early-stage research projects with risks and ambiguity
	- Passionate about delivering high-quality products, seeking to solve everyday problems in innovative ways
	- Excellent programming, problem solving and analytical skills
	- Communication and collaboration skills in a multi-functional setting
	- Ability to work hands-on with multi-functional teams
	- Ability to work under tight schedules and deliver under pressure
	- Ability to thrive in a collaborative environment and communicate clearly and confidently with partner teams
	- The Vision Products Group at Apple is actively looking for a highly motivated Machine Learning Engineer to contribute to and build Apple's future technologies in the spatial computing space. The successful candidate will demonstrate deep knowledge of, and hands-on experience, with designing, implementing, and optimizing machine learning algorithms to tackle ambitious problems. Candidate is expected to be proficient in machine learning and deep learning and be comfortable in applying their machine learning background and problem-solving skills to develop high-quality machine learning solutions that contribute to Apple's revolutionary roadmap.
	- As an Machine Learning Engineer in the Vision Products Group at Apple, you will partner with the algorithm designers to collaboratively design machine learning based solutions to solve high-impact problems on Apple product(s).
	- The primary responsibilities associated with this role, include algorithm design, implementation and optimization, integrating ground breaking research into production frameworks, and collaborating closely with product teams before and after feature launch.
	- You will work multi-functionally with multiple teams at Apple, drive requirements and deliver the end solution
	- You will help evaluate various candidate approaches for optimizing machine learning pipelines for training and inference - these could include (but are not limited to) algorithm tuning, hyper parameter tuning, hardware and software co-design.
	- You will write clean, maintainable and production code with appropriate documentation and tests.
	- You will debug quality related issues in machine learning pipelines.
	- You will contribute to architecture decisions, design reviews and peer code reviews.
	- You will be a force-multiplier, by enabling team-members to be more productive
	- M.S or Ph.D. in deep learning/computer vision/natural language processing/machine learning/computer science with 5+ years of equivalent industry experience (or in exceptional cases, BS with proven track record of relevant industry experience).
	- Bonus: Strong publication record at top conferences
	- The base pay range for this role is between $170,700 and $300,200, and your base pay will depend on your skills, qualifications, experience, and location.
+ skill set:
	- Machine Learning Engineer (Dept: SII Info Intelligence US)
	- Master's degree or foreign equivalent in Computer Science, Statistics, Software Engineering, Biomedical Engineering or related field and 2 years of experience in the job offered or related occupation.
	- 1 year of experience with each of the following skills is required:
		* Machine Learning and generative models;
		* Deep learning and language models;
		* Natural language processing;
		* Continuous integration;
		* Python frameworks needed for applied ML research;
		* Data-centric ML; and
		* Information retrieval and knowledge graphs
	- Multiple positions available in Cupertino, CA and various unanticipated locations throughout the USA. Developing and implementing production-ready algorithms and method. Co-developing machine learning solutions. Providing architectural guidance on transitioning prototypes to high-performance production models. Providing feedback on tools and new features needed back to platform teams.. Design, implement, and ship new machine learning algorithms and techniques and collaborate with production development team and engineers. Build the platform that enables teams across Apple to develop machine-learning solutions that power intelligent user experiences. Provide technical guidance to product teams on the choice of machine learning approaches appropriate for a task.
+ skill set:
	- ISE, SIML - Robustness Analysis & AI Safety ML Engineer
	- Are you passionate about inclusion, fairness and safety in AI powered features that ship on 1.5B Apple products across the globe? Are you excited about Generative AI and motivated to build out robust and safety capabilities of generative models? 
	- We are the Intelligence System Experience (ISE) team within Apple's software organization. The team works at the intersection between multimodal machine learning and system experiences. System Experience (Springboard, Settings), Keyboards, Pencil & Paper, Shortcuts are some of the experiences that the team oversees. These experiences that our users enjoy are backed by production scale ML workflows. Visual Understanding of People, Text, Handwriting & Scenes, multilingual NLP for writing workflows & knowledge extraction, behavioral modeling for proactive suggestions, and privacy preserving learning are areas our multi disciplinary ML teams focus on.
	- We have multiple ongoing efforts involving generative models, and we are looking for talented candidates to ensure that features built on top of such models are safe for deployment, and perform equally well for diverse customers within Apple's global user base.
	- Good ML fundamentals
	- Experience in training machine learning models (NLP or computer vision)
	- Familiarity with challenges associated to building robust ML datasets and models: definition and coverage of target data distribution, potential biases, potential failure modes
	- Demonstrated experience in accessing and addressing potential risks and ensuring the safety and fairness in generative models. Prior experience in LLM Safety is a big plus.
	- Strong programming skills in Python to operate models and data at scale
	- Familiarity with ML toolkits, e.g., PyTorch
	- Excellent drive, problem solving skills and analytical approach
	- Strong communication and collaboration skills in a cross-functional setting. Ability to work hands-on with multi-functional teams
	- Apple's commitment to deliver incredible experiences to a global and diverse set of users, in full respect of their privacy, has led to the development of a dedicated Robustness Analysis function. With the generative experience, creating a safe and robust platform is vital to our mission. Team's responsibilities include monitoring ML model performance on relevant axes, and surfacing, measuring and mitigating ML failure modes, in order to improve overall user experience and reduce risks, with specific attention given to safety, inclusion and fairness.
	- In this position, you will join a team of people passionate about leading RA operations for key future facing Apple features with focus on ensuring safety and robustness for generative models.
	- research and develop approaches to mitigate harmful and risk behaviors in generative models 
	- define product-centered axes of analysis relevant to target feature, in collaboration with model DRI and feature DRI
		* Directly Responsible Individual (DRI)
		* designated response individual, DRI
	- develop processes (models, tools and data) to identify other potential biases or failure modes
	- when applicable, benchmark model using targeted public datasets
	- characterize potential biases in training set and model along chosen axes
	- request data collection efforts and/or implement automated pipelines based on advanced ML technology and humans/models in the loop to create test sets covering the various axes of investigation
	- report progress and issues found in technical and sponsor meetings
	- suggest mitigation options (data and/or model) and lead mitigation experiments, when issues are found
+ Experience integrating LLMs or other generative models with data platforms a plus
+ skill set:
	- VIO/SLAM Algorithm Engineer
	- The Video Computer Vision organization is working on exciting technologies for future Apple products. Our focus is on ML based solution around real time image and video. We have contributed to the FaceID and FaceKit project in the past and more recently the new LIDAR iPad sensor. We are looking for the right Engineer to help us take our efforts to the next level.
	- In this role, you will work together with similar minds in a unique development team where your skills and expertise will be put into the Apple products. This role is highly multi-functional and you will work very closely with various highly skilled software development / ML teams developing groundbreaking algorithms.
	- Multi-view geometry
	- SLAM - Simultaneous Localization and Mapping experience
	- Traditional ML or deep learning domain knowledge for the above areas is a plus
	- Understanding of visual inertial sensor fusion / or general sensor fusion is a plus
	- Solid programming skills with c/c++
	- Passion on cutting edge computer vision/machine learning technologies and product delivery
	- Ability to communicate the results of analyses in a clear and effective manner
	- You will create 3D computer vision algorithms to deliver AR/VR experiences that are impactful, meaningful, and influential. We work closely with Apple's best-in-class designers to ensure the products we ship are more than technical demos – they resonate with users at a personal level.
	- In this role you will be working on a wide range of responsibilities: core technology algorithm development in support of future user experiences; communicating with and supporting external teams that use our algorithms; supporting low-level, cross-platform efforts; participating in code reviews; and being a constant advocate within the team for high quality results.
	- PhD in computer vision, robotics or machine learning; alternatively a comparable industry career, with significant experience on delivering products using state-of-the-art computer vision, machine learning and robotics technologies
+ skill set:
	- AIML - Machine Learning Engineer, Operations Research
	- Do you want to innovate on Operations Research and Machine Learning solutions to transform Apple product's lifecycle to the next level? The Data and Machine Learning Innovation team is looking into innovative ways to forecast key business indicators and optimization throughout end-to-end product lifecycle. We are a R&D team with strong expertise in Machine Learning, Operations Research, and Data Engineering. The team works broadly with Finance, Sales, Operations and Marketing to advance capabilities in forecasting and supply chain optimization with innovative ML/OR techniques and applications.
	- As part of our team, you will work together with domain experts in finance, econometrics and supply chain operations where your skills and expertise will impact decisions that optimizes Apple's business. This role is highly multi-disciplinary and you will collaborate closely with top notch engineers to build end-to-end ML/OR applications.
	- 2+ years experience of building Operations Research applications.
	- Deep understanding of Linear Programming, Integer Programming, and Stochastic Optimization.
	- Being proficient in solving LP/IP problems using Gurobi/CPLEX/OR-Tools.
	- In-depth knowledge about machine learning and statistical algorithms, especially forecasting algorithms.
	- Being self-driven, understanding the underlying logic of the business, adapting to rapid business changes
	- Good communication skills and courage to change business.
	- Intellectual curiosity, versatility and track record in the field of Operations Research and Machine Learning.
	- Background in supply chain planning or optimization is a plus.
	- You will have the unique opportunity to use innovative techniques from OR and ML to develop accurate forecasting models and supply chain optimization systems. Your work is particularly exciting as it will impact Apple business planning. Strong candidates operations research and machine learning skills are encouraged to apply.
+ skill set:
	- Machine Learning Performance Engineer
	- Our mission is to build the Covariant Brain, a universal AI to give robots the ability to see, reason and act on the world around them. Bringing AI from research in the lab to the infinite variability and constant change of our customer's real-world operations requires new ideas, approaches and techniques.
	- Success in the real world requires a team that represents that world: diversity of backgrounds, points of view, and experiences. Our common denominator: ambitious expectations, love of learning, empathy for those around us, and a team-first mindset.
	- The Covariant Brain is a Universal AI Platform that powers all robotic applications at Covariant. The Brain is a collection of state-of-the-art models, algorithms, and APIs that enable all intelligent behavior of the robot, from perception to 3d object understanding, grasp sampling, ranking, motion planning, and control. Each ML Performance Engineer will be expected to own a product family and use their understanding of the Covariant Brain to make improvements toward making robots highly autonomous.
	- Own all performance aspects of a robotic application 
	- Understand and iterate on all aspects of the Brain (models, algorithms, tooling, etc.) to resolve production failures and deliver human-level autonomy
	- Analyze robot performance for different errors, understand their root causes, and test/deploy improvements to production
	- Build tools to analyze a highly complex system of robots, models, components, and sensors to understand errors and enable more people across the org to make improvements to the system
	- Take real-world challenges and engineer ML & robotics solutions by training, testing, tuning, iterating, and deploying new and existing models to solve production problems
	- Collaborate closely with research, SW, HW, and infrastructure teams to deliver highly reliable robotic applications
	- Work closely with the HW team on the design of a robotic application including the gripper, vision suite, and station layout
	- Identify throughput bottlenecks in the application and work with the SW team to pinpoint and resolve them
	- Take experimental models from the research team, test them to validate improvement, and deploy them to solve application problems
	- Travel to the customer site as needed to resolve issues with robots in production (not expected for more than once per quarter, if needed at all)
	- Obsession with building products that deliver value to customers through solving hard ML and robotics challenges
	- 3+ years of professional experience working with real-world software systems, AI products, or AI research
	- Proficiency in Python and experience with tensor libraries (e.g. NumPy, PyTorch, TensorFlow)
	- Working knowledge of Linux, SQL, and web (e.g. HTML, Javascript, etc.)
	- A solid mathematical and statistical foundation with an understanding of how to apply ML concepts (e.g. training, evaluation, testing, fine-tuning, data sampling, etc.)
	- Demonstrated strong problem-solving ability: analyzing real-world problems and formulating solutions, iterating and formulating, shipping, and making an impact on products for customers
	- Clear communication and collaboration across teams: taking requests from customers, and PMs, and prioritizing work across SW and HW teams
	- Trained, deployed, and analyzed ML models or robotics applications in production
	- Strong understanding of the state of the art in Computer Vision and Robotics literature
	- Experience working with complex data infra and highly concurrent SW systems
+ skill set:
	- ***Machine learning engineer role with an EDA company to build machine learning frameworks, and machine learning infrastructure (in the context of MLOps)***
	- AI/ML Senior Engineer
	- Lahore, Pakistan
	- Siemens Digital Industry is an innovation leader in automation & digitization. We are part of Technology & Innovation department of Siemens Factory Automation, an international team of dedicated and passionate engineers working on the next generation of pre-products for Industry 4.0. We work on the complete business lifecycle from concept ideation to incubation. We are not tied to specific technology; we build our own technology. We have filed multiple patents for our innovations. Our current portfolio includes a fully managed multi-tier orchestrated industrial IoT Platform and a distributed machine learning flow manager, a no code solution for domain experts & low code solution for data scientists. We work in Machine Learning, Industrial devices and Industrial IoT on the entire stack ranging from Devices & connectivity to Platform services and UI. Our strategic search fields include Industrial grade AI, Industrial IoT & Edge Computing, IT/OT convergence & Digital Twin.
	- Design & develop functionality for our new product using technologies like Generative AI & LLMs
	- Research existing LLMs to find appropriate fit for the team's need, fine-tuning or retraining existing LLMs available in the opensource
	- Research different AI related topics which are in the interest of the team to create new product ideas and implement POCs and then translating them to complete product. These topics include Generative AI, Adoption of AI, AI Safety, Easy AI, etc.
	- Construct jobs & scripts using industry standard toolsets to automate various data querying, loading, aggregating and reporting tasks
	- Perform data analysis to identify new data sources and to optimize/identify features in existing data sources
	- Develop and evaluate the performance of predictive statistical models and selecting features, building and optimizing classifiers using machine learning techniques.
	- Design & development of enterprise scale Intelligent self-healing system including:
	- Requirement Gathering
	- Statistical Model Designing & Live deployment in production
	- Application Design & Implementation
	- Documentation
	- We're looking for experienced data scientists/machine learning engineers with either a PhD degree in Computer Science or related field with minimum 3 years of industry experience, or an MS degree in Computer Science or related field with minimum of 8 years of industry experience working in the area of Machine Learning and Data Science techniques and understanding the parameters that affect their performance.
	- 4+ years of experience with Python, C++, SQL, NoSQL
	- Good understanding of Deep Learning concepts like Time Series Analysis, Root Cause Analysis, Neural Networks, Supervised Learning, Unsupervised Learning, Regression, Classification, Reinforcement Learning, Knowledge Graphs, Transformers, Generative AI, LLMs
	- Hands-on experience with one or more of the following ML/DL frameworks: Tensorflow, Tensorflow Lite, Keras, MXNet, PyTorch, KNIME, Data Annotation Tools
	- Experience with standard build and deployment tools such as Eclipse, Maven, Git/Stash, and Jira.
	- This is what gives you an edge:
		* Previous experience with LLMs, Generative AI for Images/Vide
		* Previous experience in the field of Computer Vision
		* Knowledge of big data technologies such as Apache Cassandra, Apache Spark and experience of building systems that utilize large data sets
	- Passion to build industrial grade software systems using cutting edge AI
	- Willingness to do hands-on development
	- Strong problem-solving skills and ability to think outside the box for better solutions with an aptitude for research and innovation in AI/ML and their application
	- Strong communication skills and comfortable working with geographically distributed teams
	- Good self-management skills to efficiently work from home whenever required
	- Willingness to take ownership of the assigned responsibilities and ability to work independently with minimal supervision
+ skill set:
	- ***Machine learning engineer role with an EDA company to build machine learning frameworks, and machine learning infrastructure (in the context of MLOps)***
	- Technical Lead (ML)
	- Sri Lanka
	- Synopsys Central Engineering (SCE) team is looking for Software Engineering Experts with an excellent focus on solving complex problems, and capable of leading & building an excellent team.
	- As a part of the Synopsys SCE team, you will be collaborating with a world-class team of software engineers and architects on the mission to build our state of art tools, and you would be expected to conceptualize and develop new tools & applications with cutting-edge technology. You will work together from requirement elicitation, design, implementation, and testing phases to production deployment in the cloud environment and on-prem.
	- Leading and driving the team technically,
		* To implement & productize AI/ML based solutions.
		* To incorporate AI/ML technology into existing tools
		* To re-design and develop existing applications for key R&D productivity
		* BSc/MSc in the domain of Computer/Electronics Engineering or Computer Science
		* 4+ years of relevant industry experience in developing and productizing software solutions
		* Exemplary leadership and team-working skills
		* Solid background in Data Structures & Algorithms
		* Knowledge of Machine Learning & Data Science
		* Excellent programming skills, preferably in Python
 	- Synopsys, Inc. is the Silicon to Software™ partner for innovative companies developing the electronic products and software applications we rely on every day. As the world's 15th largest software company, Synopsys has a long history of being a global leader in electronic design automation (EDA)and semiconductor IP and is also growing its leadership in software quality and security solutions.
	- At Synopsys, we're at the heart of the innovations that change the way we work and play. Self-driving cars. Artificial Intelligence. The cloud. 5G. The Internet of Things. These breakthroughs are ushering in the Era of Smart Everything. And we're powering it all with the world's most advanced technologies for chip design and software security. If you share our passion for innovation, we want to meet you.
+ skill set:
	- ***Machine learning engineer role with an EDA company to build machine learning frameworks, and machine learning infrastructure (in the context of MLOps)***
	- Sr. Technical Lead (ML)
	- Sri Lanka
	- Staff Machine Learning Engineer
	- Synopsys Central Engineering (SCE) team is looking for Software Engineering Experts with an excellent focus on solving complex problems, and capable of leading & building an excellent team.
	- As a part of the Synopsys SCE team, you will be working with a world-class team of software engineers and architects on the mission to build our state of art tools, and you would be expected to conceptualize and develop new tools & applications with cutting-edge technology. You will work together from requirement elicitation, design, implementation, and testing phases to production deployment in the cloud environment and on-prem.
	- Leading and driving the team technically,
		* To design and implement  AI/ML based solutions
		* To incorporate AI/ML technology into existing tools
		* To re-design and develop existing applications for key R&D productivity
	- BSc / MSc in the domain of Computer/Electronics Engineering or Computer Science
	- 7+ years of relevant industry experience in developing and productizing software solutions
	- Exemplary leadership and team-working skills
	- Solid background in Data Structures & Algorithms
	- Knowledge of Machine Learning & Data Science
	- Excellent programming skills, preferably in Python
	- Knowledge of cloud technologies
	- Exposure to distributed computing will be an added advantage
	- Quick learning and adaption to new technologies
+ skill set:
	- Staff Machine Learning Engineer - Language Modeling (Remote)
	- Our small Natural Language Processing team works on providing key NLP competence to improve Quora users' experience. We build end-to-end industry-scale NLP systems for moderation (e.g. spam detection) and content-based recommendation (e.g. topic tagging and modeling content relevance). The team directly supports moderation and growth-related initiatives at Quora. As a remote-first company, our engineers have a high degree of flexibility and autonomy.
	- We are looking for an experienced Staff Machine Learning Engineer to join our growing NLP engineering team. You will have a unique opportunity to have high impact by advancing our NLP systems, as well as uncovering new opportunities to apply large language models to the Quora product. You will also play a key role in developing tools and abstractions that our other developers would build on top of.
	- Improve our existing machine learning systems using your core coding skills and ML knowledge
	- Identify new opportunities to apply large language models to different parts of the Quora product
	- Perform experiments and comparative analysis to evaluate the effectiveness of different model architectures and fine-tune hyperparameters for optimal performance
	- Take end-to-end ownership of machine learning systems - from data pipelines, feature engineering, candidate extraction, model training, as well as integration into our production systems
	- Continuously research and stay up-to-date with the latest developments in NLP and large language models, utilizing innovative techniques and methodologies to enhance our models
	- Collaborate with the manager to lead the effort to transform our NLP systems to a new era of large language models
	- Ability to be available for meetings and impromptu communication during Quora's “coordination hours" (Mon-Fri: 9am-3pm Pacific Time)
	- 6+ years of professional software development experience in machine learning, ideally in an NLP team and/or as tech lead
	- BS, MS or PhD in Computer Science, Mathematics, or a related field with a focus on machine learning and NLP
	- Previous experience building end-to-end machine learning systems
	- Strong innovator who understands the nuances of large language models and hands-on experience working with large language models like GPT, LLAMA, BERT, or Transformer-based architectures
	- Proficient knowledge of NLP techniques, including tokenization, language modeling, and embeddings
	- Experience with distributed training and optimization techniques for large-scale machine learning models
	- Excellent communication skills and the ability to collaborate effectively in a cross-functional team.
	- 2+ years of experience writing Python or C++ code
	- Experience with leading large-scale multi-engineer projects
	- For Colorado based applicants, the minimum salary range is $174,400 - $216,000 USD + equity + benefits. For California, New Jersey, New York, and Washington based applicants, the minimum salary range is $174,400 - $255,000 USD + equity + benefits.
	- British Columbia candidates only: For British Columbia applicants, the minimum salary range is $173,800 - $252,000 CAD + equity + benefits.
+ skill set:
	- Deep Learning Engineer
	- Deep Learning Engineer will develop AI applications on AlphaICs Gluon Inference Platform. We are looking to hire a trainee (6 months) or a full time engineer. 
	- 1) Development experience in Deep learning application on embedded/AI boards. (Jetson/Movidius etc)
	- 2) Experience in TensorFlow /pyTorch/Python C/C++ programming.
	- 3) Experience in profiling/ benchmarking/ validating applications in embedded/DSP/ AI boards.
	- 4) Experience working with camera interfaces Develop camera, 3D and other sensors.
+ skill set:
	- Deep Learning Software Library Development Engineer
	- In this role, you will be responsible for developing highly optimized libraries for Deep Learning operators. This role is a very critical role in our AI Processor's SDK development. It involves working on libraries, performance tuning and analysis, implementing new algorithms etc.
	- 1) Bachelors, Masters or equivalent experience in Computer Science, Artificial Intelligence, Applied Math, EE or related fields.
	- 2) Excellent C/C++ programming and software design skills, including debugging, performance analysis, and test design.
	- 3) Good working understanding of TensorFlow operators and maths behind it.
	- 4) Strong in Linear Algebra.
	- 5) Good knowledge of CPU (ARM, X-86 etc.) or GPU architecture.
	- 6) Architecting or optimizing software libraries for one or more from the list: HPC, OpenCL, CUDNN, BLAS, Eigen, LAPACK, DSP Software Library.
	- 7) Convolution Neural Networks.
+ skill set:
	- Machine learning background in Python; experience with PyTorch or TensorFlow and familiarity with combinatorial optimization, two- (or three-) sided marketplaces, or reinforcement learning.
	- Experience shipping production ML models and designing sophisticated experimentation techniques.
+ skill set:
	- Software Engineer (L5) - Machine Learning for Studio Media Algorithms
	- The Studio Media Algorithms team is at the forefront of innovation to enhance and support vision of creators of movies, TV shows and other multimedia work. This team's work is responsible for increasing member value, and driving efficiency of the content creation process, ultimately creating more joy for viewers all over the world. To learn more about the domain, here are some links related to what we do: Creating Media with Machine Learning and Computer Vision Research at Netflix.
	- We are looking for a  software engineer with experience in the machine learning (ML), computer vision (CV), and/or graphics domain to design and develop scalable systems and infrastructure for that effort. These systems will be used by our researchers to develop CV, graphics, audio, and natural language processing (NLP) algorithms to analyze, create, and transform media assets. 
	- Design and develop systems and reusable frameworks for the full cycle of machine learning in the multimedia domain, such as data processing, feature extraction, distributed model training with GPUs, and deploying the produced models into production.
	- Collaborate cross-functionally with research scientists, product managers, as well as creative and business partners and stakeholders, to help define and prioritize system requirements.
	- Work closely with ML researchers and Studio teams to productize Deep Learning models and efficiently run human-in-the-loop inference tasks.
	- Participate in algorithm development and propose scalable designs.
	- Promote and facilitate software engineering best practices in the team.
	- Experience in software engineering experience in a production setting
	- Passion for turning ideas into products and improving the user experience
	- Skills in OO programming (Python, Java, or C++) 
	- Familiarity with ML, CV, and/or graphics pipelines
	- Excellent communication and people engagement skills
	- Experience with large-scale distributed data processing systems and cloud infrastructure
	- ***Building end-to-end multimedia systems and algorithms***
	- ***Deep learning frameworks such as PyTorch and Tensorflow***
	- ***The content creation domain, such as visual effects***
	- ***Computer graphics and VFX tools and game engines such as Unreal Engine, Unity, Autodesk Maya, or Nuke***
+ skill set:
	- Staff Machine Learning Engineer (Tech Lead)
	- As our Machine Learning Tech Lead, you will play a pivotal role in leading a group of talented researchers and engineers in the development of cutting-edge voice analysis models. As our ML expert, you will communicate directly with company leadership on recent findings, strategy, and operational requirements for the success of the ML team. You'll work closely with the software engineering and product teams to ensure the seamless integration of our ML models into production. In addition, you'll collaborate with our clinical team to design data collection strategies and expand our clinically validated datasets.
	- Kintsugi offers a holistic total rewards package designed to support our employees in all aspects of their life inside and outside of work. The expected base salary for this position will range from $190,000 - $250,000 + Equity. Actual compensation may vary from posted base salary depending on your confirmed job-related skills and experience.
	- Lead ML team in the technical aspects of core-product development including investigating, planning, executing, evaluating, and reporting on the entire MLOps pipeline from problem definition, data requirements, experimentation, productization, reporting, and monitoring
	- Be self-directed to work independently in a multidisciplinary team environment
	- Roll up your sleeves and work alongside team members on portions of projects to ensure the completion of high-priority tasks and critical non-project work
	- Advise, direct, coach, inspire and review the work of early-career team members on complex projects
	- Manage the workload, inter-team communication, conflict resolution, and career development of the ML staff
	- Lead the planning, execution, and retros for the ML team sprints
	- Build, maintain, and report on the technical roadmap and quarterly OKRs for ML workstreams, milestones, and deliverables in collaboration with the product and software engineering teams.
	- Create and manage ML project plans, identifying critical paths and resource requirements, including budget allocation
	- Conduct ongoing research on emerging voice analysis technologies and make recommendations on their applicability within our organization
	- Stay current with industry advancements by attending seminars, reviewing technical literature, and establishing thought leadership in voice biomarkers
	- M.S./Ph.D. in Computer Science or a related field with 5+ years of experience building production-grade machine learning models in industry settings
	- 1+ years of experience leading R&D or ML projects
	- Strong programming skills in Python with extensive experience with the scientific and deep-learning stack (numpy, pandas, numba, torch, tensorflow, jupyter)
	- A proven track record of building end-to-end deep-learning models
	- Experience with ML model efficiency optimization for production deployment
	- Ambitious team player with strong communication skills (oral and written)
	- Experience implementing and experimenting with cutting-edge ML techniques from the latest literature
	- Experience with cloud services (GCP, AWS, Azure) for training, data processing and/or model deployment
	- Possess excellent interpersonal skills, with the ability to communicate effectively, provide guidance, negotiate, and influence others as needed, while also building strong, productive working relationships in a variety of settings.
	- Background in speech processing/recognition or audio classification
	- Experience with experiment tracking and reproducibility tools (MLFlow, WandB, DataBricks, etc)
	- Experience with sprint management and Agile methodologies
	- Recent publication(s) in peer-reviewed AI journals
	- Experience with FDA approvals for a software-as-a-medical device (SaMD)
	- Empathetic leader and mentor that is driven by the success of their team
	- Comprehensive multidisciplinary skills for everything from model training to code review to ML research to product documentation, with the ability to adapt to different challenges and collaborate effectively with cross-functional teams
	- Strategic and agile planner with an eye for MVP
	- Efficient communication skills with a reliable pattern of providing quick feedback and acknowledgments, along with the ability to complete larger projects within established timelines
	- Kintsugi is on a mission to scale access to mental healthcare for all. We are developing novel voice biomarker software to detect signs of depression and anxiety from short clips of free form speech. Awarded multiple distinctions for AI technology and recently named one of Forbes' Top 50 AI companies to watch in 2022 and Fierce 15 in 2023, Kintsugi helps to close mental health care gaps across risk-bearing health systems, ultimately saving time and lives.
	- At Kintsugi, we believe that mental health is just as important as physical health. We exist to ensure that everyone who needs mental healthcare has access to the right care at the right time. 
	- We're a female-founded organization, united and driven by our shared passion to revolutionize access to mental healthcare. Our mission is ambitious, and each member of our team wears multiple hats and plays a pivotal role. As an early-stage, Series A startup, we offer exciting growth opportunities and the chance to make a real impact. Join us to embark on a rewarding journey, learning and growing alongside our dedicated team of trailblazers.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.










###	Machine Learning Manager & Deep Learning Manager Roles





Skill sets for managing machine learning engineers, or machine learning engineering managers or machine learning managers:
+ Mojo Standard Library Engineering Manager
	- We believe that AI is a net positive force in the world. Our vision and mission are to help rebuild AI infrastructure to advance humanity and our environment. We will do whatever it takes to empower our customers, team, and company to benefit from that pursuit. You can read about our culture and careers here to understand how we work and what we value.
	- We are owners and advocates for the underlying technologies, developer platforms, product components, and infrastructure. These essential building blocks form the high-quality and coherent experiences our users expect. We aim to drive the pace of innovation for every AI/ML developer.
	- Modular is building a next-generation AI infrastructure platform that unifies the many application frameworks and hardware backends, simplifying deployment for AI production teams and accelerating innovation for AI researchers and hardware developers. A key component in our technology stack is Mojo 🔥 programming language that unlocks programmability of AI hardware. We are looking for a technical Software Engineering Manager to lead the development of Mojo 🔥Standard Library. In this role, you will own the design and implementation of  the library APIs and work closely with other teams and a growing community of Mojo 🔥 developers (aka Mojicians 🔥) to deliver outstanding user experience and performance. You will drive hiring and team growth, work to align the team on product deliverables, set team execution strategy and engineering practices, and collaborate across teams to deliver Mojo 🔥to internal and external customers. We are looking for candidates with strong communication and teamwork skills who excel in collaborating across team boundaries. Join our world-leading team and help us redefine how AI systems are built.
	- Lead an engineering team in building a well-designed, scalable, high-performance standard library for Mojo 🔥.
	- Drive development of  library APIs based on requirements of internal and external customers.
	- Engage with the Mojo 🔥developer community and, in collaboration with other teams, drive adoption and evolution of Mojo  🔥.
	- Provide technical leadership and career guidance to the team engineers helping them to realize their full potential and set and achieve career goals.
	- Collaborate with engineering and cross-functional teams to build a balanced technology stack that fully utilizes today’s complex hardware systems.
	- 5+ years experience in system library software development, including 2+ years in a management role.
	- Strong understanding of library design principles.
	- Strong knowledge of C++ and Python. 
	- Experience working with the open source developer community.
	- Proven experience in managing and developing a high-performance engineering team.
	- Ability to work in a fast-paced, dynamic environment and manage multiple priorities.
	- Creativity and passion for building high-quality user-facing products.
	- Knowledge of modern programming languages, such as Swift, Rust, Julia, Kotlin, Scala, or Zig.
	- Experience working with MLIR or LLVM.
	- The estimated base salary range for this role to be performed in the US, regardless of the state, is $207,000.00 - $286,000.00 USD. The salary for the successful applicant will depend on a variety of permissible, non-discriminatory job-related factors, which include but are not limited to education, training, work experience, business needs, or market demands. This range may be modified in the future. The total compensation for a candidate will also include annual target bonus, equity, and benefits, with equity making up a significant portion of your total compensation.
+ Experience with Hive, R, and Python preferred
	- Hive: productivity platform for fast-moving teams
	- The ***Apache Hive™*** is a distributed, fault-tolerant data warehouse system that enables analytics at a massive scale and facilitates reading, writing, and managing petabytes of data residing in distributed storage using SQL.
+ Director, Artificial Intelligence, Science
	- at Chan Zuckerberg Initiative
	- Redwood City, CA (Open to Flex)
	- We’re on an ambitious mission to solve some of society’s toughest challenges — from eradicating disease to improving education and addressing the needs of our local communities. Join us to build a better future for everyone!
	- CZI is building out our AI/ML capabilities in support of our long-term mission to cure, prevent, and manage all disease by the end of the century, and the ten-year vision of unlocking the ability to digitally model human cell function.  To this end, we are seeking a world-class leader for the consolidated and growing AI/ML research group who will tackle hard problems in pursuit of that vision.  The leader will be responsible for setting the team direction and identifying the best approaches to building models and solutions that lead to an ability to mimic and predict cellular biology mechanisms.
	- We support interdisciplinary teams of physicians, biologists, computational scientists, and engineers to expand our understanding of the human body and illness — the very science behind medicine. CZI fosters collaboration between scientists and engineers, develops tools and technologies, and builds support for basic scientific research. Our North Star objective is on understanding the mysteries of the cell, the fundamental building block of life. To that end, our approach is to digitally model cell function through research, advanced development, collaboration, and funding.
	- Building software such as 
		* CZ cellxgene - an easy to use corpus of single-cell transcriptomics data.
		* CZ ID - a metagenomics platform that delivers insights in infectious disease.
	- Funding of
		* Single cell biology and the application of technologies that enable multi-omics investigation at the level of cells.
		* Imaging and developing tools capable of observing biological processes across spatial scales at the level of tissues, cells, and proteins.
	- Doing science through
		* The CZ Biohub empowering scientists to work on their riskiest, most exciting ideas.
		* The CZ Imaging Institute and developing technologies to image the molecular architecture of the cell with atomic resolution.
	- The AI/ML Director will be a leader within CZI developing and applying state-of-the-art methods in artificial intelligence and machine learning to solve important problems in the biomedical sciences aligned with CZI’s focus on understanding the mysteries of the cell by modeling cell function. You will lead a team that will leverage datasets that are created as part of CZI’s efforts to build, fund, and do science to create models that transform our understanding of cells. 
	- You will lead a concerted ML effort within CZI Science Technology and have the opportunity to work closely with teams of scientists, computational biologists, and engineers. You will also collaborate with other groups within CZI, CZI grantees, CZ institutes, and other external labs and organizations. Your work should inspire and enhance the production and analysis of datasets by CZ teams and collaborators. Scientific focus areas could include single cell biology, imaging, genomics, and proteomics.
	- Conceive of and lead projects to solve important problems in biomedical sciences through the application of state-of-the-art methods in artificial intelligence and machine learning.
	- Be a leader on a diverse team that develops, deploys, & maintains innovative machine learning systems and software tools that enable the analysis and interpretation of complex and noisy biology data sets.
	- Identify opportunities, create, and implement solutions with respect to complex problems/scientific questions on large scale data sets, especially using machine learning approaches, predictive models, and statistical analysis, to advance understanding of cell structures, systems, and interactions.
	- Collaborate with the CZI Science Program and Technology teams to help identify problems and opportunities in the biomedical sciences that can be tackled with artificial intelligence.
	- Collaborate with the CZI Science Program and Technology teams to identify and define necessary datasets.
	- Summarize and present complex and highly technical problems and solutions to audiences with a wide variety of skills and domain knowledge
	- Enjoy working in a highly interactive and cross-functional collaborative environment with a diverse team of colleagues and partners
	- Act as a thought leader and mentor for the AI/ML team, leading hiring, developing, and retaining people to help them develop their full potential and build new skills and abilities
	- Have a passion for actively directing and managing highly skilled individuals to consistently achieve high levels of motivation, enthusiasm, inclusion, and performance
	- A passion for tackling hard problems and orchestrating team activities to face the challenges involved.
	- Have a Masters or PhD in computer science (focus on machine learning & data analytics), biocomputing or a related field or equivalent industry experience and at least 10 years of experience leading a research and development team
	- Have demonstrated experience building and training AI/ML models to address biological or adjacent problems, and developing deep learning methods
	- Have a proven track record leading teams with diverse skill sets and focused on the analysis and interpretation of complex biological data
	- The Redwood City, CA base pay range for this role is $323,000 - $485,000.
+ skill set:
	- Staff Machine Learning Engineer
	- In order to execute our vision, we need to grow our team of best-in-class machine learning engineers. We are looking for developers who are excited about staying at the forefront of deep learning technology, prototyping state-of-the-art neural net models and launching these models into production. We value hard workers who have no qualms working with terabyte-scale datasets, who are interested in learning new technologies at all levels of the machine learning stack, and who move fast and take ownership of their projects. Our ideal candidate has experience creating a working machine learning-powered project from the ground up, contributes innovative ideas and ingenious implementations to the team, and is capable of planning out scalable, maintainable data pipelines.
	- Everything involved in applying a ML model to a production use case, including designing and coding up the neural network, gathering and refining data, training and tuning the model, deploying it at scale with high throughput and uptime, and analyzing the results in the wild in order to continuously update and improve accuracy and speed
	- Write and maintain scalable, performant code that can be shared across platforms
	- Contribute meaningfully to the product and core backend systems by suggesting and executing improvements
	- Improve engineering standards, tooling, and processes
	- Develop novel, accurate, and performant ML algorithms for use at scale
	- Conduct metric-driven research experiments to improve model performance
	- Provide mentorship to and help onboard ML engineers
	- Lead cross-functional collaboration with other teams
	- Contribute to defining strategic direction, planning the roadmap
	- Maintain awareness of industry best practices for data maintenance handling as it relates to your role
	- Adhere to policies, guidelines and procedures pertaining to the protection of information assets
	- Report actual or suspected security and/or policy violations/breaches to an appropriate authority
	- You have a Bachelor's Degree in computer science or a related field
	- You have 8+ years of experience building web applications
	- You have successfully implemented highly-available distributed systems/microservices
	- You have delivered scalable backend APIs
	- You have strong interpersonal and communication skills with a bias towards action
	- You have experience writing code and training across distributed systems
	- You have the ability to understand and make well-reasoned tradeoffs in designing features
	- You are an expert in machine learning frameworks, such as PyTorch or Tensorflow
	- You are an expert in scripting languages such as Python and/or shell scripts, particularly for data analysis
	- You are a subject matter expert in at least one focus area of machine learning, such as computer vision or natural language processing
	- You can lead end to end development of new products
	- The current expected base salary for this position ranges from $200,000 - $300,000.
+ skill set:
	- Senior Machine Learning Engineer
	- In order to execute our vision, we need to grow our team of best-in-class machine learning engineers. We are looking for developers who are excited about staying at the forefront of deep learning technology, prototyping state-of-the-art neural net models and launching these models into production. We value hard workers who have no qualms working with terabyte-scale datasets, who are interested in learning new technologies at all levels of the machine learning stack, and who move fast and take ownership of their projects. Our ideal candidate has experience creating a working machine learning-powered project from the ground up, contributes innovative ideas and ingenious implementations to the team, and is capable of planning out scalable, maintainable data pipelines.
	- Everything involved in applying a ML model to a production use case, including, designing and coding up the neural network, gathering and refining data, training and tuning the model, deploying it at scale with high throughput and uptime, and analyzing the results in the wild in order to continuously update and improve accuracy and speed
	- Write and maintain scalable, performant and secure code that can be shared across platforms
	- Meaningfully contribute to the product and core backend systems by suggesting and executing improvements
	- Improve engineering standards, tooling, processes and security
	- Develop novel, accurate, and performant ML algorithms for use at scale
	- Conduct metric-driven research experiments to improve model performance
	- Provide mentorship to and help onboard junior ML engineers
	- Collaborate cross-functionally with other teams
	- Utilize OWASP top 10 techniques to secure code from vulnerabilities
	- Maintain awareness of industry best practices for data maintenance handling as it relates to your role
	- Adhere to policies, guidelines and procedures pertaining to the protection of information assets
	- Report actual or suspected security and/or policy violations/breaches to an appropriate authority
	- You have a Bachelor's Degree in computer science or a related field
	- You have a minimum of 5 years of building production scale ML models
	- You know the ins and outs modern machine learning frameworks, such as PyTorch or Tensorflow
	- You are an expert in scripting languages such as Python and/or shell scripts, particularly for data analysis
	- You have experience writing code and training across distributed systems
	- You have an ability to understand and make well-reasoned tradeoffs in designing features
	- You can lead end to end development of new products
	- You are very knowledgeable in at least one focus area of machine learning, such as computer vision or NLP
	- You strongly believe in high code quality, automated testing, and other engineering best practices
	- You have attention to detail and a passion for correctness
	- You are comfortable with ambiguity and scoping solutions with your teammates
	- You have strong interpersonal and communication skills with a bias towards action
	- The current expected base salary for this position ranges from $160,000 - $250,000.
+ skill set:
	- Machine Learning Manager
	- In order to execute our vision, we're constantly growing our machine learning team.  We are looking for an exceptional leader to help us with that growth, making sure that each engineer reaches their full potential.  We value hard workers who have no qualms working with terabyte-scale datasets. We're interested in experimenting with new models, new ideas, and training on novel datasets. Our ideal candidate has experience managing a team of machine learning engineers working on ML projects of a massive scale, contributes innovative ideas and ingenious modeling improvement strategies to the team, and is capable of mentoring junior engineers through their journey to become better.
	- Interface closely with product management, engineering, devops, labeling, and sales teams to build roadmap in supporting the long term vision of the team
	- Lead a team of highly capable and passionate machine learning engineers, helping them achieve their goals through mentorship
	- Participate in products technical design and architecture
	- Participate in the full development cycle: data collection, labeling, model development, experimentation, training, testing, and deployment in production
	- Drive delivery for our product milestones, continually releasing model with new well tested features and ensuring quality metrics are achieved
	- Implement and manage security protocols such as training, code review, and best practices
	- Own and manage the risk and security of your business function in coordination with the Security Team
	- Maintain awareness of industry best practices for data maintenance handling as it relates to your role
	- Adhere to policies, guidelines and procedures pertaining to the protection of information assets
	- Report actual or suspected security and/or policy violations/breaches to an appropriate authority
	- Undergraduate or graduate degree in computer science or similar technical field
	- 4+ years experience as a machine learning engineer, with experience in training large deep learning models and working with real world data
	- Knowledgeable in at least one focus area of machine learning, such as computer vision, audio, or NLP
	- 2+ years experience managing machine learning teams
	- You have an ability to understand and make well-reasoned tradeoffs in designing features
	- Management skills: ability to set roadmap and goals for a team and its individual members, delegate, mentor, and deliver results
	- Have a desire to interview engineers, collaborate with a recruiting team, and smoothly onboarding new team members
	- Have experience collaborating with product managers and labeling team in delivering model improvements
	- The current expected base salary for this position ranges from $180,000 - $250,000.
+ skill set:
	- Manager, Machine Learning Research Engineer, Generative AI
	- Scale's Generative AI Data Engine powers the most advanced LLMs and generative models in the world through world-class RLHF/RLAIF, data generation, model evaluation, safety, and alignment.
	- As the Manager of the Generative AI team, you will be responsible for managing and leading a group of talented researchers and engineers. Your primary focus will be to leverage your expertise in LLMs, generative models, and other foundational models to create and execute an AI roadmap which will help Scale accelerate our customers' Generative AI initiatives forward. This is an exciting opportunity to work on cutting-edge technologies and collaborate with industry-leading professionals.
	- We are building a large hybrid human-machine system in service of ML pipelines for dozens of industry-leading customers. We currently complete millions of tasks a month and will grow to complete billions monthly.
	- Manage a team of highly effective researchers and engineers. Provide guidance, mentorship, and technical leadership to a team of researchers and engineers working on Generative AI projects. Develop and evaluate methods for integrating machine learning into human-in-the-loop labeling systems to ensure high-quality and throughput labels for our customers.
	- Implement and improve on state-of-the-art models developed internally and from the community and put them into production to solve problems for our customers and taskers.
	- Work with product and research teams to identify opportunities for improvement in our current product line and for enabling upcoming product lines.
	- Work with massive datasets to develop both generic models as well as fine-tune models for specific products.
	- Work with customers and 3rd party research groups to understand their goals and define how we can enable them.
	- Build a scalable ML platform to automate our ML services, including automated model retraining and evaluation.
	- Be able and willing to multi-task and learn new technologies quickly.
	- Must be able to commute to the San Francisco Office 1-2x weekly. 
	- 7+ years of full time work experience using LLM, deep learning, deep reinforcement learning, or natural language processing in a production environment. Especially training foundational AI models through pre-training, fine-tuning, and RLHF.
	- A vision for where the field should go and what Scale should do to enable it.
	- Strong programming skills in Python, experience in PyTorch or Tensorflow
	- Experience with MLOps and the automation of model training & evaluation
	- Experience working with cloud technology stack (eg. AWS or GCP) and developing machine learning models in a cloud environment
	- Solid background in algorithms, data structures, and object-oriented programming
	- Deep appreciation for building high-quality, robust, reusable machine-learning software
	- Degree in computer science or related field
	- Graduate degree in Computer Science, Machine Learning or Artificial Intelligence specialization
	- Publication experience in the field or related topics.
	- Experience with model optimization techniques for both training and inference
+ skill set:
	- Engineering Manager, Data & Feature Infrastructure, Machine Learning Platform
	- Machine Learning drives innovation across all product functions and decision-support needs. Building highly scalable and differentiated ML infrastructure is key to accelerating this innovation.
	- We are looking for an experienced engineering leader to lead the Data & Feature Infrastructure team in the Machine Learning Platform org. The ML Platform org is chartered to maximize the business impact of all ML practice at Netflix and innovate on ML infrastructure to support key product functions like personalized recommendations, studio innovations, virtual productions, growth intelligence, and content demand modeling among others.
	- The Data & Feature Infrastructure team is building a next-generation event-driven ML feature computation platform to significantly up-level productivity of ML practitioners.  This managed infrastructure solution enables ML practitioners to easily write and test feature definitions, while our Platform takes care of the computation, storage, and serving of feature values for both training and low-latency member-scale inference use cases. The team is also innovating on centralized feature/embedding stores to enable dataset sharing across various ML domains across Netflix.
	- This team is responsible for high-profile projects with great visibility across senior engineering and data science leaders. We are looking for a leader who has ideally been an ML practitioner or led a team of ML practitioners, so they can empathize with the needs of the customer and be a strong advocate for ensuring our customers have a world-class user experience leveraging our ML Platform.
	- Vision: Understanding the media business and how technology is changing the landscape will allow you to lead your team by providing inspiring context!
	- Partnership & Culture: Establishing positive partnerships with both business and technical leaders across Netflix will be critical. We want you to regularly demonstrate the Netflix culture values like selflessness, curiosity, context over control, and freedom & responsibility in all your engagements with colleagues.
	- Judgment: Netflix teams tend to be leaner compared to our peer companies, so you will rely on your judgment to prioritize projects, working closely with your partners - the personalization research leaders.
	- Technical acumen: We expect leaders at Netflix to be well-versed in their technical domain and be a user of the products we are building, so they can provide guidance for the team when necessary. Proficiency in understanding the needs of research teams and how to bring efficient ML infrastructure to meet those needs will be crucial.
	- Recruiting: Building and growing a team of outstanding engineers will be your primary responsibility. You will strive to make the team as excellent as it can be, hiring and retaining the best, and providing meaningful timely feedback to those who need it.
	- Experience leading a team responsible for large-scale ML Infrastructure
	- Outstanding people skills with high emotional intelligence
	- Excellent at communicating context, giving and receiving feedback, fostering new ideas, and empowering others without micromanagement
	- Willing to take action, without being stubborn - the ability to recognize your own mistakes
	- Your team and partners see your humility all the time and diverse high-caliber talent wants to work with you
	- ML practitioner leader or individual contributor experience owning end-to-end ML functions for a product domain
	- Built offerings for ML Researchers, Engineers and/or Data Scientists 
	- 10+ years of total experience including 3+ years of engineering management
	- BS/MS in Computer Science, Applied Math, Engineering or a related field
	- Exposure to modern experimentation and A/B Testing methodologies for consumer-facing applications
	- Experience building high-scale services on a public cloud like AWS and exposure to Scala and Python
	- Experience in Flink, Kafka and/or Spark computations
	- To learn more about our ML Platform, you can take a look at the relevant talks/blog posts on the Netflix ML Platform Research website: https://research.netflix.com/research-area/machine-learning-platform
	- Netflix is an equal-opportunity employer and strives to build diverse teams from all walks of life. We offer a unique culture of freedom and responsibility with a clear long-term view of our business. The overall market range for roles in this area of Netflix is typically $180,000 - $900,000. This market range is based on total compensation (vs. only base salary), which aligns with our compensation philosophy.
+ skill set:
	- Engineering Manager, Machine Learning, Member Satisfaction
	- We are looking for an experienced engineering leader to lead our applied ML research on estimating long-term member satisfaction. As Netflix continues to grow, we are venturing into exciting new frontiers of personalization to help our members find the content they'll most enjoy. To do this, we have to understand which titles, and what experiences in the product, produce the most joy for each member. 
	- Your team will be at the forefront of research on causal inference, machine learning, reinforcement learning, and econometrics. You will lead a team of experts in these techniques to understand how members experience titles, and how that changes their long-term assessment of their satisfaction with the Netflix service. In this role you will be responsible for building and leading the team. Your team will be responsible for operating, as well as innovating on these algorithms. You will help select and guide projects from end-to-end: idea to production. You will partner with people from many disciplines, including behavioral scientists, machine learning researchers, and application engineers. 
	- To be successful in this role, you need a strong machine learning, engineering, and econometrics background, to be data-driven, and have the proven ability to lead multi-disciplinary, cross-functional, teams. You also need to be great at giving and receiving feedback, championing new ideas, empowering others, and balancing the needs of both research and engineering.
	- Experience building and leading a team of ML researchers and engineers
	- A track record of leading applications of ML to solve real-world problems
	- Broad knowledge of causal inference, econometrics, and machine learning
	- Great interpersonal skills
	- MS or PhD in Computer Science, Statistics, or a related field
	- 10+ years of total experience including 5+ years of engineering management
	- Experience working on high-scale consumer problems.
	- The overall market range for roles in this area of Netflix is typically $449,000 - $842,000.
+ skill set:
	- DIRECTOR IN-SEASON AI/ML ENGINEERING (REMOTE ELIGIBLE)
	- Nike is looking for an experienced Engineering leader who can lead and grow teams of machine learning engineers, data scientists, and software architects to deliver scalable machine learning and advanced analytics solutions to customers across our business. You will work on a variety of complex business problems specifically focused on inventory optimization, demand sensing and forecasting, pricing and markdown, replenishment optimization. You will lead teams testing new hypotheses, productionized and scale ML solutions in the cloud as APIs, stream processing, or extensive batch processing. You will use big data, parallel processing technologies, Artificial Intelligence, machine learning, and deep learning techniques to quantitatively plan product demand, allocate resources, and target the right customers with the best products. You will foster partnerships with best of breed open-source communities, commercial vendors, and universities. Above all, your work will accelerate Nike's core mission of serving Athletes*!
	- Artificial Intelligence and Machine Learning (AI/ML) is one of the key groups within Enterprise Data and Analytics, and we have been chartered to help scale machine learning across Nike.
	- One way we do this is by bringing cross-disciplinary teams of data scientists and engineers to areas of the business which are early in their AI journey. For areas of the business which are more mature and already have data science teams, we help scale machine learning by providing squads of engineers to enhance the velocity of those data science teams in delivering value to the business. Our teams work across time zones in the US West, US East, and Europe. Lastly, we work closely with our platform and architecture partners to develop capabilities which help machine learning scale easier at Nike (e.g. model management, A/B testing, feature stores).
	- Build artificial intelligence and machine learning products that help Nike automatically move inventory throughout the supply chain to get the consumer the right product at the right time.
	- Develop AI/ML products such as inventory optimization, demand sensing and forecasting, pricing and markdown, replenishment optimization. You will lead teams test new and interesting hypotheses, productionized and scale ML solutions in the cloud as APIs, stream processing, or extensive batch processing.
	- Build and grow highly skilled, cross-functional engineering teams that deliver solutions unlocking machine learning for Nike. Lead the professional development and career plans for those on your teams, help us develop the technology leaders of tomorrow. Develops and leads team metrics.
	- Leverage your prior experience, knowledge of industry trends, and personal creativity to develop new and innovative solutions which delight our customers. Given the rapid pace of change in technology and machine learning today, always be pushing the boundary of what's possible and be on the offense always
	- Role model clarity and accountability as a leader of Nike. Communicate effectively, build trust and strong relationships across the company, do the right thing
	- Engage employees meaningfully, assist the teams by removing roadblocks, align efforts across Nike's matrix to drive progress forward and always win as a team
	- Partners with Architecture to ensure architectural consistency across solutions
	- Stays current with industry trends and recommends relevant technologies & products in the areas of Artificial Intelligence & Machine Learning, and Data Science tools and other emerging technologies in the areas of Enterprise Data & AI.
	- 8 years of experience in developing production grade code in software or data engineering, machine learning or a related field + experience working in an Analytics environment
	- 3+ years in a management or a leadership role
	- Must have knowledge and/or experience with technologies such as AWS Sagemaker, Scikit-learn, Dask, Tensorflow, Spark, or similar platforms.
	- Should be able to communicate with customers each technology and the benefits/tradeoffs of each solution.
	- Experience in open-source technologies and impact of make/buy decisions in the area of Data Science, AI, & ML.
	- Experience with MLOps and the lifecycle of model development from notebooks into production.
	- Experience with cloud deployments, focused on scale, performance and reliability. AWS experience preferred
	- Strong skills in team leadership and building positive relationships across Product, Architecture, and Engineering, and ability to influence decisions and changes across loosely coupled teams.
	- Excellent written and oral communication skills to both technical and non-technical audiences.
	- Experience delivering software working with Agile frameworks, processes, and teams
	- Bachelor's Degree in computer science, software engineering, or related field
+ skill set:
	- Strong understanding of Computer Science fundamentals (algorithms and data structures) as well as modern techniques in machine learning and deep learning, ***deep learning model architectures (C/RNN, attention/memory, autoregressive, etc.) and extensions (Transformers, LSTM, Autoencoders, etc.)***
	- Experience in ***Natural Language Processing, Question Answering, Generative AI including training and tuning Large Language Models***
+ skill set:
	- Working knowledge of ***common ML frameworks such as PyTorch, TensorFlow, scikit-learn, ONNX***, etc.
	Prior experience with ***container technologies like Docker, Kubernetes, Buildpacks***, etc.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






















##	Machine Learning for Fairness, Accountability, Transparency, & Bias Mitigation




Skill sets for machine learning for fairness, accountability, transparency, and bias mitigation:
+ skill set:
	- We are looking for a Research Scientist Intern to join our growing Trust & Safety Research & Algorithmic Impact team. Spotify's Algorithmic Responsibility effort focuses on empowering Spotify teams to assess the algorithmic impact of their products on audio culture, avoid algorithmic harms and unintended side effects, and better serve worldwide audiences and creators. As an Algorithmic Impact research intern, you will help to define, research, and communicate how we assess our impact as a platform and our recommendations across podcasts, music, and user-generated content. We help ensure that Spotify is a safe platform that's true to our values.
	- Be part of an interdisciplinary team focused on understanding Spotify's impact as a platform, and practical implementation and operationalization of Responsible ML activities such as algorithmic impact assessments. 
	- Contribute to the wider research community by publishing. 
	- Develop and iterate policy and auditing processes related to tech responsibility, algorithmic fairness and representation in the music and podcast industry. 
	- Apply your scientific knowledge to develop strategy around cultural equity in audio and algorithmic systems, including application-oriented problems in search, recommendation and Machine Learning settings. 
	- Provide consultative support, guidance on methods, and research-based input for products. For instance, this can include algorithmic audits, or analyzing & tracking global and local trends around online abuse, hate content, misinformation, etc., with a particular focus on algorithmic amplification. 
	- Work closely with our team and internal partners to develop, refine, and launch processes that help ensure Spotify is a safe and positive experience. 
	- Be a valued member of an autonomous, multi-functional team working in collaboration with other scientists, engineers, product managers, policy experts, designers, user researchers, and analysts across Spotify to design creative solutions to exciting problems.
	- You are pursuing a PhD in Social Science, HCI, Computer Science, Information Science, Data Science, Technology Policy, or related areas with a strong computational focus.
	- You have publications in communities such as the Web Conference, AIES, FAccT, CSCW, SIGIR, CHI, ACL, NeurIPS, WSDM, EMNLP, RecSys, KDD, ICWSM, ISMIR or related venues.
	- You are curious about how interaction design, data collection strategies, and people's perceptions affect Machine Learning outcomes.
	- You are a creative problem-solver who is passionate about digging into complex problems and devising innovative ways to reach results.
	- You have experience with the complexities of real-world data, and understand the value of both in-depth, qualitative and web-scale, quantitative data working together to build a deep understanding of people's interaction with technology.
	- Knowledge or experience working in emerging markets is a plus.
	- You have strong communication skills, both written and verbal. Able to provide concise advice and translate complex challenges clearly. Willing to apply academic knowledge and frameworks into product and practice.
	- You must be comfortable reviewing or being exposed to sensitive content and topics, and having related conversations with teams.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.

























































##	Applied Machine Learning, Applied ML



For applications of machine learning, or ML, in the following fields, see the *Markdown* document for [Skill Set for the Biotechnology & Pharmaceutical Industry](bio-biochem-biotech-pharma.md)
+ bioinformatics
+ bio design automation, BDA
+ bio manufacturing automation
+ biology
+ biochemistry
+ biotechnology
+ medicinal chemistry
+ pharmacy
+ pharmaceutical science



For applications of machine learning, or ML, in finance, see the *Markdown* document for [Financial Engineering, Computational Finance, and Financial Analytics](financial-engr-n-finance-x.md)



Skill sets for generic applied machine learning, applied ML
+ counter AI engineering
+ skill set:
	- Cerebras' fully-integrated system is built from the ground up with a singular focus on AI. To explore new techniques and algorithms at the frontier of machine learning uniquely enabled by our revolutionary technology, our experienced team of Machine Learning engineers and researchers work in collaboration with other experts in the company, giving insight and access to every level of our system stack.   
	- This is an applied research position with a focus on working with state-of-the-art research and developing novel models and algorithms on top of our core technology. We are interested in a wide range of machine learning algorithms and application domains with a focus on exploring new ideas that hold the potential to substantially reduce computational constraints limiting today's machine learning research.
	- Develop algorithms for training and inference in sparse neural networks
	- Develop novel optimizers and learning algorithms such as local learning rules and layer-parallel training
	- Develop novel network architectures and layers such as, normalization, activation functions, and parameter layers
	- Publish and present research at leading machine learning conferences
	- Experience with machine learning frameworks, such as TensorFlow, Caffe/2, and PyTorch.
	- Fluency in a programming language, such as Python and C
	- Strong grasp of linear algebra and statistics
	- Strong track record of relevant research success in roles at the level of doctoral, postdoctoral in academia or in industrial R&D
	- Strong track record of relevant publications/patents
	- Familiarity with HPC kernels and their optimization 
	- IEEE floating point representations 
	- Familiarity with machine learning frameworks such as TensorFlow and Pytorch 
	- Knowledge of ML application areas and state-of-the-art networks in various application areas
+ skill set:
	- Cerebras' Wafer Scale Engine (WSE) was designed to provide significant reduction of training times for deep neural networks. Our goal is to provide customers with the computational power needed to iterate faster so that they can develop the most accurate models possible. 
	- As an applied machine learning engineer, you will work on adapting state of the art deep learning (DL) models to run on our wafer scale system. This includes both functional validation and performance tuning of a variety of core models for applications like Natural Language Processing (NLP), Computer Vision (CV), Graph Neural Networks (GNN), Recurrent Neural Networks (RNN), and Recommendation models. 
	- As a member of the Cerebras engineering team you will be implementing models in popular DL frameworks like TensorFlow and PyTorch and using insights into our hardware architecture to unlock to full potential of our chip.  You will work on all aspects of the DL model pipeline including: 
		* Dataloader implementation and performance optimization 
		* Reference model implementation and functional validation 
		* Model convergence tuning 
		* Model performance optimization 
		* Model customization to meet customer needs 
	- This role will allow you to work closely with partner companies at the forefront of their fields across many industries. You will get to see how deep learning is being applied to some of the world's most difficult problems today and help ML researchers in these fields to innovate more rapidly and in ways that are not currently possible on other hardware systems. 
	- Analyze, implement, and optimize DL models for the WSE 
	- Functional and convergence of models on the WSE 
	- Work with engineering teams to optimize models for the Cerebras stack 
	- Support engineering teams in functional and performance scoping new models and layers 
	- Work with customers to optimize their models for the Cerebras stack 
	- Bachelor's degree in engineering, science, or related field 
	- Experience programming in modern language like Python or C++ 
	- In-depth understanding of DL learning methods and model architectures 
	- Experience with DL frameworks like PyTorch and TensorFlow 
	- A deep passion for cutting edge artificial intelligence techniques 
	- Master's or PhD in engineering, science or related field 
	- Understanding of hardware architecture 
	- Experience programming accelerators like GPUs and FPGAs
+ skill set:
	- Minimum 2+ years of expertise in designing, implementing large scale data pipelines for data curation and analysis, operating in production environments, using Spark, pySpark, SparkSQL, with  Java, Scala or Python on premise or on Cloud (AWS, Google or Azure)
	- Minimum 1 year of designing and building performant data models at scale for using Hadoop, NoSQL, Graph or Cloud native data stores and services.
	- Minimum 1 year of designing and building secured Big Data ETL pipelines, using Talend or Informatica Big Data Editions; for data curation and analysis of large scale production deployed solutions.
	- Minimum 6 months of expertise in implementation with Databricks.
	- Experience in Machine learning using Python ( sklearn) ,SparkML , H2O and/or SageMaker.
	- Knowledge of Deep Learning (CNN, RNN, ANN) using TensorFlow.
	- Knowledge of Auto Machine Learning tools ( H2O, Datarobot, Google AutoML).
	- Minimum 2 years designing and implementing large scale data warehousing and analytics solutions working with RDBMS (e.g. Oracle, Teradata, DB2, Netezza,SAS) and understanding of the challenges and limitations of these traditional solutions.
	- Minimum 1 year of experience implementing SQL on Hadoop solutions using tools like Presto, AtScale, Jethro and others.
	- Minimum 1 year of experience building data management (metadata, lineage, tracking etc.)  and governance solutions for big data platforms on premise or on AWS, Google and Azure cloud.
	- Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.
	- Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.  
	- Minimum 1 year of building Business Data Catalogs or Data Marketplaces on top of a Hybrid data platform containing Big Data technologies (e.g  Alation, Informatica or custom portals).
+ skill set:
	- Minimum 2+ years of expertise in designing, implementing large scale data pipelines for data curation and analysis, operating in production environments, using Spark, pySpark, SparkSQL, with  Java, Scala or Python on premise or on Cloud (AWS, Google or Azure)
	- Minimum 1 year of designing and building performant data models at scale for using Hadoop, NoSQL, Graph or Cloud native data stores and services.
	- Minimum 1 year of designing and building secured Big Data ETL pipelines, using Talend or Informatica Big Data Editions; for data curation and analysis of large scale production deployed solutions.
	- Minimum 6 months of experience designing and building data models to support large scale BI, Analytics and AI solutions for Big Data.
	- Knowledge of Auto Machine Learning tools ( H2O, Datarobot, Google AutoML).
	- Minimum 6 months of expertise in implementation with Databricks.
	- Experience in Machine learning using Python ( sklearn) ,SparkML , H2O and/or SageMaker.
	- Minimum 2 years designing and implementing large scale data warehousing and analytics solutions working with RDBMS (e.g. Oracle, Teradata, DB2, Netezza,SAS) and understanding of the challenges and limitations of these traditional solutions.
	- Minimum 1 year of experience implementing SQL on Hadoop solutions using tools like Presto, AtScale, Jethro and others.
	- Minimum 1 year of experience building data management (metadata, lineage, tracking etc.)  and governance solutions for big data platforms on premise or on AWS, Google and Azure cloud.
	- Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.
	- Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.  
	- Minimum 3+ years of Spark/MR/ETL processing, including Java, Python, Scala, Talend; for data analysis of production Big Data applications
+ skill set:
	- Director of Applied Machine Learning Experiences
	- The Machine Learning team is building a new platform called Sparta and this platform will be used to build assistive intelligence experiences (AIEs).  These AIEs enable Splunk customers to accomplish their tasks while using real-time user feedback to build self-tuning cloud services. The focus of the selected candidate will be to manage the AIE portfolio and automate simple tasks and processes by harnessing the power of Big Data, cloud, and data science to aid in actionable decision-making and system remediation.
	- Create the capability to make intelligent recommendations, detect anomalies, and help users prioritize events and alerts.
	- Create libraries, services, and SDK to accelerate AIE development.
	- Lead a team of engineers and researchers that collaborate with product and applied research teams to build ML features into a wide variety of products across Splunk. 
	- Recruit, mentor, and grow world class engineers and managers
	- Partner with cross functional team members to develop and maintain a well-defined roadmap, while balancing technological excellence.
	- Manage the AIE portfolio (the assistive intelligence experiences)
	- Help define technical direction and architecture with engineering team members.
	- Facilitate coordination of multiple scrum teams to successfully deliver committed feature sets.
	- Drive practices in training and development, and drive efficiencies across multiple feature teams.
	- Build a culture of continuous learning, growth, and sharing of technological insights.
	- 10+ years of hands-on technical experience.
	- 4+ years of direct management experience of highly technical managers and engineers.
	- Bachelor's degree in Computer Science or another quantitative field. We will consider equivalent practical experience
	- Experience in delivering multiple complex technical projects within an Agile environment.
	- Familiar with machine learning and data science workflows.
	- Expertise in developing software on a public cloud platform (AWS, GCP, Azure).
	- Expertise in developing software with stream processing technology (Kafka, AWS Kinesis).
	- Proficiency with backend systems built using microservices, containerized infrastructure, and modern continuous delivery practices.
	- Demonstrated ability to build a culture of team building and people management.
	- Demonstrated ability to reach stretch goals in a fast-paced environment
	- Outstanding written and verbal communication skills.
+ skill set:
	- Director of Engineering - Machine Learning
	- Recruit, mentor, and grow world class engineers and managers.
	- Partner with cross functional team members to develop and maintain a well-defined roadmap, while balancing technological excellence.
	- Help define technical direction and architecture with engineering team members.
	- Facilitate coordination of multiple scrum teams to successfully deliver committed feature sets.
	- Drive practices in training and development, and drive efficiencies across multiple feature teams.
	- Build a culture of continuous learning, growth, and sharing of technological insights.
	- 10+ years of hands-on technical experience.
	- 4+ years of direct management experience of highly technical managers and engineers.
	- Bachelor's degree in Computer Science or another quantitative field. We will consider equivalent practical experience.
	- Experience in delivering multiple complex technical projects within an Agile environment.
	- Familiar with machine learning and data science workflows.
	- Expertise in developing software on a public cloud platform (AWS, GCP, Azure).
	- Expertise in developing software with stream processing technology (Kafka, AWS Kinesis).
	- Proficiency with backend systems built using microservices, containerized infrastructure, and modern continuous delivery practices.
	- Demonstrated ability to build a culture of team building and people management.
	- Demonstrated ability to reach stretch goals in a fast-paced environment.
	- Outstanding written and verbal communication skills.
+ skill set:
	- Imagimob is a fast-growing, high-tech startup with an exciting future ahead. We are currently developing our next generation hybrid AI platform that allows for advanced motion detection for smaller Internet-of-things-articles, of virtually every kind. For example, the technology is today being used in projects ranging from the automotive and manufacturing industry to the health sector.
	- We are looking for a Machine Learning / AI Application Engineer to join our development team in Stockholm. Do you have excellent programming skills and are interested in working in the frontline of artificial intelligence? Then this position might be something for you.
	- Working with us you will get the opportunity to become part of our cross functional team with creative and innovative software engineers and AI researchers building the next generation AI beyond Deep Learning. Since we are still in a startup phase, you will also be able to develop in the areas you find the most interesting.
	- Has excellent programming skills in one or several languages, preferably in C, C# or Python
	- Experience with a deep learning framework (e.g. tensorflow, keras, Torch, caffe)
	- University degree or equivalent experience in computer science, electrical engineering, engineering physics or similar
	- A passion for Artificial Intelligence and Machine Learning technologies
	- Extreme ownership and go-get attitude
	- Has experience from programming on embedded platforms
	- Good knowledge in signal processing, statistics and its practical applications
	- Experience from Artificial Intelligence and Machine Learning technologies
	- And if this is not enough, you will get the chance to change history and shape the future of humanity...
	- The opportunity to be part of building the next generation AI beyond deep learning
	- Being part of an excellent international engineering team with highly motivated individuals striving for a common goal
	- A chance to get to solve real world problems using AI
	- A prestigeless and an open minded company culture
	- Short decision paths, we love getting things done
+ skill set:
	- 2+ years of work experience developing and deploying production-quality code
	- Foundational knowledge of commonly used machine learning techniques, such as cluster analysis, classification methods, and linear and nonlinear regression modeling
	- Experience developing applications using Natural Language Processing techniques.
	- Experience working with cross-functional teams in a dynamic environment
	- Hands-on experience building deep learning models on text corpora, preferably using PyTorch and Tensor Flow
	- Experience building machine learning models in the healthcare domain
	- Experience using AWS infrastructure and tools for machine learning
	- Experience with other back-end software engineering frameworks
	- [Talkspace](https://www.talkspace.com/)
+ skill set:
	- Data/Model Validation Engineer
	- We are looking for someone passionate about learning how machine learning systems are developed to assist with validating and processing training data to evolve our state of the art systems.
	- Engage with software engineers on the Perception team to identify and collect training data to evolve our machine learning systems.
	- Working with engineers on the Perception team, train new machine learning models and perform analysis to quantify how they perform based on changes to the training data sets.
	- Provide feedback on tools and processes for efficient workflow of training data creation and validation.
+ skill set:
	- Project-based analytics including but not limited to: Machine Learning, Predictive Analytics, Comparative Effectiveness Analysis, Failure Analysis, Big Data Analytics, Optimization, Demand Forecasting, Customer Segmentation, Customer Analytic Record.
	- Minimum 3 years' experience with predictive analytics tools, including at least two of the following: R, SAS, Alteryx, Python, Spark, and Tableau.
	- Experience in the following areas: Applied Statistics/Econometrics, Statistical Programming, Database Management & Operations, Digital, Comparative Effectiveness Research.
+ skill set:
	- You've got a Master's degree in statistics, econometrics, mathematics, or deep learning architectures including convolutional, recurrent, autoencoders, GAN's, and ResNets
	- You're a coding wizard with Python, C# (.NET), Scala, MxNet, CNTK, R, H2O, TensorFlow, PyTorch, cuDNN, NumPy, and SciPy
+ skill set:
	- At least 4 years' experience in deep learning, machine learning or artificial intelligence applications like virtual agent, robotic process automation and video/image/text analytics
	- Minimum of 2 years' experience in AI/ML/RPA functional expertise with developing use cases and building/leading Proofs of Concept
	- At least 2 years architecting AI Pipelines orchestrating multiple analytics engines
+ skill set:
	- Minimum 5 years of developing machine learning methods, including familiarity with techniques in clustering, regression, optimization, recommendation, neural networks, and other.
	- Strong quantitative and analytical skills with minimum 3 years of experience with data science tools, including Python, R, Scala, Julia, or SAS
	- Ability to technically lead data science projects
	- Deadline-driven, organized and able to multi-task
	- Familiarity with using cloud services (AWS, Google, Azure) or Big Data tools (Hadoop, Hive, Spark) in data science solutions
+ skill set:
	- Proven experience with caching, queuing, RPC frameworks and other building blocks of a large scale distributed systems.
	- Experience with NoSQL AWS data stores like DynamoDB, CloudSearch or their open source equivalents like Cassandra, HBase, Solr or ElasticSearch
	- Experience with React or other modern javascript frameworks.
	- Experience with MySQL, Redis, Memcache and related web-backend technologies.
	- Experience with data pipelines (Kafka, AWS Kinesis, AWS Data Pipeline)
	- Experience building web applications, widgets, or interactive experiences.
+ skill set:
	- Cortex is a team of software engineers and machine learning scientist to developing state-of-the-art machine learning capabilities to refine and transform our products.
+ skill set:
	- solid understanding and experience using fundamental data fusion and tracking techniques, such as:
		* Kalman filtering
		* batch processing
		* multiple-hypothesis data association
		* multiple dynamic models
	- experience fusing across multiple real-world sources whose data may exhibit characterstics, such as:
		* sub-dimensioned data
		* time-late data
		* biased data
		* negative data
+ skill set:
	- scikit-learn
	- TensorFlow
	- PyTorch
	- MXNet
	- neural network architectures
		* CNNs
		* RNNs
		* autoencoders
		* generative models
	- other machine learning frameworks
	- experience deploying decision policy algorithms:
		* MDPs
		* RL algorithms
		* tree search
		* rules engines
		* path planning
+ knowledge of state estimation and data fusion algorithms
+ skill set:
	- ***LightGBM***, light gradient-boosting machine
	- ***compare bagging versus boosting***
	- usage of ***KDD data set***
	- ***MLP***
	- ***stacking***
+ skill set:
	- deep learning frameworks:
		* TensorFlow
		* PyTorch
		* PaddlePaddle
+ Expert in prototyping traditional ML (GBMs, scikit, etc.) and AI frameworks (keras, tensorflow, mxnet, pytorch, etc.) for a variety of applications
+ ***Experience with one of the ML platforms: Python / scikit-learn, Spark, vowpal wabbit, etc***
+ skill set:
	- 7+ years of industry/academic experience in Machine Learning or related field
	- You will be expected to have a good understanding of a broad range of traditional supervised and unsupervised techniques (e.g. logistic regression, SVMs, GBDTs, Random Forests, k-means and other clustering techniques, matrix factorization, LDA . . .) as well as be up to date with latest ML advances (e.g. Deep Neural Networks, or non-parametric Bayesian methods).
	- Previous experience building end to end scalable Machine Learning systems
	- Software engineering skills. Knowledge of Python and C++ is a plus.
	- Knowledge of existing open source frameworks such as scikit-learn, Torch, Caffe, or Theano is a plus
	- BS, MS, or PhD in Computer Science, Engineering, Statistics or a related technical field
	- Love of the Quora product
+ skill set:
	- BS, MS or PhD in Computer Science, Machine Learning, NLP or a related technical field
	- 5+ years of industry experience preferred
	- Good mathematical understanding of popular NLP and Machine Learning algorithms
	- Experience building production-ready NLP or information retrieval systems
	- Hands-on experience with NLP tools, libraries and corpora (e.g. NLTK, Stanford CoreNLP, Wikipedia corpus, etc)
	- Knowledge of Python or C++, or the ability to learn them quickly
	- Love of the Quora product
+ ***Experience building shallow or deep learning models (GBDT, CNN, RNN, LSTM), toolkits e.g. OpenCV, Matlab, RStudio, Weka, MLLib and frameworks PyTorch, TensorFlow, CNTK***
+ ***Expertise in multivariate analysis, graphical models, Bayesian hierarchical modelling, Markov chain Monte Carlo (MCMC), mixture models, stochastic processes, generalized linear models (GLMs), dimensionality reduction (PCA/CCA/MDS/tSNE) and other machine learning techniques***
+ ***Familiar with one or more machine learning, statistical modeling tools such as R, Matlab, scikit learn and deep learning frameworks, such as tensorflow, keras, caffe, torch.***
+ Knowledge in machine learning framework - Tensorflow, Caffe, Torch or Theano
+ Spark, Kafka
	- Spark, for large-scale data science and applied machine learning
	- Kafka, distributed stream-processing platform
+ skill set:
	- Apache Beam or Google Dataflow
		* https://beam.apache.org/
		* "Apache Beam is an open source unified programming model to define and execute data processing pipelines, including ETL, batch and stream (continuous) processing.[2] Beam Pipelines are defined using one of the provided SDKs and executed in one of the Beam's supported runners (distributed processing back-ends) including Apache Flink, Apache Samza, Apache Spark, and Google Cloud Dataflow."
			+ https://en.wikipedia.org/wiki/Apache_Beam
	- MapReduce frameworks
		* Hadoop
		* Spark, Apache Spark
			+ https://en.wikipedia.org/wiki/Apache_Spark
			+ Spark MLlib, MLlib Machine Learning Library
		* BigQuery, BigQuery SQL, Google BigQuery
	- Bayesian methods, MCMC, Gibbs sampling
	- significance testing
	- active learning methods
		* multiarm-bandit
		* active Thompson sampling
		* causal inference using instrumental variables and other forms of multi-factor attribution methods
		* sequential testing methods
		* PyMC3
	- real-time metrics tracking systems
+ skill set:
	- ***NVIDIA TensorRT***
		* https://developer.nvidia.com/tensorrt
			+ NVIDIA® TensorRT™, an SDK for high-performance deep learning inference, includes a deep learning inference optimizer and runtime that delivers low latency and high throughput for inference applications.
		* https://github.com/NVIDIA/TensorRT
+ skill set:
	- are as passionate about teaching AI/ML as you are about AI/ML itself
	- are experienced in software engineering, machine learning engineering in Python using scikit-learn: regression, trees, ensembles (nice-to-have: catboost, XGBoost)
	- are comfortable in collecting and manipulating data in Python: APIs, web scraping, Pandas, numpy/scipy
	- have tackled Deep Learning (DL), including LSTMs, RNNs, CNNs (nice-to-have: YOLO) with real-world application experience such as computer vision or NLP
	- have implemented ML and DL at scale using SparkML, Keras, TensorFlow and/or Pytorch
	- have a strong understanding of software engineering best practices, including version control, testing, monitoring and debugging
	- are highly proficient in the curriculum topics in our program
	- are available for weekly, 30-minute video check-ins with students to help them set and achieve learning goals, answer subject matter questions, provide feedback on projects, and career advice
	- have at least 3 years of experience solving real-life machine learning problems and building models
	- are empathetic and have excellent communication skills
+ skill set:
	- Experience in one or more of the following areas:
		* Control theory
		* Motion planning
		* Optimization
		* Formal logic
		* Game AI development
	- Experience in developing safety-critical, embedded or real-time systems
	- Published research in any of the above mentioned areas
	- Experience in machine learning and data analysis
	- Programming in Python, working with Linux
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.









###	Notes and Skill Sets about Applied Machine Learning, Applied ML, for Computational Science (or Scientific Computing)




Skill sets about applied machine learning, applied ML, for computational science (or scientific computing):
+ skill set:
	- Research Engineer - FAIR AI-Guided Design
	- Our team is a part of FAIR’s AI guided design group. The vision of the team is to create an AI design agent which can be used by optics experts to achieve fundamental breakthroughs in the field of optics and scientifically guided AI. These breakthroughs will power advances across the field of optics, but particularly in the design of optical devices, e.g. photonic integrated circuits. We are hiring AI engineers and scientists to advance this effort. The work will be done in collaboration with world class computational experts in optics and AI.
	- Work with both optical engineers / scientists to integrate AI into optical design workflows
	- Work with AI engineers / scientists to develop datasets and training pipelines for physics grounded AI models
	- Publish research in top tier conferences / journals
	- Lead, collaborate, and execute on research that pushes forward the state-of-the-art physics guided generative models
	- Mentor engineers / scientists on engineering best practices, building AI tooling, improving performance in simulations and training
	- Minimum Qualifications
		* Prior experience with Meta can be considered to supplement an applicant’s prior years of experience or types of prior experience to meet the minimum qualifications of the position.
		* Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
		* 3+ year(s) of work experience in an industry, university, or government lab
		* Research experience in one or more of these areas: generative AI, AI for science / mathematics, machine learning, deep learning, or related field
		* Experience writing software and executing complex experiments involving AI models and large datasets
		* Experience working with machine learning libraries like Pytorch, Tensorflow, etc.
		* Must obtain work authorization in the country of employment at the time of hire, and maintain ongoing work authorization during employment.
	- Preferred Qualifications
		* A PhD in Artificial Intelligence (AI), computer science, or related technical fields
		* Experience in applying generative AI to at least one scientific / mathematics problem. Examples could include: using theoretical knowledge, e.g of physics / optics, to build in prior to the AI architecture, design of biological systems, e.g. proteins or antibodies, applying AI to solve intractable computational problems
		* 4+ year(s) of work experience in an industry, university, or government lab
		* Experience with scientific computing, distributed computation, scaling computational experiments, working with physical, chemical, or biological simulations
		* Experience working and communicating cross functionally
		* First author publications experience at peer-reviewed AI conferences (e.g., ICML, NeurIPS, Nature etc)
		* $143,000/year to $204,000/year + bonus + equity + benefits
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.









###	Generative AI


####	Notes about Generative AI












####	Skill Sets about Generative AI



+ skill set:
	- Research Engineer, Language - Generative AI
	- Meta is seeking a Research Engineer to join our Large Language Model (LLM) Research team. We conduct focused research and engineering to build state-of-the-art LLMs, which we often open-source, like our team’s recent Llama 2. We are looking for strong engineers who have a background in generative AI and NLP, with experience in areas like language model evaluation; data processing for pre-training and fine-tuning; responsible LLMs; LLM alignment; reinforcement learning for language model tuning; efficient training and inference; and/or multilingual and multimodal modeling.
	- Design methods, tools, and infrastructure to push forward the state of the art in large language models.
	- Define research goals informed by practical engineering concerns.
	- Contribute to experiments, including designing experimental details, writing reusable code, running evaluations, and organizing results.
	- Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU).
	- Work with a large and globally distributed team.
	- Contribute to publications and open-sourcing efforts.
	- Minimum Qualifications
		* Prior experience with Meta can be considered to supplement an applicant’s prior years of experience or types of prior experience to meet the minimum qualifications of the position.
		* Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
		* Research experience in machine learning, deep learning, and/or natural language processing.
		* Experience with developing machine learning models at scale from inception to business impact.
		* Programming experience in Python and hands-on experience with frameworks such as PyTorch.
		* Exposure to architectural patterns of large scale software applications.
		* Must obtain work authorization in the country of employment at the time of hire, and maintain ongoing work authorization during employment.
	- Preferred Qualifications
		* Master's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
		* A PhD in AI, computer science, data science, or related technical fields.
		* Direct experience in generative AI and LLM research.
		* First author publications at peer-reviewed AI conferences (e.g., NeurIPS, CVPR, ICML, ICLR, ICCV, and ACL).
	- $143,000/year to $204,000/year + bonus + equity + benefits
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.












###	Computer Vision


####	Notes about Computer Vision

Topics in computer vision:
+ 3-D computer vision
	- 3D pose estimation
	- 3D scene modeling
+ based on:
	- machine learning
		* deep learning
+ event detection
+ feature extraction
+ ***frameworks, tools, and libraries***
	- ***OpenCV***
+ geometric computer vision
+ image restoration
+ image segmentation
+ image understanding systems, IUS
+ indexing
+ learning
+ motion estimation, motion analysis
	- egomotion, visual odometry
	- optical flow, optic flow
	- tracking, video tracking
+ object categorization
+ object recognition, or object classification
	- object detection
	- object identification
	- specialized tasks:
		* 2-D code reading
		* content-based image retrieval
		* facial recognition
		* object character recognition, OCR
		* pose estimation
		* shape recognition technology, SRT
+ scene reconstruction
+ system methods:
	- image acquistion
	- pre-processing
	- feature extraction
	- detection / segmentation
	- high-level processing
		* verification of model-based and application-specific assumptions
		* estimation of application-specific parameters
			+ object pose
			+ object size
		* image recognition
		* image registration
	- decision making
+ template finding
+ video tracking
+ visual prototyping
+ visual servoing
	- vision-based robot control, VS







Applications of machine learning -based computer vision:
+ automatic inspection in post-manufacturing quality control/assurance
+ autonomous vehicles
+ assisting humans in identification tasks, such as species identification system of plants and animals
+ event detection
+ human-computer interaction, HCI
+ medicine
+ modeling objects or environments
+ navigation
+ organization of information
+ process control
+ tactile feedback
+ tracking surfaces or planes in 3-D coordinates
	- enables augmented reality experiences




Machine learning -based frameworks for computer vision:
+ HALO AI










####	Skill Sets about Computer Vision


Skill sets for ***computer vision***:
+ categories of computer vision methods:
	- image segmentation methods: U-Net, Mask R-CNN
	- general-purpose image/video tools: PIL, cv2, skimage
	- object detection methods: YOLOv3, RetinaNet
	- image classification, and other general purpose networks: VCG, Inception, ResNet, ResNeXt, NASNet, EfficientNet
	- generative networks: GAN, VAE
+ ***Strong publication record in top-tier research publications and conferences such as IJCV, CVPR, ICCV, ECCV, ICRA.***
+ Successful record of publication in top-tier international research venues (e.g. ICLR, AAAI, NeurIPS, CVPR, ECCV, ICCV, SIGGRAPH)
+ At least 2 years of experience using deep learning techniques (CNN, RNN, LSTM) on computer vision tasks (object detection and tracking, classification, action recognition)
+ Experience in vision frameworks like OpenCV, gstreamer, OpenCL etc.
+ Experience with any one of segmentation, object detection, image classification, GANs, monocular depth estimation or a related field
+ Seeking motivated graduate interns in the intersection of computer vision, 3D graphics and machine learning with applications to interactive visual effects processing. In this position, you will collaborate with VFX artists and fellow researchers in NEXT team to invent algorithmic solutions to VFX challenges. This is a full-time position located in Hillsboro, Oregon.
+ skill set:
	- Develop new imaging technologies that enhance visual communication on both handheld and wearable devices
	- Develop new technologies that make it easier for users to interact with devices and well as for devices to interact with other devices
	- Introduce major innovations that can result in product features or new areas of business
	- Collaborate with the researchers and engineers to make important product decisions
	- Develop skills to inspire and manage small or large groups of researchers and engineers
	- PhD in a technical field such as computer science or electrical engineering with expertise in computational imaging, computational photography, or computer vision
	- 3+ years of research or industry experience
	- Track record of innovative work in the area of computational imaging
	- Experience or familiarity with imaging optics, illumination techniques, image processing, computer vision and computer graphics
	- Ability to perform research that is justified and guided by business opportunities
	- Ability to thrive in a fast-paced, ever-changing work environment
	- Successful record of publication in top-tier international research venues
	- Collaborative, positive, and team-oriented mindset
	- Hands-on research experience and fast prototyping skills
	- We are looking for a highly innovative, motivated, and self-directed researcher. Working closely with other researchers and our engineering teams, you will tackle unique technical challenges such as developing techniques to enhance existing products, create new products, deploying algorithms to handle our scale, and improving the experience on Snapchat for millions of people every day. In addition to impacting the company via products, researchers are encouraged to publish their results in top-tier journals and conferences.
	- We're looking for a Research Scientist to join Snap's Computational Imaging Research Lab in NYC! The mission of the lab is to create hardware and/or software approaches to computational imaging that enable new photographic functionalities and experiences that go beyond what is possible with traditional cameras and image processing methods. Our goal is to empower our users with new tools that allow them to communicate with each other more efficiently and in more creative ways than possible today.
+ skill set:
	- Strong track record of research in related areas including but not limited to (preferring candidates with publications in top-tier venues such as SIGGRAPH, SIGGRAPH Asia, CVPR, ICCV, ECCV):
		* 3D modeling and geometry processing
		* Physically-based simulation
		* 3D reconstruction
		* Light field capture and rendering
		* Material and lighting estimation
		* Character animation
		* Rendering
		* Neural rendering
		* 3D deep learning
		* Image and video manipulation
	- Experienced in implementing and optimizing complex and performance-critical systems.
+ skill set:
	- Research and practical experience in one or more areas of computer vision, including but not limited to (preferring candidates with publications in top-tier venues such as CVPR, ICCV, ECCV):
		* Generative models, GAN (generative adversarial networks)
		* Image and video synthesis/manipulation
		* Unsupervised and weakly-supervised image/video representation learning
		* Object detection, recognition, segmentation, and tracking
		* Action recognition, event detection, video summarization
		* Image and video retrieval
		* Image and video enhancement
		* Image and video restoration
+ skill set:
	- Strong track record of research in related areas including but not limited to (preferring candidates with publications in top-tier venues such as CVPR, ICCV, ECCV):
		* 3D reconstruction (structure-from-motion, multi-view stereo, photometric stereo etc.)
		* Large-scale place recognition
		* Real-time simultaneous localization and mapping (SLAM) systems
		* 3D object pose estimation and tracking
		* 3D plane estimation and 3D primitive estimation
		* 3D scene parsing
		* Light field and panorama capture
		* Novel view synthesis and image-based rendering
		* Neural rendering
		* Lighting estimation
	- Experienced in implementing and optimizing complex and performance-critical systems.
	- Self-motivated and strong problem solving skills.
	- Collaborative work style.
+ skill set:
	- Masters or PhD in a computer vision-related discipline (or equivalent professional experience), preferably in one of the following areas: probabilistic graphical models, approximate inference, combinatorial optimization, neural networks, object class and instance detection, pose estimation, 3D scene understanding and recognition from RGB-D imagery, 3D reconstruction, structure-from-motion, multi-view stereo, etc.
	- Strong publication record and/or industry experience in the above mentioned areas, in top-tier conferences such as NeurIPS, ICML, ICLR, AAAI, AISTATS.
	- Interest/background in algorithms with human-like abilities such as learning from small amounts of data and tight sensorimotor feedback.
	- Strong C++ and/or Python skills. Experience developing with OpenCV, TensorFlow, and PCL.
+ skill set:
	- OpenVX Driver Feature Development: Developing OpenVX driver for Blaize's proprietary processor involves design, implementation, unit testing, maintenance of the driver code. This also involves memory management, state management, graph algorithms.
		* Portable, Power-efficient Vision Processing. OpenVX™ is an open, royalty-free standard for cross platform acceleration of computer vision applications.
		* OpenVX is an open, royalty-free standard for cross-platform acceleration of computer vision applications. It is designed by the Khronos Group to facilitate portable, optimized and power-efficient processing of methods for vision algorithms. This is aimed for embedded and real-time programs within computer vision and related scenarios. It uses a connected graph representation of operations.
	- OpenVX Built-in kernel Development: The driver team also implements kernels using OpenCL C++ and Assembly language. This involves understanding/tweaking image-processing/CV/CNN algorithms for implementation most suited to our h/w architecture.
	- OpenVX Application Development: The driver team also designs and writes a lot of sample applications for unit testing as well as POC of the features implemented, bugs fixed and performance improved.
	- Tool Development: The driver team also writes tools relevant to its development and testing. The tools are developed using scripting languages etc. python, ruby or other prototyping languages.
	- Proficiency in C/C++, OOPS, STL, Data Structures & Algorithms, Background in Graphics/Computer-Vision/Image-processing, OpenGL/OpenCL/OpenCV/CUDA, Device Driver Architecture, GPU Architecture, OpenCL C++ programming, Assembly programming.Key Skills/Abilities:C/C++ (Must): Required for design, implementation, unit testing, debugging of the driver and application code. Candidates should be well-versed in OOPS, polymorphism, STL, templates, design patterns, memory management etc.
	- Having worked in embedded software development would be beneficial.Graphics, OpenGL, OpenCL, CV, CUDA, OpenCL C++, Assembly (highly sought after): Required for understanding h/w architecture, s/w design and architecture; Also required for writing the OpenVX built-in kernels, coming up with kernel algorithms, optimizations for driver implementation etc.
	- Python/Shell/Ruby scripting: Required for writing scripts for automating application/test generation and execution. Also useful for automating other operations like code analysis, golden output generation etc.OpenGL, OpenCL, OpenCV, Graphics, Assembly - Any experience is welcome.
	- C, C++, Data Structures, Algorithms & Graphic Libraries
+ skill set:
	- Demonstrated experience in algorithm development and application of image processing, registration, segmentation, etc.
	- Working knowledge of geometry and application experience
	- OpenGL or DirectX, Cg knowledge and development experience.
	- Proficiency in C++ development, parallelization, unit testing, and performance measurement
	- C++ GUI development experience
	- Experience in developing SQLite database application
	- Microsoft Visual Studio development experience
	- Solid software engineering foundation and a commitment to writing high quality code, including clear and understandable design and implementation, well-defined interfaces, ease of build and use & ease of extensibility.
	- Computer Vision and Image Processing algorithm development experience
	- OpenCV, IPP, CUDA experience
	- Familiarity with data formats, such as STL, OBJ, FBX, etc.
	- Familiarity with serial communication protocol, TCP/IP server/client communication protocol
	- Familiarity with software development tools and methodology
+ skill set:
	- At ApertureData, we are on a mission to solve data infrastructure challenges for machine learning on big-visual-data through our unique visual database, ApertureDB. We are an angel and NSF grant backed, fast growing startup looking for a Computer Vision Systems Engineer because dealing with images and videos is challenging, particularly at scale. If you can easily tackle the likes of OpenCV and ffmpeg, dealing with large object caching excites you, and being among the first five hires fires up your imagination on what all hats you get to wear, we are looking forward to hearing from you!
	- Minimum qualifications
		* We are focused on making access to visual data simple and fast. That requires absorbing the comlexity of these data types within ApertureDB, therefore requiring certain qualifications
		* 5+ years of experience in Computer Science, or a related technical field
		* 2+ years of experience in C++
		* Understand different image and video formats and encodings
		* Experience working with OpenCV and FFMPEG libraries
		* Systems level data structure and algorithm effects (kernel and driver level included)
		* Data structure optimization techniques
		* Valid work status in the US
	- Additional qualifications
		* It would be great if you already came to us with a few more tricks up your sleeve.
		* Be comfortable with JSON, Python, Git, and Linux
		* Other visual processing libraries
		* Understand the effects of cache/memory/disk as they interplay with each other and processing
		* Efficient algorithms for visual transformations
+ skill set for Computer Vision Algorithm Engineer:
	- Lead R&D of computer vision algorithms, including applying visual technologies to faces, images, videos, and text. This R&D applies to campus, shopping mall, transportation, logistics, medical imaging, content moderation, and other scenarios.
	- Research and develop deep learning algorithms, especially for computer vision, ***model acceleration, model encryption, and model quantization***.
	- Rich research and practical experience with video image processing and analysis, machine learning, and deep learning, and strong hands-on skills. Ability to use one of the following deep learning tools to solve problems: Caffe, PyTorch, MXNet, and TensorFlow
	- At least one paper published in a top-level conference or periodical (including ***CVPR, ICCV, ECCV, NIPS, ICML, KDD, PAMI, IJCV***, etc.) in the field preferred
	- Logical analysis skills to develop abstract mathematical models of real problems, then solve them
	- Experience with computer vision projects, including transportation, medical care, campus, OCR, images, and videos preferred
	- Good professional quality and conduct, excellent teamwork, and rigorous working style
+ skill set:
	- We are currently seeking a software engineer intern with strong Computer Vision, Graphics and Deep Learning fundamentals and solid implementation skills to contribute to the development of NVIDIA Maxine - a comprehensive suite of SDKs with state-of-the-art AI features for virtual collaboration and content creation.
	- You will work alongside brilliant engineers on core technologies to solve challenging computer graphics, vision, and deep learning problems. You will work collaboratively with research and production teams on new groundbreaking approaches that transform the industry.
	- Gain first-hand experience and grow your technical expertise in one or multiple areas of:
		* 3D human face/body/gaze tracking
		* Avatar 3D modeling and animation
		* Hand pose prediction and recognition
		* Video artifact removal, super resolution and style transfer
		* 3D reconstruction and scene understanding
	- Pursuing BS, MS, or PhD in Computer Science or related field
	- Hands on experience with building, training and debugging neural networks
	- Hands on expertise with one or more Deep Learning frameworks (Caffe, tensorflow, keras etc)
	- Strong software engineering background, Proficiency in C++ programming or Python.
	- Self-motivated, fast to act and eager to learn
	- Experience of using deep learning in computer vision and graphics
	- Background with CUDA programming, and a real passion for optimizing system performance.
	- Background with SDK development
	- Experience of building platforms to deploy computer vision and deep learning technologies.
+ skill set:
	- NVIDIA is searching for a world-class Research Scientist to join our growing research team. The ideal candidate will be conducting cutting-edge research at the intersection of Machine Learning, Computer Vision and Computer Graphics, and working alongside top experts in these fields. With incredible resources in AI, graphics and robotics, you will be able to impact, contribute and advance these exciting domains. Topics include but are not limited to AI for simulation, 3D Deep Learning, DL for animation, content generation, transfer learning, domain adaptation, computer vision, and medical imaging. With its unique open culture, NVIDIA is one of the best industry labs to do AI research.
	- Apply deep learning techniques to the simulation of complex physical phenomena such as fluid dynamics, fracture of materials, combustion, audio synthesis and propagation, and more.
	- Work on improving realism and immersive qualities of VR environments and interactions, including intelligent characters, behavior of crowds and traffic, and human-machine interface problems.
	- Participate in numerous projects to conduct Deep Learning research and publish papers to well known conferences (ex. ICCV)
	- Product development for technology in Games, Virtual Reality, Education and other applications.
	- Completion of a PhD or equivalent experience in Computer Science or a related field (or equivalent experience)
	- Expertise in computer graphics, simulation or game development.
	- 2+ years of experience with C++/C, CUDA, DX, or OpenGL.
	- Dedication to producing high quality and creative results in a collaborative environment
	- Excellent work ethic and problem-solving skills
	- Strong publication record
	- Ways to stand out from the crowd:
	- A great communicator who is self-motivated towards the team goal
	- Take pride in helping others and welcome mentoring others around you
	- Sharp mathematics skills
	- Image recognition and speech recognition — GPU deep learning has provided the foundation for machines to learn, perceive, reason and solve problems. The GPU started out as the engine for simulating human imagination, conjuring up the amazing virtual worlds of video games and Hollywood films. Now, Nvidia's GPU runs deep learning algorithms, simulating human intelligence, and acts as the brain of computers, robots and self-driving cars that can perceive and understand the world. Just as human imagination and intelligence are linked, computer graphics and artificial intelligence come together in our architecture. Two modes of the human brain, two modes of the GPU. This may explain why Nvidia GPUs are used broadly for deep learning, and NVIDIA is increasingly known as “the AI computing company.”
+ skill set:
	- As the Geometric Computer Vision Engineer you will need to develop computer vision algorithms for object detection, tracking, and classifications that are robust to lighting and weather changes. This work requires that you collaborate with state estimation engineers and assist in developing powerful feature detectors/ descriptors and large-scale 3D maps. Furthermore, it is expected that you stay organized and communicative with others to ensure that goals and objectives are being met on time. To guarantee the consistency of projects, you will participate in end-to-end development and training in Cloud to optimize development on embedded platforms.
	- 3-5+ years' significant industry experience and/or publications at venues such as ICRA, RSS, IROS, or CVPR in one or more areas-
		* Image Processing
		* Geometric Computer Vision
		* Deep Learning (ideally CNNs)
		* Classical machine learning such as SVM, decision trees, boosting, graphical models, sequential prediction, or sampling methods
	- Strong C++ programming and software design skills
	- Familiarity with a deep learning framework such as PyTorch, TensorFlow, Caffe, or Theano
	- BS, MS, or PhD in Robotics, Machine Learning, Computer Science, Electrical Engineering, a related field, or equivalent experience
	- Experience deploying CV/ML in a robot or real-time application
	- Understanding of optimization of DL models and deployment on embedded platforms such as the Nvidia Jetson
	- Experience in designing large-scale machine learning pipelines
+ knowledge of CUDA / OpenCL / OpenCV
+ skill set:
	- Design and implementation of state of the art monocular computer vision algorithms
	- Solve problems involving odometry, landmark detection, structure from motion and segmentation in large scale outdoor environments
	- Integrate vision based algorithms into our probabilistic fusion framework
	- Help in identifying core requirements for camera sensors
	- Code development in C++/Python
	- Work with real data on our self driving car
	- Masters or PhD Computer Science, Electrical Engineering or both.
	- Deep Experience in SfM, VO, and classical computer vision algorithms
	- Expert knowledge in computational geometry
	- Experience in machine learning, feature detection and classification
	- Experience with open source computer vision and linear algebra frameworks
	- A solid background in statistics, probability and linear algebra
	- Experience with real world datasets
	- Experience with real time algorithm implementation
	- Ability to work independently without direct supervision
	- Experience with CV algorithm packages (Eigen, OpenCV, etc.)
	- Knowledge of Deep learning techniques applied to CV
	- Experience in Linux based environments
	- Experience in SLAM and/or motion planning
	- Experience with CUDA, OpenCL or other GPU frameworks
	- Experience with automotive systems or UAV systems
	- Ability to lead a small technical team that balances research and application
+ skill set:
	- Strong knowledge of the state-of-the-art in computer vision and machine learning algorithms with a solid understanding of OpenCV
	- Experience working with point cloud processing and Point Cloud Library (PCL)
+ skill set:
	- Develop pipeline for data tagging, labelling and munging to be consumed for training of ML models for vision based tasks.
	- Architect and train machine learning models for object detection and tracking
	- Build testing environment to test the model and simulate edge-case performance scenarios
	- Experience with at-least one of Tensorflow/Caffe/Theano/Torch
+ skill set:
	- skills and knowledge of topics, such as:
		* object recognition
		* semantic segmentation
		* human recognition
		* SLAM, simultaneous localization and mapping.
			+ 3-D SLAM, or localization
		* 6-D object pose estimation algorithm
			+ human pose estimation
		* ray tracing
		* physically-based rendering
		* efficient 3-D map representation
	- performance tuning for robots in real environments
	- performance improvement of machine learning model using simulation
	- robot system development, using ROS 1, ROS 2
	- cloud-based distributed learning experience
	- transfer learning from simulation to real machine
	- accelerating algorithms with OpenCL and CUDA
	- sensor simulation:
		* camera
		* LIDAR
		* RBG-D sensors
+ skill set:
	- generative AI models
	- image/layout generation space
	- develop untried approaches
	- analyze data sources
	- generate, collect, and prepare data for commercial licensing in mind
	- experiment with large-scale cloud infrastructure with high-end hardware
	- set up data augmentation pipelines and perform hyperparameter searches to build production-ready AI solutions
	- CNNs, transforms, diffusion models (stable diffusion)
	- deep learning frameworks
		* TensorFlow
		* Keras
		* Theano
		* MXNet
	- Python 3
	- NumPy
	- OpenCV
	- Docker, Kubernetes
+ skill set:
	- OpenCV
	- Point Cloud Library, PCL
		* open-source library of algorithms for point cloud processing tasks, 3D geometry processing, 3-D computer vision
		* https://pointclouds.org
	- ***TensorRT, MLIR, TVM, XLA***
	- C++1x
	- ML SW stack, machine learning software stack, cuDNN, cuBLAS
	- SIMD programming 
		* avx2
		* neon
+ skill set:
	- Machine Learning Engineer, ML Developer Tools - Video Engineering
	- The Video Computer Vision org is a centralized applied research and engineering team responsible for developing real-time on-device Computer Vision and Machine Perception technologies across Apple products. We focus on a balance of research and development to deliver Apple quality, state-of-the-art experiences. Our team prides itself on innovating through the full stack, and partnering with HW, SW and ML teams to influence the sensor and silicon roadmap that brings our vision to life!
	- Experience in developer tools (ML tools preferred).
	- Experience in HCI to build robust and user-friendly products.
	- Strong prototyping skill to build demos for early feedback.
	- Strong software engineering skills (e.g., Javascript, Python; Vue.js/React; Flask/FastAPI)
	- Experience in LLM (or vision model) application for productivity.
	- Experience on machine learning model development is a big plus.
	- Strong communication skills; great work ethic and teamwork.
	- Our team builds tools that Apple in-house ML experts use everyday to optimize many models shipped in Apple devices. You will work with world-class talents in visualization, on-device optimization, ML tools/platforms.
	- We looking for a researcher / engineer who can develop reliable and scalable web services for ML developers: e.g., effective ML dev workflow, infrastructure to serve internal service using large models (e.g., LLM, vision model).
	- We also encourage publishing novel research at top HCI / ML conferences.
	- PhD in HCI, Machine Learning or M.S. with industry experience (3+ year of experience on developer tools or machine learning).
+ skill set:
	- Senior Algorithm Evaluation Engineer
	- The Video Computer Vision org is a centralized applied research and engineering organization responsible for developing real-time on-device Computer Vision and Machine Perception technologies across Apple products. We balance research and product to deliver state-of-the-art experiences, innovating through the full stack, and partnering with HW, SW and ML teams to bring our visions to life. Examples include FaceID, Animoji/Memoji, Scene Understanding, People Understanding and Positional Tracking (VIO/SLAM), and the Apple Vision Pro.
	- 4+ years experience developing or evaluating computer vision or machine learning algorithms.
	- Passion for quality, outstanding attention to detail.
	- Strong knowledge of software development lifecycle, testing terminology and processes.
	- Excellent written and verbal communication skills, able to describe and document complex topics clearly.
	- Comfortable working with technical teams specialized in a variety of fields.
	- Solid programming skills in Python, familiar with packages like Numpy, Scikit-learn, etc
	- Familiarity with the challenges of working with large scale data sets.
	- Experience using data visualization and presentation tools, such as Tableau.
	- Project and small team leadership and organizational skills preferred.
	- The Algorithm Analysis team is looking for a Senior Evaluation Engineer to enhance our data analysis capabilities for new and exciting technologies. As a member of our fast-paced group, you will have the unique and rewarding opportunity to work with world-class engineers to build detailed evaluations enabling deep understanding of algorithm performance and use case stability. Responsibilities include:
	- Oversee requirements of software design, testing, release cycles, and related processes.
	- Lead technical discussions, system architecture, and other coding requirements with multi-functional teams.
	- Define roadmap, strategic priorities, and business requirements as related to larger organizational objectives, and work within the allocated time.
+ skill set:
	- Computer Vision and Machine Learning Engineer - Apple Vision Pro
	- Apple Vision Pro is a revolutionary spatial computer that seamlessly blends digital content with your physical space. It will allow us to do the things we love in ways never before possible — all while staying connected to the people around us.
	- In this position, you will join a team of computer vision and machine learning researchers and engineers to discover and build solutions to previously-unsolved challenges and push the state of the art. We are looking for a driven and dedicated computer vision/machine learning engineer or researcher, optimally with experience in 3D computer vision algorithms, such as object detection, pose estimation, generative models, or tracking. As a member of a fast-paced team, you have the unique and rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day.
	- 2+ years of industry experience in CVML or similar fields
	- Strong experience in 3D Computer Vision algorithms
	- Experience in machine learning, preferably in 3D computer vision applications
	- Solid foundation in 3D geometry and linear algebra
	- Good experience in Python and science libraries like Numpy, Pandas, Matplotlib
	- Solid in deep learning frameworks like PyTorch or TensorFlow
	- Experience in C++ is a big bonus
	- Experience in 3D graphics and rendering is a big plus
	- Sensor fusion experience is a big bonus
	- Excellent communication and collaboration skills
	- Excellent problem solving and analytical thinking skills
	- Track record of successfully building and shipping products or open source projects
	- Creativity and curiosity for solving highly complex problems
	- You'll be working in a team of computer vision and machine learning researchers and engineers to implement world class algorithms that pushes the state of the art.
	- Inventing and implementing state of the art computer vision algorithms to solve cutting edge problems
	- Designing such algorithms to work reliably and efficiently on mobile devices
	- Collaborating with other teams in software and hardware to ensure the full pipeline runs efficiently and utilizes Apple hardware effectively
	- Cooperating with your team members to prepare presentations, papers, and talks to explain your inventions
+ skill set:
	- Algorithm Evaluation Engineer
	- The Video Computer Vision org is a centralized applied research and engineering organization responsible for developing real-time on-device Computer Vision and Machine Perception technologies across Apple products. We balance research and product to deliver state-of-the-art experiences, innovating through the full stack, and partnering with HW, SW and ML teams to bring our visions to life. Examples include ***FaceID, Animoji/Memoji, Scene Understanding, People Understanding and Positional Tracking (VIO/SLAM), and the Apple Vision Pro***.
	- 1+ years experience developing or evaluating computer vision or machine learning algorithms
	- Passion for quality, outstanding attention to detail
	- Strong knowledge of software development lifecycle, testing terminology and processes
	- Excellent written and verbal communication skills, able to describe and document complex topics clearly
	- Comfortable working with technical teams specialized in a variety of disciplines
	- Strong programming skills in Python, familiar with packages like Numpy, Scikit-learn, etc
	- Familiarity with the challenges of working with large scale data sets
	- Experience using data visualization and presentation tools
	- Strong leadership and organizational skills preferred
	- The Algorithm Analysis team is looking for an Evaluation Engineer to enhance our data analysis capabilities for new and exciting technologies. As a member of our fast-paced group, you will have the unique and rewarding opportunity to work with world-class engineers to build detailed evaluations enabling deep understanding of algorithm performance and use case stability. Responsibilities include:
	- Oversee requirements of software design, testing, release cycles, and related processes
	- Partake in technical discussions, system architecture, and other coding requirements with multi-functional teams.
	- Help define roadmap, strategic priorities, and business requirements as related to larger organizational objectives, and work within the allocated time
+ skill set:
	- Senior Computer Vision and Machine Learning Engineer - Apple Vision Pro
	- Apple Vision Pro is a revolutionary spatial computer that seamlessly blends digital content with your physical space. It will allow us to do the things we love in ways never before possible — all while staying connected to the people around us.  In this position, you will join a team of computer vision and machine learning researchers and engineers to discover and build solutions to previously-unsolved challenges and push the state of the art. We are looking for a driven and dedicated computer vision/machine learning engineer or researcher, optimally with experience in 3D computer vision algorithms, such as object detection, pose estimation, generative models, or tracking. As a member of a fast-paced team, you have the unique and rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day.
	- 4+ years of industry experience in CVML, or Ph.D./M.Sc. in similar field
	- Strong experience in 3D Computer Vision algorithms
	- Experience in machine learning, preferably in 3D computer vision applications
	- Solid foundation in 3D geometry and linear algebra
	- Good experience in Python and science libraries like Numpy, Pandas, Matplotlib
	- Solid in deep learning frameworks like PyTorch or TensorFlow
	- Experience in C++ is a big bonus
	- Experience in 3D graphics and rendering is a big plus
	- Sensor fusion experience is a big bonus
	- Excellent communication and collaboration skills
	- Excellent problem solving and analytical thinking skills
	- Track record of successfully building and shipping products or open source projects
	- Creativity and curiosity for solving highly complex problems
	- You'll be working in a team of computer vision and machine learning researchers and engineers to implement world class algorithms that pushes the state of the art.   
	- Inventing and implementing state of the art computer vision algorithms to solve cutting edge problems 
	- Designing such algorithms to work reliably and efficiently on mobile devices 
	- Collaborating with other teams in software and hardware to ensure the full pipeline runs efficiently and utilizes Apple hardware effectively 
	- Cooperating with your team members to prepare presentations, papers, and talks to explain your inventions
+ skill set:
	- Machine Learning Imaging Scientist
	- Do you want to push the limits of the best mobile phone camera in the world? The Camera Algorithms R&D team delivers algorithms that drive some of the iPhone cameras ground-breaking features such as Night mode. In this position, you will have the opportunity to be part of an extraordinary team of image processing and computer vision experts to devise and build solutions to previously-unsolved problems in digital camera image processing and push the state of the art in camera algorithms that will change the way people capture images.
	- We are looking for a driven and dedicated machine learning/computer vision scientist, optimally with experience in creating deep learning architectures for image processing. As a member of a fast-paced team, you will have the unique and rewarding opportunity to impact trillions of images and videos that are shot on the iPhone every year.
	- Strong experience in deep learning architectures and frameworks such as PyTorch
	- Experience in computer vision and image processing
	- Solid foundation in mathematics and statistics
	- Excellent problem solving and analytical thinking skills
	- Excellent communication and collaboration skills
	- Technical publication record in deep learning and/or computer vision is desirable
	- Experience in neural network optimization is a plus
	- Proficiency with C/C++ and Python
	- You'll be working in a team of image processing and computer vision experts to push the state of the art in camera algorithms.
	- Inventing and implementing innovative machine learning and computer vision algorithms to solve cutting edge problems in image processing.
	- Designing such algorithms to work reliably and efficiently on mobile devices.
	- Collaborating with other teams in software, firmware, and hardware to ensure the highest possible image quality.
	- Collaborating with your team members to prepare presentations, talks, and disclosures to explain your inventions.
	- Industry experience of 5+ years in machine learning, image processing, computer vision, or Ph.D. in similar fields.
+ skill set:
	- Computer Vision Researcher & Developer - Apple Vision Pro
	- Apple Vision Pro is a revolutionary spatial computer that seamlessly blends digital content with your physical space. It will allow us to do the things we love in ways never before possible — all while staying connected to the people around us.
	- The Computer Vision Researcher responsibility is to develop innovative solutions for capturing and reconstructing of 3D and 4D representations of detailed and deforming surface geometry and materials. They will develop and deploy research prototypes into production. We value researchers who are self- motivated and enjoy a highly collaborative environment with minimal supervision. There is a substantial R+D component to our development and production. We want an Engineer that is excited about defining new workflows, clear-headed about risks inherent with invention, but passionate about pushing the designs to their maximum potential.
	- Algorithm development in the areas reflectance capture, material estimation and photogrammetry
	- Fluent in C/C++, Python (programming and debugging)
	- Experience HLSL, GLSL, Metal
	- Knowledge of parallel computing, CUDA, OpenCL, GPGPU
	- Knowledge of software optimization and embedded programming
	- 12+ years of related experience
	- 3D and 4D geometry and reflectance reconstruction algorithms with optimization workflows
	- Engineering capture systems for face, body, and hands
	- Capturing and processing data from machine vision cameras and pipeline to production including color calibration, camera intrinsics
	- Automation of capture and processing tasks
	- Creating tools and workflow for integration into shader and rendering pipeline
+ skill set:
	- Computer Vision Engineer
	- The candidate will be required to spend considerable hands-on time designing, coding, optimizing, debugging, and testing Computer Vision applications on AlphaICs's AI Processor running Linux operating systems.
	- 1) 2-3 years' experience with Programming Languages such as C/C++, Python and experience with hands-on coding to collaborate with HW designers to adopt the proposed.
	- 2) Embedded system software development experience i.e device driver, BSP development.
	- 3) Experience enabling vision algorithms on imaging and vision accelerators or GPUs.
	- 4) Experience with OpenCV, OpenCL, OpenVX, TensorFlow, Caffe or equivalent computer vision library.
	- 5) Experience programming for raspberry pi, NVIDIA Jetson, IMX8, Google Coral, or similar SOC's.
	- 6) Experience in Design/building computer vision end to end solutions for edge devices.
	- 7) Preferable working experience in Convolutional Neural Networks.
	- 8) Experience in the Yocto build system, camera integration and V4l2 is a plus.
+ skill set for Computer Vision Algorithm Engineer:
	- Conduct research on computer vision algorithms and develop related products, including but not limited to facial recognition, facial attribute recognition, target detection, target classification, target attribute recognition, graph segmentation, image captioning, object tracking, video segmentation, video captioning, text detection, person re-identification, image generation, and image audit.
	- Conduct research on deep learning algorithms, especially on applications of computer vision technology, including model acceleration, model encryption, and model quantification.
	- Proficiency in at least one of the following programming languages: C, C++, and Python; ability to implement self-designed algorithms
	- Solid mathematical background and proficient in geometry, statistics, and machine learning, and understanding the applications of these in image recognition
	- Knowledge of at least one of the mainstream deep learning tools, including Caffe, TensorFlow, Keras, and MXNet
	- Understanding of computer architecture and ability to optimize and customize algorithm libraries via algorithms and machine code instructions (preferred)
	- Knowledge of the transportation, finance, industrial control, and environment protection industries (preferred)
+ skill set:
	- ***AI Research Scientist - Computer Vision (Technical Leadership)***
	- Pittsburgh, PA | Menlo Park, CA | New York, NY
	- Meta is seeking exceptional AI Research Scientists to join our AI organization. Individuals in this role are expected to be recognized experts in areas such as artificial intelligence, machine learning, computational statistics, and applied mathematics, particularly including areas such as deep learning, graphical models, reinforcement learning, computer perception, natural language processing and data representation. The ideal candidate will have an interest in producing new science to understand intelligence and technology to make computers more intelligent, and an equal interest in taking new research findings in this area and implementing it towards production ready problems.
	- Help Advance the science and technology of intelligent machines
	- Contribute to research that enables learning the semantics of data (images, video, text, audio and other modalities)
	- Work on projects, strategies, and problems of moderate to high complexity and scope. Can identify and define both short & medium term objectives
	- Design policies, processes, procedures, methods, tests, and/or components, from the ground up and with the understanding of how to put together end-to-end systems
	- Independently lead projects and work cross-functionally to bring research advancements to production teams and Meta Products
	- Influence progress of relevant research communities by producing publications
	- Devise better data-driven models of human behavior
	- Plan and execute cutting-edge research and development to advance the state-of-the-art in machine perception, mapping, reconstruction and localization, as well as 3D scene understanding across optical/inertial/wireless sensing systems
	- Collaborate with other researchers and engineers across machine perception teams at Meta to develop experiments, prototypes, and concepts that advance the state-of-the-art in AR/VR systems
	- Work with the team to help design, setup, and run practical experiments and prototype systems related to large-scale long-duration sensing and machine reasoning
	- Minimum Qualifications
		* Prior experience with Meta can be considered to supplement an applicant’s prior years of experience or types of prior experience to meet the minimum qualifications of the position.
		* Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
		* PhD in the following fields: Computer Vision, Robotics, State Estimation, 3D Reconstruction, Object Tracking, Physics based models, or a related field
		* Experience in applying research to production problems
		* Experience leading a team in solving modeling problems using AI/ML approaches
		* Experience communicating research for public audiences of peers
		* Proven publications in machine learning, AI, computer science, statistics, applied mathematics, data science, or related technical fields
		* Experience with real world system building and data collection, including design, coding (C++) and evaluation (C++/Python)
		* Hands-on experience implementing 3D computer vision algorithms, Sensor Fusion, Reconstruction, Object Tracking, Mapping, and Image Processing
	- Preferred Qualifications
		* Experience holding a faculty, industry, or government researcher position in a role with primary emphasis on AI research
		* Experience showing first-author publications at peer-reviewed AI conferences (e.g., NeurIPS, CVPR, ICML, ICLR, ICCV, and ACL)
		* Experience in developing and debugging in C/C++, Python, or C#
		* Experience in real-time computer graphics or modern GPU programming (CUDA, OpenGL, OpenCL)
		* Experience with designing (products or open-source) software for inertial/optical/wireless sensing devices
		* Experience working in a Unix environment
	- $205,000/year to $281,000/year + bonus + equity + benefits
+ skill set:
	- Research Scientist Intern, Computer Vision
	- Paris, France
	- Meta was built to help people connect and share, and over the last decade our tools have played a critical part in changing how people around the world communicate with one another. With over a billion people using the service and more than fifty offices around the globe, a career at Meta offers countless ways to make an impact in a fast growing organization.
	- We are committed to advancing the field of artificial intelligence by making fundamental advances in technologies to help interact with and understand our world. We are seeking individuals passionate in areas such as deep learning, computer vision, audio and speech processing, natural language processing, machine learning, reinforcement learning, computational statistics, and applied mathematics. Our interns have an opportunity to make core algorithmic advances and apply their ideas at an unprecedented scale.
	- We offer twelve (12) to twenty-four (24) weeks long internships and we have various start dates throughout the year.
	- Develop novel state-of-the-art computer vision algorithms and corresponding systems, leveraging various deep learning techniques.
	- Based on the project, help analyze and improve efficiency, scalability, and stability of corresponding deployed algorithms.
	- Perform research to advance the science and technology of intelligent machines.
	- Perform research that enables learning the semantics of data (images, video, text, audio, and other modalities).
	- Collaborate with researchers and cross-functional partners including communicating research plans, progress, and results.
	- Publish research results and contribute to research that can be applied to Meta product development.
	- Minimum Qualifications
		* Currently has or is in the process of obtaining a Masters degree in Computer Science, Computer Vision, Artificial Intelligence, or relevant technical field.
		* Must obtain work authorization in country of employment at the time of hire and maintain ongoing work authorization during employment.
		* Experience with Python, C++, C, Java or other related language.
		* Experience building systems based on machine learning and/or deep learning methods.
	- Preferred Qualifications
		* Intent to return to degree program after the completion of the internship/co-op.
		* Proven track record of achieving significant results as demonstrated by grants, fellowships, patents, as well as first-authored publications at leading workshops or conferences such as NeurIPS, ICML, ICLR, CVPR, ICCV, ECCV, ACL or similar.
		* Experience working and communicating cross functionally in a team environment.
		* Experience in advancing AI techniques in computer vision, including core contributions to open source libraries and frameworks in computer vision.
		* Publications or experience in machine learning, AI, computer vision, optimization, computer science, statistics, applied mathematics, or data science.
		* Experience solving analytical problems using quantitative approaches.
		* Experience setting up ML experiments and analyze their results.
		* Experience manipulating and analyzing complex, large scale, high-dimensionality data from varying sources.
		* Experience in utilizing theoretical and empirical research to solve problems.
		* Experience with deep learning frameworks.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.





























###	Natural Language Processing, NLP


####	Notes about Natural Language Processing, NLP



Topics for natural language processing, NLP:
+ word embeddings/vectors:
	- GLoVe
	- fastText
	- word2vec
+ contextualized embeddings
	- ELMo
	- CoVe
+ encoder-decoder models
	- seq2seq
	- vanilla transformers
+ tranformer language models
	- GPT-3
	- GPT-2
	- BERT
	- XLnet
+ named entity recognition
+ POS tagging
+ parsing
+ sentiment analysis
+ clustering
+ text prediction





Libraries for natural language processing, NLP:
+ Gensim, https://pypi.org/project/gensim/
+ ***Kaldi***, speech recognition/processing and signal processing
+ ***NLTK***, https://www.nltk.org/
+ ***spaCy***, text processing





Language models for natural language processing, NLP, including large language models (LLMs):
+ LLaMA 2 70B
+ GPT - 3.5
+ Mixtral 8x7B


Benchmarks for natural language processing, NLP:
+ MMLU (MCQ in 57 subjects)
+ HellaSwag (10-shot)
+ ARC Challenge (25-shot)
+ WinoGrande (5-shot)
+ MBPP (pass@1)
+ GSM-8K (5-shot)
+ MT Bench (for Instruct Models)










Companies involved in natural language processing, NLP:
+ https://emerj.com/ai-sector-overviews/machine-translation-14-current-applications-and-services/
+ https://localizejs.com/articles/types-of-machine-translation/





####	Skills for Natural Language Processing, NLP



Skills for natural language processing, NLP:
+ natural language processing, NLP, methods:
	- transformer language models: GPT-3, BERT, XLnet
	- encoder-decoder models: seq2seq, vanilla transformers
	- contextualized embeddings: ELMo, CoVe
	- word embeddings/vectors: GLoVe, fastText, word2vec
+ Publications in NeurIPS, ICASSP, INTERSPEECH, TASLP.
+ Publication record in top AI conferences (ACL, CVPR, NAACL, ICML, etc.) is a plus.
+ Publications for NLP at:
	- WWW
	- RecSys
	- SIGIR
	- ICML
	- AAAI
	- ACL
	- EMNLP
	- CHI
+ Data sets for NLP (research) projects:
	- Common Crawl
+ ***TensorRT, Deepstream Projects in video, speech, or NLP***
+ Experience with Natural Language Processing topics, such as:
	- Topic Modeling
	- Document Classification
	- Document Summarization
	- Sentiment Analysis
+ skill set:
	- TensorFlow, SpaCy, Scikit-Learn
	- cloud-based AI/ML services
		* Microsoft Azure Cognitive Services
		* Google Cloud
		* IBM Watson
	- Python, Django, and/or Flask
	- Linux
+ skill set:
	- SpaCy, NLTK, and comparable libraries
	- Python, Django, and/or Flask
	- Linux and/or working with cloud services with AWS, Azure, etc..
	- GitHub and Docker
+ Publications for NLP at:
	- WWW
	- RecSys
	- SIGIR
	- ICML
	- AAAI
	- ACL
	- EMNLP
	- CHI
+ skill set:
	- big data processing frameworks:
		* Apache Spark
	- machine learning and test mining (NLP) libraries and packages:
		* scikit-learn
		* Pandas
		* NLTK
		* Stanford CoreNLP
+ simultaneous machine translation (SMT) system
+ Scikit-learn, Keras/Tensorflow, Spark MLlib, Spacy or other ML libraries
	- spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython.
	- spaCy: Industrial-strength Natural Language Processing
	- spaCy is a powerful and versatile library for processing large-scale information extraction tasks in Python.
+ Good knowledge of Apache Big Data stack (any of Kafka, Hadoop, Hive, Storm etc) and open source machine learning and NLP tools (Stanford CoreNLP, NLTK, TensorFlow, scikit-learn etc)
+ skill set:
	- experience with ML deployment frameworks
	- work with highly imbalanced data sets to improve detection performance of our existing NLP models and algorithms
	- work closely with product and platform teams, participate in design reviews, and demo your work
	- apply the latest cutting-edge advancements in AI/ML research to our current solutions in a scalable manner for online detection
	- take full ownership of ML models, including:
		* collecting training data
		* evaluating and deploying models to production with ongoing quality monitoring
+ skill set:
	- noise suppression, voice activity detection, and speacker recognition
	- deep learning model optimization, such as quantization, neural architecture search, pruning
+ skill set:
	- Our Spoken Language Understanding (SLU) team is building a speech-to-meaning engine that will add to our customers' ease of use and control as we continue to differentiate an end-to-end Sonos experience for them.
	- Develop new models and algorithms for SLU with a particular focus on the interface between the speech-to-text and the text-to-meaning engines
	- Write production-grade code to be deployed with the support of our software engineering and QA teams
	- Own the development process, from the conception of the models to their evaluation
	- MS in Computer Science, Machine Learning or equivalent
	- PhD in relevant field or 2+ years of experience in deployment of production-grade ML models
	- Strong coding skills in Python
	- Knowledge of Scikit Learn and either PyTorch or TensorFlow
	- Knowledge of basic models and techniques for Natural Language Processing
	- Excellent verbal and written communication skills (English)
	- PhD and/or track record of publications in NLP
	- Working knowledge of Rust
+ skill set:
	- noise suppression, voice activity detection, and speacker recognition
	- audio processing algorithms:
		* acoustic noise cancellation
		* noise suppression
		* gain control
		* de-reverberation
		* microphone array processing
	- linear adaptive filtering
	- linear systems
	- audio data analysis
+ skill set:
	- We are looking for multidisciplinary machine learners with sharp skills in one or more of the following fields:
		* Deep Learning,
		* Bayesian Modeling,
		* Natural Language Processing.
+ data science skills in the context of NLP:
	- Excellent understanding of ML, NLP, and statistical methodologies
	- Excellent programming skills (Java/Python/R/Sas)
	- Ability to test ideas and adapt methods quickly end to end from data extraction to implementation and validation
	- Experience with search engines, classification algorithms, recommendation systems, and relevance evaluation methodologies a plus
	- Specific Big Data experience on cloud computing platforms with technologies such as Hadoop, Mahout, Pig, Hive and Spark a plus
	- 7+ years of experience with Data Science and Statistics, preferably in Life Sciences, and more specifically, in pharmaceuticals.
	- The ability to tell a story about data, in particular with visualization.
	- Solid understanding of statistics and the design and analysis of experiments. Solid skills in statistical language, SAS.
	- Provides automated and ad-hoc analysis of experiments.
	- Assesses and validates reliability of source data and business systems used to develop performance metrics.
	- Prepares recommendations and conclusions based on data summaries and communicates this information in a credible, convincing and timely manner.
	- Explores existing data for insights and recommends additional sources of data for improvements.
	- Guide the architecture of “big-data” business processes with an eye towards robustness, parsimony and reproducibility (at senior levels)
	- Define and develop software for the analysis and manipulation of large and very large data-sets
	- Narrate stories (sometimes to a non-technical audience) about our content and processes by data analysis and visualization
	- Collaborate with scientists, product groups and content groups to perform “big data” aggregations, fusion and manipulations of important data-sets
	- This is a thought leader.
	- Define, manipulate, aggregate and use both structured and unstructured "big data" in order to support descriptive and predictive analytics across the businesses.
	- Adept at all aspects of technical communications, including using presentations technologies (e.g. WebEx, PowerPoint) and software demonstrations.
	- Data Collections: Expertise in large data collection and processing including ETL, workflow and delivery of data
	- Business Intelligence (BI) tool like Qlik or Tableau
+ NLP Engineer
	- Salary: 14,000~16,000 SGD/month
	- 1. Extract and convert data from charts and textual materials in academic papers into OpenRead's internal data storage format.
	- 2. Acquire expertise in natural language processing (NLP) techniques, including text comprehension, text classification, and text summarization, and integrate viable and innovative concepts into OpenRead applications.
	- 3. Conduct a comprehensive investigation on integrating modules with diverse input formats to facilitate cross-learning across various data types.
	- 4. Execute module training and engage in research regarding the interoperability of articles, with a primary objective of developing a robust and efficient data extraction mechanism.
	- 5. Enhance the precision of data extraction to align with industry best practices.
	- 1. Exceptional aptitude for learning, outstanding proficiency in communication and collaboration, and a fervent dedication to resolving complex issues.
	- 2. Familiarity with multimodal learning is advantageous.
	- 3. Possess a robust theoretical background in Natural Language Processing (NLP) and deep learning, demonstrating extensive expertise in NLP methodologies including CRF, CNN, LSTM/GRU, Transformer, BERT, and other related technologies.
	- 4. Proficient in developing and implementing various components of natural language processing (NLP) and machine learning algorithms, including but not limited to long/short text keyword extraction, entity recognition, text classification, semantic matching, text understanding, text summarization, question-answering/dialogue systems, knowledge graphs, and information retrieval. Prior expertise in dialogue systems is highly desirable.
	- 5. Proficiency in Python or Java programming languages, accompanied by excellent programming and algorithmic skills.
	- 6. Demonstrated expertise in utilizing machine learning frameworks like PyTorch or TensorFlow, with hands-on experience in implementing advanced natural language processing (NLP) algorithms.
+ skill set:
	- Oversee research process implementation, from problem definition all the way to concrete research experiments.
	- Collaborate and communicate clearly and efficiently with the rest of the team about the status, results, and challenges of your current tasks.
	- Contribute to designing the research roadmap of the company.
	- Train and mentor other members of the team.
	- Own the research function of specific product features.
	- As a core member of our research team, you'll play an integral role in challenges such as:
	- Creating realistic voice doubles using only a few minutes of audio.
	- Designing and developing new algorithms for media synthesis, anomaly detection, speech recognition, speech enhancement, filler word detection, etc
	- Devising and implementing fast and robust algorithms for spectrogram inversion.
	- Creating tools to synthesize photo-realistic videos that match our Overdub (personalized speech synthesis) feature.
	- Developing algorithms for detecting synthesized media.
	- Coming up with new research directions to improve our product.
	- Proven experience in designing and implementing deep learning algorithms. 
	- PhD or Master's degree specialized in Deep Learning or equivalent experience. 
	- Track record of developing new ideas in machine learning, as demonstrated by one or more first author publications or projects. 
	- Good programming skills and experience with deep learning frameworks.
	- Publications at top ML/Speech conferences is a big plus: NIPS, ICML, ICLR, Interspeech, ICASSP.
+ skill set for Natural Language Processing Algorithm Engineer:
	- Carry out research on natural language processing algorithms, including but not limited to semantic analysis, intent recognition, man-machine dialogue, machine translation, knowledge graph, and named entity recognition.
	- Conduct research on cutting-edge natural language processing technologies, and provide technical solutions for the Enterprise Intelligence (EI) domain based on actual application scenarios.
	- Proficiency in one of the following programming languages: C, C++, and Python; ability to implement self-designed algorithms
	- Solid knowledge of algorithms, deep understanding of algorithm rationale and basic machine learning theories, and proficient in mathematics or statistics
	- Natural language processing knowledge and skills and deep understanding of computational semantics and text generation
	- Knowledge of common machine learning algorithms; experience in the application of deep learning, transfer learning, and reinforcement learning technologies or publication of high quality thesis papers (preferred)
	- Knowledge of the transportation, finance, industrial control, and environment protection industries (preferred)
+ Software Engineer, Full Stack (DALL-E)
	- The DALL-E team works across research, engineering, product, and design to bring OpenAI’s DALL-E 3 technology to consumers and businesses. We’re here to create the next generation of user interfaces for generative AI, both for creation and consumption.
	- We are looking for a self-starter engineer who loves building new products in an iterative and fast-moving environment. In this role, you will be bringing our DALL-E 3 and future generative models to millions of users around the world. Our users include everyday enthusiasts, creators and professionals.
	- You’ll interface directly with users to develop the features they want most. You will also collaborate closely with the DALL-E research team and work with them on continual improvement and product exploration. You will be a key part of the effort to push these technologies forward, and onto the next 100x users.
	- Own the development of new user-facing generative AI features and product experiences end-to-end
	- Talk to users to understand their problems and design solutions to address them
	- Work with the research team to get relevant feedback and iterate on their latest models
	- Collaborate with a cross-functional team of engineers, researchers, product managers, designers, and operations folks to create cutting-edge products
	- Optimize applications for speed and scale
	- Help create a diverse, equitable, and inclusive culture that makes all feel welcome while enabling radical candor and fast-paced collaboration
	- 5+ years of relevant engineering experience at tech and product-driven companies
	- Proficiency with JavaScript, React, and other web technologies
	- Proficiency with some backend language (we use Python)
	- Some experience with relational databases like Postgres/MySQL
	- Excited to rapidly prototype with futuristic OpenAI generative models as they are trained
	- Ability to move fast in an environment where things are sometimes loosely defined and may have competing priorities or deadlines
	- Annual Salary Range: $200,000—$385,000 USD
+ skill set:
	- Provide software design and programming expertise to support research projects. You will work closely with Applied Research Scientists to solve exciting research problems. You will own software development and iteration throughout the research cycle.
	- Read, understand, and replicate recent AI research papers.
	- Communicate clearly and efficiently with the rest of the team about the status, and results of your current tasks.
	- Architect and implement software libraries to allow our research to improve and scale.
	- Code data pipelines required to train deep learning models.
	- Write and maintain good quality code.
	- Work with our engineering team to deploy and maintain research models in production.
	- Creating realistic voice doubles using only a few minutes of audio.
	- Designing and developing new algorithms for media synthesis, anomaly detection, speech recognition, speech enhancement, video generation, filler word detection, and more.
	- Devising and implementing fast and robust algorithms for spectrogram inversion.
	- Creating tools to synthesize photo-realistic videos that match our Overdub (personalized speech synthesis) feature.
	- Developing algorithms for detecting synthesized media.
	- Proven experience in implementing and iterating on deep learning algorithms. 
	- BSc/BEng degree in computer science, mathematics, physics, electrical engineering, machine learning or equivalent (MSc or PhD preferable).
	- Good programming skills and experience with deep learning frameworks (preferably Pytorch).
	- Strong knowledge and experience of Python.
	- Publications at top ML/Speech conferences is a big plus: NeurIPS, ICML, ICLR, Interspeech, ICASSP.
+ skill set for Speech Recognition Algorithm Engineer:
	- Lead technology exploration and innovative research in speech recognition, propose innovative ideas and algorithms, and participate in key prototype and system design and implementation.
	- Research and implement key technologies and core algorithms such as speech recognition, voiceprint recognition, speech synthesis, and wakeup. This includes acoustic model and language model optimization as well as decoder performance improvement.
	- Explore customer requirements and make breakthroughs in key technologies to continuously improve competitiveness of HUAWEI CLOUD speech recognition technologies and solutions.
	- Ability to independently study speech recognition algorithms and develop a speech recognition engine
	- Proven research background in signal processing, acoustic modeling, language modeling, and deep learning
	- At least one paper published in ***Interspeech, ICASSP***, or related conference preferred
+ skill set:
	- This is an opportunity to join the innovation division of EON, a leader in the healthcare patient management space, and expand our Computational Linguistics and Machine Learning capabilities. You will work with our Data Science, Engineering and Product teams to develop product features based on Computational Linguistics and Machine Learning technologies, ensuring that these new features address customer needs.
	- You have a proven track record of creating CL models to extract information from unstructured texts, using advanced statistical methods to understand model results, and developing software to support these processes. You have a strong mathematical and statistics background, with the ability to understand algorithms and methods from a mathematical and intuitive viewpoint. In addition, you have a keen sense of ownership, resilience, and drive; like dynamic projects and enjoy being challenged; are comfortable in evolving requirements and occasional uncertainty, and enjoy making a difference in people's lives.
	- In this role, you will apply Computational Linguistics and Machine Learning to create systems that innovate healthcare products at scale. In addition to a world-class data set, you'll also have access to domain experts for annotations to help drive investigation and learning.
	- Proficiency in Python and SQL
	- Experience in one or more of the following languages: C++, Java, C#
	- Working knowledge of Unix commands and good security practices
	- Experience using Machine Learning frameworks such as TensorFlow, Keras, PyTorch, scikit-learn
	- Experience in developing and validating Computational Linguistics models
	- Experience with spaCy is a huge plus
	- Experience in constructing and executing queries to extract data for exploratory data analysis and model development
	- Experience performing training/testing/validation dataset construction
	- Experience with supervised and unsupervised Machine Learning techniques and methods
	- Deep understanding of CL fundamental concepts and models, such as language modeling, word embeddings, topic modeling, text categorisation, information extraction, natural language understanding, transfer learning
	- Familiarity with knowledge representation, automated knowledge acquisition, and reasoning
	- Deep understanding and experience in applying ML algorithms, such as Logistic Regression, Decision Trees, SVM, Naive Bayes, kNN, Random Forests, Dimensionality Reduction Algorithms, K-means clustering, etc.
	- Understanding and experience with Deep Learning algorithms
	- Experience with AWS
	- Experience with Elasticsearch
	- Experience with graph databases, ideally Neo4j
	- Solid knowledge of Data Structures and Algorithms, including algorithm complexity
	- Experience with visualisation libraries such as Matplotlib, ggplot, etc.
	- Problem-solving, debugging, troubleshooting, designing, and implementing solutions to complex technical issues
	- Knowledge of advanced software engineering practices including Agile techniques
	- Proven record of writing robust, clean, and understandable code
	- Ability to take ownership of a task and ensure its successful completion
	- Graduate degree (or equivalent experience) in Computer Science, Machine Learning or other quantitative fields
	- 7+ years of experience in developing and implementation of quantitative models
	- 3+ years of experience in managing people and projects
	- Working experience in a healthcare environment, with a healthcare software vendor, or in a public health setting
	- Expertise in Natural Language Processing (NLP) in the clinical or biomedical domain
	- Experience in developing CL models using spaCy
	- Experience in training custom spaCy models is a huge plus
+ skill set:
	- In addition, we contribute to open source; contributions we have made and work with include Solr, Koan, KFServing, Cloud Native Buildpacks and PyTorch Lightning that directly impact our production services. 
	- Our team makes extensive use of open source technologies such as, Kubernetes, Kubeflow, KServe, Argo, Buildpacks, and other cloud-native MLOps technologies.
	- KServe was co-created by Bloomberg to provide production-grade model inference for all of our models from SKLearn based regression models to large language models like Bloomberg GPT. 
+ skill set:
	- build and operate high volume distributed systems
	- design and build systems in a microservice-based architecture
	- experience with ML deployment frameworks
	- design, implement, and deploy NLP models
	- experience working with high growth venture-backed start-ups
+ hybrid approach to NLU combines symbolic human-like comprehension and machine learning to transform language-intensive processes into practical knowledge, providing the insight required to improve decision making throughout organizations
+ skill set:
	- Computational Linguist
	- As a Computational Linguist you will join project teams to build top-notch NLP/NLU solutions for our Customers and Partners worldwide, ensuring that all issues are dealt with in the most effective and satisfactory way. Not only you have a firm grasp of general linguistics (semantics, syntax, morphology) but you have also experience with artificial intelligence, machine learning, natural language processing and computational linguistics.
	- Identify logical patterns underlying the language, write semantic rules on Expert.ai's proprietary IDE to meet Customers' expectations
	- Perform tests and validations to verify the effectiveness of the implemented solution
	- Contribute to the continuous improvement of the core technology
	- Identify suitable solutions for clients in the field of Natural Language Processing
	- Work with Project Managers, Software Engineers and other Knowledge Engineers on Customer's projects
	- Graduated in Computational Linguist or Languages
	- Experienced in coding with Python and/or C++: write data processing scripts to transform or extract knowledge from unstructured data, including hands-on experience with regular expressions
	- Analytical person with excellent written and verbal communication skills in a technical context
	- Independent worker with the ability to effectively operate with flexibility in a fast paced, constantly evolving team environment
	- Team player with exceptional interpersonal and solution-oriented attitude
	- Fluent English, both oral and written (the knowledge of other languages will be considered a plus)
+ skill set:
	- Knowledge Engineer Intern
	- If you are completing your studies in Computational Linguistics or Languages and you would like to be part of a growing company that works in an international environment, you can send us your application: we are looking for a Knowledge Engineer Intern for our Paris office.
	- As knowledge Engineer intern you will support the Professional Services team that works on Artificial Intelligence projects aimed at helping big Companies and Public Institutions in solving the daily practical issues linked to the digital transformation and the processes' automation. During your internship you will be trained in COGITO technology and you will develop your skills in the field of Natural Language Processing / Natural Language Understanding; you will learn the use cases of NLP for Companies and carry out a first experience as a consultant. Finally, you will contribute to the continuous development of our core technology from the linguistic point of view and you will test and verify the effectiveness of the platform.
	- Degree in Languages, Literature, Linguistics or Computational Linguistics;
	- Excellent knowledge of English and another language;
	- Good knowledge of linguistics will be necessary for the rapid handling of our Cogito technology;
	- Basic knowledge of programming languages like Java and Python will be considered a plus;
	- Good general culture knowledge;
	- Attention to the quality of work and results;
	- Team work skills;
	- Ability to analyze and structure information;
	- The knowledge of the Arabic language will be considered as a plus.
+ skill set:
	- NLP/ML Lead at SciSpace (Formerly Typeset)
	- As one of the first engineers in Content Intelligence at Typeset, you will be required to design infrastructure and models for helping our users discover their research papers better. At Typeset, We are on a mission to help researchers connect the dots faster and accelerate scientific innovation. We want to use Machine Learning to provide an assisted discovery experience to our users.
	- Your job responsibilities would include:
		* 1. Choosing a technology stack for machine learning operations
		* 2. Identify problems in our domain that can benefit from ML
		* 3. Create a data collection/curation system
		* 4. Craft models to help solve problems
		* 5. Train/Tune your models
		* 6. And most importantly, deliver an amazing discovery experience to our users
	- This is an end-to-end gig. Typeset believes in full-stack teams who contribute to all parts of the product delivery and take total ownership of the product/features they work on.
	- Ph.D. holder and 2+ years of prior experience working in a team that centered on NLP/ML
	- Prior experience working with NLTK, Spacy, or similar NLP libraries
	- Strong knowledge of Python, Data Structures and Algorithms
	- Prior experience with any/both of the following will be given preferences a. Statistical modeling techniques, such as conditional random fields b. Deep learning fundamentals, such as RNN, LSTM, CNN, Language Models
	- Published papers in top-tier NLP/ML conferences or journals
	- Experience in Scholarly Document Processing (SDP) would be highly-valued
	- Hands-on experience with AWS cloud infrastructure is a bonus.
+ linguistic quality assurance process, LQA process
+ skill set for speech processing/recognition in NLP (natural language processing):
	- ASR
	- MT
	- NLP
	- NLU
	- TTS
	- DM
	- ASP
+ Speech (NLP: ASR, MT, NLP, NLU, TTS, DM, and ASP)
+ Experience with NLP libraries such as SpaCy, Stanford CoreNLP, OpenNLP, or NLTK
+ NLP library: spaCy, NLTK, GATE, CoreNLP, gensim
+ Deep Learning applied to NLP, for example through distributed representations (e.g. Word2Vec, fastText, etc)
+ Publish papers in:
	- ACL
	- EMNLP
	- SIGIR
	- NeurIPS
	- Interspeech
	- ICASSP
	- ICML
	- WSDM
	- WWW
	- RecSys
	- KDD
	- AAAI
+ skill set:
	- Software Engineer, AI Product
	- Adept's mission is to build Useful General Intelligence. We are solving open problems in AI in order to train models that can do arbitrary things on a computer, and we are solving open product problems in order to package these models into a form factor that best enhances human experience and performance. 
	- We've recently raised a $350M Series B led by General Catalyst and Spark, on top of a $65M Series A in 2022 with Addition and Greylock. We're fortunate to be supported by amazing firms and angels such as Chris Re, Andrej Karpathy, Root Ventures, Howie Liu, Dara Khosrowshahi,  and others, and were recently highlighted by Forbes. Adept is backed by a coalition of strategic partners, including Atlassian, Microsoft, NVIDIA, and Workday.
	- Adept thrives at the intersection of research and product. In this role, you will rapidly build new capabilities of our product leveraging a combination of in-house and external tooling, and help safely deploy applications built on top of large models at scale. You'll collaborate closely with the product engineering, design, and product teams to build practical solutions that address real user needs.
	- The ideal candidate is a full-stack software engineer who has built and launched applications on top of LLMs, worked with a variety of common tools for LLM-enabled software, and is familiar with research in prompt engineering techniques. You are familiar with or even have contributed to open-source libraries related to LLMs and love a 0 to 1 challenge.
	- We deeply value software engineers who can engage with new problems and get things done at a startup, and our team members come from a variety of backgrounds and experiences. 
	- 6+ years of experience as a software engineer, preferably building apps and interfaces
	- Proficiency with Python and JavaScript
	- Experience with frontend frameworks like React and REST APIs
	- Experience building applications on top of LLMs, with a familiarity of tradeoffs across performance, latency, and ease of deployment
	- Experience with LLM-enabled software tooling including frameworks such as LangChain and LlamaIndex, retrieval mechanisms like vector databases, caching solutions such as Redis, and monitoring tools
	- Familiarity with techniques to maintain secure deployments that are robust to prompt injection and have safe outputs
	- Excellent communication and collaboration skills, both verbal and written
	- Bonus: Experience building LLM-powered agents capable of using APIs
+ skill set:
	- Natural Language Generation, Research Engineer, Input Experience
	- Text generation is a key enabler for accelerated text input and intelligent interaction on Apple platforms. Our team is working on redefining user interaction with generative models for text generation. If you want to be part of an ambitious, organized and collaborative team that ships user experiences with pioneering ML applied to NLP, come join the Input Experience NLP team in Software Engineering. Recent announcements at WWDC 2023 for running Transformer models on every keystroke for autocorrection, sentence level correction and inline completions were conceived and built end-to-end on our team.
	- You will work with a hard-working and dedicated set of outstanding ML and software engineers on a wide range of text generation technologies such as long-form text generation, summarization, question-answering, etc. Our team has been working in this area for years and own the NLP and ML text input stack for the keyboard input that includes autocorrection, predictive typing on all Apple platforms. We also work on full stack ML applied to NLP and expose these key technologies across Apple on device and also to third party applications through the Natural-Language framework. If you want to amplify your strong ML and NLP skills into user experiences that will reach every person around you, this is the perfect opportunity!
	- We exemplify Apple's outstanding integration of hardware and software to create seamless input experiences. You will have the opportunity to go from building offline pioneering NLP models to optimization of the models for different hardware backends and user interfaces that make the experience magical. Our vision always includes a deep dedication to strengthening Apple's privacy policy by achieving all of the above on device with powerful ML.
	- We are looking for a NLG Research Engineer to innovate and enhance the input experience across all Apple platforms. If you are passionate about using pioneering ML for building phenomenal ML/NLP technologies, products and impacting user experience across billions of users, this is the job for you. The role will require you to set new directions, perform hands-on experimentation and implement your vision into deliverables. You will have wide impact across Apple with strong multi-functional collaboration across teams in hardware, software and design. Come join us!
	- Here are a selection of relevant WWDC presentations focusing on technologies:
		* https://developer.apple.com/videos/play/wwdc2023/10042/
		* https://developer.apple.com/videos/play/wwdc2020/10657/
		* https://developer.apple.com/videos/play/wwdc2019/232/
		* https://developer.apple.com/videos/play/wwdc2018/713/
		* https://developer.apple.com/videos/play/wwdc2017/208/
	- KEY R&D PROJECTS PRODUCTIZED ON THE TEAM:
		* Autocorrection
		* QuickType: Predictive typing
		* Quickpath: Swipe input
		* Image captioning
		* Private Federated Learning for Language Models
		* Natural Language APIs, NLP in CreateML
	- Exemplary ability to design, perform experiments and influence engineering direction and product roadmap
	- Hands-on expertise in NLP and machine learning
	- Experience being part of engineering teams and transferring research ideas to production
	- Proven record of research innovation and visionary leadership in NLP and ML
	- Track-record of publications history in credible conferences and journals (optional)
	- Experience solving analytical problems with quantitative approaches
	- As a NLG research engineer on our team, you will research, design and develop machine learning models as well as tools/pipelines for input experience across all Apple platforms. Your role will have a direct impact on shaping the future of input technology roadmap. You will work closely with the engineering teams, perform hands-on experiments applying groundbreaking NLP and ML, derive insights from experiments and convert them into features that reach the hands of billions of users.
	- PhD in Computer Science or a related field OR MS in Computer Science or related field with at least 5 years of industry experience
+ skill set:
	- AI/ML - Sr Software Engineer, Siri in the Home
	- An opportunity to join the Siri in the Home engineering team and contribute to the platform that is redefining conversational computing for our homes.
	- We are seeking a Sr Software Engineer who brings a passion for connected home technology to help us advance Siri's capabilities whilst delivering intuitive and delightful experiences to millions of customers.
	- BS/MS in Computer Science or equivalent
	- 8+ years of professional engineering experience
	- Proven track record of architecting performant scalable software, ideally both client and server side
	- Demonstrated ownership of large cross-functional and multi-team projects
	- Proven technical leadership, education, and team mentorship
	- Solid fundamentals in OO design, patterns, data structures, and algorithms
	- Are you interested in being responsible for innovating, implementing, delivering new customer facing features for Siri? Then this may be the role for you!
	- As a Siri engineer, you will blend the latest machine learning technologies with conversational and product design to deliver exceptional experiences to millions of homes globally.
	- You will join a hands-on development team that fosters creativity and generates outstanding solutions to deliver exceptional product experiences by partnering with a variety of multi-functional teams across the company.
	- You will prioritize tasks in a fast paced environment, remain flexible and calm in the face of uncertainty, and collaborate to deliver excellent results.
	- You will be a technical leader to engineers in your team and across the organization. Communicating clearly and having the flexibility to learn new technologies, while continuously developing your skills will be key to your success. You should be comfortable both giving and receiving feedback.
	- BS/MS in Computer Science or equivalent
+ skill set:
	- Software Development Engineer [Dept: ***Machine Translation***]
	- Master's degree or foreign equivalent in Information Technology, Computer Science, Computer Engineering or related field and 1 year of experience in the job offered or related occupation.
	- Experience and/or education must include:
		* Swift;
		* Xcode Developer Tools;
		* XCTests;
		* Python;
		* macOS or Unix administration and command line usage;
		* HTTP protocol; and
		* REST APIs
	- Multiple positions available in Seattle, Washington. Triage software quality issues and user feedback for improvements. Build tooling for automated triaging. Write, debug, and maintain automation tools using tools such as Swift and Python. Program in Swift or Objective C. Write XCTest Unit Tests and XCText UI automation tests. Build command line tools using Python or Swift. Provide reports on statistics around radars. Coordinate internal processes around software triaging and reporting. 40 hours/week.
+ skill set:
	- Data Scientist (80-100%)
	- You are passionate about  data processing and NLP, you love working on cloud systems?
	- Join our enthusiastic team and face the challenge to expand Open Systems unified data platform. As a Data Scientist with focus on Language Models (LM) and Natural Language Processing (NLP) you will be part of the core development team of Open Systems processing structured and unstructured data of more than 6000 devices deployed across the planet. Together with data engineers and product owners you will discuss, shape, specify and implement solutions that ease the operation of more than 6000 devices deployed around the world, and provide intelligent insights into security-relevant data and processes. You will play a pivotal role in developing cutting-edge AI-driven solutions, leveraging the power of language understanding and generation.
	- You will join one of our small development teams that works with agile methods. The team will rely on you to focus on its goals and efforts as a team player while being able to work independently. At Open Systems we are passionate about what we do. We work in an environment in which innovative solutions, rapid development times, creativity and open communication are practiced and continuously fostered. The pursuit of technical advancement is at the center of our attention. You will be based at our office in Zurich (CH).
	- Language Model Development: Research, design, and develop advanced language models, including transformer-based architectures like BERT, GPT, and XLNet.
	- NLP Application: Apply NLP techniques to solve complex business problems, such as sentiment analysis, text classification, named entity recognition, and language translation.
	- Text Data Preprocessing: Clean, preprocess, and transform unstructured text data into a suitable format for analysis, ensuring data quality and consistency.
	- LM Fine-tuning: Fine-tune pre-trained language models for specific tasks and domains, optimizing model performance and accuracy.
	- Data Analysis: Conduct exploratory data analysis (EDA) on text data to uncover patterns, insights, and trends. Collaborate with data engineers to acquire and prepare relevant data.
	- Model Evaluation: Develop and implement evaluation metrics and techniques to assess the performance of language models and NLP applications.
	- NLP Algorithms: Research and implement state-of-the-art NLP algorithms and techniques, staying up-to-date with the latest advancements in the field.
	- Collaboration: Collaborate with cross-functional teams, including data engineers, software engineers, and business analysts, to integrate NLP solutions into our products and services.
	- Documentation: Maintain comprehensive documentation of LM and NLP models, methodologies, and processes for knowledge sharing within the team.
	- Proven experience as a Data Scientist with a focus on Language Models and NLP, including experience with transformer models.
	- Strong programming skills in languages such as Python and familiarity with deep learning frameworks like TensorFlow or PyTorch.
	- Proficiency in NLP libraries and tools (NLTK, spaCy, Hugging Face Transformers, etc.).
	- Knowledge of data analysis and visualization tools.
	- ETH, university or FH degree in Computer Science or equivalent
	- Fluent in English, German is a plus.
	- Knowledge of Linux operating systems
	- Experience with managing Infrastructure as a Service resources of public cloud providers (Azure, AWS, GCP,...) with Terraform.
	- You have a passion for sustainable software development and you gathered experiences in other technical positions already.
	- In-depth knowledge and experience of at least one programming language: Python, Go, Scala, Java
+ skill set:
	- NVIDIA's technology is at the heart of AI revolution, touching people across the planet by powering everything from self-driving cars, robotics, and voice-powered intelligent assistants. We work on new models for speech recognition, speech synthesis, and natural language processing. Our team crafted Jasper, QuartzNet, Talknet and other state-of-the-art neural models for ASR and text-to-speech, and we've also developed new algorithms to accelerate training large models on our GPU cloud.
	- Be a part of the team that's released new models as part of NeMo - open-source toolkit for Conversational AI and whose models are used by world class companies for applications such as customer service, smart voice assistants, etc. This exciting opportunity will have you collaborating with internal research and product teams, as well as researchers from top machine learning labs, and we are looking for someone who's curious, tenacious, and passionate to join our applied research team to influence and build the next generation of Conversational AI systems!
	- Develop new deep learning models and training algorithms for speech recognition, speech synthesis, information retrieval, machine translation, etc.
	- Transfer your technology to NVIDIA's software product teams.
	- Publish your research at conferences (NeurIPS, Interspeech, ICASSP).
	- Partner with Deep Learning & AI researchers in leading universities and industrial research labs.
	- Master's degree (or equivalent experience) or PhD in Computer Science, Electrical Engineering, Artificial Intelligence, or Applied Math.
	- 4+ years of practical experience.
	- Advanced understanding of Deep Learning with applications in Speech Processing and NLP, and a record of publications or significant product contributions in these areas.
	- Strong Python programming skills and experience with deep learning frameworks such as PyTorch or TensorFlow.
	- Expert mathematical background, especially in optimization theory, stochastic algorithms, and/or numerical methods.
	- Excellent communication and interpersonal skills are required along with the ability to work in a dynamic, product oriented and global team. Your history of mentoring other engineers and interns is a great bonus.
	- Strong C++ programming skills.
	- Systems software engineering knowledge and expertise in optimizing software for computational performance.
	- Contribution to open source software projects.
+ skill set for SENIOR AI AND DEEP LEARNING ARCHITECT – AUDIO APPLICATION AND NLP
	- Implementing novel deep neural network architectures and learning techniques to solve a variety of audio related tasks and push the state of the art in performance.
	- Research and develop advanced audio applications including speech recognition, voice recognition, voice wakeup using state of art deep learning algorithms.
	- Research and develop advanced audio signal processing algorithms including noise cancellation, localization, acoustic detection, acoustic fingerprinting.
	- Analyze and optimize audio signal processing and deep learning algorithms on mobile/embedded devices, e.g., using hardware acceleration such as GPU/DSP.
	- M.S. in Computer Science, Machine Learning, Electrical Engineering, Robotics or similar field (Ph.D. is preferred).
	- Solid understanding on audio signal processing.  
	- Solid understanding and experience of applying deep learning to real problems in the fields of voice recognition, speech recognition, and other audio related applications.
	- Holistic understanding of deep learning concepts, state of the art in audio processing research and the mathematics of machine learning. Familiar with CNN, RNN, LSTM.
	- Strong experience in C/C++ programing.
	- Hands-on experience in deep learning frameworks, e.g., OpenCV, Tensorflow, Keras, Pytorch, and Caffe.
	- Ability to quickly adapt to new situations, learn new technologies, and collaborate and communicate effectively.
	- 3+ years of industry experience with deep learning algorithm development and optimization.
	- Experience with parallel computing, GPU/CUDA, DSP, and OpenCL programming is a plus.
	- Top-tier conference publication records, including but not limited to CVPR, ICCV, ECCV, NIPS, ICML, is a strong plus.
	- Location: Taipei/Hsinchu/USA_San Diego/Shenzhen/Zhuhai
+ skill set:
	- Personality Traits
		* Ability to work independently under tight deadlines with accountability.
		* Strong results driven personality with a high level of enthusiasm, energy and confidence.
		* Strong problem-solving skills.
	- Required Skills
		* In-depth knowledge of various Natural Language Processing/Understanding (NLP/NLU) domains such as entity extraction, speech recognition, topic modeling, parsing, question answering, etc.
		* Expertise in text mining (probabilistic topic model, word association mining, ontology learning, semantic similarity, etc.)
		* Expertise in NLP/NLU (word representation, relation extraction, natural language inference, semantic parsing, etc.)
		* Excellent background in Machine Learning (generative model, discriminative model, neural network, regression, classification, clustering, etc.)
		* Experience in deep learning on NLP/NLU is a big plus
		* Extensive experiences in using NLP related techniques/algorithms such as HMM, CRF, deep learning & recurrent ANN, word2vec/doc2vec, Bayesian modeling, etc.
		* Experience in applied statistics including sampling approaches, modeling, and data mining techniques
		* Experience in building analytical models and working with structured and unstructured data
		* Experience with data structures and algorithms; ability to work in a Unix environment and building robust data processing and analytics pipelines
		* Contributions to research communities, e.g. ACL, NIPS, ICML, EMNLP, etc. is a Plus
	- Responsibilities:
		* You will be part of a high impact team that's building the next generation of intelligence and language understanding for Cuddle
		* Build text/voice-based search engine and question answering system for Cuddle
		* You'll utilize the latest techniques in AI, ML (including Deep Learning approaches) and NLU
		* Build topic analysis, text classification, named entity recognition methods for unstructured and semi-structured data
		* Develop and perform text classification using methods such as logistic regression, decision trees, SVM and maximum entropy classifiers
		* Perform text mining, generate and test working hypotheses, prepare and analyze historical data and identify patterns
		* Generate creative solutions (patents) and publish research results in top conferences (papers)
	- Qualifications
		* Master's degree in Mathematics, Statistics, Computer Science, or related fields
		* 2+ years of ML + NLP experience
		* Software programming in Java or Python
		* Knowledge of SQL and NoSQL databases
		* Knowledge of open source machine learning libraries like scikit-learn, tensorflow, NLP tool as NLTK
+ skill set:
	- Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, recommendation systems, targeting systems, ranking systems or similar
	- Use traditional ML techniques such as Probabilistic Graphical Models, SVMs, etc. along with the latest techniques from deep learning including graph neural networks
+ skill set:
	- AI Research Intern (PhD)
	- Our mission at Duolingo is to develop the best education in the world and make it universally available. But we’ve got more left to do — and that’s where you come in!
	- Duolingo is the most popular language-learning application in the world, with over 500 million users and over half a billion exercises completed daily. Beyond our core learning product, we also offer English proficiency testing with the Duolingo English Test, and are bringing new subjects into the Duolingo app, where people can develop their Math and Music skills.
	- We are passionate about educating our users, making fact-based decisions, and finding innovative solutions to complex problems. We offer meaningful work, limitless learning opportunities, and collaboration with world-class minds. Come brighten your life and over half a billion more!
	- Duolingo AI Research is a small and nimble team, using data to develop new hypotheses about language and learning, test them empirically, and ship products based on research. As an AI Research Intern (PhD) you are a colleague, and your code and ideas will affect tens of millions of people worldwide. You will learn deeply and broadly from our team of award-winning engineers and researchers.
	- Apply AI methods to massive real-world datasets
	- Prototype new models, evaluate with small scale experiments, and/or productionize solutions at scale
	- Work with a cross-functional team of world class researchers, engineers, and others to build new product features and/or publish state-of-the-art findings
	- Contributions to research communities and efforts, including publishing papers at conferences such as ACL, CVPR, EDM, ICML, NeurIPS, etc.
	- Experience implementing AI systems in Python, Java, Scala, or C/C++ (i.e., not just R or MATLAB)
	- Pursuing a PhD in artificial intelligence, machine learning, natural language processing, or related field
	- Graduation expected by August 2025
	- 12 week consecutive availability
	- Ability to relocate to Pittsburgh, PA
	- Language learning opportunities
	- Catered in-house lunches and breakfast
	- Company-wide Hackathon
	- PTO and company holidays
	- Frequent company-wide dinners, monthly celebrations, social clubs, and so much more!
	- We invest in and support our Duos! The hourly range  for this internship is $60-$62. 
+ skill set:
	- Engineering Manager – Fine Tuning API
	- Our team brings OpenAI’s most capable technology to the world through our products. Most recently, we released ChatGPT, GPT-4, the Whisper API, and DALL-E. We empower consumers and developers alike to use and access our start-of-the-art AI models, allowing them to do things that they’ve never been able to before.
	- Across all product lines, we ensure that these powerful tools are used responsibly. This is a key part of OpenAI’s path towards safely deploying broadly beneficial Artificial General Intelligence (AGI). Safety is more important to us than unfettered growth.
	- We are looking for an experienced engineering manager to support our Fine Tuning API team – the team that enables our API developers to customize their models via fine-tuning. This is a unique team that spans both research and applied AI tech stacks. You will work closely with our research team to bring the core technology that trained GPT-4 into the hands of all of our API developers. You will also collaborate with our product teams to build a world-class model customization experience for our API developers. Above all, you will be responsible for ensuring the safe deployment of a product that can push the performance of our models to new heights.
	- Manage, build out, and mentor a team of high performing software and research engineers.
	- Work with our product team to craft both the technical and product vision for the future of our fine tuning API.
	- Collaborate closely with research teams to push to the boundaries of what is possible with large language model customization.
	- Create a diverse, equitable, and inclusive culture that makes all feel welcome while enabling radical candor and the challenging of group think
	- Have 3+ years of experience managing high performing and diverse software engineering teams, and 6+ years of experience working with production software systems.
	- Have prior experience working with training and inference of large language models, especially in production environments.
	- Have familiarity with the latest AI research and working knowledge of how these systems are efficiently implemented
	- Own problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done
	- Have the ability to move fast in an environment where things are sometimes loosely defined and may have competing priorities or deadlines
	- Annual Salary Range: $300,000—$450,000 USD
+ skill set:
	- Engineering Manager, DALL-E
	- The DALL-E team works across research, engineering, product, and design to bring OpenAI’s DALL-E 3 technology to consumers and businesses. We’re here to create the next generation of user interfaces for generative AI, both for creation and consumption.
	- We are looking for an experienced engineering manager to lead the DALL-E product engineering team. This is a unique team that spans both research and production tech stacks. In this role, you will be bringing our DALL-E 3 and future generative models to millions of users around the world. Our users include everyday enthusiasts, creators and professionals.
	- Manage, build out, and mentor a team of high performing software engineers
	- Work with research, design and product counterparts to craft both the technical and product vision for new generative model experiences
	- Collaborate with a cross-functional team of engineers, researchers, product managers, designers, and operations folks to create cutting-edge products
	- Work with the research team to get relevant feedback and iterate on their latest models
	- Talk to users to understand their problems and design solutions to address them
	- Help create a diverse, equitable, and inclusive culture that makes all feel welcome while enabling radical candor and fast-paced collaboration
	- Have 3+ years of experience managing high performing and diverse software engineering teams, and 6+ years of experience working with production software systems
	- Own problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done and push through obstacles
	- Have the ability to move fast in an environment where things are sometimes loosely defined and may have competing priorities or deadlines
	- Are willing to delve into the codebase when necessary.
	- Possess excellent communication, planning, and organizational skills
	- Have a track record of shipping ML-based products.
	- Annual Salary Range: $310,000—$385,000 USD
+ skill set:
	- Software Engineer — Engineering Acceleration
	- The Applied AI team safely brings OpenAI's technology to the world. We released ChatGPT, Plugins, DALL·E, and the APIs for GPT-4, GPT-3, embeddings, and fine-tuning. We also operate inference infrastructure at scale. There's a lot more on the immediate horizon.
	- We seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth.
	- We serve end-users directly through ChatGPT, and serve developers through our APIs, which power product features that were never before possible. 
	- The Engineering Acceleration team designs, builds and maintains the foundational systems that engineers use to build ChatGPT and the API. This is a fast-growing team and you will get a chance to own and define the strategy, vision, and plan for how to accelerate engineering.
	- Drive the design, development, and implementation of tools, systems, and processes that accelerate engineering velocity, reduce manual effort, and increase the quality of output.
	- Use our latest AI tools to re-think how we can be the most productive team in the industry.
	- Work closely with various teams within OpenAI to understand their workflows, challenges, and needs, and ensure the tools and systems built by the Engineering Acceleration team address these requirements.
	- Bring new features and research capabilities to the world by partnering with product engineers to lay the necessary technical foundations.
	- Guide and advise product engineering teams on best practices for ensuring observable, scalable systems.
	- Help create a diverse, equitable, and inclusive culture that makes all feel welcome while enabling radical candor and the challenging of group think.
	- Like all other teams, we are responsible for the reliability of the systems we build. This includes an on-call rotation to respond to critical incidents as needed.
	- Have 5+ years of experience in engineering, including 3+ years of experience in infrastructure building tooling for developers.
	- Have experience-driven empathy for the tools, frustrations, and processes that slow engineering teams down and lead to toil or burnout.
	- Care deeply about diversity, equity, and inclusion, and have a track record of building inclusive teams.
	- Have a voracious and intrinsic desire to learn and fill in missing skills—and an equally strong talent for sharing learnings clearly and concisely with others.
	- Are comfortable with ambiguity and rapidly changing conditions. You view changes as an opportunity to add structure and order when necessary.
	- As technical context: at the heart of our infrastructure is a large-scale deployment of GPU nodes running in dozens of Kubernetes clusters across regions. Some core technologies we build with include Terraform, Buildkite, Postgres, Cosmos DB, Kafka, Python, and FastAPI.
	- This role is exclusively based in our San Francisco HQ. We offer relocation assistance to new employee
	- Annual Salary Range: $300,000—$450,000 USD
+ skill set:
	- Software Engineer, Safety
	- The Applied AI team safely brings OpenAI's advanced technology to the world. We released the GPT-3 API, Codex (which powers GitHub Copilot), and DALL-E. More is coming very soon.
	- We empower developers with APIs offering state-of-the-art AI capabilities, which power product features that were never before possible. We also build AI-driven consumer applications.
	- Across all product lines, we ensure that these powerful tools are used responsibly. This is a key part of OpenAI’s path towards safely deploying broadly beneficial Artificial General Intelligence (AGI). Safety is more important to us than unfettered growth.
	- At OpenAI, we're dedicated to advancing artificial intelligence, and we know that creating a secure and reliable platform is vital to our mission. That's why we're seeking a software engineer to help us build out our trust and safety capabilities.
	- In this role, you'll work with our entire engineering team to design and implement systems that detect and prevent abuse, promote user safety, and reduce risk across our platform. You'll be at the forefront of our efforts to ensure that the immense potential of AI is harnessed in a responsible and sustainable manner.
	- Architect, build, and maintain anti-abuse and content moderation infrastructure designed to protect us and end users from unwanted behavior.
	- Work closely with our other engineers and researchers to utilize both industry standard and novel AI techniques to combat abuse and toxic content.
	- Assist with response to active incidents on the platform and build new tooling and infrastructure that address the fundamental problems.
	- Have at least 3 years of professional software engineering experience.
	- Have experience setting up and maintaining production backend services and data pipelines.
	- Have a humble attitude, an eagerness to help your colleagues, and a desire to do whatever it takes to make the team succeed.
	- Are self-directed and enjoy figuring out the best way to solve a particular problem
	- Own problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done.
	- Care about AI Safety in production environments and have the expertise to build software systems that defend against abuse.
	- Build tools to accelerate your own workflows, but only when off-the-shelf solutions would not do.
	- Our infrastructure is built on Terraform, Kubernetes, Azure, Python, Postgres, and Kafka. While we value experience with these technologies, we are primarily looking for engineers with strong technical skills and the ability to quickly pick up new tools and frameworks.
	- Annual Salary Range: $200,000—$370,000 USD
+ skill set:
	- Software Engineer, ChatGPT Data Flywheel
	- The ChatGPT team works across research, engineering, product, and design to bring OpenAI’s technology to consumers and businesses.
	- We seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth.
	- We're seeking a software engineer with an entrepreneurial spirit to take the lead in building our data pipelines for ChatGPT. These pipelines are crucial for powering analyses that guide business decisions and product growth. If you're passionate about working with data and are eager to create solutions with significant impact, we'd love to hear from you. This role also provides the opportunity to collaborate closely with the researchers behind ChatGPT and help them train new models to deliver to users. As we continue our rapid growth, we value data-driven insights, and your contributions will play a pivotal role in our trajectory. Join us in shaping the future of ChatGPT!
	- Design, build and manage our data pipelines, ensuring all user event data is seamlessly integrated into our data warehouse.
	- Develop canonical datasets to track key product metrics including user growth, engagement, and revenue.
	- Work collaboratively with various teams, including, Infrastructure, Data Science, Product, Marketing, Finance, and Research to understand their data needs and provide solutions.
	- Implement robust and fault-tolerant systems for data ingestion and processing.
	- Participate in data architecture and engineering decisions, bringing your strong experience and knowledge to bear.
	- Ensure the security, integrity, and compliance of data according to industry and company standards.
	- Have 3+ years of experience as a data engineer and 8+ years of any software engineering experience(including data engineering).
	- Proficiency in at least one programming language commonly used within Data Engineering, such as Python, Scala, or Java.
	- Experience with distributed processing technologies and frameworks, such as Hadoop, Flink and distributed storage systems (e.g., HDFS, S3).
	- Expertise with any of ETL schedulers such as Airflow, Dagster, Prefect or similar frameworks.
	- Solid understanding of Spark and ability to write, debug and optimize Spark code.
	- Annual Salary Range: $200,000—$385,000 USD
+ skill set:
	- Software Engineer, Backend (DALL-E)
	- The DALL-E team works across research, engineering, product, and design to bring OpenAI’s DALL-E 3 technology to consumers and businesses. We’re here to create the next generation of user interfaces for generative AI, both for creation and consumption.
	- We are looking for a self-starter engineer who loves building new products in an iterative and fast-moving environment. In this role, you will be bringing our DALL-E 3 and future generative models to millions of users around the world. Our users include everyday enthusiasts, creators and professionals.
	- As OpenAI scales, we’re looking for experienced, problem-solving engineers to build new products and scale our systems. Our success depends on our ability to quickly iterate on products while also ensuring that they are performant and reliable. You will also collaborate closely with the DALL-E research team and work with them on continual improvement and product exploration. You will be a key part of the effort to push these technologies forward, and onto the next 100x users.
	- You’ll work in a deeply iterative, collaborative, fast-paced environment to bring our technology to millions of users around the world, and ensure it’s delivered with safety and reliability in mind. 
	- Design and build the development and production platforms that power products for DALL-E and beyond, enabling reliability and security at scale
	- Partner with researchers, engineers, product managers, and designers to bring new features and research capabilities to the world
	- Accelerate engineering productivity by empowering your fellow engineers with excellent tooling and systems
	- Like all other teams, we are responsible for the reliability of the systems we build. This includes an on-call rotation to respond to critical incidents as needed
	- Help create a diverse, equitable, and inclusive culture that makes all feel welcome while enabling radical candor and fast-paced collaboration
	- Have been a startup founder or an early-stage engineer
	- Have meaningful experience with building (and refactoring) production systems to deliver new product capabilities and to handle increasing scale
	- Care deeply about the end user experience and take pride in building products to solve customer needs
	- Have a humble attitude, an eagerness to help your colleagues, and a desire to do whatever it takes to make the team succeed
	- Own problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done
	- Build tools to accelerate your own (and your teammates’) workflows, but only when off-the-shelf solutions won’t do
	- Annual Salary Range: $160,000—$385,000 USD
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.





















###	Machine Learning Systems for Human-Computer Interaction



+ skill set:
	- We are looking for Research Scientist interns who have applied experience in the fields of in the fields of NLP, human-computer interaction, user behavioral analysis and/or the intersection of HCI, NLP and Machine Learning including algorithmic bias. We are open to a variety of approaches and methods to answer research questions related to how people interact and engage with Spotify. You will be part of an interdisciplinary team focused on making every user interaction with Spotify amazing through personalization and discovery, and in the process pushing state of the art and contributing to the wider research community by publishing papers. We work on a broad range of Spotify features – personalized playlists such as Discover Weekly and Daily Mix, the Homepage, Search and other ML systems powering recommendations of music and podcasts to 180 million users with billions of interactions.
	- You are currently in a PhD program in human-computer interaction, psychology, NLP, statistics, IR/search/agents, data science or related area.
	- You have publications in top tier venues such as CHI, ACL, UbiComp, SIGIR, Interspeech, HRI, CSCW, RecSys, or related.
	- You are intrigued by how interaction design, data collection strategies, and people's perceptions affect Machine Learning outcomes.
	- You have a demonstrated interest in speech/natural language, personalized recommendations, crowdsourcing, diversity in AI – and music or podcasts.
	- You are a creative problem-solver who is passionate about digging into complex problems and devising new approaches to reach results.
	- You have experience with the complexities of real-world data, and understand the value of both in-depth, qualitative and web-scale, quantitative data working together to create a deep understanding of people's interaction with technology.
+ skill set:
	- We are looking for Research Scientist interns who have applied experience in the field of machine learning, machine Intelligence, user behavioural analysis, IR, NLP, and more broadly, AI. You will be part of an interdisciplinary team focused on making every user interaction with Spotify amazing through personalisation and discovery, and in the process pushing state of the art and contributing to the wider research community by publishing papers. We work on a broad range of Spotify features – personalised playlists such as Discover Weekly and Daily Mix, the Homepage, Search and other ML systems powering recommendations.
	- Courses: PhD programme in Computer Science, Data Science, or related areas with a strong computational focus.
	- Experience: Publications in top tier venues such as WWW, SIGIR, WSDM, RecSys, CHI, KDD, AAAI, ACL, NeurIPS, ICML, or related, in the following topics: search, marketplace research, recommendations, user understanding, large scale experimentation, linguistics or (more broadly) machine learning.
























###	Recommender Systems



Sets of skills for recommender systems, recommendation systems (or, recommendation platforms/engines):
+ skill set:
	- Experience in Recommendation Systems, Personalization, Search, or Computational Advertising
	- Experience using Deep Learning, Bandits, Probabilistic Graphical Models, or Reinforcement Learning in real applications
+ skill set:
	- Recommender Systems and Personalization. Almost every aspect of the Netflix experience is personalized, and much of that personalization is driven by our various flavors of recommendation algorithms. You'll apply a number of techniques, from the latest in deep learning, reinforcement learning, to causal inference.
	- Search Ranking and Query Understanding. You'll work on the algorithms that allow our members to interactively query and explore our catalog. Using the latest in NLP techniques, you'll solve problems including: query understanding, knowledge graph discovery, and learning to rank across our global catalog of titles.
	- Large Scale Machine Learning. Netflix is available in over 190 countries, with over 148+ million members. This gives us a unique dataset to work with, but also unique challenges in how we scale our models. You'll work on cutting edge techniques to scale your models for use in our production systems.
	- Strong background in machine learning with a broad understanding of unsupervised and supervised learning methods
	- Strong software development experience
	- Successful track record of delivering results in complex cross-functional projects
	- Strong mathematical skills with knowledge of statistical methods
+ skill set:
	- Responsible for content recommendation, text mining, user model construction, etc.;
	- Optimize search recommendation system algorithm;
	- Research on algorithms for knowledge extraction, mining, fusion and visualization based on big data;
	- Algorithm and functional module code development, back-end algorithm API development, testing, technical documentation writing.
	- Bachelor degree or above, major in computer, communication and other related fields;
	- Have more than 3 years of work experience;
	- Have a solid programming ability and master at least one back-end programming language (Python/Go/Java, etc.);
	- Have a deep understanding of operating systems, data structures and algorithms
+ skill set:
	- SmartNews is a leading mobile app of news aggregation services. It analyzes millions of articles to deliver most engaging information with high quality in near-real time fashion to millions of users around the world. Our AI Foundation team is responsible to research and develop world-class AI algorithms that can be applied at large scale to accomplish our mission. It works on a range of content understanding, user modeling and recommendation problems, which include natural language processing tasks of classification, entity recognition, summarization, computer vision of image/video processing, collaborative filtering, etc. The team generally produce good content/user signals and state-of-art recommendation models to News Ranking/Ads Ranking team to deliver the world's high quality information to the people who need it.
	- Responsibilities
		* Set technical and research roadmap for AI Foundation or even company level machine learning roadmaps (at principal level) and able to lead its implementation
		* The ability to solve hardest issues of AI Foundation team from fundamental algorithm development, implementation and optimization to deliver product metrics
		* Lead cross-organizational projects to improve features/models that benefit company OKR
		* Set visions for company's research direction to be industry leading in areas of personalized discovery and related areas
		* In this position, you are expected to utilize your industry leading expertise on one or more of following R&D areas to provide cutting edge solutions or core technologies for SmartNews recommendation systems (Ads, News, etc). At principal level, you are required to have overall understanding of corporate AI landscape, and set visions/roadmaps in its directions
		* General Machine Learning, Deep Learning
		* Natural Language Processing (entity recognition, categorization, text embedding, etc)
		* Computer Vision, Image Processing
		* Knowledge Graph
		* Recommendation, Collaborative Filtering Algorithms
		* Be great mentor to other machine learning scientists
		* Promote AI first culture and distill AI mindset across engineering teams (principal level)
	- Minimum Qualifications
		* 8+ years of experience in designing and implementing state-of-the-art machine learning algorithms, and applying them to real world problems
		* Industry leading expertise in certain domain of machine learning techniques, especially in deep learning, natural language processing, recommendation systems, computer visions
		* Long term track record of successfully deliver improvement of features/models to production systems with high impact by working across teams and organizations
		* Influential publications at top industry conferences/journals, well recognized in the industry for the domain of expertise
		* Strong mentors of senior machine learning scientists and able to grow them to the next level
		* Good written and spoken communication skills, can work across functional teams
		* Strong coding abilities in multiple programming languages (e.g. Java, C++, Python, Scala)
		* Ph.D in computer science, mathematics, physics or other quantitative fields
	- Preferred Qualifications
		* Strong interest in news media and our mission
		* Strong domain expertise in recommendation algorithms
+ skill set:
	- Design and develop core backend software components; create and deploy new software solutions for the NewsBreak app:
		* Apply expertise and innovation to create new technology, such as the online serving pipeline and data platform, machine learning algorithm for user click prediction, and etc.
		* Analyze the latency problems of the backend software modules to develop solutions for parallelization; thus, improving the throughput of the online serving system.
		* Write, analyze, review, and rewrite programs, using workflow chart and diagram, and applying knowledge of computer capabilities, subject matter, and symbolic logic.
		* Write, update, and maintain computer programs or software packages to handle specific jobs such as tracking inventory, storing or retrieving data, or controlling other equipment.
		* Maintain both product level and system level code, primarily using Python, Java, and PHP, to meet the technical challenges and requirements.
		* Research and evaluate the feasibility of new technologies and provide direction on the application of modem natural language understanding techniques for the online serving system.
	- Perform offline and online validation tests:
		* Develop and execute verification and validation tests for the newly designed online serving backend software components and analyze the product performance to meet efficiency requirements.
		* Modify existing backend software components to correct errors; perform revisions, repairs, or expansions of existing programs to increase operating efficiency or adapt to new requirements.
		* Store, retrieve, and manipulate data for analysis of the online serving system capabilities and requirements, using MongoDB and HDFS.
	- Develop recommendation and phrase mining algorithms:
		* Design and develop advanced recommendation and phrase mining algorithms for user click prediction using machine learning algorithms such as Collaborative Filtering, Factorization Machine, DeepWalk and etc.
		* Make use of data analytical tools such as Kibana, Azkaban, Kubernetes and etc., to analyze user needs and software requirements to determine feasibility of the proposed design within time and cost constraints.
	- Provide other technical supports & draft related documentations:
		* Discuss with managerial, engineering, and technical personnel to clarify program intent, identify problems, and suggest changes for the overall online serving system, recommendation system, and the phrase mining algorithm.
		* Confer with systems analysts, engineers, programmers and others to obtain information on limitations and capabilities, performance requirements and interfaces of a certain feature.
	- Master's degree in Computer Science, Computer Engineering or related plus 1 year experience.
+ Staff AI Research Scientist, Recommendation
	- Our mission at Duolingo is to develop the best education in the world and make it universally available. But we’ve got more left to do — and that's where you come in!
	- Duolingo is the most popular language-learning application in the world, with over 500 million users and over half a billion exercises completed daily. Beyond our core language learning product, we also offer English proficiency testing with the Duolingo English Test, and are bringing new subjects into the Duolingo app, where people can develop their Math and Music skills.
	- We are passionate about educating our users, making fact-based decisions, and finding innovative solutions to complex problems. We offer meaningful work, limitless learning opportunities, and collaboration with world-class minds. Come brighten your life and over half a billion more!
	- We are searching for an AI Research Scientist experienced with recommendation systems to join our efforts to personalize learning. Duolingo has a unique opportunity to define the future of personalized education with one of the world’s largest datasets. As an AI Research Scientist, you will apply your background in AI and machine learning to invent the technologies that will define the future of education. In many cases, this means identifying entirely new research problems, or synthesizing work that spans several fields. You will find opportunities to improve existing systems – or reinvent them completely – to tackle Duolingo's unique data. We are a fun and motivated team, building intelligent software used by millions of people around the world every day.
	- Conduct cutting-edge AI research that pushes forward the field of education
	- Work with a multi-functional team of award-winning designers, researchers, engineers, and others to build new research-based product features
	- Assist in mentoring junior scientists and engineers
	- Contribute to the broader research community by publishing and presenting about your work
	- A few past projects from the group:
		* The world's largest student model "Birdbrain" (IEEE Spectrum paper)
			+ https://spectrum.ieee.org/duolingo
		* A method to jump-start adaptive language testing (EMNLP paper)
			+ https://research.duolingo.com/papers/mccarthy.emnlp21.pdf
		* Novel bandit algorithm for mobile notifications (KDD paper)
			+ https://research.duolingo.com/papers/yancey.kdd20.pdf
		* The Duolingo English Test (TACL paper)
			+ https://research.duolingo.com/papers/settles.tacl20.pdf
	- PhD in machine learning, AI, computer science, or a related technical field
	- 2 years of industry experience except for exceptional senior faculty candidates
	- Experience working with recommendation systems
	- Experience implementing ML systems in Python, Java, Scala, or C/C++ (i.e., not just R or MATLAB)
	- Outstanding interpersonal communication and organizational skills
	- Contributions to research communities and efforts, including publishing papers at conferences such as ACL, CVPR, EDM, ICML, NeurIPS, etc.
	- Familiarity with educational and/or assessment technologies
	- Experience mentoring or managing junior scientists or engineers
	- Strong publication record
	- We invest in and support our Duos! This role is eligible for a robust compensation package of base salary, equity, and Duolingo’s world-class benefits. The starting base salary range for this role is, $197,500 - $374,000. Actual salary may vary based on level, work experience, performance, and other factors evaluated during the hiring process.
+ Senior AI Research Engineer, Recommendation
	- Our mission at Duolingo is to develop the best education in the world and make it universally available. But we’ve got more left to do — and that’s where you come in!
	- Duolingo is the most popular language-learning application in the world, with over 500 million users and over half a billion exercises completed daily. Beyond our core language learning product, we also offer English proficiency testing with the Duolingo English Test, and are bringing new subjects into the Duolingo app, where people can develop their Math and Music skills.
	- We are passionate about educating our users, making fact-based decisions, and finding innovative solutions to complex problems. We offer meaningful work, limitless learning opportunities, and collaboration with world-class minds. Come brighten your life and over half a billion more!
	- We are searching for an AI Research Engineer experienced with recommendation systems to join our efforts to personalize learning. Duolingo has a unique opportunity to define the future of personalized education with one of the world’s largest datasets. The AI Research Engineer role at Duolingo is quite broad, with responsibilities ranging from engaging with the research community via publishing papers and attending conferences, to bringing the latest advances in AI to our product by collaborating with our research scientists and software engineers. 
	- Research engineers are expected to both innovate and implement. As such, we look for applicants with both an accomplished research portfolio as well as a strong software engineering background. AI research engineers often own projects from end-to-end, beginning with ideation, data collection, R&D, and culminating in putting your work in front of our learners.
	- Solve our most ambitious problems with the right tool for the task
	- Collaborate cross-functionally to bring your ideas to life in the product
	- Identify problems, prototype solutions, evaluate their return on investment, and then implement the best solution at scale to improve the lives of our millions of learners each day
	- Share your findings both within Duolingo as well as to the broader research community
	- A creative, interdisciplinary, and entrepreneurial approach to R&D
	- Strong debugging and critical thinking skills
	- M.S./Ph.D. in machine learning, AI, computer science, or a related technical field
	- 2 years of industry experience
	- Experience working with recommendation systems
	- Outstanding interpersonal communication and organizational skills
	- Experience implementing AI systems at scale
	- Ability to relocate to New York, NY or Pittsburgh, PA
	- 5 years of post-doctoral and/or industry experience
	- Experience mentoring or managing junior scientists or engineers
	- A strong publication record
	- We invest in and support our Duos! This role is eligible for a robust compensation package of base salary, equity, and Duolingo’s world-class benefits. The starting base salary range for this role is, $166,500 - $273,000. Actual salary may vary based on level, work experience, performance, and other factors evaluated during the hiring process.













###	Artificial General Intelligence


####	Organizations/Companies Working on in Artificial General Intelligence



+ DeepMind
	- DeepMind Technologies Limited doing business as (dba) Google DeepMind
	- https://deepmind.google
+ Vicarious
	- https://vicarious.com
+ Anthropic PBC
	- https://anthropic.com
+ OpenAI
+ Google AI
+ Microsoft AI
	- https://www.microsoft.com/en-us/ai
+ Vicarious
	- https://vicarious.com
	- Part of Intrinsic (Alphabet Inc.).
+ Robust AI
	- https://www.robust.ai
+ Elemental Cognition
	- https://ec.ai
+ GoodAI
	- https://www.goodai.com
+ Nnaisense
	- https://www.nnaisense.com






###	Legal Informatics & Computational Law



This subsubsection includes skill sets for applied machine learning roles in legal services, including:
+ legal informatics
+ computational law











###	MLOps, or ML Ops, ModelOps, & AIOps 




####	MLOps, or ML Ops



MLOps is the set of practices at the intersection of Machine Learning, DevOps and Data Engineering.

MLOps or ML Ops is a set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently.

Machine learning models are tested and developed in isolated experimental systems. When an algorithm is ready to be launched, MLOps is practiced between Data Scientists, DevOps, and Machine Learning engineers to transition the algorithm to production systems.

Similar to DevOps or DataOps approaches, MLOps seeks to increase automation and improve the quality of production models, while also focusing on business and regulatory requirements. While MLOps started as a set of best practices, it is slowly evolving into an independent approach to ML lifecycle management.

MLOps applies to the entire lifecycle:
+ integrating with model generation
	- software development lifecycle
	- continuous integration/continuous delivery, CI/CD
+ orchestration
+ deployment
+ health
+ diagnostics
+ governance
+ business metrics

MLOps is a subset of ModelOps
+ MLOps is focused on the operationalization of ML models, while ModelOps covers the operationalization of all types of AI models.
+ MLOps is the intersection of:
	- machine learning engineering
	- DevOps
	- data engineering



Steps in a machine learning lifecycle:
+ data collection
+ data processing
+ feature engineering
+ data labelling
+ model design
+ model training
+ optimization
+ endpoint deployment
+ endpoint monitoring




Goals of enterprise machine learning that can be achieved through MLOps systems:
+ Deployment and automation
+ Reproducibility of models and predictions
+ Diagnostics
+ Governance and regulatory compliance
+ Scalability
+ Collaboration
+ Business uses
+ Monitoring and management


A common architecture of an MLOps system would include data science platforms where models are constructed and the analytical engines where computations are performed, with the MLOps tool orchestrating the movement of machine learning models, data and outcomes between the systems.



Need to address:
+ model effectiveness
+ model compliance
+ model life cycle (MLC) management as a cross-functional process


Use MLOps to support distributed machine learning, distributed ML.




***Skill sets for MLOps***:
+ We work with the best of open source technologies - ***Akka, Scala, Undertow, Spark, Spark ML, Hadoop, Cassandra, Mongo***.
+ In depth experience with Spark/Hadoop and either Theano/Tensorflow/Caffe/Torch.
+ MLOps engineering lead
	- As an experienced MLOps engineer, you understand that machine learning is critical to processing and analyzing massive datasets. Your ability to build, deploy, and maintain ML infrastructure makes you an integral part of delivering robust AI solutions to answer challenging problems. We need your technical expertise and domain knowledge to support the development of generative AI and natural language platforms. As an MLOps engineer in support of strategic innovations, you’ll be implementing cutting-edge ML and DevOps technologies to accelerate our clients’ understanding of their data.
	- You’ll collaborate with a large community of data scientists, software engineers, and DevOps engineers to deliver world-class solutions. Your advanced consulting skills and hands-on technical experience will guide clients as they navigate the constantly evolving landscape of various ML tools and frameworks. You will also be involved in shaping team direction and will work without considerable direction, including mentoring and supervising team members. Work with us to solve real-world challenges and define ML strategy for the client and beyond.
	- 10+ years of experience with artificial intelligence, MLOps, DevOps, or data engineering, either in a research or professional role 
	- Experience building and deploying containerized applications or microservices using Docker and Kubernetes 
	- Experience deploying AI solutions built on frameworks, such as TensorFlow, PyTorch, or Transformers 
	- Experience with CI/CD or DevOps frameworks, including Jenkins, GitHub Actions, and Argo CD
	- Experience with cloud infrastructure provisioning or configuration frameworks, including CloudFormation, Terraform, Pulumi, and Ansible
	- Experience with full-stack development
	- Experience working in an Agile team 
	- Knowledge of languages, such as Python, Java, TypeScript, JavaScript, and SQL 
	- Experience with integrating DevSecOps practices and principles throughout the project life cycle 
	- Experience writing technical documentation 
	- Experience with testing and quality assurance  
	- Experience with GPU-programming, including CUDA, RAPIDs, or similar  
	- Knowledge of front-end frameworks, such as React, Angular, or Vue
	- Knowledge of back-end and middleware services, such as NGINX, FastAPI, or Airflow
	- Knowledge of AI concepts and tooling to support deep learning, machine learning, signal processing and natural language processing 
	- CompTIA Security + Certification
	- Master's degree in Computer Science, Statistics, or a related field
+ skill set:
	- Senior Software Engineer, ML Workflows (Remote)
	- At Weights & Biases, our mission is to build the best developer tools for machine learning. Weights & Biases is a series C company with $250 million in funding and a rapidly growing user base. Our platform is an essential piece of the daily work for machine learning engineers, from academic research institutions like FAIR and UC Berkeley to massive enterprise teams including iRobot, OpenAI, Toyota Research Institute, Samsung, NVIDIA, Salesforce, Blue Cross Blue Shield, Lyft, and more.
	- We are hiring a software engineer for the Machine Learning Workflows team to build an end-to-end platform for current and future ML workloads.
	- In this role, you will own building new products that connect various stages of the machine learning lifecycle. You will have the opportunity to work directly with state-of-the-art ML organizations and ship features that will be used in cutting-edge research. You will be expected to tackle some key problems in ML operations today such as dataset management, model governance, and compute orchestration.
	- Design and build new products that reshape how ML engineers interact with their datasets and models
	- Scale APIs and systems to support enterprise-level ML workloads and datasets
	- Implement automation to assist ML engineers in finding optimal hyperparameters or run an inference job when training is finished
	- Focus on our end users and listen to customer feedback in order to deliver value
	- Keep up with the latest trends in the ML world and leverage existing tools and frameworks whenever necessary
	- Ability to synthesize complex requirements into concrete features and milestones
	- Strong software engineering fundamentals and knowledge of at least 1 modern programming language (Go, Python, Typescript, etc)
	- Experience in building ML or data systems (Kubeflow, TFX, MLFlow)
	- Basic understanding of ML algorithms or familiarity with some ML framework (PyTorch, Tensorflow, HuggingFace, LangChain)
	- Experience with cloud platforms and technologies (AWS, GCP, Kubernetes, etc)
	- Ability to synthesize complex requirements into concrete features and milestones
	- Strong software engineering fundamentals and knowledge of at least 1 modern programming language (Go, Python, Typescript, etc)
	- Experience in building ML or data systems (Kubeflow, TFX, MLFlow)
	- Basic understanding of ML algorithms or familiarity with some ML framework (PyTorch, Tensorflow, HuggingFace, LangChain)
	- Experience with cloud platforms and technologies (AWS, GCP, Kubernetes, etc)
+ skill set:
	- Are you energized by building high-performance, scalable and reliable machine learning systems? Do you want to help define and build the next generation of AI platforms powering advanced NLP applications?  We are looking for Senior Software Engineers to join the Model Serving team at Cohere. The team is responsible for developing, deploying, and operating the AI platform delivering Cohere's large language models through easy to use API endpoints. In this role, you will work closely with many teams to deploy optimized NLP models to production in low latency, high throughput, and high availability environments. You will also get the opportunity to interface with customers and create customized deployments to meet their specific needs.
	- We are looking for candidates with a range of experiences for multiple roles, from senior to staff-level engineers.
	- Experience in Golang (or, other languages designed for high-performance scalable servers)
	- Strong understanding or working experience with distributed systems
	- Experience designing, implementing, and maintaining a production service at scale
	- Experience with serving ML models
	- Familiarity with inference characteristics of deep learning models, specifically, Transformer based architectures
	- Familiarity with computational characteristics of accelerators (GPUs, TPUs, and/or Inferentia), especially how they influence latency and throughput of inference
	- Experience in performance benchmarking, profiling, and optimization
	- Hands-on experience building and debugging microservices architecture
	- Experience with cloud infrastructure (e.g. AWS, GCP)
+ skill set:
	- The Cohere Modelling team is at the forefront of cutting-edge technologies, including Retrieval Augmented Generation (RAG). We are responsible for developing state-of-the-art models that seamlessly combine retrieval-based knowledge and generative text generation. Our innovations in RAG have the potential to revolutionise the way people access and interact with information.
	- As a Full Stack Software Engineer on our RAG team, you will play a pivotal role in harnessing the power of Retrieval Augmented Generation. Your primary focus will be on frontend development, data engineering, and collaborating closely with our ML teams to support them implement and optimise RAG models. You'll have the unique opportunity to shape the future of information retrieval and content generation through RAG.
	- Develop annotation interfaces that facilitate effective knowledge retrieval.
	- Optimise data pipelines to support RAG model training and inference.
	- Build essential tools that enhance the RAG workflow.
	- Collaborate seamlessly with cross-functional teams, leveraging the capabilities of RAG in our projects.
	- Have fun and build long lasting friendships!
	- To excel in this role, we seek candidates with the following qualifications:
	- A degree in Computer Science or a related field.
	- Proficiency in various programming languages.
	- Prior experience with React.
	- Exposure to Large Language Models (LLM) and Natural Language Processing (NLP).
	- Strong problem-solving abilities.
	- Effective communication skills.
	- A collaborative and team-oriented mindset.
	- Join us and be part of the innovative RAG journey, where you'll contribute to reshaping how knowledge is retrieved, processed, and generated in the realm of natural language understanding and generation.
+ skill set:
	- Senior Software Engineer, Data Infrastructure
	- At Cohere, we strive to continually improve our large language models. Academic research and real-world experience has demonstrated that high quality, diverse datasets can contribute as much to the performance and capabilities of LLMs as the underlying model architecture and training regimen. We at Cohere believe data will play a central role in accelerating the advancement of our already world-class language models.
	- Data is therefore critical to our success. Our ability to acquire data that is accurate, relevant, and timely is key to our ability to improve the quality of our models. We strive to continuously improve our data acquisition processes and systems to ensure that we have the data we need to stay competitive and meet the needs of our customers. We run frequent experiments to learn more about the role of data for model quality, from data mixtures, to cleaning techniques, to quality control.
	- This role will be part of the Data Acquisition team, which broadly provides data for training models and is responsible for building and maintaining the infrastructure that acquires, cleans, and formats data for model training. We are looking for a technically skilled, resourceful problem-solver who is able to work in areas of ambiguity and find efficient and sometimes creative solutions. The main responsibility of this role is to improve our internal data acquisition infrastructure, which includes data crawlers, formatters, and integrations with data providers. This role would also work closely with different teams at Cohere to support their data acquisition needs, as well as engage in more experimental work to develop highly informative data signals.
	- Design, build, and maintain data infrastructure to support large-scale data pipelines
	- Establish infrastructure to enable rigorous experimentation and evaluation
	- Implement best practices for data management and governance
	- Develop technical proposals and lead vendor selection processes
	- Collaborate cross-functionally to ensure infrastructure alignment across the organization
	- Mentor junior team members and contribute to their professional growth
	- You have more than 5 years of experience working as a software engineer specializing in data infrastructure.
	- You have proficiency in Python and have used distributed processing technologies like Spark, Dask, etc.
	- You have experience working with job orchestrators (e.g. Airflow, Dagster, Prefect) and/or MLOps frameworks (e.g. Metaflow, Pachyderm, DVC).
	- You have built data pipelines and ETL processes to support large-scale datasets
	- You have experience working with unstructured and/or human-annotated data (e.g., collecting or assessing sample quality).
	- You have worked with ML frameworks such as Tensorflow, TF-Serving, JAX, and XLA/MLIR
	- You have strong communication and problem-solving skills, and prefer using the right tool for the job even if it’s outside your wheelhouse.
	- You have a demonstrated passion for applied NLP models and products
+ skill set:
	- Member of Technical Staff, Data Acquisition
	- At Cohere, we strive to continually improve our large language models. Academic research and real-world experience has demonstrated that high quality, diverse datasets can contribute as much to the performance and capabilities of LLMs as the underlying model architecture and training regimen. We at Cohere believe data will play a central role in accelerating the advancement of our already world-class language models.
	- Data is therefore critical to our success. Our ability to acquire data that is accurate, relevant, and timely is key to our ability to improve the quality of our models. We strive to continuously improve our data acquisition processes and systems to ensure that we have the data we need to stay competitive and meet the needs of our customers. We run frequent experiments to learn more about the role of data for model quality, from data mixtures, to cleaning techniques, to quality control.
	- This role will be part of the Data Acquisition team, which broadly provides data for training models and is responsible for building and maintaining the infrastructure that acquires, cleans, and formats data for model training. We are looking for a technically skilled, resourceful problem-solver who is able to work in areas of ambiguity and find efficient and sometimes creative solutions. The main responsibility of this role is to improve our internal data acquisition infrastructure, which includes data crawlers, formatters, and integrations with data providers. This role would also work closely with different teams at Cohere to support their data acquisition needs, as well as engage in more experimental work to develop highly informative data signals.
	- Develop data pipelines to acquire, prepare, and integrate high-quality datasets into model training and evaluation
	- Collaborate with research and product teams to identify, prioritize, and secure new data sources
	- Enhance and develop infrastructure for data management, pipeline orchestration, and MLOps, while avoiding premature optimization
	- Run experiments using new data inputs, preprocessing techniques, and data mixtures
	- You have more than 2 years of experience working on a software or machine learning engineering team
	- You have proficiency in Python and have used distributed processing technologies like Spark, Dask, etc.
	- You have experience building data pipelines and ETL processes for large-scale datasets
	- You have experience working with unstructured and/or human-annotated data (e.g., collecting or assessing sample quality).
	- You have experience with ML frameworks such as Tensorflow, TF-Serving, JAX, and XLA/MLIR
	- You have strong communication and problem-solving skills, preferring the right tool for the job even if it’s outside your wheelhouse
	- You feel comfortable actively reading academic literature and researching state-of-the-art NLP best practices.
	- You have a demonstrated passion for applied NLP models and products
+ skill set:
	- Full Stack Software Engineer, Forward Deployed Engineering
	- As a Full Stack Software Engineer on our Forward Deployed team you will work directly with customers to quickly understand their greatest problems and design and implement solutions using Large Language Models.
	- In this role, you’ll apply your problem-solving ability, creativity, and technical skills to close the last-mile gap in Enterprise AI adoption. You’ll be able to deliver products like early startup CTOs/CEOs do and disrupt some of the most important industries and institutions globally!
	- Own and build large new areas within our product.
	- Work across the backend, frontend, and interact with Large Language Models.
	- Experiment at a high velocity and level of quality to engage our customers and eventually deliver solutions that exceed their expectations.
	- Work across the entire product lifecycle from conceptualization through production.
	- Proficiency in one or more of Go, Python, Node, React, Next.js 
	- Experience building ML infrastructure and AI-powered solutions.
	- Experience scaling products at hyper-growth startups.
	- Strong written and verbal communication skills.
	- Ability and interest to travel up to 25%, as needed to client sites, but flexible based on personal preferences.
	- Experience building LLM applications using tools such as Langchain.
	- Experience in Information Retrieval systems for document question answering.
	- Experience in day-to-day NLP for the industry using Python and related toolchains (SpaCy, HuggingFace, NLTK, etc.).
+ skill set:
	- Engineering Manager, Forward Deployed Team
	- Our Forward Deployed Team works directly with customers to quickly understand their greatest problems and design and implement solutions using Large Language Models.
	- In this role, you’ll apply your problem-solving ability, creativity, and technical skills to close the last-mile gap in Enterprise AI adoption. You’ll be able to deliver products like early startup CTOs/CEOs do and disrupt some of the most important industries and institutions globally!
	- Own and build large new areas within our product and scale to millions of dollars of revenue impact.
	- Lead a cross-functional team of Engineers, Machine Learning Engineers and AI Data Trainers.
	- Work across backend, frontend, and customize Large Language Models.
	- Experiment at a high velocity and level of quality to engage our customers and eventually deliver solutions that exceed their expectations.
	- Work across the entire product lifecycle from conceptualization through production.
	- 5+ years of experience building AI-backed products with millions of dollars of revenue impact.
	- Experience with B2B Enterprise SaaS applications.
	- Experience scaling products and teams at hyper-growth startups
	- Strong written and verbal communication skills
	- Ability and interest to travel up to 25%, as needed to client sites, but flexible based on personal preferences.
	- Experience building LLM applications using tools such as Langchain.
	- Experience with Information Retrieval Systems for document question answering.
	- Experience in day-to-day NLP for the industry using Python and related toolchains (SpaCy, HuggingFace, NLTK, etc.).
+ skill set:
	- At Nextdoor, machine learning is starting to transform our product through personalization, driving major impact across different parts of our platform including our newsfeed, our notifications, our advertising, and our local ecosystem. Our machine learning team is lean but hungry to drive even more impact and make Nextdoor the neighborhood hub for local exchange. We are scrappy and believe that ML will be an integral part of making Nextdoor valuable to our members. We also believe that ML should be ethical and encourage healthy habits and interaction. We are looking for great engineers who believe in the power of local community to empower our members to make their communities great places to live.
	- The Impact You'll Make
		* You will be part of a scrappy and impactful team building a scalable ML platform in a rapidly changing company. In this role, you will focus on developing the underlying data processing infrastructure to support the ML platform in collecting data, labeling data, and using data to monitor model performance. You will also build infrastructure to train, serve, and monitor ML models. Finally, you will be responsible for building platform-wide model features that the entire company can utilize in building ML models. As a result, you will be laying the foundation for a critical part of Nextdoor's mission.
	- What You'll Bring to The House
		* B.S. in Computer Science, Math, Statistics, or a related field.
		* 5+ years of industry/academic experience ***building ML infrastructure at scale***.
		* Proven engineering skills. Experience ***writing and maintaining high-quality production code***.
		* Proficient in Python
	- Bonus Points
		* Experience ***using AWS to build data-intensive infrastructure: ECS, Kinesis, S3, Kafka, Spark, Druid, Flink***
		* Experience building platforms around publically available ***ML platforms*** like ***Sagemaker, Kubeflow, MLflow***, etc.
		* Experience serving models using a variety of ***ML model frameworks*** like ***Tensorflow, PyTorch, Sci-kit Learn***, etc.
+ skill set:
	- SITE RELIABILITY ENGINEER - ML OPS @ Abacus.AI
	- Responsible for building, tuning and operating the entire infrastructure that powers Abacus.AI's multi-cloud SaaS products. We have a modern technology stack built on Kubernetes, Spark, TensorFlow, Python, Go, Mysql & Redis
	- BS or MS from a top notch CS programs
	- 2+ years professional experience in hands-on engineering roles including operating production environments in public clouds: AWS, GCP, Azure
	- Strong Linux/Unix systems fundamentals
	- Python programming experience in production environments
	- Experience with modern cloud environments: containerization, infrastructure-as-code, devops, CI/CD pipelines and automation
	- Operating Kubernetes clusters
	- Experience with ML Ops: Spark, TensorFlow, GPUs
	- Experience with Terraform
	- Hands-on experience with network security, databases systems
+ skill set:
	- Experience with NoSQL databases, such as HBase, Cassandra, MongoDB
	- Experience with any of the following distributions of Hadoop - Cloudera/MapR/Hortonworks.
	- Strong experience with Apache Spark, Hive/Impala and HDFS
	- Familiar with Python, Unix/Linux, Git, Jenkins, JUnit and ScalaTest
	- Proficient in Scala, Java and SQL
	- Other functional Languages such as Haskell and Clojure
	- Big Data ML toolkits such as Mahout, SparkML and H2O
	- Apache Kafka, Apache Ignite and Druid
	- Container technologies such as Docker
	- Cloud Platforms technologies such as DCOS/Marathon/Apache Mesos, Kubernetes and Apache Brooklyn.
+ Preferred Skills: Tensorflow, Slurm, Kubernetes
	- The Slurm Workload Manager, formerly known as Simple Linux Utility for Resource Management (SLURM), or simply Slurm, is a free and open-source job scheduler for Linux and Unix-like kernels, used by many of the world's supercomputers and computer clusters.
+ skill set:
	- MLOps, ML Flow
	- protocol design using protobuf + grpc
+ skill set:
	- buildout of serverless AI platform, using a combination of Python and AWS technologies, such as:
		* Lambda
		* Kinesis
		* S3
		* EC2
		* Glue
		* Batch
		* EMR
		* CloudFormation
+ skill set for MLOps with Kubeflow:
	- Use Kubeflow (KF) as a coherent platform with end-to-end workflows across all KF services.
		* Kubeflow services:
			+ Notebooks
			+ Pipelines, Kubeflow Pipelines
			+ KFServing
	- Kubeflow components:
		* AutoML (Katib)
		* distributed training
		* HyperParameter Tuning (Katib)
		* Fairing
		* Feast
		* Kale
		* KFServing
		* Notebooks
		* MLMD
		* Seldon
		* TFServing
		* Visualization (Tensorboard)
	- deploy machine learning models into production that would deliver business value
	- steps in data science or applied machine learning workflows:
		* converting tuned models to model serving
		* connecting data pipelines to ML pipelines
		* data preprocessing and transformation
		* distributed training
		* feature engineering
		* hyperparameter tuning
		* notebook experimentation
		* manually building ML pipelines
		* model building
		* model serving
		* monitoring models
		* pipeline building
		* training models
	- checklist for MLOps, and data science or applied machine learning workflows:
		* automation
		* documentation
		* installation
		* portability
		* reproducibility
		* security
		* support
		* tutorials
	- storage classes
		* AWS EBS
		* AWS EFS
		* GCP Persistent Disk
		* Azure Disk
		* IBM
		* Arrikto Rok
		* Gluster
		* EMC
		* NetApp
		* Pure
		* Portworx
		* Rock (Ceph)
	- use Kubeflow tutorials from:
		* AgileStacks
		* AWS
		* Azure
		* Canonical
		* Cisco
		* GCP/Google
		* IBM
		* MiniKF/Arrikto
		* Patterson Consulting
	-IDEs:
		* OptionJupyterLab
		* PyCharm
		* RStudio
		* Virtual Studio Code, VSCode
	- ML frameworks & tools
		* Airflow
		* Caffe
		* Chainer
		* Keras
		* MLflow
		* MPI
		* MXNet
		* PyTorch
		* Tensorflow
		* Scikit-Learn
		* Spark
		* Theano
		* XGBoost
	- Progression of Kubeflow usage:
		* Have Kubeflow working in the lab
		* Have Kubeflow working in production
		* Use a Kubeflow cluster
		* Contributing to Kubeflow
		* Have Kubeflow
+ skill set:
	- Tensorflow
	- Object oriented programming, C++ or Java
	- Spark or Map Reduce
	- SQL and noSQL database experience
	- Linux
	- Source control experience, preferably GIT
+ skill set:
	- Have previous experience applying machine learning, and (big) data analytics frameworks such as TensorFlow, Scikit-learn, and the Apache Hadoop ecosystem, to real world problems.
	- Are well versed in the Linux operating system. Experience with cloud technology, and containers like Docker or Kubernetes, are highly desirable.
+ skill set:
	- Develop software tools for data preprocessing (e.g. sanitization and annotation) and support our algorithm development team to employ the tool chain on our datasets with data quality analysis;
	- Develop algorithms for privacy-enhancing technologies;
	- Develop algorithms for privacy-preserving machine learning;
	- Work and present the results in the form of documentation.
+ skill set:
	- AI/ML Application Framework Engineer
	- Bringing up AI/ML model including ***model deployment*** and ***accuracy verification/tuning***.
	- AI/ML model end to end performance analysis and tuning.
	- Quantized ML model development and retraining.
	- Deep learning application and flow implementation and integration.
	- Working closely with Software and Hardware team members for performance exploring and tuning.
	- 3+ years experience working in AI/ML model deployment, verification, tuning and quantization.
	- 3+ proven years of experience in developing high quality production software in C/C++/Python.
	- Experience in AI frameworks: ***Tensorflow/Tensorflow-Lite/Pytorch/Tensor-RT/CUDA***, etc.
+ Systems Software Engineer, Frontiers
	- The Multimodal Team focuses on building A.I. systems that leverage modalities outside of pure-text, including images, audio, and video. Recent accomplishments from the team include the integration of visual inputs into GPT-4, the development of the Whisper speech recognition system, and the creation of the foundational text-image contrastive model known as CLIP.
	- We are initiating a new project within the team, focused on applying these models to interact with the world through a general interface, and to solve complex real-world problems. 
	- As a Systems Software Engineer, you will be responsible for building and maintaining an infrastructure for environments where our A.I. models can interact safely and efficiently. You will closely collaborate with other team members to execute a common research agenda.
	- Architect, build, and maintain an infrastructure for the environments that scale.
	- Optimize the infrastructure for speed and efficiency (e.g. by fine-tuning resource allocation, networking, and storage).
	- Collaborate closely with other researchers and engineers to integrate your work into our larger system and to support continually emerging research needs.
	- Troubleshooting any issues that arise and making sure the infrastructure is stable and reliable.
	- Have strong programming skills in Python, C/C++, or another relevant language
	- Have experience in systems software engineering, with a focus on virtualization, containerization, and sandboxing
	- Have a good understanding of computer systems and networks
	- Have experience with tools such as Docker, Kubernetes, and VirtualBox
	- Have experience in distributed systems
	- Enjoy fast-paced, collaborative, and cutting-edge research environments
	- Take ownership of problems from start to finish, and be proactive to acquire any necessary knowledge to accomplish tasks
	- Have a collaborative mindset and a willingness to work as part of a team towards a common goal
	- Annual Salary Range: $210,000—$325,000 USD
+ skill set:
	- management of E2E (enterprise-to-enterprise) ML pipeline development and automation, to enable developers and creators alike to have the ability to go from an ML idea to production in weeks of less
	- ML ecosystem tooling
	- As a Machine Learning Platform Engineer you will build the next generation of ML Ecosystem Tooling. You will have a direct impact to the state of the Roblox platform, and the industry, to the next level of managed E2E ML Pipeline Development and Automation—providing our developers and creators alike the ability to go from an ML idea to production in weeks or less. We are looking for talented ML and Systems Engineers to help build the next generation of ML Ecosystem Tooling. 
	- Passionate about pushing the technological envelope and venturing into the unknown.
	- Possessing a toolchest of system design experience upon which to draw to build scalable, reliable platforms for all of Roblox.
	- 3+ years of professional experience working with scalable, distributed systems.
	- Well versed with the Model Development Lifecycle from initial ad hoc analysis in notebooks to monitored services in production and back again.
	- Proficient with DevOps tooling such as Docker, K8S, CI/CD systems.
	- Strong understanding of best practices in developing Platform / Infrastructure APIs.
	- Someone who has built a model in a modern ML framework such as Tensoflow, PyTorch, ML Lib, etc.
	- Experienced with developing data pipelines in a common framework such as Beam / Spark / AirFlow / etc.
	- Understand best practices around Data and Model management
	- Have deployed and maintained an ML model in production
	- Understand the use cases for various data processing and storage technologies
	- Bachelor's degree in Computer Science, Computer Engineering, Data Science or a similar technical field.
	- Design and Implement the Developer and Creator facing API for declaring E2E ML Pipelines and Model Experimentation.
	- Develop the service APIs for various ML Infrastructure components--Serving Layer, Metadata Store, Model Registry, Feature Store, and Pipeline Orchestrator.
	- Work directly with the ML Infrastructure team to identify and leverage opportunities for further automation and optimization.
	- Partner across organizations to build tooling, interfaces, and visualizations that make the ML@Roblox a delight to use.
	- Have a direct impact to the state of the Roblox platform, and the industry, to the next level of managed E2E ML Pipeline Development and Automation
	- Provide our developers and creators alike the ability to go from an ML idea to production in weeks or less. 
	- Have a direct impact as a part of the team that is building a platform to handle the thousands of model experiments per day needed to support everything from ranking and recommendations, through content moderation and fraud prevention, to studio creative tooling.
+ skill set:
	- At ApertureData, we are on a mission to solve data infrastructure challenges for machine learning on big-visual-data. We are an angel and NSF grant backed, fast growing startup looking for a Sr. Software Engineer with experience building large scale infrastructure and developing low level systems software. If you enjoy the idiosyncrasies of C++, big data systems excite you, and being among the first five hires fires up your imagination on what all hats you get to wear, we are looking forward to hearing from you!
	- Minimum qualifications
		* ***While you get the freedom to define direction and build castles on-ground for now, it comes with some requirements so we can build fast and stay focused.***
		* 5+ years of experience in Computer Science, or a related technical field
		* 2+ years of experience in C++
		* Understand concurrency well
		* Understand the effects of cache/memory/disk as they interplay with each other and processing
		* Systems level data structure and algorithm effects (kernel and driver level included)
		* Be comfortable with Linux, C++, and Python
		* Valid work status in the US
	- Additional qualifications
		* Good tools make engineering more fun and the more you know about scaling, the faster you can help us scale our product
		* Productivity, development, testing, and cluster management tools/frameworks/languages such as Gtest, git, Jupyter, shell scripting, OpenCV (to know how to handle some computer vision tasks), Kafka, Spark, Tensorflow/PyTorch/Caffe2, Docker, Kubernetes, Zookeeper, and just in general keep up with new technology to know when we should pay attention to something
		* Practical implementation knowledge of CAP theorem, distributed systems programming
		* Experience architecting a system to run as a service independent of the cloud vendor
		* Knowledge of how to interact with distributed file systems
+ skill set:
	- You've worked with: Kafka, Cassandra, Hadoop, Hive, Spark, or similar technologies
	- Knowledge of Machine Learning, Distributed Systems or Big Data.
	- Exposure to CI / CD (with either Docker, Kubernetes, SaltStack or Jenkins)
+ 
	-
+ skill set:
	- Work on cutting-edge MLOps with guidance from MIT PhDs who are prominent in ML research.
	- Develop large-scale web applications for data-centric AI. Our tools enable data scientists/engineers (across all industries) to effectively diagnose/fix issues in their datasets thus improving the quality of their business's core asset.
	- Work on interesting challenges (model deployment/monitoring, managing massive datasets, rapidly scaling cloud deployments, etc.) at a dynamic startup operating in one of the fastest growing subfields of data science & AI.
	- As a Cleanlab software engineer, you will be responsible for Cleanlab Pro, a user-friendly web app built on our ML algorithms. You'll orchestrate cloud infrastructure for data ingestion, model training, and data analysis, and you'll optimize the reliability of our web app, model deployments, and data management systems.
	- We encourage applications from software engineers with DevOps/backend/cloud experience who have some familiarity with machine learning and are interested in furthering their MLOps skills. Your contributions to our SaaS tool will be used by data scientists/engineers across all industries to improve the quality of their data and reliability of ML models produced from this data. Come help us build the next generation of data-centric AI!
	- Orchestrate cloud infrastructure to reliably support a SaaS data and machine learning pipeline.
	- Design, develop, test, deploy, maintain, and improve software, using a modern tech stack.
	- Contribute cloud/container integrations and other deployment/monitoring solutions to Cleanlab's open-source library.
	- Collaborate with other engineers to build and maintain large-scale systems and establish a strong engineering culture across the company.
	- We select candidates based on strengths, not based on weaknesses. Candidates should have at leat 3+ years experience developing web apps using a modern tech stack and shipping code to production.
		* Linux
		* Python
		* Shell
		* Java/C++
		* AWS
		* Docker + Kubernetes
		* Git
		* CI/Testing, e.g. Jenkins
		* Bonus:
			+ AWS DevOps Stack (https://aws.amazon.com/devops/)
			+ AWS Sagemaker
			+ MLSys/MLOps experience
			+ IaC, e.g. Ansible, Terraform
+ skill set:
	- Tenstorrent is seeking a High-Performance Computing (HPC) Systems Engineer to support Accelerated ML Storage platforms. You will focus on delivery of ML storage services with an emphasis of multi-tenant cloud storage requirements. Duties include administrating both high-speed and archiving cloud storage services. You will also be responsible for understanding workload bottlenecks and work with all necessary teams to drive resolution.
	- Build and maintain high-performance storage environments designed for multi-tenant HPC cloud
	- Work closely with other AI/ML Engineers and Data Engineering Subject Matter Experts
	- Work with Central IT, Cybersecurity, and Engineering teams for both on-premises and cloud deployments
	- Ensure user and technical issues are promptly prioritized and resolved
	- Effectively communicating with cloud tenants as required
	- Monitor resource usage and planning for increased capacity
	- Additional responsibilities assigned from time to time
	- Bachelor's Degree in a related discipline or equivalent experience, with 3 years of professional experience
	- Ceph Certified Specialist or equivalent experience
	- Strong sense of urgency, client-oriented and ability to maintain positive partnerships
	- ***Experience with Ceph, Swift, Luster, NFS, S3, and/or high-performance storage***
	- Experience with performance measuring/modelling of high-performance storage
	- ***Experience with OpenStack***
	- ***Automation using tools such as Ansible, Puppet, BASH and Python Scripting***
	- Willing to roll up your sleeves and help out with hardware and software issues
	- ***Experience with Luster, Weka, Vast, and/or Spectrum Scale***
	- ***Familiarity with Container Storage, including Container Storage Interfaces (CSI) and Persistent Volumes***
	- ***Familiarity with Infrastructure Automation***
	- ***Familiarity of Data Center design, including server hardware, rack diagrams, power, and cooling requirements***
	- ***Knowledge of Monitoring and Performance, such as Prometheus, Grafana, Dynatrace, Sysdig***
+ skill set:
	- Research and design scalable Machine Learning infrastructures with real time applications utilizing TB of data.
	- You will be working with talented and passionate teams and drive the evolution of Big Data and Data Science. You'll work with many exciting technologies such as Spark, Airflow, Hadoop, HP-Vertica, Aerospike, Redis, TensorFlow and Kafka.
	- Direct management of architects team. Cross-functional interaction with a wide range of people and teams, work closely with data engineers and data scientists to ensure high level of professionalism and standards, as well as satisfying project requirements and timelines.
	- Design scalable and reliable data pipelines to move huge amounts of data.
	- Design complex marketing platforms enabling effective player acquisition and retention at scale of millions of daily users.
	- Experienced with current SW development practices – SCRUM, test automation, TDD, CI, CD.
+ skill set:
	- Tenstorrent is seeking a High-Performance Computing (HPC) Systems Architect for OpenStack multi-tenant cloud deployments. You will have the chance to architect multiple clusters, ensure all data is managed and secure, and deploy and support changing requirements. The ideal candidate will be proficient in cluster administration, network administration, relevant virtualization, and relationship to storage. You will support an environment with guarantees of no data leakage, rapid recovery process from VM snapshots, and support substantial cluster service scale and growth.
	- ***Architect and evolve our Tenstorrent OpenStack environment***
	- Linux system configuration, and administration
	- Understand cluster requirements with evolving customer needs. Design and implement solution meeting requirements
	- Work across teams to provide feedback and guidance in the evolution of the platform support and maintenance practices
	- Build process and procedures through comprehensive testing resulting in published documentation
	- Define support team for all cloud tenants
	- Effectively communicate with cloud tenants as required
	- Additional responsibilities assigned from time to time
	- Bachelor's Degree in a related discipline or equivalent experience, with 6+ years of professional experience
	- 4+ years of experience of architecture experience in an OpenStack environment
	- 5+ years of experience with Linux configuration, and administration
	- Strong client service orientation and ability to maintain positive partnerships
	- Certified OpenStack Administrator or equivalent experience
	- Detailed knowledge of one of the public clouds
	- Experience with Containers
	- ***Automation using tools such as Ansible, Puppet, BASH and Python Scripting***
	- Provide product training through webinars and workshops
	- Excellent planning and problem-solving skills
	- Organized and track record of managing complex projects
	- Ability to work with internal developers to collect feedback, prioritize tasks, and manage the engineering backlog
	- Willing to roll up your sleeves and help out with hardware and software issues
	- ***Experience with Ceph/Swift***
	- ***Membership and extensive interaction with the OpenStack community and active participation in the core projects***
	- ***Familiarity with Infrastructure Automation***
	- ***Familiarity with Kubernetes***
	- ***Familiarity of Data Center design, including server hardware, rack diagrams, power, and cooling requirements***
	- ***Knowledge of Canonical's OpenStack***
	- ***Knowledge of Monitoring and Performance, such as Prometheus, Grafana***
	- ***Knowledge of Container Security, such as Falco, Sysdig Secure, Aqua, or Anchore***
	- ***Knowledge of Image Registries, such as Quay, Harbor, Docker Registry***
	- ***Knowledge of ML/AI Orchestration, such as Kubeflow, OpenDataHub.io, or Domino***
+ skill set in Cloud AI / Machine Learning:
	- Participate in our cloud AI projects, design the architecture of source code libraries/packages to support the development of various AI applications on cloud services.
	- The role requires hands-on development, problem-solving skills, and knowledge of various horizontal and vertical packages - spanning across various layers in the technical stack.
	- Creating architectural documents and community-facing tutorials. Working with potential partners in the academic/community to define specifications for open-source projects.
	- 8+ years of experience, especially on turning ML technologies into practical, and state-of-the-art systems.
	- Proficiency in Python, and the common tools and frameworks, with practical experience.
	- Knowledge of common machine learning frameworks such as Tensorflow, PyTorch and Caffee.
	- Excellent experiences in writing concise, clear, and detailed documentation for the libraries/package.
	- A portfolio or GitHub repository of applications or code snippets are welcomed.
	- Great attention to detail.
	- Preferred working experience on Data Science/Machine Learning/Deep Learning/Computer Vision-related projects
	- Basic knowledge about supervised and/or unsupervised machine learning models.
	- Experience with container orchestration/infrastructure as code, e.g. Kubernetes.
+ skill set:
	- Infrastructure Engineer
	- At Edge Impulse we are building the future of data-driven engineering.
	- This is a unique opportunity to join us as we usher in the future of embedded machine learning by empowering developers to create and optimize solutions with real-world data. Our teams make the process of building, deploying, and scaling embedded ML applications easier and faster than ever, unlocking massive value across every industry, with millions of developers making billions of devices smarter.
	- Improving the scalability, performance and resilience of our infrastructure
	- Improving the stability of our platform with observability, monitoring, alerts at the center of workflow
	- Manage per-customer on-premise infrastructure for enterprise customers on multiple cloud providers (e.g. AWS & Azure)
	- Ensure our cloud infrastructure meets security compliance standards (e.g. SOC2)
	- Iterate quickly on experimental new features to solve real user problems, and enable other engineers in the team to do so too by offering high-quality CI & CD pipelines & integration tests
	- Work alongside our ML and embedded teams to push the boundaries in embedded ML
	- Technical curiosity and a willingness to help across the team and learn new skills
	- Knowledge of cloud compute and storage, including public cloud vendors (AWS, GCP, or Azure)
	- Experience using infrastructure provisioning tools such as Terraform, CloudFormation or Pulumi
	- Experience with observability tools like AWS CloudWatch, Splunk or Grafana
	- Experience with CI & CD solutions like Github, Gitlab or Jenkins
	- Experience working in Linux environments
	- Good understanding of software engineering principles and distributed systems constraints
	- Ideally, experience with (a subset) of the following technologies & programming languages: Typescript, Node, Python, Tensorflow, Kubernetes and/or Docker
+ skill set:
	- develop distributed traning infrastructure for faster training of ML models
	- efficiently deploy ML models into production
	- create automation pipelines for continuous training, evaluation, and deployment of models
	- improve tracking of models, data, and experiments
	- create the interfaces, infrastructure, and clusters to process data efficiently
	- advance monitoring to identify model drift and active learning opportunities
	- establish scalable, efficient, automated processes for data analyses, model deployment, model validation, and model implementation
	- create and deploy new product features via collaboration with data scientists and software developers
	- ***champion engineering excellence and culture, establish metrics for regular improvement***
	- automate ML pipelines and deploy ML models in production environments
	- design and build systems in a microservices-based architecture
	- experience with ML deployment frameworks
	- experience with containerized applications, databases, and distributed computing
	- experience with deploying ML models as a Web service, and building scalable machine learning systems spanning multiple teams and organizations
+ skill set:
	- Principal Software Engineer - Cloud Service and Machine Learning
	- As the Principal Software Engineer for our Machine Learning team you will be responsible for ensuring that the development of ML systems and services meets all technical and quality standards. You will work with Product Management and other technical teams within Splunk, incorporating new requirements and providing technical information related to this sophisticated ML Platform as needed.
	- work with a team of senior ML engineers, applied researchers and security researchers, and experts within their own specialty. You will set an example for this group, as well as set high standards on quality, communication and ability to deliver with deadlines.
	- contribute to architecture and technical decisions while also mentoring junior members within the team.
	- be working in a multi-office, multi-location development environment and prior experience working with local and remote teams or groups will be a plus.
	- While expertise with ML products and their application within enterprise solutions is highly desirable, it is not required, provided you are willing to quickly come up to speed and you have some prior experience of ML technology and its application.
	- 12+ years software development with focus on large scale distributed systems.
	- Some Machine Learning application development experience, this is NOT a data scientist role, but a services/platform development role.
	- Ability to communicate effectively in conversations with researchers and engineers from academia background.
	- Passionate about building and encouraging good engineering practices and processes such as continuous integration and deployment.
	- Experience developing and putting into production test automation and CI/CD systems.
	- Expertise in developing software with container deployment and orchestration technologies at scale, with strong knowledge of the fundamentals including service discovery, deployments, monitoring, scheduling, load balancing.
	- Strong background in building streaming applications or streaming analytics platforms.
	- Expert in one of the streaming platforms, preferably Flink.
	- Expertise in developing software on a public cloud platform (AWS, GCP, Azure).
	- Expertise in developing software with stream processing technology (Kafka, AWS Kinesis).
+ skill set:
	- You will also work closely with our data scientists to make sure our customers have the necessary tools to perform high quality data integrations by building out the Machine Learning and AI infrastructure for entity resolution, automated data mapping, predictive analytics, and risk analysis.
	- As a Software Engineer Intern you will work with a mentor to improve storage, compute, privacy, security, and compliance features necessary to support the operational workflows that help people get the assistance they need.
+ skill set:
	- We are seeking a strategic technical leader who will be responsible for delivering the core infrastructure for machine learning on Databricks. This includes the ML runtime (a packaged environment containing Spark, Tensorflow, and other frameworks), our own machine learning algorithms, storage and IO optimizations, as well as higher level abstractions such as hyper parameter tuning and feature registries.
	- Grow a team of application developers responsible for the Databricks ML Runtime.
	- Grow Databricks' machine learning capabilities - increase YoY product revenue and adoption at > 100%
	- Manage technical debt, including long term technical architecture decisions and balance product roadmap
+ [***MLflow***, An open source platform for the machine learning lifecycle](https://mlflow.org/)
+ skill set:
	- The Machine Learning Platform team is hiring strong engineers to help us design MLflow, an open source tool for managing the Machine Learning lifecycle. In this role you will help define the APIs creating the standard that organizations use to manage their Machine Learning, from tracking offline experimentation through deployment to production systems. You will also build the services supporting the APIs in the open source and their integration into the Databricks product, a unified analytics platform that helps manage data processing and machine learning workloads in a collaborative, enterprise grade product.
	- Design new and extend existing components of MLflow, such as experiment tracking, project management, and model deployment
	- Implement proprietary integrations of MLflow into the core Databricks product
	- Be responsible for full software development lifecycle - design, development, testing, operating in production
	- Architect solutions to achieve a high level of reliability, scalability and security
	- Communicate effectively with other engineers in the same team, with other teams and with various other stakeholders such as product managers
	- Mentor junior engineers or other engineers on the team to help level up their skillset
	- 7+ years of production experience developing services in: Java, Scala, C++, Go, or Python
	- Has designed and developed APIs used in production systems.
	- Deployed production web services using container and orchestration technologies, such as Docker and Kubernetes to public or private clouds.
	- Developed services leveraging SQL backend stores.
	- Demonstrates customer obsession: has altered designs for frontend or APIs with the user experience in mind
	- Developed and debugged software running on Linux OS
	- Experience with Continuous Integration/Continuous Deployment frameworks.
	- Preferred Experience working on a SaaS platform or with Service Oriented Architectures
	- Preferred Experience with software security and systems that handle sensitive data
+ skill set:
	- Development and optimization of storage systems for deep learning and simulation
	- Our goal is to develop the technology to deliver the training data in storage media (either HDD or SSD), to the memory of GPU or MN-Core, as well as the technology to store the data obtained by simulation into our storage media.
	- Communication Language: English/Japanese
	- System programming in Linux (TCP/IP, Ethernet, system calls, file I/O, FUSE)
	- Kernel programming in Linux (VFS, kernel modules, etc.)
+ skill set:
	- Research and development of large-scale computing infrastructure (infrastructure technology) for machine learning
	- We will work on research and development of large-scale computers (clusters) using GPUs and MN-Core. We plan to adjust the content of the work from themes such as performance improvement of calculation infrastructure, verification of elemental technologies, and better operation technology (visualization and automation).
	- Communication Language: Japanese
	- Ability to work on research projects voluntarily and ambitiously
	- Basic computer science knowledge and hardware skills
+ skill set:
	- distributed machine learning
	- query assistance
		* autocomplete, and popular and related searches
	- user experience, with universal search systems and diversity-aware ranking
	- indexing, visual content representation and content understanding
	- retrieval, query understanding and language understanding
	- ranking
		* topical, contextual, personalized, and business objective feature modelling and ranking systems
	- metrics and experimentation
		* development of sensitive offline and online metrics, and more efficient and predictive experimentation systems
	- information retrieval technologies
		* OpenSearch
		* ElasticSearch
		* Solr
		* Learning to Rank algorithms and toolkits
		* build ML solutions that meet SLA guidelines, beyond ML model training
	- skills in:
		* Learning to Rank algorithms and toolkits
		* machine learning
		* information retrieval
		* search-specific experimentation and metrics
- skills to develop:
	- Deep understanding of at least one popular server side MVC Framework (e.g Django, Rails, AngularJS etc).
	- Knowledge of backend storage systems like MySQL, HBase, Memcached, Redis, Kafka etc.
	- Experience working with open source technologies like Kafka, Hadoop, Hive, Presto, and Spark
	- Take end to end ownership of Machine Learning systems - from data pipelines and training, to realtime prediction engines.
	- General understanding of Machine Learning at the level of a semester-long ML class (college or multiple MOOCs)
+ tech stack:
	- Experience with NoSQL databases. MongoDB is a plus
	- Experience with real-time and streaming data processing
	- Experience with queuing platforms like Kafka
	- Knowledge of BigQuery
	- Familiarity with GCP/AWS cloud services
	- Familiarity with TensorFlow
	- Comfortable with CI/CD Pipelines
	- Experience with Git version control
+ skill set:
	- Software Engineer, Platform
	- The Platform team is responsible for building the core abstractions and infrastructure on which the products can be built and iterated rapidly. The team owns how data flows throughout the scale platform. We're looking for people with a strong background or interest in building distributed systems, data-intensive applications, and machine learning infrastructure. You have a growth mindset and are comfortable learning new technologies.
	- Build engineering foundations for Scale, such as machine learning infrastructure, data platform, APIs framework and task dispatching systems.
	- Collaborate with stakeholders across the organization, such as production engineers, machine learning scientists, customer operations, etc.
	- Own services or systems and define their long-term health goals, while also improving the health of surrounding components.
	- Mentor other engineers and become deeply involved in design and code review.
	- Improve our high engineering standards, tooling, and process.
	- Work directly with our engineering and sales teams to create backend and infrastructure solutions to meet their challenging data and security needs.
	- Work with our Security Team on security compliance, pen tests and mitigations that improve security across Scale.
	- Build systems capable of handling millions of frames of data every day, making it available to both our workforce and our internal teams with high availability.
	- 2-7 years of industry experience as a software engineer post graduation
	- Systems engineering experience with real-time and distributed system architecture.
	- Experience building systems that process large volumes of data.
	- Experience  in using the following systems in production: AWS, Typescript, Node, MongoDB, MLflow, Python (note that we are mostly language-agnostic and are open to using whatever is the best tech for the problem at hand)
	- Experience working with Docker, Kubernetes, and Infrastructure as code (eg terraform); bonus points for running GPU/ML workloads
	- Prior startup experience to help us grow responsibly
	- Experience with core AWS technologies such as VPC, EC2, ALB, ASG, Spot Instances
	- Experience in operating or managing Infrastructure such as Spark, Presto, Hive
	- Mentored and grown members of your team or been a tech lead on large projects
+ skill set:
	- MLOps Engineer - Deep Learning & HPC
	- We are looking for a talented MLOps Engineer with a focus on Deep Learning and High-Performance Computing that will work with a growing multidisciplinary team of talented research scientists and machine learning engineers to improve and scale the efficiency within our computing capacity. 
	- Optimizing Deep Learning Workflows: 
		* Monitor reports and dashboards and detect low utilization jobs, projects, users
		* Partner with researchers to check their workflow when they lack performance
		* Identify bottlenecks and suggest scripting optimisations
		* For high-scale jobs, introduce AWS proprietary profiler and libraries to boost performance
		* Scale-up gating process: check the scripts performance and vet requests to scale up
		* Build a knowledge base / best practices documentation for all researchers
		* Implement and monitor CPU usage levels for our CPU clusters; identify users that need assistance in properly coding to maximize usage of CPU's
		* Train researchers on best practices on how to implement automatization strategies to minimize human oversight on jobs.
	- Develop and Test Strategies for Future Workloads:
		* Benchmark new systems capabilities and identify strategies to properly utilize them (H100, TRN2, TPUv5, Intel Gaudi)
		* Define the minimum needs for storage speeds and find better data loading strategies to support high processing demands of the new accelerators
	- High-Performance Computing:
		* Maintain HPC cluster operations
		* Monitor dead nodes and recover them; document dead nodes and their fixes
		* Monitor shared volumes health, usage, and clean-up needs, pursue users to clean-up
		* Partner with users that do not adequately use POSIX permissions on shared storage
		* Monitor the HPC Help Center and solve user problems
		* Assist users in properly launching their jobs
		* Maintain the future S3 access permissions, debug problems, etc
		* Monitor all CPU clusters for users 
		* Create and maintain processes around authentication, authorization and accounting for clusters usage
		* Develop processes around security aspects of the HPC clusters, including tools to in case of security risks are identified (globally, by user, by team, by location, etc)
		* Convert and deploy SLURM scheduling for all clouds and all resource types; integrate TPUs into our larger enterprise approach when SLURM becomes available. 
		* If needed to use k8s infrastructure for research, then maintain SLURM on top of K8S
		* Solve SLURM support tickets with Sched MD's bug management  tools
		* Maintain AWS resources associated with the HPC clusters (login nodes, S3 buckets, FSx volumes, VPCs, subnets, NAT Gateways, S3 VPC Endpoints, routing tables)
	- At least 8+ years of relevant experience
	- Applied programming experience in Python, C, and/or C++
	- Experience with libraries and tools like PyTorch and CUDA
	- Experience in building, productizing and monitoring orchestration pipelines for AI and Machine Learning pipelines
	- Experience with training frameworks like Megatrong, NVIDIA or similar frameworks
	- Experience in leading more junior engineers
	- Experience with AWS and/or GCP
	- Experience/exposure to CI tools infra tools is a nice to have (Kubernetes)
	- Experience with Linux-based environments and scripting (Shell Scripting, Python, Powershell)
	- Ability to work well as an individual contributor as well as within a multidisciplinary team environment
	- Strong communicator with excellent interpersonal skills and can-do attitude to work and thrive in a fast-paced team environment
+ skill set:
	- Machine Learning Solutions Engineer
	- We are very optimistic about opportunities for Japanese content and the Japan market, and so we are fully committed to serving Japanese creators, companies, and organizations. We will provide free and open models that incorporate Japan-specific datasets to the community as well as custom private models to clients and partners. Our current focus is on generative models related to images/video and text/chat.  
	- We are looking for a versatile Solutions Engineer who can successfully manage and deliver software projects for our clients/partners. This role will work closely with other engineers and BizDev/sales, as well as directly collaborating with clients/partners. You will adapt quickly as we try various approaches to various industries in a fast-changing environment. You will have access to state-of-the-art high-performance computing resources, and you will be able to work with top talent in Japan and globally to truly make an impact in the fast-growing world of generative AI.
	- Develop and maintain positive relationships with clients/partners, identifying their needs and requirements and finding solutions to meet those needs
	- Take ownership of architecting, executing, and delivering software projects to clients/partners, including hands-on coding for model-fine tuning
	- Communicate with key client stakeholders to align expectations on the proposed solution. Write project proposals, manage technical evaluations, define solution architecture, facilitate product demonstrations, etc
	- Collaborate with other technical staff and help plan their work to ensure that projects are delivered in a highly satisfactory way that will lead to more business
	- Provide technical expertise/support/training to clients/partners; demonstrate to partners (such as cloud vendors and system integrators) how to use and fine-tune our models
	- Work closely with the BD/sales team to identify and pursue new business opportunities with existing clients
	- Speak at industry events to evangelize our models/products, build our brand, and network with potential clients/partners/users
	- Make good use of media (blog posts, podcasts, etc.) to make our solutions understood and appreciated by a broad audience
	- Fluent in spoken/written Japanese and business-level English
	- 8+ years of experience in the software industry and 5+ years of experience in a customer-facing (or partner-facing) technical role
	- 5+ years of programming experience, including 2+ years of ML engineering
	- Experience owning and delivering entire projects to a client/partner from beginning to end with several past examples of successful delivery
	- Software project management experience
	- Strong teamwork and relationship management skills
	- Ability to quickly understand new technical topics and explain them to a non-technical audience
	- Excellent oral communication and writing skills - including comfort in front of large audiences
	- Solid interest and experience in working with Generative AI models such as Stable Diffusion or large language models is a big plus
	- Experience architecting cloud solutions (especially on AWS) is a big plus
+ skill set:
	- MLOps Engineer, DL & HPC
	- We are looking for a talented MLOps Engineer with a focus on Deep Learning and High-Performance Computing that will work with a growing multidisciplinary team of talented research scientists and machine learning engineers to improve and scale the efficiency within our computing capacity. 
	- Optimizing Deep Learning Workflows: 
		* Monitor reports and dashboards and detect low utilization jobs, projects, users
		* Partner with researchers to check their workflow when they lack performance
		* Identify bottlenecks and suggest scripting optimisations
		* For high-scale jobs, introduce AWS proprietary profiler and libraries to boost performance
		* Scale-up gating process: check the scripts performance and vet requests to scale up
		* Build a knowledge base / best practices documentation for all researchers
		* Implement and monitor CPU usage levels for our CPU clusters; identify users that need assistance in properly coding to maximize usage of CPU's
		* Train researchers on best practices on how to implement automatization strategies to minimize human oversight on jobs.
	- Develop and Test Strategies for Future Workloads:
		* Benchmark new systems capabilities and identify strategies to properly utilize them (H100, TRN2, TPUv5, Intel Gaudi)
		* Define the minimum needs for storage speeds and find better data loading strategies to support high processing demands of the new accelerators
	- High-Performance Computing:
		* Maintain HPC cluster operations
		* Monitor dead nodes and recover them; document dead nodes and their fixes
		* Monitor shared volumes health, usage, and clean-up needs, pursue users to clean-up
		* Partner with users that do not adequately use POSIX permissions on shared storage
		* Monitor the HPC Help Center and solve user problems
		* Assist users in properly launching their jobs
		* Maintain the future S3 access permissions, debug problems, etc
		* Monitor all CPU clusters for users 
		* Create and maintain processes around authentication, authorization and accounting for clusters usage
		* Develop processes around security aspects of the HPC clusters, including tools to in case of security risks are identified (globally, by user, by team, by location, etc)
		* Convert and deploy SLURM scheduling for all clouds and all resource types; integrate TPUs into our larger enterprise approach when SLURM becomes available. 
		* If needed to use k8s infrastructure for research, then maintain SLURM on top of K8S
		* Solve SLURM support tickets with Sched MD's bug management  tools
		* Maintain AWS resources associated with the HPC clusters (login nodes, S3 buckets, FSx volumes, VPCs, subnets, NAT Gateways, S3 VPC Endpoints, routing tables)
		* At least 8+ years of relevant experience
		* Applied programming experience in Python, C, and/or C++
		* Experience with libraries and tools like PyTorch and CUDA
		* Experience in building, productizing and monitoring orchestration pipelines for AI and Machine Learning pipelines
		* Experience with training frameworks like Megatrong, NVIDIA or similar frameworks
		* Experience in leading more junior engineers
		* Experience with AWS and/or GCP
		* Experience/exposure to CI tools infra tools is a nice to have (Kubernetes)
		* Experience with Linux-based environments and scripting (Shell Scripting, Python, Powershell)
		* Ability to work well as an individual contributor as well as within a multidisciplinary team environment
		* Strong communicator with excellent interpersonal skills and can-do attitude to work and thrive in a fast-paced team environment
+ skill set:
	- Tools and Pipeline Software Engineer - Apple Vision Pro
	- Apple is where individual imaginations gather together, committing to the values that lead to great work. Every new product we build, service we create, or Apple Store experience we deliver is the result of us making each other's ideas stronger. That happens because every one of us shares a belief that we can make something wonderful and share it with the world, changing lives for the better. It's the diversity of our people and their thinking that inspires the innovation that runs through everything we do. When we bring everybody in, we can do the best work of our lives. Here, you'll do more than join something — you'll add something.
	- Apple Vision Pro is a revolutionary spatial computer that seamlessly blends digital content with your physical space. It will allow us to do the things we love in ways never before possible — all while staying connected to the people around us.
	- We are looking for a driven and dedicated Tools and Pipeline Software Engineer to join our fast-paced team. As a member of the Face and Body technologies team, you have the unique and rewarding opportunity to work on upcoming releases of Apple products that delight and inspire millions of people every day. We invite you to contribute to our current spatial computing software platform and craft the future of this technology.
	- 2+ years of production experience in tools and pipeline development with track record of successful projects
	- Strong proficiency in Python, writing clean and well structured code
	- Strong understanding of data structures and algorithms
	- Experience working in distributed processing
	- Passion for delivering high quality software to end-users
	- Self-motivated with proven ability to effectively prioritize and deliver tasks on schedule
	- Excellent communication and experience working with cross-functional teams
	- Apple's Vision Products Group (VPG)Face and Body technologies team is looking for a skilled Tools and Pipeline Software Engineer with a passion to accelerate the development of new algorithms and help the team achieve confidence in their results at scale. In this role, you will perform research and development work to design, implement, benchmark, optimize and distribute large scale dataset processing for ambitious computer graphics and computer vision projects for Apple Vision Pro.
	- Our team delivers algorithms that power Apple Vision Pro's Eyesight, Persona and other visionOS technologies. In this position, you will have the opportunity to be part of our extraordinary team of Computer Vision and Deep Learning researchers and engineers to discover and build solutions to previously-unsolved challenges and push the state of the art in Computer Vision / Machine Learning, 3D Reconstruction and Neural Rendering algorithms that will change the way people experience the world!
	- BS, MS or PhD in computer vision, machine learning, computer science, computer engineering or related fields
+ skill set:
	- AIML - Sr Engineering Program Manager, Text to Speech
	- Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Do you love taking on challenges that create a positive impact? Are you passionate about empowering many ground-breaking intelligent experiences to be made? The Apple AIML org is building groundbreaking technology... and we are looking for people like you!
	- The AIML org Text-To-Speech team is building innovative Text-To-Speech solutions to enable most accurate, natural and connected voice and audio experiences for Apple users. We're looking for a strong Senior Program Manager with a solid track record of building and maintaining sophisticated software technologies, tools and processes that deliver the best experiences that delight customers. The program manager will lead projects in Text-To-Speech program to serve our over 1 billion customers. You will work with world level deep learning and AI engineers applying innovative machine translation and AI technologies to solve challenges on speech generation, both on user experiences and technologies.
	- 8+ years of experience in driving large scale program building machine learning powered products
	- Excellent program management skills including program structuring and managing multiple work streams interdependently
	- Have personally orchestrated the delivery of multiple significant client/server software products requiring large organizations (100+) to complete
	- Solid knowledge of technical system architecture and systems design tradeoffs
	- Capability to work across a large number of teams to enforce process and efficient outcomes in a data-driven environment
	- Strong analytical thinking, analysis, and problem-solving skills
	- Attention to details
	- Strategic mentality focusing on driving what matters
	- Self-motivated and proactive, with demonstrated creative and critical thinking capabilities required to forge a path to success
	- Strong leadership skills, including coaching, team-building, conflict resolution and management
	- Ability to communicate abstract ideas clearly and independently manage complex project objectives
	- Strong verbal and written communication skills including negotiation, presentation and influence
	- Lead annual and quarterly planning for Text-To-Speech core engineering team and dependency feature teams via strong prioritization framework  
	- Create and manage project timelines with clear dependencies, critical path and systematic methodology to communicate status  
	- Break down complex issues into discussion topics, lead the discussion and drive alignment  
	- Keep teams on critical path to accomplish quarterly goals   
	- Proactively identify issues, manage risks and mitigations, and re- plan as events warrant  
	- Provide clear, timely and objective communication, including regular program status updates and one-off reviews as needed to executive team  
	- Effectively drive requirements, dependency management and alignment cross-functionally across Text-To-Speech core engineering team, dependency feature teams and other function teams  
	- Collaborate with other teams within and outside of the organization to promote cross-team technology sharing  
	- Lead competitor analysis to understand competitor landscape and opportunities for Apple Text-To-Speech technologies  
	- Network with internal customers to continuously look out for opportunities for Text-To-Speech services or technologies to improve user experience and (or) Apple values  
	- Lead measurements to help team understand and measure success, including quality, usage scale and other critical metrics   
	- Reflect on how the team operates, propose and implement new ways to work in order to improve the rate at which the team delivers value to customers
	- Bachelors or Master's degree in Computer Science, or related field and equivalent experience
+ skill set:
	- AIML - Machine Learning Engineer, Visual Intelligence
	- Imagine what you could do here. At Apple, great ideas have a way of becoming great products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish.
	- Do you want to make Siri and Apple products smarter for our users? Do you want to be a part of redefining how people use their computing devices to search and access information? Are you excited by early stage initiatives with potential for huge impact?
	- The AIML Information Intelligence teams are building groundbreaking technology for algorithmic search, machine learning, natural language processing, , computer vision and artificial intelligence. The features we build are redefining how hundreds of millions of people use their computers and mobile devices to search and find what they are looking for. Our universal search engine powers search features across a variety of Apple products, including Siri, Spotlight, Safari, Messages and Lookup.
	- Join a new team in Apple AIML that is investigating novel visual capabilities across all Apple products that will transform the way people engage with the world around them! We're looking for strong engineers to work on cutting-edge technology, collaborate with experts across Apple, and deliver new end-to-end experiences that delight customer
	- 3+ years of professional experience in machine learning for computer vision applications
	- Excellent knowledge and good practical skills in major machine learning algorithms
	- Proven track record of developing and productionalizing high-quality computer vision algorithms
	- Strong interpersonal skills able to work independently as well as in a team
	- Excellent software design problem solving and debugging skillsFluency in Python and another language (C/C++, Go, Rust)
	- Experience with relevant deep learning software packages (Keras, Tensorflow, PyTorch…)
	- As a machine learning engineer you are excited to seek and tackle high impact problems using deep learning and large data sets. You will stay up to date with the latest research in detection, segmentation and metric learning and work with a team of highly qualified computer vision and machine learning specialists to develop innovative computer vision/machine learning systems in the area of visual search. You'll be involved in all phases of model development including data analysis, prototyping, testing, deployment.
	- We work closely with teams across Apple worldwide and are looking for expert Applied ML Engineers to join our Agile development teams. You will have great technical skills, a drive for high quality software and the ability to innovate creative solutions. Communicating clearly and having the flexibility to learn new technologies, while continuously developing your skills will be key to your success. You will fit into our teams, be a fantastic collaborator, comfortable with giving and receiving feedback and able to thrive in a dynamic environment.
	- MS, Ph.D. in a related field , or equivalent experience
+ skill set:
	- Develop, deploy, and refine solutions centered around infrastructure and how it hooks into generative AI platform and our GPU ETL/AI pipelines
	- Spearhead data pipelines and solutions focusing on OSINT applications of our platform, incorporating diverse data sources such as using social media data, news media, government records, and enterprise data
	- Act as a pivotal interface with enterprise, tech, and multinational government teams, aiding sales engineering efforts around onboarding and tuning rapidly evolving deployments
	- Collaborate on special projects for premium customers
	- Forge partnerships with senior staff from other technology providers to create innovative integrations around their traditional SIEM platforms  (Splunk, Zeek, Kafka), modern data stacks (BigQuery, Snowflake, Databricks), and new Graphistry ecosystem technologies (Python, Jupyter, Streamlit, Graphistry, Louie.AI, Nvidia RAPIDS, Nvidia Moprheus, Apache Arrow, graph neural networks, Kubernetes, generative AI)
	- Contribute to shaping our engineering culture and approach to company building
	- Ideally, share knowledge through avenues such as public speaking, private training sessions, customer demos, tutorials, and blog posts
	- Enjoy Python and PyData ecosystem: Linux/Docker, notebooks, dataframes
	- Experience with GB and ideally TB or even PB data volumes such as with tools like ELK/OS, Splunk, Spark, SQL
	- Practice IaaS and reliable software engineering
	- Security/fraud/etc investigation platform experience, especially using SIEM, UEBA, SOAR, and code
	- Broader investigative experience such as sigint, osint, and fraud
	- Built custom investigation platforms and content, including data engineering, detection as code, and dashboards
	- Experience in on-premise, cloud, and Kubernetes environments
	- Experience in both startup, government, and enterprise environments
	- Developed or used traditional ML models and neural networks, and especially graph or NLP
	- Used GPU computing, including in bigger-than-memory settings
	- Used graph technologies like graph databases, graph analytics, graph visualization, and graph AI, and especially in at-scale detection and investigative scenarios
+ skill set:
	- develop edge AI tooling ecosystem
	- design deep learning-capable data processing devices
	- experience working with the following:
		* open-source machine learning framework TensorFlow
		* Caffe
		* neural network architectures
		* CUDA
		* OpenCL
		* OpenCV
	- design AI system architectures:
		* deep neural networks
		* machine learning algorithms
		* computer vision
			+ video processing
			+ object detection
			+ object tracking
		* speech recognition
		* text analysis
	- tasks include:
		* implementing, training, and testing AI algorithms with 3-D game engines, and optimizing them for given hardware
		* develop and improve a range of AI-oriented tools and frameworks
		* work with Linux and other open-source operating systems
		* automate workflow for validation vi auatomted testing/verification and continuous integration (CI) scripts
+ skill set:
	- Software Engineer, Backend
	- We bring OpenAI's technology to the world through products like ChatGPT and the OpenAI API.
	- We seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth.
	- As OpenAI scales, we’re looking for experienced, problem-solving engineers to build new products and scale our systems. Our success depends on our ability to quickly iterate on products while also ensuring that they are performant and reliable.
	- You’ll work in a deeply iterative, collaborative, fast-paced environment to bring our technology to millions of users around the world, and ensure it’s delivered with safety and reliability in mind. 
	- Design and build the development and production platforms that power ChatGPT, enabling reliability and security at scale
	- Partner with researchers, engineers, product managers, and designers to bring new features and research capabilities to the world
	- Accelerate engineering productivity by empowering your fellow engineers with excellent tooling and systems
	- Help create a diverse, equitable, and inclusive culture that makes all feel welcome while enabling radical candor and the challenging of group think
	- Like all other teams, we are responsible for the reliability of the systems we build. This includes an on-call rotation to respond to critical incidents as needed
	- Have meaningful experience with building (and rebuilding) production systems to deliver new product capabilities and to handle increasing scale
	- Care deeply about the end user experience and take pride in building products to solve customer needs
	- Have a humble attitude, an eagerness to help your colleagues, and a desire to do whatever it takes to make the team succeed
	- Own problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done
	- Build tools to accelerate your own (and your teammates’) workflows, but only when off-the-shelf solutions won’t do
	- Have been a startup founder or an early-stage engineer
	- Annual Salary Range: $160,000—$385,000 USD
+ skill set:
	- Software Engineer, Model Inference
	- Our team brings OpenAI’s most capable technology to the world through our products. Most recently, we released ChatGPT, GPT-4, the Whisper API, and DALL-E. We empower consumers and developers alike to use and access our start-of-the-art AI models, allowing them to do things that they’ve never been able to before.
	- Across all product lines, we ensure that these powerful tools are used responsibly. This is a key part of OpenAI’s path towards safely deploying broadly beneficial Artificial General Intelligence (AGI). Safety is more important to us than unfettered growth.
	- We're looking for an engineer to join our team at OpenAI to help us scale up our critical inference infrastructure, which efficiently services every customer request to use our state-of-the-art AI models, including GPT-4 and Dall-E. 
	- Work alongside machine learning researchers, engineers, and product managers to bring our latest technologies into production.
	- Introduce new techniques, tools, and architecture that improve the performance, latency, throughput, and efficiency of our deployed models.
	- Build tools to give us visibility into our bottlenecks and sources of instability and then design and implement solutions to address the highest priority issues.
	- Optimize our code and fleet of Azure VMs to utilize every FLOP and every GB of GPU RAM of our hardware.
	- Have an understanding of modern ML architectures and an intuition for how to optimize their performance, particularly for inference.
	- Own problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done.
	- Have at least 3 years of professional software engineering experience.
	- Are an expert in core HPC technologies: InfiniBand, MPI, CUDA.
	- Understand how to overlap compute and communication to maximize utilization of scarce compute, memory, and bandwidth resources.
	- Have experience architecting, observing, and debugging production distributed systems.
	- Have a humble attitude, an eagerness to help your colleagues, and a desire to do whatever it takes to make the team succeed.
	- Have needed to rebuild or substantially refactor production systems several times over due to rapidly increasing scale.
	- Are self-directed and enjoy figuring out the most important problem to work on.
	- Have a good intuition for when off-the-shelf solutions will work, and build tools to accelerate your own workflow quickly if they won’t.
	- Annual Salary Range: $200,000—$370,000 USD
+ skill set:
	- Software Engineer, Infrastructure
	- The Applied Engineering team works across research, engineering, product, and design to bring OpenAI’s technology to consumers and businesses.
	- We seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth.
	- The Applied Infrastructure team designs, builds, and operates the foundational infrastructure that powers ChatGPT and the API.
	- Design and build the development and production platforms that power our products, enabling reliability and security at scale
	- Accelerate engineering productivity by empowering your fellow engineers with excellent tooling and systems
	- Bring new features and research capabilities to the world by partnering with product engineers to lay the necessary technical foundations
	- Guide and advise product engineering teams on best practices for ensuring observable, scalable systems
	- Help create a diverse, equitable, and inclusive culture that makes all feel welcome while enabling radical candor and the challenging of group think
	- Like all other teams, we are responsible for the reliability of the systems we build. This includes an on-call rotation to respond to critical incidents as needed.
	- Have 8+ years of experience in engineering, including 4+ years of experience in infrastructure
	- Care deeply about helping to build a diverse, equitable, inclusive culture
	- Take pride in building and operating scalable, reliable, secure systems
	- Are comfortable with ambiguity and rapid change
	- Have a voracious and intrinsic desire to learn and fill in missing skills—and an equally strong talent for sharing learnings clearly and concisely with others
	- Some of the technologies you’ll be working with include Kubernetes, Python, FastAPI, Cosmos DB, Postgres, and Terraform.
	- Annual Salary Range: $160,000—$385,000 USD
+ skill set:
	- Software Engineer, Infrastructure
	- We believe that increasing compute is a huge lever to AI progress.
	- The Supercomputing team owns the entire process of building OpenAI’s compute and infrastructure, which includes 1) the sourcing of hardware and system design, 2) the deployment of huge clusters using Kubernetes and Azure, 3) building the internal experiment platform for running/training the world’s largest AI models.
	- We work at the very cutting edge of speed and scale, combining the traditions of High-Performance Computing (HPC) in a modern cloud and containerized environment.
	- We build some of the largest Supercomputers in the world. When our Owl cluster launched it in 2019 it would've been among the top 5 of the TOP500 supercomputers in the world. Since then we've only continued to grow. See this blog post to get a sense of what kind of challenges we solve in our day-to-day work: Scaling Kubernetes to 7,500 Nodes
	- You won’t encounter any other organization in the world with as much compute per employee. We are a small team that moves quickly, with access to huge resources, working with a direct impact on the success of OpenAI and, by extension, the field of AI as a whole.
	- In this role, you will work with a small team of software engineers to build primarily the infrastructure and compute platform that all of the researchers at OpenAI use for their work.  You do not need to be an ML/DL expert to deliver world-class infrastructure, but you do need to be able to quickly obtain a deep technical understanding of new domains.  You should enjoy being self-directed and identifying the most important problems to solve as the team matures with standardized tools and processes around stability, observability, and scaling.
	- As a Software Engineer focused on infrastructure with the Supercomputing team, you should:
		* Know your way around bash, Terraform, Python, and/or Chef  
		* Have experience designing large, highly available distributed systems with Kubernetes or Mesos clusters in the range of 500+ nodes. Even better is experience with GPU workloads on those clusters.
		* Have experience working with Azure or other cloud platforms such as AWS or GCP
		* Have expertise debugging problems across the stack, such as networking issues, performance problems, hardware issues or memory leaks
	- Want to help build and maintain some of the world’s largest modern, cloud-based supercomputing systems
	- Would enjoy working with world-class AI Research as your primary workload
	- Have built large clusters but have motivation to scale beyond 
	- Love building large distributed, highly available systems without having to manage complex databases 
	- Enjoy owning things end-to-end and coming up with solutions to yet unsolved problems
	- Enjoy the cycle of designing and building the next generation supercomputing cluster year after year
	- We estimate that someone with 3-5+ years of experience as a software engineer working on a team building and monitoring a large-scale infrastructure deployment will quickly contribute to our challenges.  Any experience with high-performance computing or open-source contributions is a bonus.
	- Annual Salary Range: $200,000—$370,000 USD
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.





















####	ModelOps



MLOps is a subset of ModelOps
+ MLOps is focused on the operationalization of ML models, while ModelOps covers the operationalization of all types of AI models.


ModelOps (model operations), as defined by Gartner, "is focused primarily on the governance and life cycle management of a wide range of operationalized"
+ artificial intelligence (AI) models
+ decision models
	- machine learning models
	- knowledge graphs models
	- rules
	- optimization
	- linguistic models
	- agent-based models
	- decision optimization models
+ optimization models
+ transformational models



ModelOps has overlaps wothin:
+ DataOps
+ DevOps


ModelOps is a programming model for reusable, platform-independent, and composable AI workflows.
+ Mitigate the accumulation of AI and machine learning models that are:
	- undeployed
	- unused
	- unrefreshed
	- manually deployed
+ Support model management of AI and machine learning models
+ address the gap between model deployment and model governance
+ ensure that all models are running in production with strong governance, and aligned with technical and business KPIs while managing the risk
+ programmatic solution for AI-aware staged deployment and reusable components that would enable model versions to match business apps, and which would include AI model concepts such as:
	- model monitoring
	- drift detection
	- active learning
+ cloud-based framework and platform for end-to-end development and lifecycle management of artificial intelligence (AI) applications
+ extend the principles of software lifecycle management to enable the following for AI model pipelines:
	- automation
	- trust
	- reliability
	- traceability
	- quality control
	- reproducibility
+ includes:
	- routine deployment of machine learning models
	- continuous retraining
	- automated updating
	- synchronized development
	- deployment of more complex machine learning models




References:
+ Hummer, Waldemar; Muthusamy, Vinod. ModelOps: Cloud-based Lifecycle Management for Reliable and Trusted AI. IEEE International Conference on Cloud Engineering. Parijat Dube, Kaoutar El Maghraoui. p. 1.


The ModelOps process focuses on:
+ automating the governance, management and monitoring of models in production across the enterprise
+ enabling AI and application developers to easily plug in life cycle capabilities
	- bias-detection
	- robustness and reliability
	- drift detection
	- technical, business and compliance KPIs
	+ regulatory constraints and approval flows for putting AI models into production as business applications



The ModelOps process starts with a standard representation of candidate models for production that includes a metamodel (the model specification) with all of the component and dependent pieces that go into building the model such as:
+ data
+ hardware and software environments
+ classifiers
+ code plug-ins
+ business and compliance/risk KPIs




Skill set for ModelOps:
+ Spring Boot, Spring Data Rest, and Microservice Development experience
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.












####	AIOps

AIOps, a similarly named, but different concept - using AI (ML) in IT and Operations.



Skill set for AIOps:
+ skill set:
	- Experience in contextual multi-armed bandit algorithms and/or reinforcement learning
	- Recommendation Systems, Personalization, Search, or Computational Advertising
	- Deep Learning or Causal Inference
	- Cloud computing platforms and large web-scale distributed systems
+ skill set for Intelligent O&M Research Engineer:
	- Use big data analysis and machine learning algorithms to mine data value from massive amounts of machine data (indicators, logs, call chains, and events), and build HUAWEI CLOUD AIOps intelligent O&M competitiveness.
	- Design, verify, and develop core algorithms, and resolve specific problems of intelligent O&M, such as anomaly detection, pattern recognition, forecasting, intelligent association, and log understanding.
	- Investigate customer pain points, fully understand customer requirements, track new technologies in the AIOps field, identify key technical difficulties, and provide solutions and engineering implementation.
	- Network exception detection
	- System log analysis
	- Capacity/Traffic forecasting
	- Causal inference based on big data
	- Distributed machine learning
+ skill set:
	- We are looking for a seasoned software engineer to build the next generation AI platform scaling to petabyte level data volumes.
	- As a member of C3.AI's platform engineering team, you will be responsible for the entire software engineering lifecyle, i.e design, document, build, test, maintain. As one of the core teams, this role is integral to the success of the company. A successful candidate will thrive in a fast-paced, highly collaborative environment and demonstrate an ability to execute precisely and quickly. The ideal candidate will have in-depth experience with Data Science workflows and built scalable machine learning systems.
		* Build systems and tools that enable data scientists to create machine learning applications using the C3 AI Platform.
		* Enable scalable, end-to-end machine learning pipelines in a distributed system.
		* Work with other platform engineering teams to enable streaming, batch, or ad-hoc data analysis.
		* Collaborate with and support data scientists to understand the utility of the C3.ai Platform and define new requirements.
		* Define and lead the development of longer-term C3 AI Platform capabilities.
		* Mentor junior members of the team.
	- Requirements:
		* Advanced degree in computer science, math, or similar field.
		* Excellent programming and algorithmic skills and a taste for DRY code.
		* In-depth understanding of supervised and unsupervised machine learning algorithms.
		* Proven track record of applying learning algorithms in a production system.
		* Strong programming skills in Java, Python and JavaScript.
		* Demonstrated end-to-end ownership of projects.
		* Stellar listening and explanation skills.
		* Thorough knowledge of data structures, algorithms, profiling/optimization, and Object-Oriented and Functional Programming.
		* A minimum of 3 years of work experience in a fast-paced software company.
+ skill set for Intelligent Computing Development Engineer:
	- Plan and optimize the overall intelligent computing architecture. Based on the in-depth convergence and optimization of AI and big data and the optimization of computing resource scheduling, continuously improve the competitiveness of intelligent computing in business scenarios and develop industry best practices.
	- Lead topic research on intelligent computing products and how HUAWEI CLOUD can use them.
	- Participate in end-to-end delivery of intelligent computing service features, covering phases such as requirement analysis, module design, development, and rollout. Communicate with customers about HUAWEI CLOUD intelligent computing solutions.
	- AI and big data research background, and related project experience preferred
	- Expertise with Linux. Proficient in C++, Java, Python, or Golang. Excellent ability to implement algorithms
	- Strong motivation to learn new technologies, excellent communication skills, and good team spirit
+ skill set for Big Data & AI Cloud Architect:
	- Responsible for the system design, coding, testing, and maintenance of the features of HUAWEI CLOUD AI services.
	- Responsible for the delivery of AI service features, system design documentation, and interfaces, and contribute to writing core code.
	- Ensure the quality of AI service architecture and support resolution of issues found during AI service development.
	- Proficiency in at least of the following programming languages: C, C++, Java, and Python
	- Experience in end-to-end development and maintenance of core system modules
	- Experience in open source AI platforms including TensorFlow, MXNet, and GraphLab (preferred)
		* GraphLab
	- Experience in graph computing, distributed graph computing, or deep neural networks, including DNN, CNN, and RNN. (preferred)
+ skill set for AI4System Algorithm Engineer:
	- Conduct research, problem modeling, mathematical modeling, algorithm design, and basic prototype development to solve system-related complex problems.
	- Using AI, optimize the algorithms of the database kernel optimizer and the configuration tuning parameters.
	- Predict and optimize network performance using AI algorithms and conduct correlation analysis of network events.
	- Use AI to optimize underlying storage data structures and algorithms, such as indexing, compression, hot and cold data identification, and cache prefetch.
	- Expertise in underlying principles of machine learning, deep learning, and reinforcement learning algorithms, and extensive experience with mathematical analysis. Skilled at using basic machine learning, deep learning, or reinforcement learning frameworks. Computer science, mathematics, or related major preferred
	- Familiar with the principles and parameter tuning of internal database optimizers preferred
	- Solid knowledge of computer networking and systems preferred
	- Broad knowledge of underlying storage technologies and principles preferred



















##	Logical AI + Other AI




















##	Differential Machine Learning











##	Differential Privacy





+ Hestia - Differential Privacy - Data Anonymization Challenge, https://www.topcoder.com/challenges/30082341
	- https://github.com/uber/sql-differential-privacy
	- https://github.com/arx-deidentifier/arx










##	Information Retrieval



Sets of skills for ***information retrieval***, including search engine development:
+ Experience with search and information retrieval systems, either custom or commercial (Elasticsearch, Solr).
+ Experience using different types of datastores such as Postgres, Mongo, Redis, and Elasticsearch
+ You have used GraphQL in production environments
+ skill set:
	- Understand product objectives; Take full advantage of modern machine learning and information retrieval techniques to improve search experience;
	- Provide technical leadership to drive search strategy iteration including query understanding, recall & ranking, query recommendation, reliability, etc;
+ Background in music information retrieval (MIR).
+ Familiarity with search domain (Information retrieval, NLP, Solr/ Lucene or related tech)
	- information retrieval
	- Solr/Lucene
		* Apache Solr: open-source enterprise search platform.
		* Apache Lucene: open-source search engine software library
+ Elasticsearch / Kibana: You can readily access information & love metrics
	- Elasticsearch is a distributed, RESTful search and analytics engine capable of addressing a growing number of use cases. 
	- Elasticsearch is a search engine based on the Lucene library. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents.
	- Kibana provides visualization capabilities on top of the content indexed on an Elasticsearch cluster. Users can create bar, line and scatter plots, or pie charts and maps on top of large volumes of data.
	- Kibana is a source-available data visualization dashboard software for Elasticsearch.
+ Knowledge of NoSQL technologies (e.g. Cassandra, MongoDB, Redis, etc.) and/or search-based data stores and libraries (Lucene, Solr, etc.)
+ Knowledge of NoSQL technologies (e.g. Cassandra, MongoDB, Redis, etc.) and/or search-based data stores and libraries (Lucene, Solr, etc.
+ Demonstrated knowledge of Redis/MySQL/Elasticsearch/Druid/Spark Streaming.
+ skill set:
	- Elastic Search, Lucene, SQL Server, Kibana, or similar experience
	- Prior experience aligning platform architecture with security, data
	- Demonstrated ability to document architectural standards and decisions
	- SaaS or high scale cloud experience
+ skill set:
	- Database hands-on experience (Elasticsearch and Mongo preferred)
	- Administration of systems including Jenkins, Elasticsearch, Kibana, Mongo, Grafana, etc.
+ skill set:
	- Mongodb
	- Elasticsearch
+ Experience with relational (MySQL), NoSQL databases (Couchbase/Aerospike), search engines (ElasticSearch), caching solutions;
+ skill set:
	- Experience with JVM tuning is a plus
	- Experience with Apache Solr is a plus
		* enterprise search platform
+ skill set:
	- intermediate proficiency in Java and Python,
	- proficiency in Spark framework,
	- basic understanding of REST,
	- practical knowledge of Docker Kubernetes,
	- good english communication skills,
	- ability to share your knowledge,
	- willingness to learn continuously,
	- basic machine learning knowledge (regression, classification, clustering, validation methods, time series forecasting).
	- knowledge of Kafka platform,
	- knowledge of Hadoop framework,
	- basic programming skills in Scala/R,
	- familiarity with ELK stack (Elasticsearch, Logstash, Kibana),
	- knowledge of NoSQL databases (e.g. Cassandra, ELK),
	- Storm, Nginx technologies.
































##	Data Science + Data Engineering + DataOps


###	Notes about Data Science + Data Engineering + DataOps

This section provides information about data science roles and skills set regarding:
+ [Generic data science positions]()
+ [Business analytics]()
+ [Sports Analytics]()
+ [Data Science for public health]()
+ [Data Science for Advocacy, Lobbying, Think Tanks]()
+ []()
+ []()
+ []()
+ []()
+ []()




For skill sets in data science roles regarding finance, see the *Markdown* document [](financial-engr-n-finance-x.md).





For skill sets in data science roles regarding the following fields, see the *Markdown* document [](bio-biochem-biotech-pharma.md).
+ bioinformatics
+ bio design automation, BDA
+ bio manufacturing automation
+ biology
+ biochemistry
+ biotechnology
+ medicinal chemistry
+ pharmacy
+ pharmaceutical science






Notes:
+ In database normalization, unnormalized form (UNF), also known as an unnormalized relation or non first normal form (N1NF or NF^2),[1] is a database data model (organization of data in a database) which does not meet any of the conditions of database normalization defined by the relational model. Database systems which support unnormalized data are sometimes called non-relational or NoSQL databases. In the relational model, unnormalized relations can be considered the starting point for a process of normalization. It should not be confused with denormalization, where normalization is deliberately compromised for selected tables in a relational database.







###	Generic Data Science Roles



Sets of skills for generic data science roles, or data scientist positions (i.e., junior to mid-level data scientists):
+ Notebook products:
	- Binder/JupyterHub
	- Databricks Collaborative Notebooks
	- Google Cloud Datalab Notebooks
	- Amazon Sagemaker Studio
	- Code Ocean
	- Google Cloud AI Platform Notebooks
	- IBM Watson Studio
	- Amazon EMR Notebooks
	- Kaggle Notebooks
	- Azure Notebooks
	- Paperspace/Gradient
	- Colab Notebooks
+ computing platforms for data science projects:
	- deep learning workstation: NVIDIA GTX, or LambdaLabs
	- cloud computing platform: AWS, Azure, GCP, hosted notebooks, ...
+ media sources to learn data science:
	- Slack communities: ods.ai, kagglenoobs
	- YouTube: Kaggle YouTube, Cloud AI Adventures
	- journal publications: peer-reviewed journals and conference proceedings
	- email newsletters: Data Elixir, O'Reilly Data & AI
	- Course forums: forums.fast.ai, Coursera forums
	- Kaggle: notebooks, forums
	- Blogs: Towards Data Sciecne, Analytics Vidhya
	- Twitter: data science influencers
	- podcasts: Chai Time Data Science, O'Reilly Data Show
+ topics in mathematics and statistics to learn:
	- Linear Algebra
	- Probability (e.g. Bayes' Theorem, Distributions, Conditional Expectations)
	- Multivariate Calculus (e.g. Integration, Multivariate Differentiation)
	- Unsupervised Learning (e.g. KMeans, mixture models)
	- Regression (e.g. Linear Regression, ANOVA)
	- Classification (e.g. Naive Bayes, Logistic Regression, SVM, Random Forests)
	- Numerical Analysis
	- NLP (e.g. Bag of Words, TF/IDF, Topic Modeling)
	- Time Series (e.g. AR, ARMA, ARCH, EMA)
	- Matrix Factorization (e.g. PCA, NMF)
	- Statistics (e.g., hypothesis testing, t-tests, p-values)
	- Experimental Design
+ tool or platform for data analysis:
	- basic statistical software, spreadsheets: Microsoft Excel, Google Sheets
	- advanced statistical software: SPSS, SAS
	- business intelligence software: Salesforce, Tableau, Spotfire
	- local development environments: RStudio, JupyterLab
	- cloud-based data software & APIs: AWS, GCP, Azure
+ platforms for data science courses:
	- Udemy
	- DataCamp
	- Kaggle Learn Courses
	- Udacity
	- Cloud-certification programs: AWS, Azure, GCP
	- university courses, resulting in a university degree
	- Coursera
	- edX
	- Fast.ai
	- LinkedIn
+ skill set:
	- ***You have setup end to end data pipeline***
	- ***You have worked on real world data sets that range into millions of data points that contain missing values, and unclean data***
	- ***You have owned and delivered data science projects that are live on production***
	- ***You have practical knowledge of a wide variety of data science methodologies and an intuitive understanding of which methodology is applicable to which problem***
+ Intermediate to advanced proficiency with R (tidyverse, ggplot2)
+ ***Experience with metrics systems such as Grafana.***
+ ***Experience working with analytics tools such as Google Analytics, Heap Analytics, Chartmogul, Baremetrics, Periscope, Tableau, Mode Analytics, Looker, or similar***
+ Experience with open source platforms like Hadoop, Spark, ***Hive, Pig***; and/or ***ML life-cycle/collaboration/automation platforms like AirFlow, FB Learner, MLFlow***; and/or assistants like Alexa, a plus.
+ ***Experience with a variety of data sources.*** Our data includes Salesforce, Zuora, Zendesk, Marketo, NetSuite, Snowplow and many others (see the [data team page](https://about.gitlab.com/handbook/business-ops/data-team/#-extract-and-load))
+ Data engineering experience and ***data pipeline tooling (e.g. Airflow, DBT)*** experience is a plus
+ NoSQL databases, such as MongoDB, Cassandra, HBase
+ Experience with ***scheduling engines*** such as ***Airflow***
+ Proficiency in using query languages such as SQL on a big data platform e.g. Hadoop, Hive
+ data visualisation tools, such as D3.js, GGplot, Tableau etc.
+ RStudio packages: The tidyverse, R Markdown, and Shiny
+ You have data analytics skills with Hive, Scalding, or Spark.
+ Experience within the domain of Advanced Analytics and Data Science is highly desirable, e.g. hands-on experience with solutions such as Spark, MapReduce, Python, Redshift, Hive, Pig and visualization tools.
+ Experience with relational (e.g. postgres, SQL) and/or distributed (e.g. MongoDB) databases
+ Experience with SQL and Statistical/mathematical programming software packages (R, SPSS, CPLEX, LONDO or Xpress etc)
+ Second, help build a Data Science team to support the delivery of the Predictive Analytics core AI offerings for US-based pharmaceutical companies. These offerings include developing algorithms to find undiagnosed patients (often patients with rare diseases) or algorithms to predict patients likely to experience rapid disease progression and / or switch therapies. These core offerings involve very large datasets (typically many millions of patients) extracted from claims and prescription data and use Python and PySpark tools and libraries as part of IQVIA's Hadoop cloud environment.
+ Experience building data science models (Regression, Decision Trees, K-Means, etc.)
+ skill set:
	- Efficient in SQL, Hive, SparkSQL, etc.
	- Serve as technical “go to” person for our core technologies – Hadoop, Spark, AWS, Vertica, Tableau, Cassandra, Graph Databases and others
	- Advanced SQL skills to perform data segmentation and aggregation from scratch; experience working with granular web clickstream data a plus!
	- Knowledge of programming languages and stats packages (e.g. python, R); comfortable running multiple regression analyses
+ Python libraries:
	- dask
	- pandas
	- scikit-learn
+ skill set:
	- Exceptional SQL skills and experience working with granular web clickstream data and behavior tracking tools like SiteCatalyst
	- Fluency in data analysis, including defining KPIs, statistical and predictive modeling concepts, descriptive statistics, experimental design and multivariate A/B testing
+ skill set and tasks of role:
	- Deeply understand the behaviors of Substack readers and writers
	- Explore, measure, and track metrics related to the growth of the Substack ecosystem
	- Derive denormalized tables to enable simplified analytics
	- Partner with product teams on developing key metrics and testing intuitions with data to inform better decision making
	- Develop data insights that can empower Substack writers to better understand their newsletters
	- Love analyzing problems with data and synthesizing results to tell the narrative of the product
	- Have expertise in SQL (we use ***Postgres + Snowflake***) and ***event-based analytics and metrics (à la Segment)***
	- Understand growth funnels and how to measure them
	- Enjoy ***building dashboards (Sisense/Periscope Data)*** to memorialize findings and monitor key metrics
	- Believe that building canonical datasets can empower an organization
	- Have a proven track record of making meaningful impacts through data insights and discovery in past roles.
	- Nice to haves: ***Airflow/Luigi/other DAG tool experience***, Python, Node
+ skill set:
	- A fluidity with tools commonly used for data analysis such as Python (numpy, pandas, and scikit learn), R, and Spark (MLlib).
	- Experience with MPP databases, such as Snowflake, Redshift, BigQuery, Vertica, etc.
	- Familiarity with data visualization tools/frameworks as well as notebooks.
	- Experience with time-series forecasting.
	- Experience building and deploying production-grade models in a real-time setting.
	- Expert-level abilities building and deploying unsupervised, semi-supervised, and supervised models on large-scale data (in that order of importance).
	- A degree of comfort at the command line. That means a thorough understanding of basic file-system commands, as well as the ability to ssh into remote machines and troubleshoot without a GUI, grep through logs, and deploy scripts and applications.
+ skill set:
	- Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business products.
	- Partner with Product and Engineering teams to solve problems and identify trends and opportunities.
	- Work on large scale data pipelines by leveraging different SQL/non-SQL technologies to build automated data analysis and dashboard.
	- 2+ years' experience doing quantitative analysis within a high-tech company. Startup is a plus
	- BA/BS in Computer Science, Math, Physics, Engineering, Statistics or other technical fields
	- Experience in SQL or similar programming languages
	- Experience with one general purpose programming language (e.g., Java, C/C++, Python)
	- Experience in data processing using traditional and distributed systems (e.g., Hadoop, Spark, Dataflow, Hive, Impala, Airflow)
	- Knowledge of statistics and machine learning
* ***Plotly.js***
	- plotly.js, a JavaScript library for creating interactive charts
	- Data visualization libraries
		* Plotly.js is an open-source JavaScript library for creating graphs and powers Plotly.py for Python, as well as Plotly.R for R, MATLAB, Node.js, Julia, and Arduino and a REST API.
		* Plotly can also be used to style interactive graphs with Jupyter notebook.
	- compare with:
		* ***Dash*** is an open-source Python, R, and Julia framework for building web-based analytic applications.
+ Experience with product/web analytics tools (Pendo, Heap, Hotjar, Google Analytics).
+ Experience in using relational databases like MySQL, Redshift, ***Graph DB***.
+ To learn about the latest trends in hiring, technology, software development practices, data science workflows, machine learning workflows, and research
+ Specialist quantitative skills and/or qualifications in quantitative methods for social science, including data visualisation, database management (SQL), Python, Tableau visualisation or other data analysis tool sets.
+ skill set:
	- You are an expert user of tools like Sketch, Figma, etc.
	- You have demonstrable experience building new products (please show us examples!). You can iterate quickly by putting an MVP in people's hands, and test ideas and hypotheses before any code is written.
+ Experience with Python ORMs like SQLAlchemy and Python libraries like Pandas, Scikit-Learn, Numpy and Scipy
	- ORMs: Object Relational Mapping (ORM)
		* Object–relational mapping (ORM, O/RM, and O/R mapping tool)
+ skill set:
	- Expert knowledge of either Python or R, strong experience with database management systems like SQL, preferably also Spark ML, Scala, Hive and Impala
	- Confidence and comfort working on projects and goals that are happening in a hypothesis driven environment (build – measure – learn mindset)
	- An excellent understanding of SQL.
	- Experience with big data technologies (Hive, Impala, Spark, etc.) would be a plus.
+ personalized data pipelines/models using tools like:
	- Hive
	- Airflow
	- Kafka
	- Spark
+ data science skill set:
	- Advanced knowledge of ElasticSearch/Solr/Lucene.
	- Advanced knowledge of backend paradigms
	- Knowledge with vector space models, text classification and categorization
	- Implement high quality code in an agile software development environment.
	- Able to respond and present work to peers, answer in-depth questions, accept constructive feedback, and modify product accordingly.
+ data science modeling frameworks
	- statsmodels
	- scikit-learn
	- XGBoost
+ Experience with common data science tools, such as ***Pandas, NumPy, Scikit-Learn, Tensorflow, Dash/Streamlit/Gradio*** etc.
+ Data Scientist:
	- Amida Technology Solutions is a DC-based technology company focused on solutions for data interoperability, data utility, and data security. We create open-source solutions that collect, reconcile, transform, and standardize data for business intelligence, predictive analytics, decision support, and user transactions. We specialize in taking data from inception to impact.
	- Our team is comprised of creative, forward thinkers who are passionate about using cutting-edge technology to make a difference in people's lives and have a positive impact on our country. We offer an entrepreneurial, high-growth environment that values fresh ideas, candid conversations, and authentic teamwork.
	- Amida is currently looking for a Data Scientist to join our team in Washington, DC. In this role you will work across our client engagements, providing expertise in machine learning algorithms, natural language processing (NLP), data collection, data analysis, data mapping, data profiling, data mining, data modeling, and data visualization. You will architect data science solutions on the cloud using AWS or Azure data science services and participate in the implementation of the solutions. You will help with the business development activities and will be responsible to describe data science solutions in our proposals.
	- Perform data analyses in the Azure Cloud
	- Lend your expertise in the development of solutions using machine learning, NLP, data profiling, and/or data mining to projects and proposals across the company
	- Use expertise in machine learning to design and implement predictive models for diverse fields such as health claim processing and electronic design automation
	- Use expertise in NLP methods and healthcare data to identify relevant open-source NLP models and adapt them to free text data
	- Leverage modern ML/NLP methodologies (e.g., deep learning), computing hardware (e.g., GPUs), cloud infrastructure (AWS/Azure), open-source modeling frameworks (e.g., TensorFlow, Keras, PyTorch, XGBoost)
	- Develop standardized evaluation and validation frameworks for current and future work
	- Create training materials for colleagues at different levels of experience
	- Identify, create, and curate training datasets
	- Bachelor's Degree in a quantitative field such as Computer Science, Statistics, or Mathematics (or related)
	- 4+ years of recent professional experience in data science, data mining, data analysis, business process analysis, and/or healthcare analytics
	- 3+ years working with Machine Learning and/or Natural Language Processing (in particular, Named Entity Recognition) methodologies
	- 3+ years of programming experience in Python
	- 2+ years of experience using Machine Learning tools, deploying models, and deploying software in Azure or Amazon Web Services (AWS) preferably holding certifications
	- Experience to model data in Graphs
	- Experience using Graph databases
	- Experience contributing to proposals preferably in federal government contracting
	- Ability to conduct data profiling and predictive analysis using a variety of standard tools
	- Experience with data visualization tools and methodologies
	- Excellent ability to communicate concisely and effectively with software engineers and clients
	- Ability to obtain a Public Trust security clearance
	- ADF
	- Azure ML
	- Azure SQL
	- Databricks/Data Lake
	- Python (for data wrangling, joins, cleansing, visualization, and statistical learning)
	- Git
	- Apache Spark (cluster computing/management)
	- Deep Learning
	- Neural Networks
	- Master's Degree in a quantitative field such as Computer Science, Statistics, or Mathematics (or related)
	- Previous experience in Knowledge Graphs and Graph Neural Networks
	- Previous experience working with Databricks
	- Prior experience working with healthcare data, or in the Healthcare field
	- Previous experience working with government clients such as Dept. of Defense (DoD), Dept. of Veterans Affairs (VA), or The Centers for Medicare & Medicaid Services (CMS)
	- Prior experience with metadata management to include meta-tagging
	- Previous experience working in an Agile Team setting and using Agile management tools such as Jira
	- Experience conducting business process analysis to identify gaps and inefficiencies
	- Ability to uncover data-driven insights using statistical analysis or predictive analytics
	- Communication is the key to success at Amida. Our people are known for their can-do attitude and their ability to work effectively with client teams. We pride ourselves on having a collegial, multidisciplinary team with diverse backgrounds and experience. Our best team members pay intense attention to detail in all aspects of their work, have a strong sense of initiative, and are willing to be opinionated about the best ways of doing things. A sense of humor is an asset at Amida.
	- We help solve the biggest challenges in data management. If you're looking for an opportunity to help important organizations get their data right, we hope you'll forward your resume and let us know why this role appeals to you. We look forward to hearing from you.
+ skill set:
	- 2021.AI CVR
	- 2021.AI seeks a motivated Data Scientist to join our highly-skilled team of Data Scientists, working at the forefront of solving business challenges with AI and ML. In this role, you will participate in and lead data science projects and deliveries. In addition, you will assist in the future development of different AI / ML and technology services on our GRACE platform.
	- You have high ambitions and want to positively impact the world with the AI / ML technology you develop and deliver to clients globally. This shines through in your ability to use AI / ML solutions to deliver impactful and valuable business solutions across different industries in the private and public sectors.
	- You are independent, driven, motivated, and solutions-oriented.
	- You work well with others. This entails teamwork with your internal team and with clients on- and off-site.
	- Your expertise is with data science, AI/ML, and related technologies, and you are passionate about delivering AI/ML solutions all the way from initial ML model research to implementing the working model in production.
	- You have experience in independently developing AI/ML or statistical models that solve particular business challenges, including the process of preparing the models for deployment and production.
	- You are interested in working with one of the best data science teams on the planet, technology rock stars, and business magnates, all dedicated to responsibly and positively impacting the future with AI and other emerging technologies.
	- As a Data Scientist at 2021.AI, you will make your mark and directly influence the direction of data science in 2021.AI while delivering value with AI and ML to our partners and clients.
	- You will participate as a Data Scientist in client projects and work closely with other teams in 2021.AI to improve our core product features, and demonstrate product value to clients on the GRACE Platform.
	- Take part in projects developing AI and ML models for clients and partners
	- Embed those actions and insights into integrations and solutions for our clients’ businesses
	- Develop high-quality models with the business value behind in mind
	- Bring business objectives to the center of the ML development process
	- M.Sc. or equivalent in Engineering, Statistics, Mathematics, Computer Science, or a related field
	- 2-3 years of hands-on, practical experience from a similar position
	- Solid experience in scripting/programming languages (Python, R, and their related packages such as Scikit-learn, Shap, Pandas) combined with a mathematical/theoretical foundation
	- Data manipulation skills, including database handling and data cleaning/management
	- Experience with data visualization tools and packages (Plotly, Dash, Python Seaborn)
	- Understanding of how to implement and deploy AI and ML into production via e.g. Flask or Docker
	- Full working knowledge of English
	- Excellent presentation skills both toward business leaders and technical experts
	- Exceptional human and superb collaboration skills
	- The ability to identify potential use cases to create business value for our customers
	- Experience with computer vision
	- Founded in Copenhagen with several offices worldwide, 2021.AI is a fast-growing AI company focused on closing the gap between AI ambitions and real AI value for companies worldwide. Large private and public organizations globally trust us to help them stay competitive, compliant, and in control when applying AI.
	- We are a team of passionate people who care deeply about the mission we are on; to positively impact the future with AI. Our tight-knit culture of camaraderie instills more than just a sense of belonging but great pride in our work. With high cultural ambitions, we expect you to bring lots of energy to the workplace and participate in company-related and social activities. In return, we promise great professional experiences and the freedom to tackle and own your tasks.
+ Data Scientist, Product
	- Earlier in 2022, we introduced DALL-E 2, AI that creates images from text. In 2021 we launched Copilot, powered by Codex, in partnership with GitHub – and developers love it. In 2020 we introduced GPT-3 which the MIT Technology Review listed as one of its 10 Breakthrough Technologies of the year (alongside mRNA vaccines).Our product team is bringing OpenAI technologies to consumers and businesses around the world. We recently launched ChatGPT and ChatGPT Enterprise.
	- As an early member of our Data Scientist team on the Applied Product team, you will establish the data-driven product development culture for either consumer products or developer platform at OpenAI. You should expect to define our north-star metrics, design our first A/B tests, and establish source-of-truth dashboards that the entire company can use to answer their own product questions. Most importantly, you should expect to be a core member of the product development team building our first party offerings.This role is based in our San Francisco HQ. We offer relocation assistance to new employees.
	- Embed with the product development team as a trusted partner, uncovering new ways to improve the product and drive growth
	- Define and interpret A/B tests that help answer critical questions about the impact of model and UX changes to our product
	- Establish a data-driven product development culture by driving the definition, tracking, and operationalizing of feature-, product-, and company-level metrics
	- Develop and socialize dashboards, reports, and other ways of enabling the team and company to answer product data questions in a self-serve way
	- 5+ years experience in a quantitative role navigating highly ambiguous environments, ideally as a founding data scientist or product analyst at a hyper-growth product company or research org
	- Proposed, designed, and run rigorous experiments with clear insights and product recommendations utilizing SQL and Python
	- Defined, implemented, and operationalized new feature and product-level metrics from scratch
	- Excellent communication skills with demonstrated ability to communicate with product managers, engineers, and executives alike
	- Strategic insights beyond the paradigm of statistical significance testing
	- Demonstrated prior experience in NLP, large language models, or generative AI
	- Strong programming background, with ability to run simulations and prototype variants
	- Experience validating quantitative insights with qualitative methods (e.g. surveys, UXR)
+ Research Engineer - Data Specialization
	- San Francisco, California, United States — Reinforcement Learning
	- Our team is responsible for the “post-training” or alignment of chatGPT. We integrate various improvements from the rest of the company into our RLHF process ultimately producing the models used by millions of users both in the chatGPT product and API.
	- One of the most important parts of training chatGPT is building and training on extremely high quality datasets. We are looking for somebody to help us build infrastructure to manage this data! In contrast to most data engineering, dataset size is not the key factor here – instead we aim to bring more insight and continually increase the quality of our training data.
	- Ideal candidates should have a strong technical background and general knowledge. Given how coupled our data systems are with the underlying models, candidates should have some familiarity with ML / ML Engineering either in a research context, or in an applied ML setting.
	- This role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.
	- Build systems and tools for researchers to look at and transform datasets.
	- Co-design and build experimental primitives used to construct data pipelines to train prototype chatGPT models.
	- Work with the chatGPT product team building distributed pipelines to look at and understand large scale usage data.
	- Help with other, more out there research ideas involving data pipelines.
	- Help own the entire training distribution we train ChatGPT on.
	- Are a team player – willing to do a variety of tasks that move the team forward.
	- Experience working in complex technical environments
	- Enjoy working in a more research setting – these data systems are new and the right solution is often not clear ahead of time.
	- Experience with the python
	- Experience with kubernetes / distributed infrastructure
	- ***Experience with 1 or more large scale data system such as beam or spark.***
	- The annual salary range for this role is $210,000 – $325,000.
+ Research Engineer - Fine-Tuning API
	- San Francisco, California, United States — Applied AI Engineering
	- Our team brings OpenAI’s most capable technology to the world through our products. Most recently, we released ChatGPT, GPT-4, the Whisper API, and DALL-E. We empower consumers and developers alike to use and access our start-of-the-art AI models, allowing them to do things that they’ve never been able to before.
	- Across all product lines, we ensure that these powerful tools are used responsibly. This is a key part of OpenAI’s path towards safely deploying broadly beneficial Artificial General Intelligence (AGI). Safety is more important to us than unfettered growth.
	- We are looking for an experienced research engineer to help push the boundaries of our Fine-Tuning API to the next level. You will be responsible for researching and implementing the methods used by developers to customize their models on our API. You will work closely with our research team to explore new and unproven fine tuning methods. You will also collaborate with our engineering team to take those methods and put them into production. Your work will help power the customization of GPT models for developers around the world.
	- Research and explore the boundaries of foundation model fine-tuning methods for end-customer use cases.
	- Deploy your research into production for customers to use.
	- Interact with developers to understand their needs.
	- Collaborate closely with a broad set of stakeholders, including product, research, go-to-market, and engineering.
	- Have prior experience fine-tuning LLMs
	- Have experience working with large distributed systems for both model training and inference.
	- Have built production machine learning systems at internet scale.
	- Own problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done
	- Have the ability to move fast in an environment where things are sometimes loosely defined and may have competing priorities or deadlines
	- Annual Salary Range: $245,000—$450,000 USD
+ Research Engineer, Post Training Infra
	- San Francisco, California, United States — Reinforcement Learning
	- Our team is responsible for the “post-training” or alignment of chatGPT. We integrate various improvements from the rest of the company into our RLHF process ultimately producing the models used by millions of users both in the chatGPT product and API.
	- We are looking for an engineer to help improve the efficiency and reliability of our AI model training systems. You will have the opportunity to work across the technology stack, from optimizing low-level components like GPU kernels and network traffic, to developing intuitive front end interfaces.
	- The ideal candidate will have a strong technical background across areas like data technologies, distributed systems, and writing reliable software. Research experience is not required but experience in some kind of ML environment is (i.e. applied ML roles). This role involves analyzing and troubleshooting complex system issues, implementing solutions, and finding ways to prevent future failures.
	- This role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.
	- Be responsible for unblocking and keeping our systems which power the models behind chatGPT running smoothly.
	- Be willing to dive into large ML codebases to debug.
	- Be responsible for keeping very large ML training jobs going smoothly.
	- Fixing a variety of non-ml software things involving data quality, data prep, job startup speed, CI performance for our team’s tests, and so on.
	- Debug and fix issues on the intersection of ML and systems.
	- Sample projects include:
		* Figuring out why a new cluster suddenly has 10% of experiments fail.
		* Diagnosing and fixing regressions in our data pipelines.
		* Fixing 30% slowdown in our RLHF training code.
	- Are a team player – willing to do a variety of tasks that move the team forward.
	- Experience working in complex technical environments
	- Experience debugging ML systems.
	- Experience with reinforcement learning and or transformers
	- Experience with the python
	- Experience with kubernetes / distributed infrastructure
	- Experience with GPU’s
	- Experience with 1 or more large scale data system such as beam or spark.
	- The annual salary range for this role is $210,000 – $325,000. 
	- Annual Salary Range: $310,000—$385,000 USD (additional salary range with contradictory information)
+ graph data scientist
	- We are looking for a data scientist to join us & our users on trying new graph solutions. Your primary goal is to help our users prototype visual graph data science solutions, and secondarily, create related useful integrations and educational materials for fellow data scientists and developers. You will begin as part of a team of some of the industry’s most-known graph data scientists and developers and helping Fortune 500 organizations across multiple departments adopting graph technologies. Over time, you will work directly with top data teams from top data organizations across the world, and our partners who are many of the top data technology creators. The role’s primary technologies include Graphistry, Cypher+SPARQL, Python, Jupyter, StreamLit, pandas / RAPIDS.ai, Docker, and Linux/AWS/Azure. Of additional interest are graph neural networks, huggingface, mlflow, networkx/graphx, Tableau/PowerBI, and SQL.
+ graph data scientist:
	- The role’s primary technologies include Graphistry, Cypher+SPARQL, Python, Jupyter, StreamLit, pandas / RAPIDS.ai, Docker, React, and Linux/AWS/Azure. Of additional interest are graph neural networks, huggingface, mlflow, networkx/graphx, Tableau/PowerBI, and SQL.
	- Required: Comfortable with pydata - Python, Jupyter, pandas, viz, cloud (Linux/AWS/Azure)
	- Ideal: Experience with graphs - databases (cypher/sparql), algorithms, visualizations, & neural networks; Dashboarding (StreamLit/Ploty/Tableau/PowerBI/…); GPU PyData (RAPIDS, Tensorflow, numba, …)
	- Amazing: Ability to live debug with friendly users (pair-programming) and assist with open source & partner technology integrations, tutorials, & presentations.
	- Required: Comfortable with coding (Python, minor HTML/JS/CSS)  and/or ML (hands-on or courses around linear algebra, statistics, classical ML, neural networks)
	- Ideal:  
		* Practitioner who has led or been a primary contributor to graph data projects
		* STEM MS/PhD/PostDoc or equivalent in experience (ex: worked on data projects), especially around graph data
		* Even if you do not have a degree, *please apply*, it is just 1 data point
	- Amazing: Can help onboard bleeding-edge technologies & algorithms and innovate new solutions that combine them with Graphistry’s core technologies for new combined experiences, especially in IC/DoD/etc. scenarios
	- Required: Interested in collaborative work with multidisciplinary teams
	- Ideal: Strong written & verbal communication skills
	- Amazing: Can inspire users during interactions like customer pair-programming / help chats / hackathons, write clear code & tutorials, make engaging talks & articles,  manage customer/internal data projects, and help with government R&D programs (see related R&D role)
	- Ideal: Graph & data technologies; graph-y domains like security/fraud/bio/NLP/…
	- Amazing: Loves picking up new technologies / working on new problems; Successfully used graph/investigative technologies for tough use cases; Brimming with high-impact ideas that are both practical & innovative; Can share inspiring stories
+ skill set:
	- We are looking for a motivated, data-driven and results-oriented self-starter who is passionate about Growth Marketing to join our Revenue Marketing team. Our key focus is to accelerate Self-Service revenue across the entire customer journey - from new customer acquisition to retention and cross-sell / upsell. With a portfolio of hundreds of thousands of paying customers, you will lead insights at scale to find new user growth opportunities across Self-Service customer journey by helping more of our customers to discover the value of DigitalOcean through engaging, differentiated experiences. The focus will be on delivering engaging experiences for key high-value strategic initiatives and facilitating & enhancing Revenue Marketing's ability to engage with new audiences in new ways.
	- You will lead experimentation for the team, driving improvements in user acquisition, engagement and long-term growth at scale by measuring and optimizing new channels, platforms and strategic marketing initiatives - with a specific focus on helping our team identify key product and marketing levers for user growth - backed by systematic testing and optimization.
	- As a Data Scientist, your mission is to turn our data into insights and gain a deep understanding of our users to impact the strategy and direction of DigitalOcean. You will study user behavior, marketing strategies, markets, content, new features and bring data and insights into every decision we make. Above all, your work will impact how we think about user growth and how we can make DigitalOcean available and accessible for more people in the world.
	- Perform analyses on large sets of data to extract insights that will help drive DigitalOcean's strategy across the user funnel
	- Work cross-functionally with marketing, product, engineering, design and user research to propel DO's customer growth forward
	- Drive end to end execution of data science projects, from experimental design and analysis of test results to building predictive models and assisting engineers to productionize the model
	- Establish and maintain a culture of rigor and curiosity to drive tangible business impact
	- Proven experience with:
	- Large-scale data sets in both structured & unstructured formats
	- Causal inference & experimentation, time-series analysis, and building predictive models related to churn reduction or revenue expansion
	- Helping engineering teams move models from prototype to production
	- Experience with growth marketing for a tech company preferred
	- Coding skills (such as Python/R and SQL) and analytics tools experience (Segment, Looker, or similar tools)
	- Capacity and passion to translate business objectives into actionable analyses, and analytic results into business and product recommendations
	- Experience with international markets, growth marketing, web platforms or content marketing a plus
+ skill set:
	- data pipeline and workflow management teams:
		* Airflow
		* Luigi
	- Big Data tools:
		* Hadoop
		* Hive
		* Spark
	- AWS Cloud services:
		* EC2
		* EMR
		* RDS
		* Redshift
		* S3
	- languages:
		* Python
		* Java
		* Scala
	- Linux
	- expanding and optimizing data pipeline architecture, data flow and collection for cross-functional teams
		* ETL
		* re-designing infrastructure to improve scalability, reliability, and accuracy 
	- ensure optimal delivery architecture by supporting software engineering initiatives
	- use appropriate tools to analyze data pipeline, and provide actionable insights into operational efficiency, data accuracy, and other KPIs
	- experience with:
		* relational databases
		* data warehoouses
		* big data platforms
	- perform root cause analysis on external and internal data and processes to answer specific business questions and identify opportunities for improvement
	- improve processes to support data transformation, data structures, metadata, dependency, and workload management
	- working knowledge of:
		*  message queueing
		* stream processing
		* highly scalable big data stores
+ skill set:
	- We are looking for Data Scientist Interns to #JoinTheBand and help drive a data-first culture across our Finance teams at Spotify. Data scientists within our Finance team has the mission of utilizing data insights to drive decision-making for the organization. You will study user behavior, strategic initiatives, markets, content, and new features and bring data and insights into every decision we make. Above all, your work will impact the way the world experiences music.
+ skill set:
	- Undertake analysis to monitor and report key performance indicators (KPI's)
	- Building out our KPI Dashboards for monitoring game performance
	- Design, run, analyse and report on A/B tests
	- Experience with business intelligence software like Tableau, Looker etc
+ skill set:
	- The candidate must have a sufficient understanding of and practical experience with classic statistical modeling techniques (e.g. logistic regression, CART, K-means clustering) and machine learning algorithms (e.g. gradient boosting, neural networks, random forests)
	- Comfort with ambiguous and large streams of data across different formats and entry points; Hands-on experience working with large data processing (processing large datasets); hands on experience with cloud environments (e.g. AWS, Azure) and Big Data technologies (e.g. Hadoop, Spark)
	- Expert-level Python, R and SQL coding; Experience with TensorFlow or Microsoft Cognitive Tool Kit required
	- Experience developing high value features; Hands-on experience deploying models in real-time environments
+ skill set:
	- Expert-level familiarity with reporting and visualization platforms (e.g. Tableau, Mode)
	- SQL expertise beyond querying: query optimization, schema design, and ETL maintenance
+ skill set:
	- Work with large, complex data sets. Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed. Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations.
	- Build and prototype analysis pipelines iteratively to provide insights at scale.
	- Develop comprehensive knowledge of TikTok data structures and metrics, advocating for changes where needed for product development.
	- Interact cross-functionally, making business recommendations (e.g., cost-benefit, forecasting, experiment analysis) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information.
	- Research and develop analysis, forecasting, and optimization methods to improve the quality of TikTok ads products.
	- 3+ years of relevant work experience, including expertise with statistical data analysis such as linear models, multivariate analysis, stochastic models, sampling methods.
	- Experience with statistical software (e.g. R, Python, MATLAB) and database languages (e.g. SQL)
	- Demonstrated leadership and self-direction. Willingness to both teach others and learn new techniques.
	- Demonstrated skills in selecting the right statistical tools given a data analysis problem. Effective written and verbal communication skills.
+ skill set:
	- Generate useful features from large amount of data
	- Apply supervised and unsupervised machine learning techniques, such as linear and logistic regression, decision trees, and k-means clustering
	- Develop segmentation models, classification models, propensity models, LTV models, experimental design, optimization models
	- Perform statistical analysis such as KPI deep dives, performance marketing efficiency, behavioral clustering, and user journey analytics
	- Curate audiences and inform engagement tactics to enable differentiated, relevant marketing touches across channels (social, email, in app, push)
	- Synthesize analytics and statistical approaches into easy-to-consume storylines, both visually and verbally, and provide indicated actions for executive audiences
	- Capture business requirements for data and analytic solutions and collaborate XFN to ensure business requirements align with business needs
	- Analyze creatives and surface insights that will help drive engagement and retention.
	- Support day-to-day collaboration with performance marketing to communicate insights and recommend data informed strategies
	- Experience building data science models (Regression, Decision Trees, K-Means, etc.)
	- Experience with large data sets and analytical tools, e.g. Hive, Spark)
	- Proficiency in scripting languages (SQL, Python, R, etc.)
	- Experience working with international partners in different time zones
+ skill set:
	- 6-7 years of overall experience working with data science methodologies & techniques like dimensionality reduction (PCA, Factor Analysis, etc.), clustering (supervised, unsupervised), time series forecasting, optimization, parametric modelling (SEM, GLM, GLMM, etc.), ML (tree based learners like RF, GBM, XGBOOST, CATBOOST, etc.), BBN, Neural Networks (ANN, CNN, RNN, etc.), DL, RL, Transfer learning, text mining & NLP, etc.
	- Graduate or Under-graduate degree holder in Statistics/Mathematics/Economics/Science/Engineering/Business Management
	- Any industry certification(s) related to Data Science techniques (DL, RL, NLP, etc.) \& platforms (SAS, R, Python, Spark, etc.), and Big Data technologies (AWS/MS Azure/GCP)
	- P\&C Insurance domain knowledge preferredAt least 2-3 years working experience in P\&C Insurance domain
+ skill set:
	- As a Data Scientist, you will participate in the definition of new analytics capabilities able to provide our customers with the information they need to make proper decisions to support our customers in operating the internet of things (IoT). In addition, you will help find the appropriate machine learning / data mining algorithms to answer these questions. Finally, you will be responsible for implementing this into the product and making it available to our customers.
		* Qualified candidates will have an in-depth knowledge of most common machine learning techniques and their application. You will also understand the limitations of these algorithms and how to tweak them or derive from them to achieve similar results at large-scale.
	- Your Responsibilities:
		* Driving adoption of Deep Learning systems into next-generation of C3 AI products.
		* Designing and deploying Machine Learning algorithms for industrial applications such as fraud detection and predictive maintenance.
		* Collaborating with data and subject matter experts from C3 AI and its customer teams to seek, understand, validate, interpret, and correctly use new data elements.
	- Requirements:
		* MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields.
		* Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning). 
		* Strong mathematical background (linear algebra, calculus, probability and statistics).
		* Experience with scalable ML (MapReduce, streaming).
		* Ability to drive a project and work both independently and in a team.
		* Smart, motivated, can do attitude, and seeks to make a difference.
		* Excellent verbal and written communication.
	- Preferred
		* Experience with JavaScript and prototyping languages such as Python and R. Experience with Java and Scala is a plus.
		* Knowledge in electrical engineering and cyber-physical systems is a plus.
		* A portfolio of projects (GitHub, papers, etc.) is a plus.
+ skill set:
	- Agile workflow practices and familiarity with Atlassian tools
		* Jira
		* Confluence
	- statistical methods
		* exploratory data analysis
		* hypothesis testing
		* regression techniques
	- techniques and best practices for data visualization
		* visualization libraries:
			+ Altair
			+ seaborn
			+ matplotlib
			+ Tableau
			+ ggplot2/shiny
		* storytelling with data, to support data-driven decisions using compelling visualizations
	- analytical toolkit
		* Python
		* pandas
		* R
	- SQL, JSON, and unstructured data
	- Amazon Web Services ecosystem
+ used mixed methods to inform/drive product prioritization, via quantitative data (e.g., metrics and data analytics) and qualitative data (e.g., user feedback)
+ You have familiarity with any query language like SQL, SPL etc.
+ Bonus: experience with Kubernetes, Terraform, AWS, Puppet.
+ Familiarity with Python, React, GraphQL, and MySQL or similar relational databases
+ Familiarity with Python, React, GraphQL and online storage systems such as MySQL or MyRocks
+ Data visualization with ggplot and matplotlib.
+ Experience with Analytics tools is appreciated  (***Segment, Amplitude***)
	- Segment
		* single hub to collect, translate, and send (customer) data with the flip of a switch
	- Amplitude
		* event tracking and segmentation platform
		* pinpoint most valuable behavioral patterns within hours
+ Comfortable with tools such as: Amplitude, Segment Sources, Looker, Postgres, Graylog, Github, Datadog
+ skill set:
	- solid-hands-on skills in sourcing, cleaning, manipulating, analyzing, visualizing, and modeling real data.
	- Break down complex problems into manageable steps that have an immediate impact on critical, real-world projects, without losing sight of long-terms roadmaps.
+ skill set:
	- Curious mindset : Solve ambiguous business problems using in-depth analysis to discover and size opportunities for growth levers.
	- Empower stakeholders: Be a strategic partner to product and engineering and drive data informed decisions
	- Build for future: Build and improve on the availability, integrity, accuracy, and reliability of data logging and data pipelines to democratize data and insights for extensive future scaling.
	- Communication: Define how success is measured and own the creation of metrics to track product / launch performance. Build self serve dashboards reports for tracking these metrics
	- Experiment: Design and measure experiments  using statistical and econometric models to draw detailed and impactful conclusions
	- Build the foundation: Establish and detail foundational work and frameworks, and establish data science processes
	- Strong storytelling: distill interesting and hard-to-find insights into a compelling, concise data story
	- Burning desire to inspire change through data and are enthusiastic about innovating in a fast-paced data science team
	- Comfortable with ambiguity and able to thrive with minimal oversight and process
	- Curious and bring genuine excitement to learn new subject areas and are comfortable to be scrappy as and when needed
	- Effective communicator and pay attention to the finer details
	- Empathize with customers and stakeholder and build meaningful relationships
	- Self-aware of strengths and seeking to constantly learn and improve
	- You don't allow perfect to become the enemy of the good
	- 5+ years of professional experience doing quantitative analysis (or 2+ if PhD in a quantitative field)  
	- MS or higher in a quantitative field (e.g., Math, Economics, Statistics, Sciences, Engineering, CS, OR, ML or other quantitative fields)
	- Advanced experience with experimental design and statistical methods such as causal Inference
	- Expert knowledge of a scientific computing language (such as R or Python), SQL, visualization, data modeling, ETL, and the data warehousing concepts
	- 2+ years within SaaS industry-ideally at an prosumer SaaS platform
+ Knowledge of predictive analytics/statistical and mathematical modeling/data mining algorithms;
+ skill set:
	- Advanced modeling and data visualization skills in Tableau Desktop
	- Advanced Python coding talent including familiarity with common and emerging data science and scientific computing toolsets/libraries (matplotlib, pandas, scipy, numpy, et al)
	- Savvy with collaborative data workbench tools and environments like Cloudera Data Science Workbench, Jupyter, Shiny, RStudio
	- Data manipulation and ETL skill in Talend or a similar tool
	- Strong interpersonal skills, including the knack for translating customer business needs and user stories into requirements and real-world outcomes
	- Relevant education or experience in Computational Statistics
	- An autodidact who keeps on learning
	- Expert-level Excel | Google Sheets skills with scripting
	- Understanding of ITIL concepts
	- Experience with an RDBMS (Oracle, MySQL, Teradata, etc)
	- Experience with containerization tools (Kubernetes, Docker)
+ set of skills:
	- Statistical analysis and modeling
	- Database architectures
	- Hadoop-based technologies (e.g. MapReduce, Hive and Pig)
	- SQL-based technologies (e.g. PostgreSQL and MySQL)
	- NoSQL technologies (e.g. Cassandra and MongoDB)
	- Data modeling tools (e.g. ERWin, Enterprise Architect and Visio)
	- Python, C/C++ Java, Perl
	- MatLab, SAS, R
	- Data warehousing solutions
	- Predictive modeling, NLP and text analysis
	- Machine learning
	- Data mining
	- UNIX, Linux, Solaris and MS Windows
	- Python (3.5>=), packages: argparse, shapely, Munkres, numpy, cv2, logging, Pillow
+ skill set:
	- experience using Web services, such as:
		* WCF, Windows Communication Foundation
		* Spark
		* Rest
	- experience using a statistical process control system, such as Camline SPACE.
	- experience in Hadoop, Spark, and Impala for large-scale data manipulations.
		* Apache Impala
			+ modern SQL query engine for Apache Hadoop
			+ open-source massively parallel processing (MPP) SQL query engine for data stored in a computer cluster that runs Apache Hadoop.
	- software source code repository tools:
		* Git
		* Subversion
		* ***Azure DevOps Server***, formerly known as ***MS TFS or Microsoft Team Foundation Server***
	- VoC, voice of customer software tools
+ skill set:
	- As a data scientist at Quora, you'll work closely with product managers, product designers, and engineers to devise appropriate measurements and metrics, design randomized controlled experiments, build visualizations, and tackle hard, open-ended problems that uncover usage patterns and opportunities for the company. Quora has a wide range of rich data, giving you ample room for exploration and creativity. Examples of some projects our data scientists have worked on include modeling our long-term growth, improving the relevance and personalization of the homepage feed, and exploratory analysis of factors driving question-asking behavior. For more about our work, see Quora's Data blog at https://data.quora.com/.
	- As a staff data scientist, you will draw on your experience to excel not only in your own work but also to elevate data's impact at a company-wide level. You will provide team mentorship that propels the work of your colleagues while helping to establish best practices for data usage across Quora.
	- Extract actionable insights from broad, open-ended questions
	- Create, design, and evaluate experiments to measure the impact of product changes
	- Analyze data from across the product to uncover the root causes of metric movements
	- Communicate data-driven results to cross-functional stakeholders to inform product decisions
	- Develop tools to scale and automate analyses, improving productivity across the company
	- Improve the work of other data scientists through mentorship and by bringing industry best practices to the team
	- Ability to be available for meetings and impromptu communication during Quora's "coordination hours" (Mon-Fri: 9am-3pm Pacific Time).  Learn why here
	- 5+ years work experience in an analytical or quantitative role as a Data Scientist or similar title
	- 3+ years experience working on product analytics
	- Extensive experience generating insights using statistical techniques (e.g. regression, hypothesis testing)
	- Demonstrated ability to clearly explain data results to cross-functional teams
	- Experience using a procedural programming language (e.g. Python, R) to manipulate, clean, and analyze data
	- Ability to exercise judgment and combine quantitative skills with intuition and common sense
	- Experience evangelizing best practices and process improvements on your team
	- Experience using a procedural programming language (e.g. Python, R) to manipulate, clean, and analyze data
	- Experience pushing code and navigating a complex codebase
	- Active Quora user with curiosity about the product
+ skill set:
	- Bachelor's degree in Computer Science, Math, Statistics, Economics, or other quantitative field; Masters or PhD strongly preferred
	- Previous experience in data science or quantitative analytics role, preferably in a high-growth company
	- Comprehensive understanding of statistical modeling, machine learning and data mining concepts, and experience applying these methods within a business environment
	- Strong knowledge of Python. Familiarity with at least one statistical modeling / machine learning tool such as R or Matlab is a plus, as well as experience with languages such as Scala or Go
	- Expert knowledge of, and hands-on experience with, SQL
	- Demonstrable critical thinking and analytical skills, including the ability and confidence to make conclusions and recommendations from data
	- Experience interacting with key stakeholders in different fields, interpreting challenges and opportunities into actionable data-driven analysis and implementing science-driven data products
+ skill set:
	- Because Quora is such a data-driven company, our data scientists play a central role in the product development process by uncovering key insights from our data. As a data scientist, you'll work closely with engineers, product designers, and product managers to devise appropriate measurements and metrics, design randomized controlled experiments, build visualizations, and tackle hard, open-ended problems. You'll also develop tools and infrastructure to scale and automate the analyses that enable rapid product iteration. Quora has a wide range of rich data, giving you ample room for exploration and creativity. We use a variety of tools -- primarily Python and SQL — to analyze data and communicate results with the rest of the company.
	- While Quora's data scientists come from a variety of backgrounds, including statistics, computer science, economics, physics, mathematics, sociology, chemical engineering, and so on, we all share a love for data and continuous learning. Especially in your first role post-graduation, we realize that mentorship is important for professional growth and development. Every data scientist has a mentor and weekly 1:1s with their managers to get feedback and support for your career growth.
	- To give you a taste of what data scientists at Quora do, here are some example projects:
		* Analyze traffic patterns to similar questions and understand the metric implications of duplicate questions
		* Forecast growth trajectory of Quora in different languages and identify growth bottlenecks and drivers
		* Evaluate long term effects of a ranking algorithm change beyond short term metric gains as shown in experiments
		* Devise metrics and build dashboards to measure the success of a new product feature or initiative
		* Explain suspicious metric spikes as measured by dashboards and A/B tests
		* Make trade-off and recommend product decisions when a key metric improves but another one drops in an A/B test
	- Responsibilities:
		* Extract actionable insights from broad, open-ended questions to influence product strategy and drive roadmap decisions
		* Analyze data to understand the root causes of metric movements and uncover growth opportunities
		* Design and evaluate A/B tests to make informed recommendations on product changes
		* Develop metrics and create dashboards to orient the direction of product development and track the success of the product
	- Minimum Qualifications:
		* B.S., M.S., or Ph.D. in a scientific or quantitative field
		* Proficiency in using SQL and procedural programming languages (e.g. Python, R) to manipulate and analyze data
		* Rigorous coursework in statistical techniques (e.g. hypothesis testing, regression)
		* Relevant past internship or research experience working with large data sets and experiments
		* Demonstrated ability to exercise judgment and combine quantitative skills with product judgment to translate numbers into insights
		* Demonstrated ability to clearly explain data results to cross-functional teams
	- Preferred Qualifications:
		* Experience in working with large data sets and distributed computing tools (Hive, Redshift)
		* Experience pushing code and navigating a complex codebase
		* Active Quora user with curiosity about the product
+ skill set:
	- Because Quora is such a data-driven company, our data scientists play a central role in the product development process by uncovering key insights from our data. As a data scientist, you'll work closely with engineers, product designers, and product managers to devise appropriate measurements and metrics, design randomized controlled experiments, build visualizations, and tackle hard, open-ended problems. You'll also develop tools and infrastructure to scale and automate the analyses that enable rapid product iteration. Quora has a wide range of rich data, giving you ample room for exploration and creativity. We use a variety of tools -- primarily Python and SQL--to analyze data and communicate results with the rest of the company.
	- A Quora internship is not an ordinary internship. There is no busy work. Every project that our interns work on is important to the company and its goals. As a team, we are dedicated to holding high standards, developing a strong and passionate culture, and emphasizing impact. Interns play an important role in this, as they work alongside full-time employees as equals, working on the same projects that help drive the company and product forward. We expect interns to become valuable contributors to the team, as they work hand-in-hand with people ranging from engineering to design to business development.
	- We also realize that mentorship is important to allow interns to grow and develop skills in areas which they're looking to improve. Every intern will have a full-time data scientist as a mentor and weekly 1:1s with their managers to get feedback and ensure things are going well.
	- To give you a taste of what interns can do at Quora, here are some projects that data science interns have worked on in the past:
		* Analyze external traffic patterns over time to better understand how changes in outside products cause increases or decreases in visits to Quora
		* Study the usage differences between the English and Spanish Quora products to understand how various mechanics of Quora translate across different languages
		* Develop methodology and prototype features in our internal experimentation platform to identify and capture novelty effects in experiments
		* Investigate the effect of how “satisfying” a question page is on user engagement and clickthrough patterns through the rest of the product
		* Understand effects of positional bias on home feed ranking to identify opportunities to improve ranking and feed engagement
		* Improve the accuracy of a user engagement prediction model and understand what factors are important in determining new users' long term usage.
		* Build a recommender system to suggest Quora topics to a user based on provided interests
		* Evaluate statistical properties of various methods used to determine significance in ratio metrics, considering coverage, power, and feasibility
		* Create dashboards and perform ad-hoc analyses to monitor and understand important product metrics
	- Responsibilities:
		* Extract actionable insights from broad, open-ended questions to influence product strategy and drive roadmap decisions
		* Analyze data to understand the root causes of metric movements and uncover growth opportunities
		* Design and evaluate A/B tests to make informed recommendations on product changes
		* Develop metrics and create dashboards to orient the direction of product development and track the success of the product
	- Minimum Qualifications:
		* Third year undergraduate student or final year master or Ph.D. in a scientific or quantitative field
		* Proficiency in using SQL and procedural programming languages (e.g. Python, R) to manipulate and analyze data
		* Rigorous coursework in statistical techniques (e.g. hypothesis testing, regression)
		* Demonstrated ability to exercise judgment and combine quantitative skills with product judgment to translate numbers into insights
		* Demonstrated ability to clearly explain data results to cross-functional teams
	- Preferred Qualifications:
		* Relevant past internship or research experience working with large data sets and experiments
		* Experience in working with large data sets and distributed computing tools (Hive, Redshift)
		* Experience pushing code and navigating a complex codebase
		* Active Quora user with curiosity about the product
+ skill set:
	- 3+ years of data scientist experience with proven industry experience in a large scale environment (PBs scale & globally distributed teams).
	- 2+ years experience with a fast-growing SaaS business based company is preferred.
	- Strong experience in scientific computing using Python, R, or Scala.
	- Experience with Spark, SQL, Tableau, Google Analytics, Hive and BigQuery (or any other Big data/Cloud equivalent) etc.
+ skill set:
	- Fluent in machine learning frameworks such as TensorFlow, PyTorch, Caffe, or Theano and libraries such as NumPy and pandas.
	- Passion for seeing research through from initial conception to eventual application.
	- Past experience with writing performant implementations of ML research.
	- Have experience working with CUDA, Docker and AWS platform (Lambda, S3, RDS, and/or EKS).
	- Have an artistic/creative practice of your own.
	- Have published high-impact machine learning research.
	- Have experience in a creative application (Unity, Photoshop, Blender, Processing, etc)
+ skill set:
	- Strong experience in scientific computing using Python, R, or Scala
	- Experience with Spark, SQL, Tableau, Google Analytics, Hive and BigQuery (or any other Big data/Cloud equivalent) etc.
	- Experience working with and processing structured, unstructured, and semi-structured data
	- Experience building data systems at scale
	- 5+ years of engineering experience with proven industry experience in big data engineering
	- 2+ years experience with a fast-growing SaaS business based company is preferred
	- Experience building big data systems required, experience building Machine Learning pipelines is a strong plus
+ skill set:
	- project management skills to:
		* manage complexity
		* make informed trade-offs to quickly escape rabbit holes and make on-time deliveries
	- Agile workflow practices and familiarity with Atlassian tools
		* Jira
		* Confluence
	- statistical methods
		* exploratory data analysis
		* hypothesis testing
		* regression techniques
		* power analysis
		* generalized linear models
		* time series
		* survival analysis
	- machine learning techniques
		* supervised learning
		* unsupervised learning
		* general machine learning workflow
		* linear regression
		* logistic regression
		* decision trees
		* neural networks
		* clustering
	- techniques and best practices for data visualization
		* visualization libraries:
			+ Altair
			+ seaborn
			+ matplotlib
			+ Tableau
			+ ggplot2/shiny
		* storytelling with data, to support data-driven decisions using compelling visualizations
	- analytical toolkit
		* Python
		* pandas
		* scikit-learn
		* R
	- database management:
		* SQL
		* JSON
		* unstructured data
		* NoSQL data environments and tools:
			+ Hadoop
			+ Spark
			+ DynamoDB
	- Amazon Web Services ecosystem
	- software development practices:
		* story estimation
		* test-driven development
		* code review
		* version control with Git
+ skill set:
	- Zoomies help the world connect — and deliver happiness while doing it. We set out to build the best video conferencing product for the enterprise, and today help people communicate better with products like Zoom Phone, Zoom Rooms, Zoom Video Webinars, Zoom Apps, and OnZoom.
	- Our Data Science teams lie at the foundation of Zoom's success. As a Data Science, Intern on the Customer Success team, you will play an important role in driving the growth of Zoom by surfacing, analyzing, and reporting on data that drives mission-critical business decisions. 
	- This paid internship is for a duration of approximately 10 - 12 weeks during the spring of 2021. The program offers cutting edge projects, as well as a mix of additional types of learning in areas of leadership and business acumen-- and is packed full of fun!
	- Responsibilities:
		* Assist with building and maintaining Zoom product features and services. 
		* Build, deploy and upgrade our real time compute infrastructure.
		* Design and implement features to improve our systems. 
		* Connect with customers to understand their goals and needs and translate those into solutions our team can deliver.
		* Configure tooling for systems scalability, ensure we have capacity for future growth.
		* Ensure our systems are continuously monitored and running efficiently with a consistent, unified experience across products, platforms, and devices.
		* Test current algorithms and write testing documents.
		* Collaborate with internal stakeholders across the business to drive the delivery of features, processes and happiness.
	- Requirements:
		* At least 18 years old, currently enrolled in a four year academic institution completing an undergrad, grad, or PhD degree in Business/Economics, Human-Computer Interaction, Computer Science or a related STEM field.
		* Legally authorized to work in the United States. Due to the limited duration of this program, sponsorship for employment visa status is not available for this position.
		* Availability to complete the full 10-12-week internship program during Spring 2021, with a time commitment of approximately 30-40 hours per week.
		* Must be highly proficient in SQL and Microsoft Excel
		* Minimum 4+ years of experience using data to facilitate decisions  
		* Strong understanding of growth principles, product development, and product go to market processes 
		* Self-starter, ability to envision solutions and take initiative to see the solution to the end despite challenges. 
		* Ability to crystallize vague concepts into concise plans with clear documentation and data driven decision making .
		* Detail oriented, organized, ethical, responsible, and self-motivated.
		* Team player, ability to work effectively in a matrix organization.
		* Consumer facing experience
		* Strong communication and problem solving skills and a desire to learn something new.
		* A passion for creating products that resonate emotionally with people.
		* A passion for Zoom's mission, vision, values, and culture.
+ skill set:
	- We are looking for Data Scientist Interns to #JoinTheBand and help drive a data-first culture across Spotify. Our Data Scientist mission is to turn terabytes of data into insights and get a deep understanding of music and listeners so we can impact the strategy and direction of Spotify. You will study user behavior, critical initiatives, markets, content, and new features and bring data and insights into every decision we make. Above all, your work will impact the way the world experiences audio. 
	- Perform analyses on large sets of data to extract concrete insights that will help drive decisions across the business
	- Build dashboards and recurring reporting results, empowering creative growth and business decisions.
	- Communicate data-driven insights and recommendations to key collaborators
	- Work closely with cross-functional teams of analysts, product owners, marketers, designers, and others across the company who are passionate about Spotify's success
	- You are pursuing a Bachelor's, Master's degree or bootcamp certification in Science, Computer Science, Statistics, Economics, Mathematics, or similar quantitative field
	- You are a sophomore, junior or senior in undergrad or a first or final year in a Master's program
	- You have harbor a passion for numbers and the use of data to make decisions
	- You have have technical competence to perform more analytics in one or more of the following areas:
	- Coding skills (such as Python, Java, or Scala)
	- Analytics tools experience (such as Pandas, R, SPSS, SQL or Tableau)
	- Experience performing analysis with large datasets
+ skill set:
	- We are looking for Data Scientist Interns to \#JoinTheBand and help drive a data-first culture across Spotify. Our Data Scientist mission is to turn terabytes of data into insights and get a deep understanding of music and listeners so that we can impact the strategy and direction of Spotify. You will study user behavior, critical initiatives, markets, content, and new features and bring data and insights into every decision we make. Above all, your work will affect the way the world experiences audio. 
	- Perform analyses on large sets of data to extract practical insights that will help drive decisions across the business
	- Build dashboards and recurring reporting results, empowering creative growth and business decisions
	- Communicate data-driven insights and recommendations to key collaborators
	- Work closely with cross-functional teams of analysts, product owners, marketers, designers, and others across the company who are passionate about Spotify's success
	- You are pursuing a Bachelor's, Master's degree, or bootcamp certification in Science, Computer Science, Statistics, Economics, Mathematics, or a similar quantitative subject area
	- You have a graduation date of 2022 or 2023
	- You currently have valid work authorization to work in the country in which this role is based that will extend from June to August 2022
	- You harbor a passion for numbers and the use of data to make decisions
	- You have the technical competence to perform more analytics in one or more of the following areas:
		* Coding skills (such as Python, Java, or Scala)
		* Analytics tools experience (such as Pandas, R, SPSS, SQL, or Tableau)
		* Experience performing analysis with large datasets
+ skill set:
	- Participate in our cloud AI projects, design the architecture of source code libraries/packages to support the development of various AI applications on cloud services.
	- The role requires hands-on development, problem-solving skills, and knowledge of various horizontal and vertical packages - spanning across various layers in the technical stack.
	- Creating architectural documents and community-facing tutorials. Working with potential partners in the academic/community to define specifications for open-source projects.
	- 3+ years of experience, especially on turning ML technologies into practical, and state-of-the-art systems.
	- Proficiency in Python, and the common tools and frameworks with practical experiences.
	- Knowledge of common machine learning frameworks such as Tensorflow, PyTorch and Caffee.
	- Excellent experiences in writing concise, clear, and detailed documentation for the libraries/package.
	- A portfolio or GitHub repository of applications or code snippets are welcomed.
	- Great attention to detail.
	- Preferred working experience on Data Science/Machine Learning/Deep Learning/Computer Vision-related projects
	- Basic knowledge about supervised and/or unsupervised machine learning models.
	- Experience with container orchestration/infrastructure as code, e.g. Kubernetes.
+ skill set:
	- Excellent skills in AWS, MapReduce
	- Experience in machine learning, quantitative analysis
	- Experience in knowledge graphs, statistical relational learning, trends-driven analysis
	- Experience in modelling both structured and unstructured data
	- Excellent skills in C++, Python
	- Excellent skills in Postgres
	- Ability to work/report remotely
+ skill set:
	- Understand data landscape i.e tooling, tech stack, source systems etc. and work closely with the data Engineering team to improve the data collection and quality.
	- Ability to define and spot macro and micro levels trends with statistical significance on a regular basis and understand key drivers driving those trends.
	- 8+ years of data analyst experience with 4+ years of proven industry experience in a large scale environment(PBs scale, globally distributed teams).
	- Strong experience in Python, R, SQL, Tableau, Google Analytics, Hive and BigQuery (or any other Big data/Cloud equivalent) etc.
+ skill set:
	- Partner and align with business leaders, stakeholders, product managers and internal teams to understand the business and product challenges and goals and address them using predictive analytics in a globally distributed environment.
	- Understand data landscape i.e tooling, tech stack, source systems etc. and work closely with the data Engineering team to improve the data collection and quality.
	- Understand business/product strategy and high-level roadmap and align analysis efforts to enable them with data insights and help achieve their strategic goals.
	- Strong audience focused presentation and storytelling skills focused on key takeaways in a crisp and concise manner.
	- Define hypothesis driven models and best practices to derive and publish model scores/insights/learnings at scale within the company.
	- Ability to define and spot macro and micro levels trends with statistical significance on a regular basis and understand key drivers driving those trends.
	- 8+ years of data scientist experience with 4+ years of proven industry experience in a large scale environment (PBs scale, globally distributed teams).
	- Proven lead in driving multi-million dollar revenue generator models for the company and setting up data science related best practices at a company.
	- 2+ years experience with a fast-growing SaaS business based company is preferred.
	- Strong experience in Python, R, Spark, SQL, Tableau, Google Analytics, Hive and BigQuery (or any other Big data/Cloud equivalent) etc.
+ Experience with data analytics platforms, such as Semantic Pro, Semantic Cortex, IBM i2
+ tech stack:
	- 2+ years of analytical work experience (experience working with product organizations a plus)
	- Strong critical thinking and problem solving skills
	- Experience  communicating effectively with non-technical audiences
	- Strong ability to devise data-driven solutions to business problems
	- Strong competency with SQL
	- Experience with or exposure to a scripting language (Python preferred)
+ tech stack:
	- 5+ years of relevant analytical experience working with data or MS in a relevant technical field and 2+ years of analytical work experience (experience working with product organizations a plus)
	- Strong critical thinking and problem solving skills
	- Comfort and expertise communicating effectively with a wide-range of audiences (including product managers, engineers, business development managers, occasionally executives)
	- Strong ability to devise data-driven solutions to business problems
	- Ability to drive impact by thoughtfully tackling open-ended problems
	- Strong data intuition and deep understanding of and experience with statistical and/or ML modeling techniques
	- Strong competency with SQL
	- Fluency in a scripting language (Python preferred)
	- A plus: Experience with large scale data processing tools (Apache Spark) or implementing systems in production at scale
+ skill set:
	- Strong proficiency in Python a necessity, especially the Python data science stack
	- Experience developing data science models, workflows, and software for real world applications and working with imperfect data
	- Exploratory analysis, modeling, and visualization in Jupyter notebooks
	- Integrating data sources, creating subsets (ex. train/test) for modeling, and assessing potential datasets, tools, and approaches
	- Translating the results of analysis into implications for people and problems
	- Developing well-organized code that can be collaboratively reviewed, reproduced, and integrated into applications
	- Quickly assessing and becoming productive in relevant new technologies and methods
	- Experience with core data science tools (ex. pandas, scikit-learn, numpy, jupyter)
	- Experience working with messy data and real-world applications
	- Experience using IaaS like Amazon AWS
	- Working on a small team means doing a little bit of a lot of things. We're looking for somebody who can ask the right questions to figure out what is important, iterate between brainstorming together, working independently, and managing other data scientists, scope new data science projects, and exercise sound judgment to make reasonable decisions under conditions of ambiguity.
	- Communication is a core data science skill at DrivenData. Doing client-facing work involves articulating concepts, interpreting results, and selecting the method that satisfies the constraints of the project.
	- Working familiarity with the tools and practices used in software engineering and deployment (including test-driven deployment, containerization (ex. Docker), platform as a service (ex. Heroku), and infrastructure as a service (ex. AWS, Azure)
+ skill set:
	- Use Python and SQL to draw insights from data at scale
	- Extract actionable insights from broad, open-ended questions
	- Create dashboards and develop metrics to track the success and growth of the product
	- Design and evaluate experiments to measure the impact of product changes
	- Analyze data from across the product to uncover the root causes of metric movements
	- Communicate results to cross-functional stakeholders to inform product decisions
	- Develop tools to scale and automate analyses, improving productivity across the company
	- Improve the work of other data scientists through mentorship and by bringing industry best practices to the team
	- Experience generating insights using statistical techniques (e.g. regression, hypothesis testing)
	- Demonstrated ability to clearly explain data results to cross-functional teams
	- Experience using a procedural programming language (e.g. Python, R) to manipulate, clean, and analyze data
	- Ability to exercise judgment and combine quantitative skills with intuition and common sense
	- Experience evangelizing best practices and process improvements on your team
	- Experience working with large data sets and distributed computing tools (e.g. Redshift, Presto)
	- Experience pushing code and navigating a complex codebase
+ skill set:
	- Identify new methods to test product changes where traditional A/B testing is not possible
	- Drive adoption of good experimental and statistical practices across the company
	- Apply statistical techniques to increase the efficiency and rigor of our experimental analyses
	- Proactively identify ways to optimize and scale up the way we run experiments, and to increase data scientists' impact in general, and create processes and tools to meet these needs
	- Mentor other data scientists in experimental design and causal inference techniques
	- Coursework in experimental design, causal inference, and/or econometrics
	- Experience running and analyzing behavioral experiments
	- Statistical intuition and knowledge of various hypothesis testing and regression approaches, e.g. hierarchical modeling, difference-in-differences
	- Demonstrated ability working effectively with cross-functional teams
	- Experience using git and pushing to a codebase
	- Experience with software engineering projects or coursework
	- Develop tools to scale and automate analyses, improving productivity across the company
	- Experience working with large data sets and distributed computing tools (e.g. Redshift, Presto)
	- Experience pushing code and navigating a complex codebase
+ skill set:
	- Experience in data store design (data lakes; relational, columnar, NoSQL databases, analytics/OLAP cubes)
	- AWS and DevOps experience with AI/ML pipelines
	- Create the vision to build and evolve the team's data infrastructure and tools. Technically lead for the design, building, and launching of new data models and data pipelines
	- Ensure production quality methods to retrieve, condition, validate, synthesize, and manipulate data
	- Full-stack build custom integrations between cloud-based systems using APIs
	- Continuously refine and improve the data architecture and delivery as new requirements surface
	- Experience ensuring data integrity, security, and encryption
+ skill set:
	- Associate Data Scientist (Internship):
	- VMware Tanzu Labs partners with organizations worldwide to accelerate innovation, while reducing operating costs and risk.  The data science team at VMware Tanzu Labs is primarily a consulting practice; we work with our customers to solve real world problems.  Our customers, like us, are cross-disciplinary. We service engagements with use cases running from customer churn to optimization to detecting fraud and misconduct.  We are not just doers; we are also educators and enablers. programs.
	- You have a passion for exploring data and connecting the value hidden in data with business outcomes and user needs.  You're agile and retrospective, and not afraid to identify what we're doing wrong so we can fix it, and what we're doing right so we can improve on it.  You'll be working on a wide variety of data problems for a diverse range of clients. You will often be asked to learn new technologies and domains on the fly.   Above all, you judge your success by the success of your team and the happiness of your customers.
	- Be given an opportunity to attend fun and educational events to kickstart your career, meanwhile, you'll get a better feel for our culture. 
	- Get hands-on exposure with cutting edge technology from managers, mentors, and fellow team members.
	- Acquire the tools and knowledge to contribute on a large scale.
	- Have the ability to advance your career in the direction you choose in the future. 
	- While there is no such thing as a “typical day”, these are activities we frequently find ourselves doing the following:
	- Partnering with clients to uncover and frame new opportunities for data science. Clients often come to us without a clear understanding of what we can do, so this is our chance to open their eyes to new possibilities for their businesses.
	- Pairing and writing code together with clients around engineering features, training models, tuning hyperparameters and evaluating results.  We emphasize rigor, because data science done right at this stage leads to models that shine in production.
	- Taking the models we build into production. This is an exciting stage for anyone who likes collaborating with product teams and seeing their model become real when users interact with it.
	- Helping our clients develop their internal data science practices, through mentoring and pair programming, so that they can be successful when we hand off the project.
	- Continuous learning by building demos and prototypes on new technologies, methodologies, and frameworks.  Presentation of learnings and findings for internal audiences, external conferences, and blog posts.
	- Bachelor's degree in an analytical or quantitative field, or currently pursuing a master's or doctorate degree in an analytical or technical field (e.g. applied mathematics, statistics, computer science, operations research, economics, data science, etc.). 
	- Clear and empathetic communicator. You'll be the one sharing your insights with clients and stakeholders. As such, frequent communication and tireless empathy are essential to succeed in this role.
	- Fluent speaking and writing ability in Chinese and English.
	- Advanced knowledge of statistical modeling and/or machine learning methods. These are the technical skills we need to iterate and improve data science pipelines.
	- Strong exploratory data analysis skills. Every engagement starts with an investigation of the data, and thorough EDA saves us a lot of headaches in the long run.
	- Strong programming skills in SQL and Python/R
	- Hands-on experience working in a distributed computing environment
+ ***A project around the areas of big data, searching and statistical modelling***
+ skill set:
	- ***Familiarity with analytics notebooks (Jupyter, RStudio, DataBricks)***
	- ***Strong programming skills and ability to utilize a variety of data/analytic software/languages/tools; e.g., Spark (ML, Mllib, Spark SQL), R (caret, ggplot2), Python (pandas, numpy, scipy, scikit-learn), Scala, Hive, SQL, SAS, Tableau, etc.***
	- Familiarity with cloud computing (in AWS or Azure)
	- Deep knowledge of a variety of statistical and data mining concepts and procedures including: generalized regression, machine learning algorithms, deep learning, media mix algorithms, and statistical graphics
	- Predictive Analytics experience desired
	- Experience with big data- Spark, Hive, Hadoop desired
	- Designing and overseeing implementation of solutions for non-routine problems utilizing a large array of know-how areas within analytics e.g. generalized regression, decision tree, non-parametric; and machine learning, e.g., gradient boosting, random forest, neural networks, clustering, pattern recognition
	- Developing best practices and repeatable processes for routine problems arising in business problems business cases including driving targeted marketing campaigns for tune-in and product adoption, creating an enhanced consumer experiences, and developing digital/social advertising audience segments
	- Assisting with strategic decisions about processes, frameworks and standards
+ skill set:
	- Proficient in SQL/Hive
	- Proven ability to apply scientific methods to solve real-world problems
	- Knowledgeable about the machine learning trade-offs and model evaluation
	- Over 4 years of industry experience with proven ability to apply scientific methods to solve real-world problems on web scale data
	- Ability to lead initiatives across multiple product areas and communicate findings with leadership and product teams
+ Hands-on experience with open source big data platforms (Hadoop, Hive, Presto) and familiarity with data visualization (Tableau, D3) technologies
+ Familiarity with implementing metric logging and interpreting metrics to make decisions
+ Must possess knowledge in SW to Enterprise, SaaS and on Premise, and cloud technologies Elasticsearch for text indexing, MongoDB for structured data storage, Mysql/postgres for SQL storage, JanusGraph for Properties' based graph storage, ArangoDB for Documents/Key Value/Graph storage, and Amazon AWS.
+ skill set:
	- Deep understanding of machine learning, statistical modeling and data mining techniques such as gradient boosting, neural networks, natural language processing and clustering
	- Understanding of experimental design and adaptive sampling
	- Experience working with big data platforms (Hadoop, Spark, Hive)
	- Experience working with relational SQL and NoSQL databases
	- Familiar with ML and statistical modeling tools such as R, SparkML, TensorFlow, SciKit
	- Proven track record overseeing multiple data science projects at all stages, from initial conception to implementation and optimization
	- Good programming skills using analytics-oriented languages such as Python, R and Scala
+ skill set:
	- Hands-on experience with AWS (Lambda, SAM, S3, DynamoDB, CloudFormation, EC2, IAM)
	- Experience building and interpreting data models and analytics dashboards
+ skill set:
	- Experience with data quality processes, data quality checks, validations, data quality metrics, definition, and measurement.
	- Ability to operate with cross-functional teams (for example, customer support, data science, engineering, and sales), including a willingness to balance the changing needs of a client-facing team with a demand for data engineering best practices and the ability to communicate the tradeoffs.
+ skill set:
	- Experience with presentation or data visualization software, such as Microsoft PPT, Tableau, Shiny, etc.
	- Practical understanding of and experience with predictive analytics, machine learning, and/or causal inference
+ skill set:
	- Proficiency with statistical programming languages (R, Python, etc.) and proven ability to work pragmatically with statistical concepts
	- Practical understanding of and experience with predictive analytics, machine learning, and/or causal inference
+ Proficiency with machine learning and statistical modeling (e.g., scikit-learn, TensorFlow, Stan)
+ Experience identifying data quality and developing automated QC checks and/or reports
+ A senior analytics professional with a proven track record of data analysis, reporting and visualization (e.g. Tableau, D3)
+ skill set:
	- Use Databricks to build internal data warehouse and integrate it with BI and CRM services used internally
	- Use Databricks to analyze usage data, and create dashboards and reports
	- Build self-serving internal data products to make data simple within the company
	- Work closely with Product Management and other stakeholders to understand product usage patterns and trends and to make data-driven decisions and forecasts
	- Provide product feedback to PM and Engineering teams
	- Strong desire to work at a rapidly growing startup
	- Knowledge of data processing and applied statistics
	- Proficient in data analysis and visualization using R or PyData
	- Familiar with SQL and databases like MySQL or PostgreSQL
	- Experience with distributed data processing systems like Spark and Hadoop
	- General-purpose languages such as Python and Scala
	- Desire to explore lots of data to find unexpected insights
	- Strong communication and presentation skills
	- [Plus] Advanced degrees in statistics, computer science, math, or similar fields
	- [Plus] Familiarity with interactive data visualization using tools like D3.js
+ Research, evaluate, and present statistical or Machine Learning methods to provide actionable insights.
+ Enforce SOX & GDPR compliance across the analytics database and reporting tools
+ Good grasp of statistical concepts (e.g. hypothesis testing, regression)
+ skill set:
	- Project-based analytics including but not limited to: Machine Learning, Predictive Analytics, Comparative Effectiveness Analysis, Failure Analysis, Big Data Analytics, Optimization, Demand Forecasting, Customer Segmentation, Customer Analytic Record.
	- Minimum 3 years' experience with predictive analytics tools, including at least two of the following: R, SAS, Alteryx, Python, Spark, and Tableau.
	- Experience in the following areas: Applied Statistics/Econometrics, Statistical Programming, Database Management & Operations, Digital, Comparative Effectiveness Research.
+ **Experience and knowledge of programming languages, data analysis packages (e.g., Python, R, SAS, MatLab, Stata, GAMS, SPSS, Hadoop, BigML, Pandas). Experience and knowledge of visualization tools (e.g., Tableau, Sigma JS) is preferred.**
+ Working knowledge of data analysis packages (e.g., SAS, MatLab, Stata, GAMS) is strongly preferred.
+ skill set:
	- analytical mindset and strong experience with data-driven product decisions using analytics tools, such as:
		- Amplitude
		- Retool
	- AI-driven insights and recommendation engines to help creators build better businesses
	- category defining analytics platform to help creators better understand their audience
+ Expertise in statistical inference including experimentation and observational methods to causal inference
+ Strong coding experience. Experience with open-source ML packages (specifically sklearn, TensorFlow/Keras/PyTorch).
+ tech stack:
	- 5+ years of research experience with a track record of delivering quality results
	- Expertise in machine learning spanning supervised and unsupervised learning methods
	- Experience in successfully applying machine learning to real-world problems
	- Strong mathematical skills with knowledge of statistical methods
	- Strong software development experience in languages such as Scala, Java, Python, C++ or C#
	- Great interpersonal skills
	- PhD or MS in Computer Science, Statistics, or related field
	- Experience in Recommendation Systems, Personalization, Search, or Computational Advertising
	- Experience using Deep Learning, Bandits, Probabilistic Graphical Models, or Reinforcement Learning in real applications
	- Experience in optimization algorithms and numerical computation
	- Experience with Spark, TensorFlow, or Keras
	- Experience with cloud computing platforms and large web-scale distributed systems
	- Open source contributions
+ tech stack:
	- 5+ years of research experience with a track record of delivering quality results
	- Expertise in machine learning spanning supervised and unsupervised learning methods
	- Experience in contextual multi-armed bandit algorithms and/or reinforcement learning
	- Experience in successfully applying machine learning to real-world problems
	- Strong mathematical skills with knowledge of statistical methods
	- Strong software development experience in languages such as Scala, Java, Python, C++ or C#
	- Great interpersonal skills
	- PhD or MS in Computer Science, Statistics, or related field
	- Recommendation Systems, Personalization, Search, or Computational Advertising
	- Deep Learning or Causal Inference
	- Optimization algorithms and numerical computation
	- Spark, TensorFlow, or Keras
	- Cloud computing platforms and large web-scale distributed systems
+ Expertise in additional statistical methods (e.g., Bayesian approaches, dyadic analysis, causal inference approaches, factor analysis, SEM)
+ Experience with Databricks or Spark, EMR
	- Databricks: data lakehouse architecture, cluster management for computer clusters (in the context of cluster computing), and associated machine learning technology
	- Adobe Spark, or Spark: open-source unified analytics engine for large-scale data processing
		* large-scale, multi-language engine extreme data engineering, data science, and machine learning on single-node machines or clusters
		* for the following tasks:
			+ machine learning
			+ data science, or data analytics, at scale
			+ batch/streaming data
			+ SQL analytics
		* for programming languages:
			+ Python
			+ SQL
			+ Scala
			+ Java
			+ R
	- Amazon Elastic MapReduce, Amazon EMR
		* for applications in:
			+ machine learning
			+ extract, transform, load (ETL)
			+ real-time streaming
			+ genomics
			+ clickstream analysis
		* accessed using:
			+ AWS Command Line Interface, AWS CLI
			+ AWS Console
		* Not EMR, electronic medical record = electronic health record
+ build multivariate simulation data pipelines on a cloud for integration tests
+ skill set:
	- experience with defining, implementing, and analyzing A/B and multivariate experiments
	- capacity as data analysts to work with data engineers and data scientsts as appropriate to design, scope, and work through new projects
	- statistical modeling and analysis in R and/or Python
	- reporting and analysis using major Web analytics tools, such as:
		* Google Analytics
		* Adobe Analytics
		* Parse.ly
		* comScore
		* SimilarWeb
	- analyze data and build dashboards using business intelligence, BI, tools, such as:
		* Data Studio
		* Looker
		* Tableau
	- use SQL-based database applications for handling large data sets:
		* Snowflake
		* BigQuery
		* Athena
		* RedShift
+ A fluidity with tools commonly used for data analysis such as Python (numpy, pandas, and scikit learn), R, and Spark (MLlib).
+ skill set:
	- B.S., M.S., or Ph.D. in a quantitative field
	- 4+ years work experience in an analytical or quantitative role as a Data Scientist
	- 2+ years experience working on product analytics in a two-sided marketplace
	- Extensive experience generating insights using statistical techniques (e.g. regression, hypothesis testing)
	- Demonstrated ability to clearly explain data results to cross-functional teams
	- Experience using a procedural programming language (e.g. Python, R) to manipulate, clean, and analyze data
	- Ability to exercise judgment and combine quantitative skills with intuition and common sense
	- Experience evangelizing best practices and process improvements on your team
	- Experience working with large data sets and distributed computing tools (e.g. Redshift, Presto)
	- Experience pushing code and navigating a complex codebase
	- Active Quora user with curiosity about the product
	- Deep experience with MySQL, NoSQL data stores like HBase or similar
	- Strong grasp of Configuration Management (Chef, Puppet, Ansible, Salt Stack)
+ Experience with SQL and Statistical/mathematical programming software packages (R, SPSS, CPLEX, LONDO or Xpress etc)
+ ***Experience with big data techniques (such as Hadoop, MapReduce, Hive, Pig, Spark)***
+ skill set for data science:
	- ***Technical mastery in one or more of the following languages/tools to wrangle and understand data: Python (NumPy, SciPy, scikit-learn), Spotfire, Tableau.***
	- ***Experience with Spark (MapReduce, PIG, HIVE)***
	- 5+ years of experience with R or Python and some knowledge of SQL and experience with other software environments e.g. SAS, Matlab, Spotfire, Tableau, Qlikview, SPSS, KNIME and/or other data mining tools. Experience with other software components for data preparation and integration e.g. Data Virtualization and Big Data tools such as Hadoop and Spark and/or further programming or scripting environments e.g. .Net, Java, IronPython, Javascript, C++ is a plus.
	- 5+ years of experience with R or Python and some knowledge of SQL and experience with other software environments e.g. SAS, Matlab, Spotfire, Tableau, Qlikview, SPSS, KNIME and/or other data mining tools. Experience with other software components for data preparation and integration e.g. Data Virtualization and Big Data tools such as Hadoop and Spark and/or further programming or scripting environments e.g. .Net, Java, IronPython, Javascript, C++ is a plus.
+ data science:
	- Knowledge of ElasticSearch/Solr/Lucene is a big plus.
	- Understanding in Java server platform and system tuning is a plus.
	- Knowledge with vector space models, text classification and categorization.
	- Implement high-quality code in an agile software development environment.
+ data science skill set:
	- Implement scalable algorithms and services using technologies such as Scala, Akka, elasticsearch, Kafka, Cassandra and Hadoop technologies such as Hive, Spark or MapReduce
	- Hands-on experience in analyzing large datasets (e.g. with SQL, Python, R, Hive, etc.)
	- Some knowledge and experience in working with technologies such as Kafka, Cassandra, Elasticsearch, Akka, Kubernetes, etc.
	- Experience in Scala or Java is a plus
	- You are fluent in English; German skills are a plus
+ skill set:
	- Python
	- R
	- SQL
	- Jupyter Notebooks
	- Tableau
	- Looker Studio
+ skill set:
	- Data Scientist
	- Algorithmically agile including experience with a variety of classical and deep learning based machine learning capabilities. Should be familiar with packages like scikit-learn, keras, spacy, open cv, tensorflow, pytorch.
	- Strong programming skills including at least 1 dynamic (preferably Python) and 1 compiled language (e.g. Java, Scala, C++).
	- BS or advanced degree (MS or PhD preferred) in computer science, engineering, or related technical field.
	- Great communication skills including the ability to communicate directly with customers communicating challenging machine learning concepts. Ability to create great data visualizations is necessary.
	- Experience working in a distributed computing environment.
	- Published academic work in core machine learning (ML) and/or open-source NLP software contributions.
	- Experience developing, testing, and shipping production software.
	- Knowledge of cloud services in AWS, for example EC2, S3, etc.
	- Familiarity with distributed source control management system such as GIT.
	- Experience accelerating startups and working on green space problems.
	- Passionate about building innovative products that delight customers
	- Excited to work on multiple ML problems in a variety of domains with different data types
	- Fun to work with and thrilled to make an impact
	- The type that doesn't whine or complain, but rather tries and instigates change or disagrees and still commits
	- Thrilled to work on a small team of full stack data scientists
+ skill set:
	- Data Scientist, Generative AI
	- Scale is looking for a data scientist to join our team to help advance the development of AI. As a member of the data science team, you will lead the charge of building our data science infrastructure for Gen AI products and driving insights that lead to step-function improvements in how we operate. The ideal candidate is detail oriented, rigorous about validating results, talented at distilling down complexity, and loves tackling and solving hard problems.
	- Build evaluation frameworks to measure LLMs efficacy, ground truth dataset quality, and guide product development roadmap
	- Adapt statistical models to solve specific hard problems in fields of economics, price theory, and marketplace experimentation
	- Be a proactive partner to your business stakeholders and provide insights and conclusions rather than just data outputs/models
	- Tackle business-critical questions by developing and testing hypotheses, and aid evidence-based decision making
	- Partner with Product Managers, Data Engineers, Data Scientists, and Business Stakeholders to drive business decisions and product roadmaps
	- 4+ years of industry experience in a highly analytical role
	- Degree in a quantitative field (e.g., Maths, Engineering)
	- Expert-level proficiency in writing complex SQL queries across large datasets
	- Experience NLP/NLU models
	- Strong proficiency in python, experience in writing production-grade code
	- Expertise in designing metrics and diagnosing data inconsistencies
+ skill set:
	- Experience working with non-Transact-SQL databases and SQL dialects, preferably Oracle PL/SQL or Cerner Command Language
	- Experience with large-scale data analysis systems, such as Databricks, Hadoop, Pig, Scala, Spark or MPP databases
+ skill set:
	- The role's primary technologies include Graphistry, Cypher+SPARQL, Python, Jupyter, StreamLit, pandas / RAPIDS.ai, Docker, React, and Linux/AWS/Azure. Of additional interest are graph neural networks, huggingface, mlflow, networkx/graphx, Tableau/PowerBI, and SQL.
	- Required: Comfortable with pydata - Python, Jupyter, pandas, viz, cloud (Linux/AWS/Azure)
	- Ideal: Experience with graphs - databases (cypher/sparql), algorithms, visualizations, & neural networks; Dashboarding (StreamLit/Ploty/Tableau/PowerBI/...); GPU PyData (RAPIDS, Tensorflow, numba, ...)
	- Required: Comfortable with coding (Python, minor HTML/JS/CSS)  and/or ML (hands-on or courses around linear algebra, statistics, classical ML, neural networks)
+ skill set:
	- You will collaborate with our users, technology partners, and Graphistry staff as part of a new locally-based team and growing community. Together, you will augment security data platforms with Graphistry's graph AI and GPU visualization capabilities. Due to your privileged access, you will be a key innovator and implementer. The role provides significant room for growth, ownership, and startup experience. You will have day-to-day flexibility and competitive compensation.
	- Develop, deploy, and iterate on visual and automated security AI solutions for detection, correlation, recommendation, prioritization, and investigation
	- Learn, develop, integrate, and scale using graph neural networks, end-to-end GPU acceleration, vector search, UMAP, and other AI technologies in the Graphistry ecosystem, including Nvidia RAPIDS, Nvidia Morpheus, DGL, PyTorch, and PyGraphistry[AI]
	- Share knowledge through public speaking opportunities, private trainings & presentations, customer demos, and tutorials & blog posts on topics such using the Graphistry ecosystem and workflows you build on top to tackle problems like cybersecurity investigations, anti-misinformation, and anti-fraud
	- Enjoy Python and PyData ecosystem: Linux/Docker, notebooks, dataframes, visualization
	- Experienced with neural networks, time series analysis, classical machine learning, underlying math, and computing over GB+ datasets
	- Experienced with cybersecurity use cases, or equivalent digital forensic scenarios like fraud or sigint, such as for anomaly detection, entity fingerprinting, and analyzing machine logs from large systems
	- Developed and deployed security AI models in operational settings
	- Used GPU computing, including in bigger-than-memory settings
	- Used graph technologies like graph databases, graph analytics, graph visualization, and graph AI, and especially in at-scale detection and investigative scenarios
	- Strong communicator in-person, in writing, and in presentations
	- History of project leadership & ownership from both a technical perspective and business
	- Graphistry is a visual graph AI startup that spun out of UC Berkeley to accelerate investigation processes. It is a Gartner Cool Vendor and features the first GPU-accelerated visual graph analysis environment, low-code investigation automation, autoML for deploying graph AI, and integrates with popular data science & database technologies. Profitably growing 3X+ year-over-year, Graphistry is helping enterprise, tech, and public sector teams begin their modern graph journey, especially around digital crime and commercial analytics. It helped start the modern GPU dataframe compute movement (Apache Arrow, Nvidia RAPIDS) and is working to scale & democratize graph neural networks.
+ Experience with Google Analytics, MixPanel, and content optimization tools
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.



















Sets of skills for more senior data science roles, such as senior data scientists and management of data science teams (i.e., data science managers):
+ Sr. Data Scientist
	- Amida Technology Solutions is a DC-based technology company focused on solutions for data interoperability, data utility, and data security. We create open-source solutions that collect, reconcile, transform, and standardize data for business intelligence, predictive analytics, decision support, and user transactions. We specialize in taking data from inception to impact.
	- Our team is comprised of creative, forward thinkers who are passionate about using cutting-edge technology to make a difference in people's lives and have a positive impact on our country. We offer an entrepreneurial, high-growth environment that values fresh ideas, candid conversations, and authentic teamwork.
	- Amida is currently looking for a Senior Data Scientist to join our team in Washington, DC. In this role you will work across our client engagements, providing expertise in machine learning algorithms, natural language processing (NLP), data collection, data analysis, data mapping, data profiling, data mining, data modeling, and data visualization. You will architect data science solutions on the cloud using AWS or Azure data science services and participate in the implementation of the solutions. You will help with the business development activities and will be responsible to describe data science solutions in our proposals.
	- Lend your expertise in the development of solutions using machine learning, NLP, data profiling, and/or data mining to projects and proposals across the company
	- Use expertise in machine learning to design and implement predictive models for diverse fields such as health claim processing and electronic design automation
	- Use expertise in NLP methods and healthcare data to identify relevant open-source NLP models and adapt them to free text data
	- Leverage modern ML/NLP methodologies (e.g., deep learning), computing hardware (e.g., GPUs), cloud infrastructure (AWS/Azure), open-source modeling frameworks (e.g., TensorFlow, Keras, PyTorch, XGBoost)
	- Develop standardized evaluation and validation frameworks for current and future work
	- Create training materials for colleagues at different levels of experience
	- Identify, create, and curate training datasets
	- M.S. and/or Ph.D. in a quantitative field such as Computer Science, Statistics, or Mathematics (or related)
	- 7+ years of recent professional experience in data science, data mining, data analysis, business process analysis, and/or healthcare analytics
	- 5+ years working with Machine Learning and/or Natural Language Processing (in particular, Named Entity Recognition) methodologies
	- 5+ years of programming experience in Python
	- 3+ years of experience using Machine Learning tools, deploying models, and deploying software in Azure or Amazon Web Services (AWS) preferably holding certifications
	- Experience to model data in Graphs
	- Experience using Graph databases
	- Experience contributing to proposals preferably in federal government contracting
	- Ability to conduct data profiling and predictive analysis using a variety of standard tools
	- Experience with data visualization tools and methodologies
	- Excellent ability to communicate concisely and effectively with software engineers and clients
	- Ability to obtain a Public Trust security clearance
	- Previous experience in Knowledge Graphs and Graph Neural Networks
	- Previous experience working with Databricks
	- Prior experience working with healthcare data, or in the Healthcare field
	- Previous experience working with government clients such as Dept. of Defense (DoD), Dept. of Veterans Affairs (VA), or The Centers for Medicare & Medicaid Services (CMS)
	- Prior experience with metadata management to include meta-tagging
	- Previous experience working in an Agile Team setting and using Agile management tools such as Jira
	- Experience conducting business process analysis to identify gaps and inefficiencies
	- Ability to uncover data-driven insights using statistical analysis or predictive analytics
	- Communication is the key to success at Amida. Our people are known for their can-do attitude and their ability to work effectively with client teams. We pride ourselves on having a collegial, multidisciplinary team with diverse backgrounds and experience. Our best team members pay intense attention to detail in all aspects of their work, have a strong sense of initiative, and are willing to be opinionated about the best ways of doing things. A sense of humor is an asset at Amida.
	- We help solve the biggest challenges in data management. If you're looking for an opportunity to help important organizations get their data right, we hope you'll forward your resume and let us know why this role appeals to you. We look forward to hearing from you.
+ skill set:
	- develop programs for data transformation, integration, or reduction;
	- prototype and ship production-grade applications for (among others) data coding, entity resolution, predictive analytics, data visualization, data dashboards, and report generation;
	- perform custom data analysis to support all phases of the data collection and research pipeline;
	- design and implement research plans for program evaluation, using both experimental and quasi-experimental methods;
	- participate in business development, including researching and crafting sections of technical proposals;
	- coordinate and conduct internal data science presentations and workshops;
	- communicate research findings to colleagues, clients, and research peers across a range of media;
	- keep current with innovations and trends in data science and survey methodology.
	- An advanced (Masters or above) degree in one of the following fields is required: math, statistics, computer science, data science, or a social science or public policy related field.
	- At least five years' experience in positions of increasing responsibility in a research or data analysis role, which may include graduate-level training at the PhD level or equivalent experience in applied research, is required.
	- Proficiency in statistics and statistical methods (e.g. probability, regression, generalized linear models) is required.
	- Proficiency in at least one of R or Python and their packages for data manipulation, visualization, statistics, and machine learning is required.
	- Experience in communicating scientific research to both specialist and general audiences is required.
	- Familiarity and interest in social scientific and public policy research, as well as applications of data scientific methods to such research, is preferred.
	- Familiarity with methods for causal inference, including the potential outcomes framework, experimental design, and quasi-experimental designs (e.g. difference-in-differences, instrumental variables, regression discontinuity), is preferred.
	- Experience in conducting original research – either independently or as a member of a research group or lab – including research design, novel data collections, data analysis, and preparation of papers, posters, or other presentations, is preferred.
	- Familiarity with areas of data science such as multi-level modeling, machine learning (e.g. methods for regularization, classification, and clustering), natural language processing (text pre-processing, text classification, named entity recognition, etc.), computer vision (e.g. image classification, image object detection), or deep learning libraries is preferred.
	- Familiarity with Bayesian estimation and software for Bayesian inference (e.g. JAGS, Stan) is preferred.
	- Experience with version control workflows and tools (e.g. Git), databases (e.g. SQL), big data technologies (Hadoop, Spark, Hive, etc.), and cloud computing environments (e.g. AWS, Google Cloud, Azure, etc.) is preferred.
+ skill set:
	- At the heart of Netflix Product Innovations is an experimentation driven culture led by Science & Analytics (S&A).  In this role, you will lead teams of data scientists and analysts responsible for shaping UI and Content Innovations decisions through experimentation (A/B, quasi) and empirical studies to guide product strategy.
	- Set an impact-focused, strategic science roadmap to guide product innovations.
	- Recruit and inspire exceptional data scientists focused on the span of causal inference, behavioral research, and analytical activities.
	- Uphold the culture of rigor in product decision-making through active participation in product debates.
	- Lead and contribute to cross functional initiatives between product development (product management, design, engineering), content, and marketing.
	- Define a team culture that balances supporting high impact business needs with forward looking research.
	- Serve as thought partner to product development executives across product management, engineering, and design.
	- 5+ years experience in building and inspiring a high-performing data science and analytics team.
	- Capacity and passion to translate business objectives into actionable analyses, and analytic results into business and product recommendations
+ skill set:
	- Starsky Robotics is looking for a full-time Senior Data Scientist. Your job will tackle a wide variety of problems in autonomous vehicles. From finding every time a car cut in front of our truck, to figuring out how to report on the quality of autonomous driving, to creating new tools and statistical methods for robotics engineers to characterize the behavior of their systems, we're looking for someone motivated to attack self-driving problems with mounds of data. Tackling these problems will require learning about the whole suite of robotics fields applied to make autonomous vehicles: motion planning, controls, perception, and behavior planning.
	- You'll own high-level decisions such as “How do we determine if a route fits our current driving capabilities”. Day-to-day projects may have mission statements as technical as “Help us solve this spike in cross-track error on curves”, or as business-focused as “Can we get a heatmap of all the places our trucks have driven over the last year”.
	- Additionally, you can bring best-practices for data-science to the company, including helping build up the base platform and infrastructure necessary to speed up data-centric work. Starsky has a solid base of tooling around our data, but it is ripe for improvement.
	- Demonstrated expertise in the data scientists modern toolkit: Pandas, R, SQL, etc, and don't mind sharing your experience with the team
	- Deep quantitative thinker: Masters or PhD in a quantitative field, or multiple years of experience in a quantitative-focused position
	- Relish delivering answers and metrics and seeing change affected by your work
	- Can take high level directives and take them through from research project, proof of concept, to applied & implemented feature.
	- Are constantly looking for problems that could be solved with liberal application of data
+ skill set:
	- AIML - Head of Data Engineering, Data & Machine Learning Innovation
	- Are you passionate about data, data quality, efficiency, and scale?  Would you like to play a critical part in accelerating data-informed product development to drive innovations and amazing user experiences?
	- As the Head of Data Engineering, you and your team will be responsible for the crucial role of designing, operating, and supporting the increasingly complex environments that power modern data analytics and machine learning use cases for Apple products such as Siri, Dictation, Translations, Apple Search and others.
	- You will partner closely with cross-functional teams and be responsible for the planning, execution, and success of technical projects as well as help drive scalable practices to accelerate the evolution of our products. You will lead existing data resources, build new datasets and data pipelines, and implement new technologies and tools to enable rigorous scalable science and analytics, and data-informed product development. Your team and vision will enable data to inform product engineering teams at scale, with the ultimate purpose of improving the product experience for Apple users across hardware, software, and services, while preserving Apple's privacy values. You will drive a strong culture of data excellence!
	- 10 years in a managerial role, growing and scaling organizations
	- Experience in multiple large-scale data processing systems, data telemetry, data-driven performance and reliability improvement across platforms and products, the data foundation for advanced machine learning problems, and data/analytics.
	- Demonstrated passion and leadership in data engineering, data-informed product development, building and shaping data culture
	- Proven ability to proactively drive a data engineering agenda and prioritize work based on impact and strategic investment
	- Experience with modern data engineering stack, processing technologies, data, and analytic pipelines, including batch (Spark, others), streaming systems (Flink, etc.), and scalable query engines (e.g. Trino, Druid, Pinot, etc.)
	- Solid understanding of both relational and NoSQL database technologies and experience in engineering datasets and metrics out of massive and complex data
	- Expertise in data engineering partnering with analytics and ML teams (comprised of data scientists and statisticians) to enable horizontal and vertical use cases
	- Demonstrated ability to establish strong partnerships and drive processes across organizations, e.g. to manage the creation, processing, and use of instrumentation to enable using data impactfully in developing products
	- Outstanding communication and presentation skills, written and verbal, to all levels of an organization
	- Proactively drive the vision for Data Warehouse, Data Platform, Analytics, and ML analytics to accelerate the building and improvement of our products, and define and execute a plan to achieve that vision.
	- Grow and scale a large, established data engineering team and build strong relationships with partner teams
	- Drive the design, building, and launching of new data models and data pipelines in production
	- Stay focused and prioritize a heavy workload while achieving exceptional quality and driving long-term vision
	- Bachelors or Master in CS, Engineering, Math, Statistics, or a related field, or equivalent practical experience in engineering
+ skill set:
	- The FSQ BI app manager will lead a small team of Backend and Frontend engineers to build and develop the FSQ BI application. The candidate should have a relevant background in building analytic dashboard products, with an understanding of basic SQL, charts, and maps.
	- Manage, lead, and coach a team of backend and frontend engineers to develop the FSQ business intelligence application
	- Own the team's technical roadmap and direction, working closely with Product Management, Program Management, Client Success, Engineering, and stakeholders to achieve company goals
	- Lead the development of a scalable and robust application stack for delivering business intelligence dashboards
	- Contribute hands-on engineering solutions as needed
	- Partner with engineering, product teams, and department stakeholders to drive forward broader engineering and company initiatives
	- Recruit talent to grow the team in line with Foursquare company growth and priorities
	- Proven experience with business intelligence application development, and building data analytic products
	- In-depth knowledge of data analytic concepts, tools, and methodologies
	- Hands-on experience with data analytics tools (e.g., Tableau, Power BI, SQL, Python, etc.)
	- Familiarity with data modeling, ETL processes, and data warehousing techniques
	- Knowledge of data visualization, charts, and maps
	- Familiarity with cloud platforms (e.g., AWS, Azure, GCP) and data warehouses (e.g., BigQuery, Snowflake)
+ skill set:
	- Data Science & Engineering Manager - Auction/Yield, Ad Platforms
	- At Apple, we work every single day to build products that enrich people's lives! Our Advertising Platforms group makes it possible for people around the world to easily access informative and visionary content on their devices while helping publishers and developers promote and monetize their work. We are a team of passionate scientists and technologists, dedicated to helping publishers and developers find their audience, and changing the way advertising works with data. Our technology and services power advertising in Apple News and Search Ads in App Store. Our platforms are highly-performant, deployed at scale, and setting new standards for enabling effective advertising while protecting user privacy. Our auctions power rapidly growing marketplaces and are critical to the health and diversity of our ecosystem.
	- We are looking for an exceptional data science and engineering manager who can thrive in a fast-paced environment and is highly knowledgeable in the space of auctions and marketplace optimization for online advertising. You will lead teams and systems that drive marketplace optimization, budget pacing, pricing, and winner selection algorithms. You will drive the conception, development, and delivery of innovative capabilities that differentiate our products and are core to our business. You should have experience developing and implementing machine learning algorithms, ideally within the ads space. You will have an excellent understanding of scalable architectures and thrive working in Agile environments.
	- Recognized expertise in the areas of marketplace optimization and auction theory.
	- Demonstrated success mentoring and growing a team technically as well as developing growth plans for its members.
	- Ability to apply and implement research concepts, ultimately in production quality code.
	- Experience defining clear, testable research hypotheses, including intended impact on the business.
	- Deep knowledge of design of experiments, online experimentation approaches, preferably at scale.
	- Ability to formulate and advocate for R&D objectives and results to multi-functional team members including executive business leadership and product management.
	- Experience contributing and/or reviewing research for top conferences and publications.
	- Experience owing real time production systems.
	- Deep fluency in Java or Python.
	- Experience with Spark, Hadoop or other distributed frameworks.
	- You will have the opportunity to work on optimizing a marketplace that serves ads millions of times a day. You will own the auction systems and marketplace optimization framework which have strong requirements for both technical SLA performance and delivering a fair and vibrant marketplace for discovery. We operate a platform with extreme scale requirements and value. 
	- You will, in partnership with our product management colleagues, propose, design and analyze new features and algorithms to improve the performance of our auctions. You will work closely with operational teams on deployment, monitoring, management concerns. You will participate and lead Apple internal Data Science & Machine learning interest groups, meet ups, and conferences. You will join a team passionate about data privacy, fairness, and trust, with profound responsibility to ensure those things, while protecting the value our customers and developers count on from our advertising products for.
	- PhD in a quantitative field (or BS/MS with equivalent work experience) with 5+ years experience in managing a data science team.
+ skill set:
	- Senior Data Scientist (Remote)
	- Quora is a "remote-first" company. This position can be performed remotely from anywhere in North America. Please visit careers.quora.com/eligible-countries for details regarding employment eligibility by country.
	- Quora's mission is to grow and share the world's knowledge. To do so, we have two knowledge sharing products:
		* Quora: a global knowledge sharing platform with over 400M monthly unique visitors, bringing people together to share insights on various topics and providing a unique platform to learn and connect with others.
		* Poe: a platform that lets people ask questions, get instant answers, and have back-and-forth dialogue with various AI language models (bots). As AI capabilities rapidly advance, Poe provides a single platform to instantly integrate and utilize these new models.
	- Behind these products are passionate, collaborative, and high-performing global teams. We have a culture rooted in transparency, idea-sharing, and experimentation that allows us to celebrate success and grow together through meaningful work. Join us on this journey to create a positive impact and make a significant change in the world.
	- The Data Team is highly empowered at Quora, helping navigate complexity and influencing product and company strategy directly. Quora's outsized commitment to data is visible in everything we do, from our rigor-driven experimentation processes to the backgrounds of our leaders. With this emphasis on data and empirics, we aim to balance rigor and pragmatism, searching for scrappy solutions in pursuit of our mission. In joining Quora's strong data team, you'll both benefit from and work to advance our culture of rational decision making.
	- As a member of our team, you'll work closely with product managers, product designers, and engineers to devise appropriate measurements and metrics, design randomized controlled experiments, build visualizations, and tackle hard, open-ended problems that uncover usage patterns and opportunities for the company. Quora has a wide range of rich data, giving you ample room for exploration and creativity. Examples of some projects our data scientists have worked on include modeling our long-term growth, improving the relevance and personalization of the homepage feed, and exploratory analysis of factors driving question-asking behavior. For more about our work, see Quora's Data blog at https://data.quora.com/.
	- As a Senior Data Scientist, you will draw on your experience to excel not only in your own work but also to elevate data's impact at a company-wide level. You will provide team mentorship that propels the work of your colleagues while helping to establish best practices for data usage across Quora.
	- Extract actionable insights from broad, open-ended questions
	- Design and evaluate experiments to measure the impact of product changes
	- Analyze data from across the product to uncover the root causes of metric movements
	- Communicate results to cross-functional stakeholders to inform product decisions
	- Develop tools to scale and automate analyses, improving productivity across the company
	- Improve the work of other data scientists through mentorship and by bringing industry best practices to the team
	- Ability to be available for meetings and impromptu communication during Quora's “coordination hours" (Mon-Fri: 9am-3pm Pacific Time)
	- 3+ years work experience in an analytical or quantitative role as a Data Scientist or similar title
	- 2+ years experience working on product analytics
	- Extensive experience generating insights using statistical techniques (e.g. regression, hypothesis testing)
	- Demonstrated ability to clearly explain data results to cross-functional teams
	- Experience using a procedural programming language (e.g. Python, R) to manipulate, clean, and analyze data
	- Ability to exercise judgment and combine quantitative skills with intuition and common sense
	- Experience evangelizing best practices and process improvements on your team
	- Experience working with large data sets and distributed computing tools (e.g. Redshift, Presto)
	- Experience pushing code and navigating a complex codebase
	- Active Quora user with curiosity about the product
	- At Quora, we value diversity and inclusivity and welcome individuals from all backgrounds, including marginalized or underrepresented groups in tech, to apply for our job openings. We encourage all candidates who share a passion for growing the world's knowledge, even those who may not strictly meet all the preferred requirements, to apply, as we know that a diverse range of perspectives can have a significant impact on our products and our culture.
	- US candidates only: For Colorado based applicants, the minimum base salary range is $122,000 - $171,000 USD + equity + benefits. For California, New Jersey, New York, and Washington based applicants, the minimum salary range is $122,000 - $201,000 USD + equity + benefits.
	- British Columbia Candidates Only: For British Columbia based applicants, the minimum base salary range is $122,000 - $201,000 CAD + equity + benefits.
+ skill set:
	- LEAD DATA SCIENTIST
	- The annual base salary for this position ranges from $112,600.00 in our lowest geographic market to $251,800.00 in our highest geographic market. Actual salary will vary based on a candidate's location, qualifications, skills and experience.
	- We need an experienced Data Scientist to join our Digital planning and analytics team. You are an extraordinary, driven teammate with a curiosity for all things data, and while you rely on data to prove your point, you love to think creatively to solve problems. You build novel models and algorithms to solve business problems, deliver insights, and drive recommendations. You thrive in an entrepreneurial environment, and you are excited by the challenge of building something from the ground up.  You ask questions, are continually learning as well as finding opportunities to share knowledge with others. You are a strong communicator who is endlessly curious, takes pride in hard work and is committed to rapidly advancing your knowledge and expertise.
	- As a Data Scientist, you will work with the Digital Supply Chain team to ensure Nike delivers an elevated consumer experience, using data.  You will build demand forecasts for our regional distribution network to inform capacity planning, develop models that optimize inventory placement, simulate SKU velocities to plan new facilities against capacity and inventory constraints, and transform ad hoc analyses into scalable solutions and tools that can provide repeatable insights for the business.  You will share your results and recommendations with a broad and senior audience, inspiring change in the organization by making analytics part of day-to-day business strategy.  You'll also track model accuracy, ensuring model relevance and reliability.
	- As a member of Nike's North America Digital Marketplace Operations team, you will work alongside experienced analytics and supply chain professionals passionate about driving operational efficiency and better serving athletes* digitally. You will be reporting into the North America Digital Marketplace Operations Analytics leader, liaising closely with business strategy, Marketplace Operations, and Logistics (DC & Transportation) teams as well as product squads consisting of senior data scientists and engineers.  You will collaborate with other data scientists across teams to problem solve and share best practices.
	- 3+ years of relevant professional experience.
	- Strong ability to solve complex analytical problems and take a new perspective on existing solutions.
	- Strong understanding of common coding languages (Python, SQL, R) with demonstrated ability to learn new skills or apply skills in new environments.
	- Strong quantitative and analytics background, with experience in statistical modeling, and visualization.  Exposure to or experience in data engineering preferred.
	- Deep understanding of solution and technical design.
	- Demonstrated ability to work well with internal and external customers.
	- Strong collaboration skills with a demonstrated ability of working well within a team.
	- Bachelor's degree in Mathematics, Statistics, or quantitative field; or equivalent combination of education and experience.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.












####	Data Visualization






Skill sets for data visualization:
+ data visualization libraries and tools:
	- Ggplot/ggplot2
	- Seaborn
	- D3.js
	- Matplotlib
	- Bokeh
	- Plotly / Plotly Express
	- Altair
	- Geoplotlib
	- Shiny
	- Leaflet / Folium
+ data visualization with the following tools and/or libraries:
	- Plotly
	- Tableau
	- PowerBI
	- Qlik
	- Google Charts
	- d3.js
	- plotly.js
	- Angular.js
	- PowerBI
+ Producing effective and interactive data visualizations (Tableau, Shiny, D3)
+ Bonus points for experience building interactive data visualizations using libraries like D3, Highcharts, and Leaflet, and for experience working with big data systems like Hive, Hadoop, Scalding and Spark.
+ illustrate visualization ideas using storyboards, process flows, wireframes, and prototypes
+ [Plus] Familiarity with interactive data visualization using tools like D3.js
+ metrics systems:
	- ***Grafana.***
+ skill set:
	- experience in the use of data visualization libraries (d3.js, Processing);
	- knowledge of tools and languages for data analysis and visualization (eg Tableau, R, Python, Gephi, NodeBox);
	- interest and propensity to learn work dynamics in an international company, dealing with highly innovative and experimental projects;
	- academic background in information design and data visualization;
	- experience in the design and implementation of static and / or interactive data visualizations and infographics;
	- imagine, design and collaborate with UX / UI and development teams to create static and interactive data visualizations, infographics, reports and dashboards;
	- interact and design solutions with customers that can satisfy both explicit and unidentified needs.


















####	Data Science for Social Media Companies



+ skill set:
	- The Consumer Data Science organization works closely with our cross-functional partners, and Twitter's leadership to understand user behavior, inform product decisions, safeguard the health and integrity of our services, and to influence company strategy. We are currently hiring for the following subteams on Consumer Data Science. These high-impact teams value creativity, critical thinking, and teamwork.
	- The Consumer Data Science organization is hiring Senior Data Scientists in the following areas:
		* Health (SF, Boulder) - The goal of this team is to improve the health of the public conversation, ensuring that users feel safe while using our platform. As part of our team, you'll help the Health Organization make strategic decisions that ensure that Twitter is a safe and informative experience for our customers. You will do this by performing and mentoring others through analyses, metrics, experimentation, research, and more.
		* Growth (SF) - Their mission is to increase Twitter's daily utility for new and returning users through impactful and creative applications of experimentation and data analysis. As a key member of Growth Data Science, your work will directly influence exciting new product areas and help grow Twitter usage around the globe.
		* Metrics (SF) - This team works to support company strategy by helping to define, maintain, and understand key success metrics to ensure that we continue to meet the demands of our customers.
		* Video (NY) - This team works with the Live Video, Video on Demand, Publishers, and Camera products. The team is involved in opportunity sizing, experiment setup and analysis, and metric design in order to influence video and media strategy at Twitter.
	- Support the entire product development lifecycle from product ideation to opportunity sizing to measurement design to experimentation and causal analysis to post-launch learning and iteration into the next development cycle.
	- "Design and implement experiments or other econometric methods to understand how changes to the platform affect user behavior."
	- Build novel metrics, identify the impact of product and policies, and study causal impact of our Product launches and Health initiatives.
	- Work in tandem with team members, applying advanced statistical methods; writing complex data flows using multiple languages/frameworks such as SQL, Scala (Scalding, Spark), Python; and using data visualization tools.
	- Communicate findings to executives and cross-functional stakeholders.
	- You are a self-starter who is capable of learning on the job, taking initiative, and thriving within a large team.
	- You are excited to learn and apply new data analysis techniques and tools. You are passionate about insights, not just data and methods. You are a strategic thinker and are able to synthesize technical concepts into actionable recommendations for a diverse audience.
	- You communicate your findings clearly and effectively to a wide audience of relevant partners and are capable of building meaningful presentations and analyses that tell a story.
	- You are rigorous, care about data quality, and strive to understand surprising results and underlying mechanisms in your analyses. You combine business insight with detailed data knowledge and statistical expertise to ensure an accurate interpretation of results.
	- You are a capable mentor. You enjoy knowledge sharing and working with junior teammates to up-level their skills and take the time to learn from them.
	- You value teamwork and teammates. You contribute positively and meaningfully to cultivate an inclusive team culture. You are personable, empathetic, and able to connect with each and every person on the team and throughout the company.
	- Experience using SQL, R, or Python for analysis, modeling, and data visualization.
	- 5+ years experience working with and analyzing large datasets to understand behavior, solve problems, and answer business questions.












###	Business Analytics



This subsubsection includes the following topics of business analytics, except financial analytics which is found in the following *Markdown* document for [Financial Engineering, Computational Finance, and Financial Analytics]().
+ [Marketing Analytics]()
+ [Human Resource Analytics]()
+ [Data Science for Logistics, Supply Chain Management, Industrial Distribution, & Retail Sales]()




Skill sets for business analytics:
+ business intelligence tools:
	- Domo
	- Tableau
	- Microsoft Power BI
	- Looker
	- Salesforce
	- SAP Analytics Cloud
	- TIBCO Spotfire
	- Sisense
	- Alteryx
	- Einstein Analytics
	- Google Data Studio
	- Qlik
	- Amazon QuickSight
+ Form and validate data-driven hypotheses for accelerating customer retention and revenue, working closely with engineering, design, marketing, and analytics
+ ***Own and optimize P&L and adoption KPIs for the business.***
+ skill set:
	- Gather business requirements and create technical requirements for statistical analytics solutions.
	- Create data processing systems for production purposes.
	- Using established Nielsen development, testing and deployment practices, draft design documents that are presented to internal and external stakeholders.
	- Present material to internal department stakeholders.
	- Partner with the Software Engineering department to build best-of-class Cloud-based analytical solutions based on the Agile solutions development methodology.
	- Implement statistical and econometric models.
	- Analyze (i.e., to determine the quality of) econometric models, and implement and analyze supervised and unsupervised learning approaches.
	- Write modules for Nielsen analytics platform.
	- Prototype and design analytic methods.
	- Extract, and conduct quality assurance for, market research/marketing, economic and company data from different external and internal platforms.
	- Conduct research to identify new quality assurance measures.
	- Train and mentor (without supervisory authority) 1-2 Data Scientists.
	- Involves domestic travel, 1-2 times per year, for up to 2-3 days per trip.
	- Tools used include: SQL, Python, Pandas, Scikit Learn, R, Spark MLib and Scala.
	- Master's degree in statistics, mathematics, economics, or a related hard science, social science or engineering field with a quantitative focus, such as computer science or engineering, physics, chemistry or sociology (foreign equivalent degree acceptable) plus 3 years of experience in conducting data modeling and statistical analysis using large and complex (at least 10 GB) datasets (would also accept a Ph.D. in such a field plus 1 year of experience).
	- 3 years of experience (or 1 year of experience after a Ph.D.) in/with:
		* gathering data requirements for statistical, econometric and/or predictive analytics research that drives market research/marketing analytics product innovation and implementation
		* handling large volumes (at least 10 GB) of structured and unstructured data
		* Python and its libraries (such as Pandas, Numypy and/or SciKit Learn), SQL, Spark, and R, all via a Cloud-based platform (such as AWS and/or Azure)
		* 1 year of experience in/with: building efficient data processing pipelines for analytical systems; and Airflow
		* Must be willing to travel domestically, 1-2 times per year, for 2-3 days per trip.
+ skill set:
	- Field tools like TargetSMART, NGP VAN, and EveryAction
	- Digital tools like ThruText, ThruTalk, ActionKit, and Google / Facebook ads
	- Data warehousing tools like Civis Platform
	- Dashboard tools like Periscope and Tableau
	- Familiarity with NGP-VAN required; Catalist and Targetsmart helpful, but not required
+ skill set:
	- Minimum of 3 years' delivery experience in advanced modeling environment: strong understanding of statistical concepts and predictive modeling. (e.g., AI neural networks, multi-scalar dimensional models, logistic regression techniques, machine-based learning, big data platforms, SQL, etc.).
	- Minimum 3 years' experience with predictive analytics tools, including at least two of the following: R, SAS, Alteryx, Python, Spark, and Tableau.
	- Experience in the following areas: Applied Statistics/Econometrics, Statistical Programming, Database Management & Operations, Digital, Comparative Effectiveness Research.
	- Possess a blend of marketing acumen, consulting expertise and analytical capabilities that can create value and insights for our clients.
+ You're familiar with business intelligence reporting platforms like OBIEE, Tableau, MicroStrategy, and Business Objects
+ skill set:
	- Work with large, complex data sets. Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed. Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations.
	- Build and prototype analysis pipelines iteratively to provide insights at scale.
	- Develop comprehensive knowledge of TikTok data structures and metrics, advocating for changes where needed for product development.
	- Interact cross-functionally, making business recommendations (e.g., cost-benefit, forecasting, experiment analysis) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information.
	- Research and develop analysis, forecasting, and optimization methods to improve the quality of TikTok ads products.
	- Master's degree in a quantitative discipline (e.g., Statistics, Operations Research, 2. Economics, Computer Science, Mathematics, Physics) or equivalent practical experience.
	- 3+ years of relevant work experience, including expertise with statistical data analysis such as linear models, multivariate analysis, stochastic models, sampling methods.
	- Experience with statistical software (e.g. R, Python, MATLAB) and database languages (e.g. SQL)
	- Demonstrated leadership and self-direction. Willingness to both teach others and learn new techniques.
	- Demonstrated skills in selecting the right statistical tools given a data analysis problem. Effective written and verbal communication skills.
+ skill set:
	- 2+ years SQL working experience (Redshift/PostgreSQL/MySQL)
	- Experience with BI & reporting dashboards (Periscope, Tableau, etc)
+ skill set:
	- Use machine learning methods (e.g., cluster analysis, decision trees, random forest, neural networks, logistics regression) to model and predict research outcomes
	- Use advanced mathematical techniques (correlation, regression, time series analysis, analysis of variance, etc.) to forecast outcomes
	- Identify appropriate methods to conduct analyses including simulation methods (e.g., bootstrap, monte carlo, bagging methods), machine learning, and statistical analyses
	- Develop data visualizations to capture trends and summarize data
	- Create reports of data metrics, trends, outliers, etc.
	- Hands on experience with R and/or Python to manipulate and transform data
	- Ability to communicate through graphical representation/visualizations, reports, algorithms, models, and dashboards
	- Process and prepare both structured and unstructured data sets to ensure successful modeling further downstream of the insight generation and modeling process
	- Hands on experience with R, SAS and/or Python to manipulate and transform data
	- Experience working with databases (Teradata, Oracle, SQL and NoSQL dbs) and interpreting data; experience with feature engineering and data wrangling of both unstructured and structured data sets;
	- Exposure to data visualization tools and techniques (matplotlib, ggplot or Tableau);
	- Experience with business case analysis (problem identification, quantitative modeling and problem solving)
+ skill set:
	- enterprise resource planning, ERP
		* ***business intelligence***
			+ customer relationship management, CRM, customer services
			+ sales:
				- invoicing
				- order placement
				- order scheduling
				- shipping
		* e-commerce, electronic commerce
			+ product lifecycle management, PLM
				- planning
				- optimizing manufacturing capacity and material resources
				- manufacturing resource planning, MRP
					* material requirements planning, MRP
			+ supplier relationship management, SRM
				- maximize cost savings with support for the end-to-end procurement and logistic processes
		* enterprise asset management
			+ corporate performance and governance
			+ human resource
		* industrial distribution, logistics, supply chain management, SCM
		* accounting
			+ financial operations
			+ regulatory compliance
+ skill set:
	- SQL
	- Snowflake, Redshift, BigQuery
	- marketing platforms:
		* Facebook Ads
		* Google Ads
		* Appsflyer
		* SA360
		* CM360
		* TikTok ads
	- GeoXExperience
	- Looker, Mode, Tableau
+ PowerBI, Tableau, Qlikview
+ implementing BI solutions in a heavily regulated environment e.g. PII, GDPR, HIPPA & SOX
	- PII, personal identifiable information
	- GDPR, general data protection regulation
	- HIPPA, Health Insurance Portability and Accountability Act
	- SOX
		* Sarbanes-Oxley Act
+ skill set:
	- Utilize tools such as Pentaho, MSSQL SSIS, Microsoft Power BI, Microsoft  Data Factory, Microsoft Data Analytics to build web usage analytic reports.
	- 4-6 years in developing BI reports, dashboards, KPIs, and scorecards.
	- 4-6 years development experience in Data Analytic technologies such as: Pentaho, Microsoft – Power BI or Tableau
	- Experience with Microsoft Azure platform a plus (Data Factory, Data Lake, Data Analytics, Streams)
	- Experience with Solr is a plus
+ skill set:
	- Business Intelligence Developer
	- Unity (NYSE: U) is the world's leading platform for creating and operating real-time 3D (RT3D) content. Creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use Unity to make their imaginations come to life. Unity is the foundation upon which the world's most powerful digital content is created. Specifically, Unity's platform provides a comprehensive set of software solutions to create, run and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices.
	- We are seeking a BI Developer who combines an intense curiosity about data with a strong dedication to practical problem solving for business collaborators. This role will require proficiency in a sophisticated and evolving data model unique in the industry not only for its scale but also in the magnitude of business processes involved. Our team works in close alignment with all business units to understand and conduct research on the analytical requirements of our data projects. Most importantly, we are looking for a keen analytical problem solver who enjoys working with and using data to find exciting insights!
	- As a BI Developer you will make individual contributions, in the form of report and dashboard building, code and pipeline maintenance, testing and documentation, supporting many of our projects in cross-departmental teams including Sales and Developer Relations, Marketing, Finance, Product and Engineering, Data Science, Customer Support and Operations.
	- Design, deployment, and maintenance of BI and data systems:
	- Build supporting pipelines, data models and reports which deliver analytics to a broad audience
	- Translate business requirements into data architecture choices and automate ad hoc processes into robust, performant, highly available, business user-friendly reports
	- Stand up and maintain production quality databases and ETLs with a practical eye towards the end users
	- Provide analysis (in the form of custom queries, reports and dashboards) for partners and internal collaborators under high time pressure when priority demands
	- Experience and competence with a modern data tech stack: SQL (ETL/Database Administrator experience a plus), Python, Github, Apache Airflow, BigQuery, GCS and AWS
	- Experience with Excel/Google Sheets, Tableau and Looker for reports and data visualization
	- Comfortable thinking about data and systems, specifically ad tech data streams
	- Outstanding attention to detail; willingness to understand data at a very deep level
	- Mentorship and presenting technical information
	- The ability to communicate with both technical and non-technical audiences
+ skill set:
	- Senior Data Scientist, Ads Fraud Protection
	- At Unity, our Trust & Safety team plays a crucial role in fostering developer confidence in Unity's Network. We prioritize providing safe access to supply and demand along with insights and controls in a privacy-focused world.
	- As our new Senior Data Scientist in our Ads Fraud Protection team, you will be partnering closely with the Trust & Safety department, which focuses on safeguarding our advertisers from invalid activities and ensuring the integrity of the supply. You will collaborate with our engineering and product teams to analyze data and build reliable, accurate, and scalable Machine Learning models that detect fraudulent traffic among games and developers. With an emerging set of products, evolving problems, and an enthusiastic team committed to growth, you will have the opportunity to drive positive change at various levels within the organization and influence the technical direction and team culture.
	- Design, implement, and deploy scalable machine ML models using TensorFlow and Sklearn.
	- Validate, monitor, and evaluate the performance of ML models, making necessary adjustments and optimizing continuously.
	- Use your expertise in Cloud technologies to deploy and manage machine learning applications, leveraging Kubernetes for container orchestration and workload management.
	- Collaborate closely with BIs, BizOps, and other teams to identify new fraud threats and respond to or mitigate current fraud threats.
	- Produce well-written documentation, including modelling details, design options, and findings resolutions, to communicate complex concepts and analysis results to other stakeholders.
	- Hands-on experience in Machine Learning (deep learning), system design, software development, graph, and/or anomaly detection.
	- Strong programming skills in Python, SQL, and a deep understanding of data structures and algorithms.
	- Familiar with GCP (an experience with other Cloud platforms is valuable), Kubernetes, Tensorflow, Sklearn, and Kubeflow.
	- Good interpersonal and teamwork skills, passionate about learning new techniques and taking on challenging problems
	- Prior experience working on Graph Neural Networks (GNNs), graph databases, federated learning, and TF-secure.
+ skill set:
	- Scale is a rapidly growing post-Series B startup. Our mission is to accelerate the development of AI applications. Our first product is a suite of APIs that allow AI teams to generate high-quality ground truth data. Our customers include Alphabet (Google), Zoox, Lyft, Pinterest, Airbnb, nuTonomy, and many more, and we've become an industry standard for the self-driving car market.
	- https://scale.ai/careers/444bb0b1-932f-4065-a3bc-5a45004f5440
	- In this role, you will apply statistical models, design and interpret experiments, build mission-critical dashboards, and help structure and order our data in the pursuit of transparency over how we operate and how we can improve.
	- Build machine-learning models that power core operations, such as quality assessment and fraud detection
	- Expert knowledge of a scientific computing language (e.g. *R, Python*) and SQL
	- Strong knowledge of statistics (clustering, regression, etc.) and experimental design
	- Comfort setting up and using BI tools
	- Experience with ETL tools and building / maintaining a data warehouse
+ skill set:
	- At Nextdoor, we believe in the transformative power of community. In the Business Intelligence team at Nextdoor, we believe in the transformative power of information, bringing together data from a wide variety of sources and making it digestable and actionable by everyone in the company. We are a lean but powerful team with diverse backgrounds and perspectives, because that's what we seek out and respect in others. We collaborate cross-functionally to make the numbers available and clear, playing a key role in the company's overall effort to foster stronger and healthier communities.
	- As Nextdoor's first Engagement Data Science Manager, you'll lead data science for all of our member-facing initiatives, including activation, retention, trust and safety, moderation, and much more. You'll be the voice of data within engagement leadership, and you'll work with your team to bring value to Nextdoor's millions of members and help build stronger & safer communities. You'll lead an agile, nimble data team, and you'll work with leaders across the business to inform Nextdoor's overall data strategy. You'll directly contribute to growing and improving our core product, and will help lead us to the future of Nextdoor.
	- You should be excited to bring your experience and expertise every day in order to:
		* Lead, develop, and grow a team of 6-8 data scientists working in our engagement teams
		* Conduct in-depth analysis on Nextdoor data, analyzing neighborhood vitality, member experience, cross-platform initiatives, acquisition cycles, and new product development
		* Partner with cross-functional teams to support product development efforts (including product, design, engineering, marketing, operations, and finance) and manage and align priorities
		* Work on the leadership team to inform long-term business strategy and roadmaps
		* Develop and socialize best practices around metric development, A/B testing and experimentation, usage tracking and instrumentation
		* Drive self-service for our data platform by creating and documenting data structures and sets, SQL and data tools training, and dashboard development
		* Develop and share key strategic insights through data analysis, visualization, and story-telling
		* Work with the team to create and optimize statistical models and algorithms to help drive product and strategic decision-making
		* Care deeply about data quality and empowering employees to leverage data to help Nextdoor grow and succeed
	- What You'll Bring to The House
		* Advanced degree in a quantitative field and 8+ years work experience in data science
		* 3+ years of people management
		* Experience working in consumer internet, especially social networks
		* Expert knowledge of SQL
		* Comfort working with large, complicated, evolving (and sometimes messy) data sets
		* Experience with distributed processing methods and ETL systems
		* Experience with with Python/Pandas, R, or some other computation analysis software, and experience building and deploying machine learning models
		* Experience effectively presenting insights and summarizing complex data to diverse audiences through visualizations and other means
		* Ability to understand, tackle, and communicate problems from both technical and business perspectives
		* Innate curiosity around finding meaningful insights that inform the way we think about and develop both our product and our business strategies
	- Bonus Points
		* Looker expertise
		* Experience with topics like feed ranking, content moderation, and community modeling
		* You've built a data team up from the ground and you're up for a challenge!




















####	Marketing Analytics




+ Use marketing technology such as Hubspot, Salesforce, WordPress, Sendoso, and Go-To-Webinar
	- While this list is provided for a marketing position, it indicates technologies people in marketing analytics can build for people on these platforms.
+ skill set:
	- Participate in the development of a large-scale Ads system for TikTok.
	- Participate in the development and iteration of Ads algorithms by using Machine Learning.
	- Partner with product managers and product strategy & operation team to define product strategy and features.
	- Solid programming skills, proficient in C/C++, good programming style and work habits;
	- Familiar with at least one mainstream deep learning programming framework (TensorFlow/Caffe/MXNet), familiar with its architecture and implementation mechanism;
	- Familiar with deep learning algorithms (CNN/RNN/LSTM, etc.);
	- Ability to solve problems independently, good sense of teamwork and communication skills;
	- Has experience with open sourced deep learning framework.
	- Familiar with main components for Ads system, including bidding, ranking and auction.
	- Experience in resource management and task scheduling with large scale distributed software (such as Spark and TensorFlow).






####	Human Resource Analytics









####	Data Science for Logistics, Supply Chain Management, Industrial Distribution, & Retail Sales


+ skill set:
	- At least 5 years demonstrated results in areas of Operations Research and/or Supply Chain Projects (inventory optimization, network design, and S&OP) in sophisticated and complex environments including the use of simulation and modeling tools (Llamasoft, CPLEX, Gurobi, or other similar)
	- At least 5 years performing data analytics and modeling with advanced languages (e.g. Python or R)






####	Data Science for Economics



+ skill set:
	- B.S. or M.S. in Economics, Statistics, or a similar field and 1+ year work experience in data science or analytics, or Ph.D. in a quantitative social/behavioral science (e.g. Economics, Sociology, Psychology, Statistics, or a similar field)
	- Coursework in experimental design, causal inference, and/or econometrics
	- Experience running and analyzing behavioral experiments
	- Statistical intuition and knowledge of various hypothesis testing and regression approaches, e.g. hierarchical modeling, difference-in-differences
	- Familiarity with Python or similar scripting language
	- Experience communicating technical statistical concepts clearly, for example, teaching or consulting
	- Demonstrated ability working effectively with cross-functional teams
	- Experience using git and pushing to a codebase
	- Experience with software engineering projects or coursework










###	Sports Analytics or Data Science for Sports




+ skill set:
	- NBA's Team Marketing and Business Operations ("TMBO") group is a unique in-house consulting arm within the NBA league office that drives best practice sharing and innovation across all NBA, WNBA, NBA G-League and NBA2K teams.
	- The Data Scientist role will be a technical expert within TMBO in all matters surrounding statistical analysis, data manipulation and interpretation, and process automation. You will be a thought leader, tasked with the responsibility to leverage the NBA's various internal data sources to create new and innovative analytical products and outputs to inform league executives about the state of team businesses. You will uncover insights through predictive analyses and data visualization, drive better decision making by using various statistical modeling techniques, and promote efficiencies in reporting to various stakeholder groups within the league office. The demand for advanced analytical solutions to business operations issues in sports continues to grow exponentially, and this is your opportunity to grow with us in a fast-paced, collaborative environment.
	- Help lead TMBO's efforts to develop and maintain analytical products for communicating the state of team businesses to key stakeholders at the league office
	- Work with TMBO executives to further proprietary analytical research for presentation to teams at various league workshops
	- Enhance the current report generation processes within TMBO through the lens of potential automation and conversion to different, more useful development environments (e.g., R, Python, Tableau, etc.)
	- Develop an understanding of current needs in data collection at the league office and create solutions to gather the required information
	- Perform statistical analysis and create and maintain descriptive and predictive models as needed on a project basis
	- Demonstrated skills, knowledge and experience in converting data into insights
	- Passion for developing methods to streamline processes and data flow through automation
	- Experience in understanding existing data structures, including collection and standardization processes, and ability to help shape future processes going forward with an eye toward business needs
	- Ability to consult with business analysts and operators to understand their data needs, develop systems to access the data and convert the outputs into various formats for analysis
	- Comfort with ambiguity in data and experience in working with partners to optimize third-party data streams
	- Detail-oriented, extremely organized with ability to manage projects from inception through execution
	- Strong communication skills, both verbal and written, particularly for presentations
	- Expertise in leveraging R and Python to perform statistical analysis, build models and automate processes
	- Expertise in using SQL to tap expansive databases
	- Expertise in creating informative data visualizations through Tableau
	- Familiarity with other coding languages, statistical analysis tools and business intelligence platforms preferred
	- Familiarity with Microsoft Office software required, strong skills in Excel and VBA preferred
	- Expertise in developing, executing and implementing: various classification and regression models and familiarity with more advanced machine learning techniques
	- Expertise in parsing existing code and developing ways to increase its efficiency
	- Familiarity with accessing and manipulating data via APIs
	- Experience in an advanced analytical role, preferably in an industry focused on leveraging data to develop loyal fans or customers
+ skill set:
	- Implement and maintain the League's data analytics platform(s) to manage the ongoing monitoring of internal and external information related to Sports Betting/gaming;
	- Coordinate with other departments and third-parties to identify internal and external sources of meaningful information and assist in the process of data collection;
	- Work with and coordinate the integration of multiple data sets into the selected data analytics platform(s) and/or visualization tool(s);
	- Work with technical partners to automate data flows and reduce reliance on manual data development;
	- Develop queries and manage the technical aspects of data interrogation;
	- Maintain a reporting mechanism and protocols to ensure appropriate communication of alerts and/or findings, including through visualization and dashboards;
	- Oversee information requests and project activities to ensure accurate, timely, and efficient reporting deliverables; and
	- Support the investigation and review of any alerts
	- Five+ years of experience in data analytics or a comparable area of expertise
	- Integrity monitoring experience and/or understanding of the Sports Betting/Gaming industry preferred
	- Ability to exercise discretion and use independent judgment in making decisions and work with minimal functional guidance; demonstrated project management skills
	- Excellent oral and written communication skills, ability to share findings with non-technical audience, and deal effectively with the senior management, staff members, and vendors
	- Exceptional problem solving and issue-spotting skills
	- Excellent interpersonal and time management capabilities
	- Experience with data analytics platforms, such as Symantic Pro, Symantic Cortex, IBM i2
	- Understanding of statistical modeling techniques
	- Proficiency in at least one of the following languages: R, Python, SQL query writing, working with JSON/XML data
	- Data transfer and encryption knowledge, such as sftp, pgp, and others; and
	- Knowledge of Cloud platforms, such as AWS, Azure, and others













###	Data Science for Public Health










###	Data Science for Health Companies & Other Organizations


+ skill set:
	- At least 2 years designing and building healthcare data analysis solutions for the business payer or provider industry
	- At least 2 years using new developments in AI, machine learning, cognitive systems, and robotics to build amazing analytical tools
	- At least of 2 years working with tools like SAS, Python, SPSS, R, or SQL
	- At least 2 years working with data integration tools to streamline processes in platforms like Cerner EMR, Apache Spark, MapReduce, MongoDB and Couchbase
	- You can use data mining techniques to solve real world business problems
+ tech stack:
	- Hadoop ecosystem and its components.
	- Hadoop, Hive, HBase, and Pig
	- Working experience in HQL
	- Pig Latin Scripts and MapReduce jobs
	- Hands-on experience in backend programming, particularly Java, and Node.js
	- Analytical and problem-solving skills
+ skill set:
	- knowledge of:
		* clincial trials
		* digital health tools
		* employee's health management
		* health care system in other countries
	- management of health care real-world data, RWD
	- experience in defining/creating requirement documents (e.g., PRD) of health care product/service, launch them, and improve in an agile way 
















###	Data Science for Advocacy, Lobbying, Think Tanks












###	Data Science for Legal Informatics & Computational Law


This subsubsection includes skill sets for data science roles in legal services, including:
+ legal informatics
+ computational law











###	Data Science for Semiconductor Manufacturing




+ skill set:
	- Our vision is to transform how the world uses information to enrich life. Join an inclusive team passionate about one thing: using their expertise in the relentless pursuit of innovation for customers and partners. The solutions we build help make everything from virtual reality experiences to breakthroughs in neural networks possible. We do it all while committing to integrity, sustainability, and giving back to our communities. Because doing so can fuel the very innovation we are pursuing.
	- As a Data Science Engineer at Micron, you will employ techniques and theories drawn from areas of mathematics, statistics, semiconductor physics, materials science, and information technology to uncover patterns in data from which predictive models, actionable insights, and solutions can be developed.
	- You will interact with experienced Data Scientists, Data Engineers, Business Areas Engineers, and UX teams to identify questions and issues for data analysis projects and improvement of existing tools. In this position, you will help develop software programs, algorithms and/or automated processes to cleanse, integrate, and evaluate large datasets from multiple disparate sources. There will be significant opportunities to perform exploratory and new solution development activities.
	- Strong desire to grow a career as a Data Scientist in highly automated industrial manufacturing doing analysis and machine learning on terabytes and petabytes of diverse datasets.
	- Experience in the areas: statistical modeling, feature extraction and analysis, supervised/unsupervised/semi-supervised learning. Exposure to the semiconductor industry is a plus but not a requirement.
	- Ability to extract data from different databases via SQL and other query languages and applying data cleansing, outlier identification, and missing data techniques.
	- Strong software development skills.
	- Strong verbal and written communication skills.
	- Experience with or desire to learn:
		* Machine learning and other advanced analytical methods
		* Fluency in Python and/or R
		* pySpark and/or SparkR and/or SparklyR
		* Hadoop (Hive, Spark, HBase)
		* Teradata and/or another SQL databases
		* Tensorflow, and/or other statistical software including scripting capability for automating analyses
		* SSIS, ETL
		* Javascript, AngularJS 2.0, Tableau
		* Experience working with time-series data, images, semi-supervised learning, and data with frequently changing distributions is a plus
		* Experience working with Manufacturing Execution Systems (MES) is a plus
		* Existing papers from CVPR, NIPS, ICML, KDD, and other key conferences are plus, but this is not a research position
		* Masters or PhD and several years of industry experience majoring in Engineering, Mathematics, Computer Science, Data Science, Physics, or equivalent
		* Semiconductor industry experience and/or knowledge preferred























###	Data Science for Computational Science and Computational Engineering (except EDA)




Skill sets for data science roles in computational science (or scientific computing) and computational engineering (except EDA):
+ skill set:
	- Imagine a super-resolution microscope so easy to use that anyone on earth can take high-resolution images of bacteria, proteins, cells, and even genes. Imagine the same microscope accelerating cancer research, pharmaceutical development, and virus identification by empowering scientists with real-time, nanoscale imagery of cells and proteins. We're building this technology at ONI!
	- Our aim is to make super-resolution imaging so easy and the insights so impactful that it becomes widely used by scientists and leads to radical discoveries and innovations. To achieve this goal, our platform will automate every stage of the workflow, integrating the Nanoimager, a microfluidics device (Roboflow) and an online analysis package (CODI) with next-gen super-resolution assays and application-specific microfluidic consumables. 
	- We will soon be launching our first kit which is designed for extracellular vesicles. With one click, the kit captures, images and analyses these tiny particles allowing researchers to characterise their biomarkers for the first time. We are also developing a revolutionary new super-resolution technology called Every Molecule Counts (EMC) that will give our customers a new level of confidence about the biology underlying their images. EMC technology will be integrated into all of our future consumables.
	- To drive all this innovation we have built a world-class R&D team with colleagues from disciplines including biology, computer science, mathematics and physics. A core principle behind our work is to be detailed in our thinking, but to make products that are simple and intuitive so they can be put in the hands of anyone irrespective of experience, background, or training. We are excited to welcome new team members who share these values and who are excited by our vision.
	- Currently employing a diverse team of 120+ people, representing over 40 nationalities, ONI is in a period of rapid growth. We closed our $75m Series B round at the start of 2022, led by ARCH Ventures and Casdin Capital, putting our post money valuation at c. $225M, to drive the development of our next generation of products. What we have achieved so far is just the beginning and we are always looking for passionate people to join us on this journey.
	- We are looking for a Senior Software Engineer who will support the team that develops and deploys leading edge data analysis tools and solutions to the users of our microscope. You will develop creative methods that can extract information from these results and use software engineering skills to consolidate these methods into usable tools. This role is a fantastic opportunity to work on ground breaking applications for super-resolution and single-molecule microscopy as well as to help shape this new diverse team.
	- As an experienced member of the team, you will be at the heart of developing new tools and techniques for super-resolution data analysis. You will take a leading role working closely with Data Scientists, Software Engineers, Application Development Scientists, and Hardware R&D, to create a bridge between the back-end and the data science team, mentoring, coaching and empowering data scientists, and helping provide infrastructure and system support to help supercharge the work of the data science team, and increase the delivery of code into the cloud platform.
	- Drive communications between data scientists and backend cloud developers to deliver fast and effective research tools
	- Be confident in applying domain specific knowledge to the development of algorithms.
	- Have a strong background in mathematics, probability, and statistics.
	- Be able to work independently or as part of  a team. 
	- Be comfortable with ambiguity and complexity, thrive in group discussions and be an able communicator with colleagues with diverse technical backgrounds.
	- Have a passion for learning, working in a team, teaching others & making an impact on the world.
	- Greater than 4 years experience as a software developer in a professional environment.
	- Have an academic background (BSc, MSc, or PhD) in Computer Science, or STEM related fields. 
	- Strong familiarity with the python ecosystem, and available tools, and best practices of python in the context of both Data Science and delivery of production code. 
	- Strength in packaging using pypi, and optionally conda, or alternatives, including compiled C++ accelerated bindings (Pybind11) across platforms.
	- Strength and familiarity using Cmake to build C++ projects across Linux and Windows platforms. 
	- Strong understanding of C++ ecosystem, standards, and comfortability navigating and learning unknown code-bases. 
	- Strength in maintenance and establishment of CI/CD workflows for python and C++, including integration testing and deployment, using common solutions such as Github Actions or CircleCI.
	- Experience utilizing Docker to enhance development, testing, and deployment.
	- Sound knowledge of basic mathematics and statistics concepts
	- Confidence communicating between scientists and backend cloud developers
	- GPU acceleration using CUDA.
	- MLOps; with deployment and or training in cloud infrastructure, or deployment of C++ compiled models in real-time.
	- Image processing experience. 
	- Strength in development and implementation of computationally intensive numerical algorithms. 
	- Experience with cloud and web-based solutions and toolings, including tools such as Django, Kubernetes, Celery, RabbitMQ, on platforms such as GCP, or AWS
+ skill set:
	- ONI is looking for a highly motivated and creative scientist to join our Applications Development team as a Data Scientist. The Applications Development team invents new, cutting-edge molecular biology techniques based on single-molecule microscopy, and converts them into integrated bioware products that enable our users to access the full potential of super-resolution imaging. This work spans a diverse range of biological and technological fields, firmly founded in advanced fluorescence microscopy.
	- The work of the Applications Development team demands creative, innovative ways to process and analyse imaging data of many formats - including localisation-based point clouds, single-particle tracking information, and pixel-based data. As the Data Scientist within the team, you will be responsible for identifying and developing the most effective and efficient ways to analyse data generated in the course of our developmental work. In the process you will bring new analysis tools into the company, and design bespoke tools that are unique to ONI. The insights that we need to extract from our data are highly dynamic and change according to the state of each project, and so this role is well-suited to a talented Data Scientist who likes solving problems creatively and rapidly. 
	- This role is open to candidates able to work in our Oxford, UK office and will involve interaction with scientists at both of our research centres. You will work across several research projects involving multiple development teams, and fulfil a vital function within the company by pushing the boundaries of the insights we can derive from our imaging technology.
	- Take a leading role in defining how data are analysed within Applications Development's product- and technology-development process. This is through the development of new analytical methods to unlock previously unobtainable information within our data; advising on the most appropriate analytical approaches to take; and transferring the most cutting-edge analyses into the team
	- Directly handle the processing of some data collected by the wider team as part of our ongoing developmental work
	- Assist and support other members of the team in their data analysis 
	- Bridge ONI's Applications Development and Software teams to ensure that requirements and strategies are fully understood by scientists with diverse biology and computing backgrounds
	- Contribute to ONI's ongoing research projects as an integral and intellectually-invested team member
	- Contribute positively to ONI's mission beyond your immediate work - e.g. providing technical advice/support to the wider company, promoting an exciting work culture etc.
	- Significant expertise in image analysis methods, particularly single-molecule methods
	- Experience of data analysis using Python
	- Understanding of super-resolution or single-particle imaging methods
	- Some laboratory experience in cell biology, molecular biology, or biochemistry
	- A passion and hunger for improvement, and inability to settle for average
	- Ability to be motivated by the success of a team, and derive fulfilment from enabling others
	- Strong cultural alignment to ONI and excellent people skills
	- Excellent record-keeping and data-handling skills
	- Ability to work to a high standard as part of a dynamic team
	- Ability to think independently and take initiative
	- Practical experience in sample preparation for fluorescence microscopy
	- Domain knowledge in a specific area of biology or biochemistry; preferably immunology, extracellular vesicle biology, oncology, virology, neurology, developmental biology, genetics/epigenetics, or pathology
	- Experience of other relevant data-handling resources; e.g. MatLab, R etc. 
	- Obtained a higher qualification (BSc, MSc, PhD, or equivalent) in a relevant area of science
	- Worked in an environment for with significant focus on imaging analysis methods (in either academia or industry)
	- Solved challenging data science problems in creative and innovative ways
	- Worked as part of a close team to deliver ambitious results together
	- Contributed creatively and intellectually to the success of your projects












###	Data Engineering



####	Notes about Data Engineering


Data engineering roles involve creating *Big Data* extract, transform, load (ETL) pipelines, and provide infrastructure support to help data scientists obtain insights from processing huge amounts of data.

They address:
+ readiness of data (sets)
+ format of data sets
+ resilience of infrastructure support for information systems
+ scaling of infrastructure support for information systems
+ security of infrastructure support for information systems

They support databases for:
+ operational data stores
+ data marts
+ data lakes
+ (enterprise) data warehouses, DW, DWH, or EDW




####	Skill Sets for Data Engineering





***Skill sets for data engineering***:
+ big data products:
	- relational databases, data warehouses, data lakes
	- IBM Db2
	- MySQL
	- Oracle Database
	- Microsoft Azure Data Lake Storage
	- Amazon DynamoDB
	- PostgresSQL
	- Microsoft Access
	- MongoDB
	- Amazon RedShift
	- Google Cloud SQL
	- Google Cloud BigQuery
	- SQLite
	- Snowflake
	- Microsoft SQL Server
	- Amazon Athena
	- Google Cloud Firestore
+ ***process structured and unstructured data***
+ You've used several data storage technologies like ***Elasticsearch, Solr, PostgreSQL, MongoDB, or Cassandra*** and have some idea how they work and why they work that way.
+ Experience with ***Scala, Scalding, Luigi, Hive, machine learning pipelines and model training*** is a plus
	- Luigi:
		* [The Enterprise-Ready Micro Frontend Framework](https://luigi-project.io/)
			+ "Luigi helps you to build modularizable, extensible, scalable and consistent UIs and Web Apps."
			+ "Create a unified user experience around your complex functionality in a distributed development environment."
			+ "Build administration and business User Interfaces using Luigi and discover its benefits."
		* [***Luigi is a Python module that helps you build complex pipelines of batch jobs. It handles dependency resolution, workflow management, visualization etc. It also comes with Hadoop support built in.***](https://github.com/spotify/luigi)
			+ "Luigi is a Python (3.6, 3.7, 3.8, 3.9 tested) package that helps you build complex pipelines of batch jobs. It handles dependency resolution, workflow management, visualization, handling failures, command line integration, and much more."
			+ "The purpose of Luigi is to address all the plumbing typically associated with long-running batch processes. You want to chain many tasks, automate them, and failures will happen. These tasks can be anything, but are typically long running things like Hadoop jobs, dumping data to/from databases, running machine learning algorithms, or anything else."
			+ "There are other software packages that focus on lower level aspects of data processing, like Hive, Pig, or Cascading. Luigi is not a framework to replace these. Instead it helps you stitch many tasks together, where each task can be a Hive query, a Hadoop job in Java, a Spark job in Scala or Python, a Python snippet, dumping a table from a database, or anything else. It's easy to build up long-running pipelines that comprise thousands of tasks and take days or weeks to complete. Luigi takes care of a lot of the workflow management so that you can focus on the tasks themselves and their dependencies."
			+ "You can build pretty much any task you want, but Luigi also comes with a toolbox of several common task templates that you use. It includes support for running Python mapreduce jobs in Hadoop, as well as Hive, and Pig, jobs. It also comes with file system abstractions for HDFS, and local files that ensures all file system operations are atomic. This is important because it means your data pipeline will not crash in a state containing partial data."
				- Hive:
					* ["The Apache Hive ™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage. A command line tool and JDBC driver are provided to connect users to Hive."](https://hive.apache.org/)
						+ "The Hive DDL operations are documented in Hive Data Definition Language."
						+ "The Hive DML operations are documented in Hive Data Manipulation Language."
						+ ["The Apache Hive™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage and queried using SQL syntax."](https://cwiki.apache.org/confluence/display/Hive//Home)
							- "Tools to enable easy access to data via SQL, thus enabling data warehousing tasks such as extract/transform/load (ETL), reporting, and data analysis."
							- "Hive is not designed for online transaction processing (OLTP) workloads. It is best used for traditional data warehousing tasks."
							- "Hive is designed to maximize scalability (scale out with more machines added dynamically to the Hadoop cluster), performance, extensibility, fault-tolerance, and loose-coupling with its input formats."
				- Pig:
					* ["Apache Pig is a platform for analyzing large data sets that consists of a high-level language for expressing data analysis programs, coupled with infrastructure for evaluating these programs. The salient property of Pig programs is that their structure is amenable to substantial parallelization, which in turns enables them to handle very large data sets."](https://pig.apache.org/)
						+ At the present time, Pig's infrastructure layer consists of a compiler that produces sequences of Map-Reduce programs, for which large-scale parallel implementations already exist (e.g., the Hadoop subproject).
						+ Pig's language layer currently consists of a textual language called Pig Latin, which has the following key properties:
							- Ease of programming. It is trivial to achieve parallel execution of simple, "embarrassingly parallel" data analysis tasks. Complex tasks comprised of multiple interrelated data transformations are explicitly encoded as data flow sequences, making them easy to write, understand, and maintain.
							- Optimization opportunities. The way in which tasks are encoded permits the system to optimize their execution automatically, allowing the user to focus on semantics rather than efficiency.
							- Extensibility. Users can create their own functions to do special-purpose processing.
				- ["The ***Cascading Ecosystem*** is a collection of applications, languages, and APIs for developing data-intensive applications."](https://www.cascading.org/)
			+ ["Luigi is a Python (2.7, 3.6, 3.7 tested) package that helps you build complex pipelines of batch jobs. It handles dependency resolution, workflow management, visualization, handling failures, command line integration, and much more."](https://luigi.readthedocs.io/en/stable/index.html)
				- "The purpose of Luigi is to address all the plumbing typically associated with long-running batch processes. You want to chain many tasks, automate them, and failures will happen. These tasks can be anything, but are typically long running things like Hadoop jobs, dumping data to/from databases, running machine learning algorithms, or anything else."
			+ From https://qconnewyork.com/ny2015/system/files/presentation-slides/MattWilliams%20-%20qcon2015%20-%20luigi.pdf:
				- Python module to help build complex pipelines
					* dependency resolution
					* workflow management
					* visualization
					* hadoop support built in
				- Doesn't help you with the code, that's what Scalding (scala), Pig, or anything else is good at.
				- It helps you with the plumbing of connecting lots of tasks into complicated pipelines, especially if those tasks run on Hadoop.
				- Luigi doesn't replace Hadoop, Scalding, Pig, Hive, Redshift. It orchestrates them.
				- Core beliefs of Luigi:
					* Should remove all boilerplate code.
					* Be as general as possible.
					* Be easy to go from test to production code.
	- Scalding:
		* ["Scalding is a Scala library that makes it easy to specify Hadoop MapReduce jobs."](https://twitter.github.io/scalding/)
			+ https://github.com/twitter/scalding
			+ "Scalding is built on top of Cascading, a Java library that abstracts away low-level Hadoop details."
			+ "Scalding is comparable to Pig, but offers tight integration with Scala, bringing advantages of Scala to your MapReduce jobs."
+ Should have experience in dealing with XML and JSON data formats.
+ skill set:
	- Redesigning our data systems from a warehouse-centric to a lake-centric architecture to be more cost-effective as our data volume grows.
	- Rolling out a structured events pipeline for analytics and productization of high-volume event streams.
	- Building a centralized, discoverable data catalog to enable users across the company to efficiently find and use data.
	- We currently support a 100TB data warehouse used by hundreds of people to make mission-critical decisions for our products and business.
	- An experienced data engineer. You have several years of experience operating large-scale distributed data processing systems—advanced ETL pipelines and data lakes or warehouses. Experience with Spark and AWS data services (EMR, Glue, Redshift) is preferred.
+ modern tech stack:
	- React
	- Redux
	- Jest
	- React Testing Library
	- styled-components
	- RxJS
	- cutting-edge libraries
+ data warehouses:
	- Snowflake
	- BigQuery
	- RedShift
	- Spark
	- Presto
+ skill set:
	- data engineering
	- Amazon Web Services
	- Oracle
	- Hive / Spark
	- Hadoop
	- Python
	- Snowflake
	- Airflow
+ ***Experience working with large data sets and distributed computing tools (e.g. Redshift, Presto)***
+ skill set:
	- Experience with ETL process, real time or batch pipelines
	- Experience with Kafka
	- Experience with Vertica
	- Knowledge in containerized environments (Docker, Kubernetes)
+ Sr. Data Engineer
	- Amida is currently looking for a Sr. Data Engineer to provide expertise and implementation services in data collection, data integration, data analysis, data mapping, data profiling, data mining and data modeling.
	- In this role, you will be responsible for designing and maintaining data pipelines, data warehouses, and data integration solutions. You will work closely with cross-functional teams to ensure data quality, optimize performance and implement scalable data infrastructure.
	- Bachelors Degree in Computer Science or technical field AND;
	- 5+ years of recent professional experience in data engineering
	- Expertise in data modeling and ETL processes
	- Proficiency in programming languages like Python and Scala
	- Experience in SQL and Databricks
	- An in-depth understanding of the terminologies, code sets, and standards of healthcare data
	- Ability to communicate clearly, concisely and persuasively with software engineers and clients
	- Experience working with non-Transact-SQL databases and SQL dialects, preferably Oracle PL/SQL or Cerner Command Language
	- Experience with large-scale data analysis systems, such as Databricks, Hadoop, Pig, Scala, Spark or MPP databases
+ skill set:
	- Responsibilities
		* Design, develop and support data pipelines, warehouses and reporting systems to solve business operations, users and product problems.
		* Create extract, transform, and load (ETLs) and reporting systems for new data using a variety of traditional as well as large-scale distributed data systems.
		* Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
		* Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
		* Designs data integrations and data quality framework.
		* Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.
	- Minimum Qualifications
		* BS or MS degree in Computer Science or a related technical field
		* Experience with one general purpose programming language (e.g., Java, C/C++, Python).
		* Experience in data processing using traditional and distributed systems (e.g., Hadoop, Spark, Dataflow, Hive, Impala, Airflow).
		* Experience designing data models and data warehouses and using SQL and NoSQL database management systems.
		* Experience in custom ETL design, implementation and maintenance.
		* Experience analyzing data to identify deliverables, gaps and inconsistencies.
	- Preferred Qualifications
		* Experience with more than one coding language.
		* Experience with SQL performance tuning and E2E process optimization.
		* Experience with designing and implementing real-time pipelines.
		* Experience with anomaly/outlier detection
		* Excellent communication, organizational, and analytical skills.
+ skill set:
	- Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.).
	- Experience with performing data analysis, data ingestion and data integration.
	- Working industry experience with Big Data systems and projects.
	- Experience in building large scale distributed systems in a product environment.
	- Experience with ETL(Extraction, Transformation & Loading) and architecting data systems.
	- Experience with schema design and data modeling.
	- Experience in writing, analyzing and debugging SQL queries.
	- Experience in data privacy and security related projects.
	- Deep understanding of various Big Data technologies.
	- Passionate and self-motivated about technologies in the Big Data area.
	- Design and build data transformations efficiently and reliably for different purposes(e.g. reporting, growth analysis, multi-dimensional analysis).
	- Design and implement reliable, scalable, robust and extensible big data systems that support core products and business.
+ Experience writing production datasets in SQL/Hive OR building internal/production data tools for ETL, experimentation, or exploration in a scripting language (Python, R, etc.)
+ MongoDB, Redis, Memcached, experience crafting NoSQL data models.
+ data engineering tooling: Airflow and Databricks
+ Experience working with Big Data, Data Pipelines, Caching and Technologies such as ElasticSearch and Redis
+ Very strong experience in scaling and optimizing schemas, performance tuning SQL and ETL pipelines in the OLTP, OLAP and Data Warehouse environments
+ Passionate about various technologies including but not limited to SQL/No SQL/MPP databases etc.
+ skill set:
	- Data Engineer, Applied Engineering
	- Design, build and manage our data pipelines, ensuring all user event data is seamlessly integrated into our data warehouse.
	- Develop canonical datasets to track key product metrics including user growth, engagement, and revenue.
	- Work collaboratively with various teams, including, Infrastructure, Data Science, Product, Marketing, Finance, and Research to understand their data needs and provide solutions.
	- Implement robust and fault-tolerant systems for data ingestion and processing.
	- Participate in data architecture and engineering decisions, bringing your strong experience and knowledge to bear.
	- Ensure the security, integrity, and compliance of data according to industry and company standards.
	- Have 3+ years of experience as a data engineer and 8+ years of any software engineering experience(including data engineering).
	- Proficiency in at least one programming language commonly used within Data Engineering, such as Python, Scala, or Java.
	- Experience with distributed processing technologies and frameworks, such as Hadoop, Flink and distributed storage systems (e.g., HDFS, S3).
	- Expertise with any of ETL schedulers such as Airflow, Dagster, Prefect or similar frameworks.
	- Solid understanding of Spark and ability to write, debug and optimize Spark code. 
+ Hands-on experience with Big Data technologies (e.g Hadoop, Hive, Spark)
+ Have a thirst for technical challenges with big data and distributed systems, including HBase, Kafka, Elasticsearch and Dropwizard
+ data plane development kit, DPDK, from the Linux Foundation for computer networking and interactions with the Linux operating system kernel
+ Experience with big data engineering principles and technology stacks (eg., Kafka and distributed data processing) is a plus.
+ skill set:
	- data architecture
	- big data stack environment, including Snowflake, EMR, EC2, S3, SQS, Lambda, Hadoop, Sqoop, Apache Spark, Hive, and Python
	- data warehousing and BI Solutioning
	- ETL analytics and reporting tools
	- Amazon Web Services
	- leading the technical design and implementation of data ingestion and integration
	- databases, including NoSQL, DynamoDB, and Teradata
	- Airflow Scheduler to build complex workflows
	- SQL and Linux / Unix shell scripting
	- performance tuning data pipelines
+ skill set:
	- TuneIn reaches nearly 70 MAUs and we have a relentless appetite for data: our listeners collectively generate tens of millions of events per hour at peak. We are a small data engineering team and our contributions have a profound impact on the success of the business: from shipping the next strategic insight to building the data-centric products that power our listeners' experiences - our Data Engineering team is the hub of TuneIn. Our environment currently includes Java, Python, Pandas, Go, microservices, AWS services like amazon redshift, kinesis, emr (hadoop, spark), s3, lambdas. Kubernetes, Docker and Spinnaker for deployment. As well as music station recommendation engines, and advancements in Discovery and personas.
	- Data pipelines are critical to TuneIn's success, powering many aspects of our analytics and supporting products. We are looking for data engineers who will build data applications to solve product problems. In this role, you'll partner closely with our data analysts and Product team to create the technology that generates and transforms data into applications, insights and experiences for our users.
	- Example Projects
		* Build and rewrite existing data pipelines using Java/Python/Go to improve efficiency and latency
		* Develop and automate ETL pipelines
		* Design data models for optimal storage and retrieval, and optimize the data architecture to meet critical product and business requirements
		* Improve data quality through anomaly detection by building and working with internal tools to measure data and automatically detect changes
		* Data Modeling and improving our existing data models for analytics
	- 5+ years of software Engineering experience, with an emphasis in the design, development and deployment of high volume data centric applications (millions of transactions per day)
	- Past experience developing and maintaining ETL pipelines
	- Working knowledge of both relational and NoSQL database design and management (here at TuneIn we are using  Redshift, DynamoDB and Aurora)
	- Past experience with cloud services (such as AWS or similar)
	- Expertise with any object-oriented languages such as Java, Go, Python
	- History of building resilient, stateless, scalable, distributed and observable systems
	- Demonstrated ability to analyze data sets to identify gaps and inconsistencies, provide data insights, and advance effective product solutions
	- Experience designing and deploying production systems with reliable monitoring and logging practices
	- Practical perspective on software engineering discipline, focus on learning and delivering, and passion for high quality
	- Great energy and enthusiasm with a positive, collaborative working style, clear communication and writing skills
	- Enthusiasm for audio content preferred
+ skill set:
	- Working on systems that are used by millions of passionate users every day
	- Working with data on the scale of hundreds of billions of records a year
	- Evangelizing best practices in software development
	- Working in an Agile development methodology and own data driven solutions end-to-end
	- Increasing efficiency and automate processes by collaborating with our SRE team to update existing data infrastructure (data model, hardware, cloud services, etc.)
	- Experimenting with frameworks in the Big Data ecosystem to identify the optimal approach for extracting insights from datasets
	- Designing platforms for building, launching and maintaining efficient and reliable data pipelines in production
	- Identifying performance bottlenecks in data systems and architect faster, more efficient solutions when necessary
	- Designing, developing, and owning new systems and tools to enable our consumers to understand and analyze the data more quickly
	- Solid experience writing well-abstracted, reusable code components in Python, Scala or similar languages
	- Cloud engineering experience (AWS preferred)
	- Experience using common CI/CD tools such as TravisCI, and Jenkins for application and infrastructure automation tasks
	- A self-starter who thrives in owning the products and platforms they develop
	- Experience ingesting, processing, storing, and querying large datasets
	- Experience with Spark, Kafka, or similar is a plus
	- Experience working in the Hadoop/Spark ecosystem is a plus
	- Experience with Docker/Kubernetes is a plus
+ skill set:
	- iHeartRadio is looking for a talented Data Engineer to help us in our data-driven mission to reshape the world of music and podcasts. You will work in a highly collaborative team of engineers, and alongside data scientists and analysts, to distill existing data processes, import new external data sources, and create complex data mashups. Your work will provide valuable insights and power important music data products. Expect to build high throughput data pipelines and improve the existing big data infrastructure. You will also improve performance, squash bugs, and increase visibility across the data ecosystem. You will have end-to-end ownership of your code, though ideally you also relish reviewing a good pull request. If you enjoy working with large sets of data and the challenges associated with them this is the role for you.
	- Working in an Agile development methodology and own data driven solutions end-to-end
	- Experimenting with various frameworks in the Big Data ecosystem to identify the optimal approach for extracting insights from out datasets
	- Identifying performance bottlenecks in data pipelines and architect faster, more efficient solutions when necessary
	- Creating new data warehouse solutions and define and demonstrate best practices in schema and table design in varied databases like Hive, Redshift, Spectrum etc.
	- Developing end-to-end batch and real time pipelines for large data sets to our Hadoop/Spark clusters, and bring summarized results back into a data warehouse for downstream business analysis.
	- Increasing efficiency and automate processes by collaborating with our SRE team to update existing data infrastructure (data model, hardware, cloud services, etc.)
	- Designing, building, launching and maintaining efficient and reliable data pipelines in production
	- Designing, developing, and owning new systems and tools to enable our consumers to understand and analyze the data more quickly.
	- Experience ingesting, processing, storing, and querying large datasets
	- Ability to write well-abstracted, reusable code components in Python, Scala or similar language(s)
	- Experience working in an Hadoop/Spark ecosystem
	- Experience with workflow managers and schedulers, such as Airflow
	- Ability to investigate data issues across a large and complex system by working alongside multiple departments and systems
	- A self-starter who thrives in owning the products and pipelines they develop
	- Experience with AWS big data technologies (S3, Redshift, EC2, RDS, EMR, Dynamo) is a plus
	- Experience with configuration management tools (Ansible, Chef, Puppet, etc) is a plus
	- Experience with streaming frameworks like Spark or Kafka is a plus
+ Build data pipelines with tools like Apache Beam/Spark, Scio, Storm, ML tools such as Kubeflow, and cloud computing platforms such as Google Cloud Platform and AWS (Amazon Web Services). And, Google BigQuery, DBT.
	- DBT
	- Scio
	- Storm
+ skill set:
	- Minimum of 3+ years experience implementing large-scale production systems
	- Experience with Java or Scala build systems: maven, ant, sbt
	- OO design and implementation
	- Understanding of database design (SQL/noSQL)
	- Experience with multiple Apache Hadoop / Spark ecosystem applications, like: Spark, Hadoop, Hive, Zeppelin
	- Experience with Python
	- Experience building and operating at scale
	- Excellent analytical and problem solving skills
	- BS/MS in Math, Computer Science, or equivalent experience
	- Nosql data storage solutions
	- AWS
	- Continuous delivery
	- Microservice architectures
	- Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities
	- Implementing ETL process
	- Monitoring performance and advising any necessary infrastructure changes
	- Defining data retention policies
	- Create and maintain optimal data pipeline architecture,
	- Assemble large, complex data sets that meet functional / non-functional business requirements.
	- Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
	- Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS "big data" technologies.
	- Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
	- Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
	- Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
	- Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
	- Work with data and analytics experts to strive for greater functionality in our data systems.
	- Manage databases running on MySQL, MongoDB, Redis Technologies
	- AWS: EC2, EMR, RDS, Redshift.
	- Experience with big data tools: Hadoop, Spark, Kafka, etc.
	- Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
	- Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
	- Experience with AWS cloud services: EC2, S3, EMR, RDS, Redshift
	- Experience with stream-processing systems: Storm, Spark-Streaming, etc.
	- Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
	- RDS, DynamoDB
	- Microservices
	- Docker
	- Elastic caching (Redis, Memcached)
	- NodeJS, Python, Rails
	- Github
	- JIRA & Confluence
	- Proficient understanding of distributed computing principles
	- Understanding of how to manage Hadoop clusters, with all included services
	- Ability to solve any ongoing issues with operating the cluster
	- Proficiency with Hadoop v2, MapReduce, HDFS
	- Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming
	- Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala
	- Experience with Spark and Scala
	- Experience with integration of data from multiple data sources
	- Experience with NoSQL databases, such as HBase, Cassandra, MongoDB
	- Knowledge of various ETL techniques and frameworks, such as Flume
	- Experience with various messaging systems, such as Kafka or RabbitMQ
	- Experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O
	- Good understanding of Lambda Architecture, along with its advantages and drawbacks
	- Experience with Nifi/Kylo.io, or other ETL tools, such as Cloudera/MapR/Hortonworks
	- Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
	- Experience building and optimizing "big data" data pipelines, architectures and data sets.
	- Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
	- Strong analytic skills related to working with unstructured datasets.
	- Build processes supporting data transformation, data structures, metadata, dependency and workload management.
	- A successful history of manipulating, processing and extracting value from large disconnected datasets.
	- Working knowledge of message queuing, stream processing, and highly scalable "big data" data stores.
	- Strong project management and organizational skills.
	- Experience supporting and working with cross-functional teams in a dynamic environment.
	- We are looking for a candidate with 3+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
+ skill set:
	- Other preferred experience includes working with DevOps practices, SaaS, IaaS, code management (CodeCommit, git), deployment tools (CodeBuild, CodeDeploy, Jenkins, Shell scripting), and Continuous Delivery
	- Primary AWS development skills include S3, IAM, Lambda, RDS, Kinesis, APIGateway, Redshift, EMR, Glue, and CloudFormation
	- Extensive experience developing big data, business intelligence, marketing automation and/or other analytics infrastructure or pipelines - data lake experience preferred
	- 10 years experience in developing and architecting solutions using big data, data warehousing
	- 3 ++ years hands-on experience developing data lake solutions using Amazon's AWS (certification preferred)
	- Experience with data streaming technologies (Kinesis, Storm, Kafka, Spark Streaming) and real time analytics
	- Working experience and detailed knowledge in Java, JavaScript, or Python
	- Knowledge of ETL, Map Reduce and pipeline tools (Glue, EMR, Spark)
	- Experience with large or partitioned relational databases (Aurora, MySQL, DB2)
	- Experience with NoSQL databases (DynamoDB, Cassandra)
+ skill set:
	- Working experience of Databricks or similar
	- Knowledge of concepts such as data warehouse, star schemas, KPIs
	- Hands on experience with Linux, HDFS, HIVE, HADOOP
	- Experience with ETL / Informatica, JSON structures and REST Based web services a plus
+ skill set:
	- Familiarity with ETL/ELT and related techniques
	- Exposure to CI / CD (with either Docker, Kubernetes, SaltStack or Jenkins)
	- Prior experience in adtech or martech
+ skill set:
	- high-volume heterogeneous data with distributed systems, such as:
		* Hadoop
		* BigTable
		* Cassandra
	- distributed, high-volume services in Java, Python, or Scala
	- knowledgeable about data modeling, data access, and data storage techniques
+ JVM-based data processing frameworks, such as Beam, Spark, and Flink.
+ XGBoost, TensorFlow, PyTorch
+ Kylin, Elastic Search, Druid
	- Kylin
		* Apache Kylin is an open source distributed analytics engine designed to provide a SQL interface and multi-dimensional analysis on Hadoop and Alluxio supporting extremely large datasets.
		* Apache Kylin™ is an open source, distributed Analytical Data Warehouse for Big Data; it was designed to provide OLAP (Online Analytical Processing) capability in the big data era. By renovating the multi-dimensional cube and precalculation technology on Hadoop and Spark, Kylin is able to achieve near constant query speed regardless of the ever-growing data volume. Reducing query latency from minutes to sub-second, Kylin brings online analytics back to big data.
		* Apache Kylin is a distributed open source online analytics processing (OLAP) engine for interactive analytics Big Data. Apache Kylin has been designed to provide SQL interface and multi-dimensional analysis (OLAP) on Hadoop/Spark.
	- Elastic Search
		* Elasticsearch is a distributed, RESTful search and analytics engine capable of addressing a growing number of use cases. As the heart of the Elastic Stack, it centrally stores your data for lightning fast search, fine‑tuned relevancy, and powerful analytics that scale with ease.
		* Elasticsearch is a search engine based on the Lucene library. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents.
		* Elasticsearch is a distributed search and analytics engine built on Apache Lucene.
	- Druid
		* Apache Druid
		* Druid is a column-oriented, open-source, distributed data store written in Java. Druid is designed to quickly ingest massive quantities of event data, and provide low-latency queries on top of the data. The name Druid comes from the shapeshifting Druid class in many role-playing games, to reflect that the architecture of the system can shift to solve different types of data problems.
+ skill set:
	- Develop ETL operations using Python, Spark, SqlServer, Redshift and Kafka.
	- Develop the core tooling library to support Airflow data pipelines.
	- Design and implement the testing framework for Airflow dags and write test cases.
	- Document our systems for internal and external stakeholders
	- Support business stakeholders, analysts and data scientists on diverse projects.
	- Monitor and debug data pipelines running on Airflow.
	- Participate in code reviews.
	- Deliver quality work on tight deadlines.
	- Experience building systems with a framework, ideally Airflow (web frameworks are helpful, too)
	- Experience with data manipulation tools like Pandas, or ideally Spark
	- Experience with test automation
	- Experience accessing data via an API
	- Total control of Git
	- Working knowledge of Linux
	- Deployment tools (i.e. Ansible, Puppet, Chef)
	- Working knowledge of set-based querying (joins, etc...) ideally indexing, too.
	- Hadoop/Spark experience
	- Flume/Gobblin/Kinesis
	- AWS experience
	- Web analytics experience
	- Docker experience
	- Jupyter (notebook) experience
	- Log processing experience
+ skill set:
	- As a Data Engineer, you will join a growing Data Engineering team within our Engineering Services organization  that collaborates with decision-makers across the organization to catalyze business growth by providing insightful and actionable analysis, insights and data products. The Data Engineering team is hands-on with a wide variety of datasets, including user data, product behavior data, financial/payment data, upper-funnel marketing data, trust and safety data, and operational/infrastructure data, and is responsible for leveraging that data into usable analytical products by stakeholders across the company.
	- Develop and implement metrics and dimensions for powering analytical use cases across the company, incorporating a wide variety of data sources across the company at varying levels of complexity and scale
	- Focus on data quality of the data environment and data products being delivered to the business, and effectively communicate to internal user base regarding production status
	- Interface closely with data infrastructure, engineering and technical operations teams to ensure correctness and soundness of metrics built in the data environment and availability of data product services
	- Pioneer initiatives around data quality, integrity, security and governance
	- Work closely with data stakeholders across the company, both technical and non-technical, to understand evolving needs as more complex data models are introduced for reporting and data science
	- Bachelor's degree in Computer Science, Math, Statistics, Economics, or other quantitative field;  or equivalent experience.
	- Experience in custom ETL design, implementation and maintenance
	- Track record of developing in complex data environments and intelligence platforms for business users
	- Demonstrable ability to relate high-level business requirements to technical ETL and data infrastructure needs, including underlying data models and scripts
	- History of proactively identifying forward-looking data engineering strategies, utilizing appropriate technologies, and implementing at scale
	- Extensive hands-on experience with schema design and dimensional data modeling
	- Experience interacting with key stakeholders in different fields, interpreting challenges and opportunities into actionable engineering strategies
	- Experience with analytics databases like Snowflake, Redshift, or BigQuery.
	- Advanced SQL and relational database knowledge (MySQL, PostgreSQL) in addition to warehousing and dimension modeling
	- Experience scripting in Go or Python or a similar scripting language.
	- Effective communication and interpersonal skills
	- Experience implementing dimensional modeling in a configuration tool like dbt or LookML a plus
	- Experience designing and building dashboards in BI tools like Looker, Tableau, or PowerBI a plus.
	- Experience with job schedulers (Airflow, Luigi, Azkaban, etc.) a plus
+ skill set:
	- Bachelor's degree in Computer Science, Math, Statistics, Economics, or other quantitative field; Masters or PhD strongly preferred
	- Significant experience in custom ETL design, implementation and maintenance, including serving machine learning models in production for multiple high-growth companies, preferably those with technical products
	- Track record of developing and evolving complex data environments and intelligence platforms for business users
	- Demonstrable ability to relate high-level business requirements to technical ETL and data infrastructure needs, including underlying data models and scripts
	- History of proactively identifying forward-looking data engineering strategies, utilizing cutting-edge technologies, and implementing at scale
	- Hands-on experience with schema design and dimensional data modeling
	- Understanding of statistical modeling, machine learning and data mining concepts
	- Demonstrable critical thinking and analytical skills, including the ability and confidence to make conclusions and recommendations from data
	- Experience interacting with key stakeholders in different fields, interpreting challenges and opportunities into actionable engineering strategies
	- ***Experience with Big Data/distributed frameworks such as Spark, Kubernetes, Hadoop, Hive, Presto,***
	- ***Experience with job schedulers; Airflow, Luigi, Azkaban, etc.***
	- Experience with continuous integration and automation tools and processes
	- Advanced SQL and relational database knowledge (MySQL, PostgreSQL) in addition to warehousing and dimension modeling
	- Scripting in Python required, experience with Scala/Go a plus
	- Programming against APIs required
	- Experience with Snowflake and/or Looker a plus
	- Effective communication and interpersonal skills
+ skill set:
	- RDS Postgres, Snowflake, Airflow, AWS DMS, Spark on EMR, Python
	- data pipeline and workflow management tools:
		* Airflow
		* Luigi
	- Big Data tools:
		* Haddop
		* Hive
		* Spark
	- AWS cloud services:
		* EC2
		* EMR
		* RDS
		* Redshift
		* S3
	- Programming languages:
		* Python
		* Java
		* Scala
	- Linux
	- working knowledge of message queueing, stream processing, and highky-scalable Big Data stores.
	- expand and optimize data pipline architecture, and data flow and collection for cross functional teams
		* automating manual processes
		* ETL
		* re-designing infrastructure for greater scalability
		* improving relaiability & accuracy
	- support software initiatives tpo ensure optimal delivery architecture is consistent throughout ongoing projects
	- using appropriate tools to analyze the data pipeline and provide actional insights into operational efficiency, data accuracy, and other KPIs.
	- working knowledge of:
		* workload management
		* message queueing
		* stream processing
		* highly scalable big data stores
+ skill set:
	- Flume/Gobblin/Kinesis
	- Develop ETL operations using Python, Spark, SqlServer, Redshift and Kafka.
	- Develop the core tooling library to support Airflow data pipelines.
	- Design and implement the testing framework for Airflow dags and write test cases.
	- Monitor and debug data pipelines running on Airflow.
+ skill set:
	- support existing scientific workflows
	- set the vision for future data generation and collection efforts
		* Or, set data engineering vision
	- design, build, and maintain databases and data warehouses that underpin our scientific endeavors and accelerate the company's ability to ask new, sophisticated questions spanning multiple organisms, data modalities, and timescales.
	- understand common uses cases and data access needs
	- design strategies for data storage and integration across different data sources for multiple use cases
	- implement, document, and maintain processing pipelines, databases, and data warehouse and data lake infrastructure
	- build out core infrastructure, tooling, and software development processes
	- ETL tools and frameworks
		* Airflow
		* Luigi
	- Python data ecosystem
		* NumPy
		* pandas
		* Jupyter
	- SQL and relational database systems, such as:
		* PostgreSQL
		* MySQL
		* RESTFUL APIs
	- experience implementing RESTful APIs, GraphQL, and other programmatic interfaces to complex multi-dimensional data
		* GraphQL - query RESTful APIs
	- experience deploying flexible and high-performance data backends and interfaces in the cloud with Google Cloud Platform, Amazon Web Services, or similar platforms
	- built backends for high-dimensional graph or network data
	- designed or worked with auditable data systems suitable for regulatory review
	- experience working with diverse and cutting-edge datasets:
		* RNASeq
		* metabolomics
		* high-content imaging
	- experience with on-prem high-performance computing clusters, such as SLURM
		* SLURM, SLURM workload manager, Simple Linux Utility for Resource Management, free and open-sop
+ skill set:
	- We are looking for an experienced Data Engineer who thinks in clever ways to solve data problems of scale and load with elegant solutions. Our Data Engineering team supports several clusters of PostgreSQL databases of up to 2+TB each with hundreds of millions of rows, as well as many on prem and cloud data storage systems, such as Aurora, Redis, Redshift, CockroachDB, and Cassandra. As a senior member of this team, you will work closely with our DevOps, QA, Engineering, Business Unit and Project Management Teams to help us bring automation and stability to this architecture.
	- Our team is currently working remotely until our Oakland, CA office re-opens.
	- Key Responsibilities: 
		* Protect, tune, migrate, and administer On-premises and Cloud Datastores
		* Participate in a 24x7 on-call rotations
		* Always perform in a manner that guarantees the Protection, Availability, and Performance of our Global Datastores.
		* Be opinionated enough to speak up when you think we could be doing something better than we're doing it now - and tactful and empathetic enough to communicate this in a way that brings people along instead of distancing them.
	- Qualifications
		* Passion for datastores and a high sense of ownership while performing critical duties based on senior-level experience in Security, Disaster Recovery, and High Availability.
		* Ability to have a strong work ethic in a fast-paced environment with multiple priorities that may occasionally change.
		* Ability to work independently and perform under pressure.
		* Good interpersonal skills, friendly, and approachable.
		* Deep Linux experience.
		* Strong SQL skills.
		* Expert in PostgreSQL tuning and best practices.
		* AWS experience, including Terraform.
		* Bachelor's degree in Computer Science or equivalent experience.
		* Automated monitoring and alerting of On-premises and Cloud data technologies, such as Aurora, Redshift, Redis, CockroachDB, and Cassandra.
		* Kubernetes experience.
		* Working experience with configuration management tools, preferably Puppet and Terraform.
+ Splunk is looking for a Software Engineer to join the Data Federation engineering team and have a large impact on a team responsible for building ***Federated Search*** capabilities
+ skill set:
	- act as a domain leader in roadmapping prioritization, planning, and stakeholder management for the Fab and Design domains
	- design and build interactive tools, dashboards and interfaces to enable turnkey analysis by teams across the company
	- experience in modern data pipeline technologies built with DBT, Stitch, Fivetran, or other modern ETL (Extract, Transform, Load) tools.
	- understanding of low-level protocols for communicating with metrology tools
+ skill set:
	- managed, maintained, and monitored systems, using:
		* Amazon Web Services
		* Datadog
		* Postgres
		* Redis
		* Memcached
		* Elasticsearch
+ skill set:
	- We are looking for a Senior Software Engineer to join our Data Science team and help further develop Deezer's data-driven mindset.
	- We are part of the BI and Data Analytics team, whose mission is to find the correct levers within the product to further drive Deezer's growth. Through our analysis and predictions tools, we ensure Deezer is fitting our users' needs.
	- As a Senior Software Engineer in the Data Science team, you will be responsible for the engineering and implementation of scalable technical solutions around data science production. This solution will have significant impact to Deezer's results in areas of fraud detection, churn, inactivty & conversion.
	- What you will do:
		* Develop a deep understanding of the business & product and their requirements to develop solutions to insure the fully adoption of our prediction modelling (visualisation, alerting, API).
		* Design, build, and maintain data pipelines between our Data science team & product, CRM and other relevant systems.
		* Help our Data Scientists implement and maintain those ML pipelines & data architecture related, supervise the GCP migration and deployment of real time modelling.
		* Improve and build solutions to address architectural gaps or technical debt.
		* Propose best technologies for ***data processing and data framework***, test regularly new technologies that may ease team work (***Skein, Meta Flow***).
		* Mentor Data Scientists on their Engineering skills ; Drive enforcement of standards, tools and methodologies ; Ensure that the pipeline is fully tested.
		* Participate in story planning, standups and retrospectives.
		* Produce documentation and tutorials that enable other teams to use easily our pipeline.
		* Pro-active communication to users and management on issues.
	- What we are looking for:
		* At least 5 years of experience of software engineering/data engineering, with a degree in computer science.
		* Experience in micro services architecture
		* Experience with Docker, Kubernetes, REST API.
		* Fluent in at least one language in Python, Scala Java;
		* Experience of functional code.
		* Experience in designing, building and launching efficient & reliable data pipelines is preferred.
		* Experience with Hadoop/Hive, Spark, Cassandra and data warehouse technologies is preferred.
		* Passion for technology, industry research and enjoys solving business problems.
		* Experience in Agile Processes, Test Driven Development and Framework design.
		* Excellent verbal, written, communication, interpersonal and presentation skills - ability to clearly communicate data analyses results to end users.
	- Bonus Points.
		* Building and launching new data models that provide intuitive analytics for the analysts and customers.
		* Mathematical/machine learning background with the ability to understand & implement distributed algorithms.
+ skill set:
	- As part of this initiative, we are looking for a Data Engineer and help us build a scalable petabyte scale data lake and Enterprise Data Warehouse (EDW) using modern tech stack from the ground up using open source technologies. Success in this role comes from marrying a strong data engineering background with product and business acumen to deliver scalable data pipelines and analytics solutions that can enable advanced analytics via a self-service user interface.
	- Experience building and supporting modern data lake and EDW technologies (Hadoop, Spark, Cloud, NoSQL etc.) and workflow technologies (eg. Airflow)
	- Solid understanding of Google Cloud Platform, Python, Hive, and Kafka
	- Experience with Tableau, Google Analytics and BigQuery (or any other Big data/Cloud equivalent) etc.
	- Experience working with and processing structured, unstructured, and semi-structured data
	- Experience building data systems at scale
+ skill set:
	- Joining us as a Data Engineer, you'll play a key role in one of the aspects of developing software/tech for best in class road features, navigation, and high definition maps. You'll bring your experience and skills to our exciting project within a competent, cross-functional, passionate and self-organized team.
	- Take ownership, improve, scale and iterate on existing data processing pipelines
	- Design and implement new data processing pipelines;
	- Collect and monitor performance metrics;
	- Play a central role in discussing and implementing security best practices.
	- Good knowledge of at least one programming language (Python, Scala, Java);
	- Comfortable with SQL, good understanding of SQL engine basics;
	- Proficient understanding of distributed computing principles;
	- Hands-on experience with Spark / PySpark;
	- Experience with Hadoop (or similar) Ecosystem;
	- Experience with workflow management tools (Airflow, Oozie, Luigi);
	- Experience with AWS services, in particular S3, EC2, IAM, EMR, Glue, Athena, Kinesis;
	- Creative, resourceful and innovative problem solver;
	- Excellent team player with the ability to work within a collaborative environment;
	- Good communication skills in English, both written and spoken.
+ skill set for data engineering:
	- work with Scala-based core science and data platform
	- consumer-facing product layer in java and React
	- AWS-deployed software, using CI/CD with Kubernetes.
	- build, optimize, test, and improve REST and gRPC services
	- weight technical trade-offs and collaborate with coworkers to reach consensus about balancing practical necessities and ideological concerns
	- functional programming languages:
		* Scala
		* Haskell
		* Erlang
	- cloud computing tools
		* AWS
		* Docker
		* Kubernetes
		* Terraform
	- database systems:
		* schema design
		* query optimization
		* database tuning
		* migration tools
+ skill set:
	- Spotify is looking for Data Engineering Interns to join us this Summer. You will build data driven solutions to bring audio and digital media experiences to our millions of active users and artists either by working directly on product features, publishing and insight tools for artists, or by improving the quality of our data tools and large scale data infrastructure. You will take on complex data-related problems using some of the most diverse datasets available — user behaviors, acoustical analysis, revenue streams, cultural and contextual data, and other signals across our broad range of mobile and connected platforms. Above all, your work will impact the way the world experiences audio.
	- Build large-scale batch and real-time data pipelines with data processing frameworks like Scalding, Scio, Storm, Spark and the Google Cloud Platform.
	- Use best practices in continuous integration and delivery.
	- Help drive optimization, testing and tooling to improve data quality.
	- Collaborate with other engineers, ML experts and collaborators, taking learning opportunities that will arise every single day.
	- Work in multi-functional agile teams to continuously experiment, iterate and deliver on new product objectives.
	- You are pursuing a Bachelor's or Master's degree or a bootcamp certification in Computer Science or Computer Engineering or a related field of study.
	- You currently have valid work authorization to work in the country in which this role is based that will extend from June to August 2022
	- You are a current sophomore, junior or senior in undergrad or a first or final year Master's student
	- You've dabbled in high volume data, preferably with distributed systems such as Hadoop, BigTable, and Cassandra.
	- You know how to write distributed, high-volume services in Java, Scala and Python.
	- You've had exposure to data modeling, data access, and data storage techniques.
	- You have an interest in agile software processes, data-driven development, reliability, and responsible experimentation.
	- You understand the value of collaboration within teams.
+ skill set:
	- Investigate the feasibility of applying scientific principles and concepts to business problems.
	- Understand the ***Goodreads/Amazon data structures (MySQL/Data Lake/Redshift)***.
	- Acquire data by building the necessary ***SQL ETL queries***.
	- Import processes through various company specific interfaces for RedShift and Data Lake storage systems.
	- Analyze data for trends and input validity by inspecting univariate distributions, exploring bivariate relationships, constructing appropriate transformations, and tracking down the source and meaning of anomalies.
	- Build models using statistical modeling, mathematical modeling, econometric modeling, network modeling, social network modeling, natural language processing, machine learning algorithms, genetic algorithms, and neural networks.
	- Validate models against alternative approaches, expected and observed outcome, and other business defined key performance indicators.
	- Develop metrics to quantify the benefits of a solution and influence project resources. Partner with Engineering/Data Engineering to improve the quality of existing data and bring additional data sources in line. Audit metric data and measure project progress and success. Build/automate reports/dashboards (in Tableau) that allow the business leaders to get a clear snapshot of their operations. Design and analyze A/B tests to quantify impact of customer-facing changes. Develop innovative experimental design and measurement methodologies to understand customer growth and business efficacy. Participate in discussions, team planning, office hours, and metric reviews. Design and implement scalable and reliable approaches to support or automate decision-making throughout the business. Communicate insights to the business partners, Goodreads leadership, and Amazon stakeholders, with an emphasis on clarity, completeness, and actionability.
+ skill set:
	- Senior Data Engineer (US Remote Available)
	- The Senior Data Engineer will be involved in building data pipelines at a large scale to enable business teams to work with data and analyze metrics that support and drive the business. You will partner with cross functional teams to identify opportunities and continuously develop and improve processes for efficiency.
	- The team is looking for a Senior Data Engineer who can architect and build solutions across multiple data sources to deliver metrics/reporting use cases. This position is responsible to build and scale the data platform that works to provide business analytics. The role involves ownership and technical delivery, working closely with other members (BI engineer and infrastructure teams). Strong technical experience within enterprise software is essential.
	- Responsible for developing and supporting data pipelines that support and enable the overall strategy of expanded data programs, services, process optimization and advanced business intelligence
	- Leading data discovery sessions with business teams, comprising product owners, data analysts, and cross-team technologists to understand enterprise data requirements of analytics projects
	- Partner with business domain experts, system analysts, data/application architects, and development teams to ensure data design is aligned with business strategy and direction
	- Identify and document standard methodologies, standards, and architecture guidelines
	- Dive deep, as required, to assist Business Intelligence Engineers through technical hurdles impacting delivery
	- 7+ years of data architecture related experience such as data analysis, data modeling, and data integration.
	- Experience with GTM and customer success business processes and applications
	- ***Experience in custom ETL design, implementation, and maintenance***
	- Knowledge of programming languages (e.g. Python and Object Oriented Programming)
	- Hands-on experience with SQL database design
	- Experience working on CI/CD processes and source control tools such as Github and GitLab
	- Experience working Snowflake and relational databases
	- ***Extensive hands on experience in leading large-scale full-cycle cloud enterprise data warehousing (EDW) implementations like Snowflake***
	- Strong knowledge and experience with Agile/Scrum methodology and iterative practices in a service delivery lifecycle
	- Excellent communication and interpersonal skills with a demonstrated ability to influence a large organization
	- Passionate about data solutions, technologies, and frameworks
+ skill set:
	- Build and Support scalable and reliable data solutions that can enable self-service reporting and advanced analytics at Cloudflare using modern data lake and EDW technologies (Hadoop, Spark, Cloud, NoSQL etc.) in a agile manner.
	- 3+ years of development experience in Big data space working with Petabytes of data and building large scale data solutions.
	- Solid understanding of Google Cloud Platform, Hadoop, Python, Spark, Hive, and Kafka.
	- Experience in all aspects of data systems(both Big data and traditional) including data schema design, ETL, aggregation strategy, and performance optimization.
	- Capable of working closely with business and product teams to ensure data solutions are aligned with business initiatives and are of high quality.
+ skill set:
	- You know how to work with data engineering technologies like Spark, no SQL DB or Lambda
	- You know everything there is to know about Robotic Process Automation
	- A minimum of 7 years experience in deep learning, machine learning or artificial intelligence applications like virtual agent, RPA, or video/image/text analytics
+ Experience in working with large data sets and distributed computing tools (Hive, Redshift) is a plus
+ skill set:
	- Our data infrastructure team is responsible for all things data — our data warehouse, Hadoop, Redshift, Spark, Kafka, Airflow and so on.
	- Deep experience with MySQL, NoSQL data stores like HBase or similar.
	- Strong understanding of Unix/Linux variants, web network protocols, persistence solutions
+ skill set:
	- Python/Java Developer (Datagens)
	- LAB  SYSTEM & DATA ENGINEER
	- Are you interested in being part of a small, diverse team passionate about building technologies that change the way people learn?  Splunk Education is looking for a Lab and Data Engineer to join our Education Technologies Team. Our team is focused on building systems that help users learn to use our products in innovative ways.
	- Do you love tackling interesting problems and coming up with clean, stable solutions that delight users? We need to talk.
	- Opportunity to grow as an engineer. This role will provide a constant stream of new things to learn, providing the opportunity to expand your current knowledge and deep dive into new technologies.
	- Growth. We strongly believe in growing team members through ownership and leadership opportunities.
	- We pride ourselves on a collaborative, open and supported work environment.
	- The ability to work from home, or one of our many offices across the globe.
	- Participate in design and development of projects, either independently or in a team.
	- Be self-sufficient and take ownership of seeing projects through to successful conclusions.
	- Work with a diverse team of experts in education, video production, security and IT infrastructure.
	- Tasks include creating Terraform and Ansible playbooks to provision lab instances, along with building data generators that mock machine data across many technologies. 
	- B.S. degree in Computer Science or related field.
	- 8 years of experience
	- Deep knowledge of Python, Ansible, Terraform, Java, and AWS technologies.
	- Ability to read, understand and reproduce machine logs.
	- Experience with Docker, Kubernetes, GIT, and Splunk.
+ skill set:
	- Senior Software Engineer
	- We are seeking a passionate engineer to join our group, Data Platform. Our team designs distributed systems to collect and analyze high volumes of machine-generated data at scale. We are proud of owning what we build even after it's deployed to production. We ensure code hygiene, use open source libraries, employ continuous integration and delivery, and have a strong belief in automated testing at multiple levels (unit, integration, system). We are uniquely positioned as a globally distributed team with team members in a variety of locations. 
	- Develop and debug client-server system software written in C++ and/or Golang
	- Experience in distributed systems and large scale environments deployed at scale, both "on-premise" and in "cloud".
	- Experience with Linux deployments hosted by cloud service providers such as AWS and GCP.
	- Excellent problem solving, collaboration and communication skills, both verbal and written.
	- Mentored junior engineers in their development skills via code reviews and design discussions.
	- Owned features or sub-systems end-to-end from design to deployment and continuous improvement..
	- Develop server-side applications for data collection, indexing, clustering and other distributed systems.
	- Build robust, fault-tolerant distributed systems in a multi-threaded, multi-process environment.
	- Analyze, identify and resolve the bottlenecks of distributed systems, data pipeline, multi-threaded coherency and other complicated scenarios.
	- Analyze and improve the scalability of data collection, storage and retrieval.
	- Interact cross-functionally with other partners such as PMs, SREs, Devops, and support engineers.
	- Participate in rotating on-call duties to diagnose and fix customer issues.
+ skill set:
	- Principal Technical Program Manager - GDI (Remote - US)
	- We are looking for a Principal Technical Program Manager, who will be responsible for leading large-scale, complex programs from start to end within our GDI (getting data in) area. You will be working cross-functionally with a broad set of technical and business partners to drive programs that will further Splunk's long range goals. We want a TPM who can thrive with a nebulous problem set, distill complex problems into concrete work, and guide multiple teams with their strong, critical thinking skills.
	- Strategically leading technical programs in the Platform Engineering organization, with a clear and constant understanding of priorities to drive expected outcomes, including New Product Introduction (NPI) and Go To Market (GTM) processes
	- Breaking down problems and operationalizing initiatives into coherent workstreams; defining program timelines and ensuring accountability of program goals; operating as the single source of truth in execution of highly complex programs
	- Proactively anticipating risks, developing mitigation plans, and driving problems to resolution
	- Aligning with organizational leadership and key business customers as a program lead across multiple programs
	- Understanding system interdependencies and facilitating technical discussions; communicating solutions and decisions with both engineers and non-technical audiences
	- Creating and maintaining detailed and easy-to-digest program documentation, managing dependencies, and tracking status across multiple teams and workstreams
	- 10+ years experience in software program management or closely related roles
	- Experience with enterprise software and cloud technologies, along with a deep understanding of the software development lifecycle
	- Understanding and experience with creating and consuming APIs
	- Experience working with or knowledge of Data Ingestion messaging or stream processing technologies, such as Flink, Kafka, Kinesis, Pulsar, Spark or similar
	- Extensive experience with large, cross-functional programs that have broad organizational impact
	- Demonstrated ability at juggling multiple, concurrent programs and prioritizing tasks based on criticality
	- Communication and risk management are your forte. You can communicate effectively with stakeholders of all levels and develop plans to act upon risks appropriately
	- Phenomenal at decision-making, consensus building, and problem solving; you don't shy away from challenges
	- Strong technical proficiency required to understand development tasks and identify and resolve issues as they arise
	- Understanding of key development tools and technologies such as Gitlab, AWS, Kubernetes, Terraform, etc. Experience with program management tools in the Atlassian stack (Jira and Confluence) are great
+ skill set:
	- Data Engineer, DevOps (US Remote Available)
	- The Analytics & Data Platform team (ADP) is responsible for Splunk's data platform from ingestion to visualization. This platform enables our business partners to make the best data-driven decisions possible. We're looking for a Data Engineer to join the team and contribute to the development and adoption of a true, self-serve, Data Mesh platform, with a focus on automation and observability. This position is responsible for the development, maintenance, and support of the data platform (including on-call rotations), partnering with all levels of customers in the course of support/adoption/migration activities, and actively participating in the growth and development of the ADP team and its capabilities and processes.
	- Operate: Perform the day to day updates, changes, and scheduled activities on the data platform. All the while, being attentive to opportunities for automation.
	- Support: Ensure SLAs are met by monitoring the data platform and responding to issues as they arise. Partner with other engineers or dependent teams as needed to resolve issues.
	- Develop: SQL and Python will be your go to tools, but by no means is that all. You'll have a broad range of technologies that you'll need to wrestle into submission to be successful: Terraform, Gitlab, Airflow, K8, Docker, DBT, and Linux, just to name a few.
	- Collaborate: Members of the ADP team are expected to work together to continuously improve the team's processes, infrastructure, codebase, etc. Asking questions, challenging ideas, and recommending alternatives are all necessary for the team to continue to grow and improve. Passionate opinions are welcome.
	- Innovate: Develop creative solutions to edge cases that are causing unnecessary complications, with a focus on maintainability and scalability.
	- 4+ years of work experience in a relevant field (Data Engineer, DevOps Engineer, Backend Engineer, etc.)
	- Experience with data warehousing technologies (Redshift, Snowflake, BigQuery, or similar)
	- Proficient SQL skills and strong experience working with relational databases
	- Proficiency in a major programming language (ideally Python)
	- Excellent code and repo hygiene
	- Past experience as a user of Splunk
	- Experience with or a strong interest in containerization and/or Kubernetes
	- Experience with declarative configuration tools such as Terraform
	- Past experience contributing to an open source project
	- Passionate about technology with an insatiable curiosity for learning new things
	- B.S. degree in computer science, mathematics, statistics or a similar quantitative field, or sufficient relevant experience
+ skill set:
	- Director, Engineering
	- This Director for Engineering will lead critical services within our Data Processing umbrella. Success will be measured by your ability to build and lead your team as part of our overall engineering strategy. You will seamlessly integrate within our deeply innovative culture and contribute to our excellent record for delivering market leading solutions. You are a seasoned leader with a demonstrated history building and leading both established and emerging engineering talent, while encouraging an environment of inclusion, creativity, and innovation.
	- Our Data Processing team is a dynamic technology group with a mission to be the primary data processing path for any type of data transformation and routing activity in near real-time. If you possess a passion for extraordinary technology leadership and embrace the challenge of working at the frontier of what is possible in the industry today, then this position is for you. We are building state-of-the art capabilities, real-time messaging and streaming systems, support tools, and automation instrumentation that will greatly impact how our customers successfully use data to improve their businesses performance, scalability, profitability, and market strategies.
	- We are looking for a proven, seasoned engineering leader to lead streaming capabilities for the Data Processing team. You will build and lead an elite team of engineers who will be working on our streaming platform that will power the next generation of Splunk and enable ever deeper customer insights. You are a force multiplier who looks for ways to gain efficiencies for greater impact. You will influence the technical strategy and the roadmap to best serve our customers.
	- Hire and grow a new team within the Data Processing Engineering organization, focused on making our industry leading technology even more valuable to our customers.
	- Be an advocate of scalable and extensible, recoverable, manageable architecture for Core products and services.
	- Work with senior leadership on business goals, resource requirements and influence technical strategy
	- Diagnose and resolve systemic obstacles that prevent your team from delivering high-quality software.
	- Champion an atmosphere of continuous improvement by serving as a coach, mentor, and technical advisor for senior managers, managers and engineers.
	- Plan and support career development.
	- Recruit and retain top talent.
	- Masters or PhD in Computer Science or Engineering with 15+ years of industry experience, of which 10+ years is in Engineering Management.
	- 3+ years of experience managing multiple managers/teams on working on solutions to deeply challenging problems in processing data at massive scale.
	- Experience hiring and cultivating teams.
	- Experience developing new products, either in small companies or within the context of larger organizations. A mix of start-up and bigger company experience is a plus.
	- Experience working within geographically distributed organizations.
	- Experience building and cultivating strong engineering practices and processes.
	- Consistent track record of delivering scalable, high performance, and high quality software systems.
	- Broad understanding of various cloud development technologies and trends for enterprise-scale, distributed systems.
	- Strong technical acumen, creativity, interpersonal skills, and emotional intelligence.
+ ***[Apache Airflow, Luigi](https://towardsdatascience.com/data-pipelines-luigi-airflow-everything-you-need-to-know-18dc741449b7), workflow management system (WMS), Azkaban, [Open Source Data Pipeline – Luigi vs Azkaban vs Oozie vs Airflow](https://www.bizety.com/2017/06/05/open-source-data-pipeline-luigi-vs-azkaban-vs-oozie-vs-airflow/), [Pinball](https://robinhood.engineering/why-robinhood-uses-airflow-aed13a9a90c8), Airbnb Airflow vs Apache Nifi***
	- ***Jenkins vs Airflow. Jenkins is an open source continuous integration tool written in Java.***
	- ***Flyte***
		* https://flyte.org/
		* Build & deploy data & ML pipelines, hassle-free
		* The infinitely scalable and flexible workflow orchestration platform that seamlessly unifies data, ML and analytics stacks.
		* Create extremely flexible data and ML workflows
		* End-to-end data lineage
		* Collaborate with reusable components
		* Integrate at the platform level
		* Allocate resources dynamically
	- ***Dagster***
		* https://dagster.io/
		* Cloud-native orchestration of data pipelines
		* Ship data pipelines with extraordinary velocity
		* The cloud-native orchestrator for the whole development lifecycle, with integrated lineage and observability, a declarative programming model, and best-in-class testability.
		* Manage your data assets with code
		* An orchestration platform for the development, production, and observation of data assets.
+ Exposure to big data systems like Hadoop, Spark, Kafka, etc.
+ skill set:
	- Understanding and experience with NoSQL such as MongoDB or Neo4j
	- Experience with the Hadoop ecosystem (HBase, MapReduce, Hive/Pig) or Spark
+ skill set:
	- Implements, troubleshoots, and optimizes distributed solutions based on modern big data technologies like Hive, Hadoop, Spark, Python, Elastic Search, Storm, Kafka, Oozie WFs etc. in both an on premise and cloud deployment model to solve large scale processing problems
	- Design, build and maintain Big Data workflows/pipelines to process billions of records into and out of our data lake
	- Provide technical leadership in the area of big data systems development including data ingestion, data curation, data storage, high-throughput data processing, analytics, user access, and security
	- Proficiency in Amazon AWS big data technologies including S3, RDS, RedShift, Elasticsearch, Lambda, AWS Glue
	- Keen understanding of big data and parallelization accompanied with a stellar record of delivery
	- Experience working within the AWS Big Data/Hadoop Ecosystem (EMR is preferred), AWS Glue
	- Experience with on-premises to cloud migrations including re-hosting, re-platforming and re-factoring
	- Experience with orchestration template technologies such as AWS CloudFormation
+ skill set:
	- Architect and operate high quality, large scale, multi-geo data pipelines that drive business decisions.
	- Redesigned data pipelines using the applicable DBR features, and incorporating external tools where necessary to have better reliability and tighter SLAs.
	- Established conventions or new APIs for logging feature usage for PM use-cases.
	- Understandable SLAs for each of the production data pipelines.
	- Improved test coverage (90+%) for data pipelines. Best practices and frameworks for unit, functional and integration tests.
	- CI and deployment processes and best practices for the production data pipelines.
	- Reduction in overall alert noise and increase responsiveness by rethinking the current alert categories and priorities.
	- Design schemas for financial, sales and support data in the data warehouse.
	- Experience building, shipping and operating multi-geo data pipelines at scale.
	- Experience with working with and operating workflow or orchestration frameworks, including open source tools like Airflow and Luigi or commercial enterprise tools.
	- Experience with large scale messaging systems like Kafka or RabbitMQ or commercial systems.
	- Excellent communication (writing, conversation, presentation) skills, consensus builder
	- Strong analytical and problem solving skills
	- Passion for data engineering and for enabling others by making their data easier to access.
	- Experience with pipelines that are used by many downstream teams, including non-engineering functions.
	- Experience with streaming data frameworks like spark streaming, kafka streaming, Flink and similar tools a plus.
	- Experience working with Apache Spark and data warehousing products.
	- Direct experience with a log collection and aggregation system at scale.
	- Demonstrated execution at a growth stage technology company.
+ skill set:
	- If you are looking for an unparalleled opportunity to build the next generation big data processing platform, and learn how to launch hundreds of thousands of VMs a day at scale while running thousands of Kubernetes clusters, you have come to the right place. The platform team builds and manages the core systems powering Databricks, allowing it to seamlessly scale and run across various geographic regions/clouds, and making Databricks the go-to product for big data processing in the cloud.
	- You will be a senior software engineer responsible for architecting scalable systems to power Databricks, making it the de-facto platform for running Big Data and AI workloads. You will build and extend the Databricks cloud platform, which is based on a micro service architecture and includes systems for managing thousands of Kubernetes clusters at scale, systems for streaming and consuming gigabytes of log data per minute, onboarding and managing thousands of data scientists on Databricks, scalable API gateway, rate limiting framework, network security and encryption, build infrastructure (we use Bazel), and scalable CI/CD framework among many others.
	- Develop and extend the Databricks platform. This implies, among others, writing clean, efficient code in Scala or Python and/or interacting with: cloud APIs (e.g., compute APIs, cloud formation, Terraform), with open source and third party APIs and software (e.g., Kubernetes) and with different Databricks services
	- Experience with cloud APIs (e.g., a public cloud such as AWS, Azure, GCP or an advanced private cloud such as Google, Facebook)
+ skill set:
	- Develop and extend the Databricks product. This implies, among others, writing software in Scala, Python or Javascript and/or interacting with: cloud APIs (e.g., compute APIs, cloud formation, Terraform), with open source and third party APIs and software (e.g., Kubernetes) and with internal APIs.
+ skill set:
	- Develop and extend the Databricks product. This implies, among others, writing software in Scala, Python, and Javascript, building data pipelines (Apache Spark, Apache Kafka), integrating with third-party applications, and interacting with cloud APIs (AWS, Azure, CloudFormation, Terraform).
	- To achieve this, we build data reporting pipelines that support the underlying pricing infrastructure supporting tens to hundreds of millions of DBUs (Databricks Units) across multiple clouds and regions, UIs that allow Databricks administrators to view and manage their bill, and APIs and integrations to downstream processors to handle payments for all customers.
	- Experience in architecting, developing, deploying, and operating large scale distributed systems.
	- Experience with distributed data processing systems (Apache Spark, Apache Kafka).
	- Experience with cloud APIs (e.g. a public cloud such as AWS, Azure, GCP, or an advanced private cloud such as Google, Facebook).
	- Experience working on a SaaS platform or with Service-Oriented Architectures.
	- Experience with API development.
	- Good knowledge of SQL.
	- Experience with software security and systems that handle sensitive data.
	- Exposure to container technologies, such as Kubernetes, Docker.
	- Unified Analytics Platform
+ skill set:
	- Our team drives state-of-the-art, open source Delta Lake project bringing reliable, scalable, ACID transactions to Apache Spark and other Big Data engines. Our mission is to deliver a robust and performant engine that enables users to build reliable data pipelines that ingest massive data volumes, optimize data layout, generate metadata and evolve data schemas all while guaranteeing transactional correctness and high query performance.
	- Build the core features that make Delta Lake the world's best Big Data storage abstraction in terms of performance, stability, security and scalability.
+ [***Delta Lake Community***; Delta Lake is an open-source storage layer that brings ACID transactions to Apache Spark™ and big data workloads.](https://delta.io/)
+ skill set:
	- You will build tools and features to make Databricks the best place for large-scale enterprise R workloads.
	- Improve state of distributed R computing through Apache Spark and R integration on Databricks
	- Implement new features on Databricks platform for R users (e.g., ACL)
	- Improve and extend Databricks R notebooks to satisfy R users' use cases and requirements
	- Implement new R-based APIs on Databricks platform (e.g., secret management API)
	- Expand Databricks workspace through integration with third-party tools such as RStudio and Shiny.
	- Integrate critical packages from the R ecosystem into Databricks Runtime
	- Provide engineering support and thought leadership to Databricks field engineering teams on R
	- Give talks and write blog posts about R on Databricks
+ skill set:
	- You revel in building features quickly and iterating in a data-driven fashion
	- You lay awake thinking about improving the design, implementation and maintenance of large software systems with millions of users
	- Passion to hack social commerce
	- Data & Relevancy engineers work on our massive semi-structured datasets. They have domain experience in data mining, information retrieval, or machine learning, and a strong system orientation. Key product initiatives include product feed relevance, ad targeting, information extraction, and recommendations.
	- Infrastructure engineers scale a massive, highly-available platform end-to-end. They design distributed systems, validate performance, factor in security, and proactively monitor every corner of our stack. When things do go wrong, they are on-hand to fight the fires.
+ skill set:
	- Experience with data processing frameworks and data warehouses such as Hadoop, Spark, Redshift
	- Experience with designing, implementing, and optimizing ETL in Pentaho
+ skill set:
	- Technical fluency in one language and tool such as Python, Java or Scala, AWS (S3/EMR/Athena/Glue) and SQL.
	- Experience with big data processing tools including Spark, Hadoop, Hive, Yarn, and Airflow.
	- Experience working with either a MapReduce system of any size/scale.
+ skill set:
	- Minimum 3 years of designing, building and operationalizing large scale enterprise data solutions and applications using one or more of Azure / AWS / GCP data and analytics services in combination with custom solutions -  Spark, Azure Data Lake, HDInsights, SQL DW, DocumentDB, Search, Elastic Pool etc.  
	- Minimum 3 years experience introducing and operationalizing self-service data preparation tools (e.g. Trifacta, Paxata) on AZURE.
+ skill set:
	- Familiarity with No SQL databases (i.e. MongoDB, Hadoop, Hive Spark, etc.), data streaming and integrating unstructured data will be plus.
	- Experience working in a DevOps environment, and using industry standard tools (GIT/OneStash, JIRA)
	- Exposure to rules engines e.g. drools, ESBs e.g. MuleSoft & integration with enterprise systems
+ skill set:
	- Knowledge of ETL, Map Reduce and pipeline tools (Glue, EMR, Spark)
	- Experience with large or partitioned relational databases (Aurora, MySQL, DB2)
	- Experience with NoSQL databases (DynamoDB, Cassandra)
	- Experience with data streaming technologies (Kinesis, Storm, Kafka, Spark Streaming) and real time analytics
	- Other preferred experience includes working with DevOps practices, SaaS, IaaS, code management (CodeCommit, git), deployment tools (CodeBuild, CodeDeploy, Jenkins, Shell scripting), and Continuous Delivery
	- Experience with large or partitioned relational databases (Aurora, MySQL, DB2)
	- Experience with data streaming technologies (Kinesis, Storm, Kafka, Spark Streaming) and real time analytics
	- Primary AWS development skills include S3, IAM, Lambda, RDS, Kinesis, APIGateway, Redshift, EMR, Glue, and CloudFormation
+ skill set:
	- Demonstrates knowledge of the data engineering domain with experience in building and supporting non-interactive (batch, distributed) or real-time, highly available data, data pipelines.
	- Able to build fault tolerant, self-healing, adaptive computational pipelines
	- Contribute to the decision-making process related to the selection of software solutions that make up the architecture
+ skill set:
	- Minimum 3+ years of architecting, implementing and successfully operationalizing large scale data solutions in production environments using Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using  many of the relevant technologies such as  Nifi, Spark, Kafka, HBase, Hive, Cassandra, EMR, Kinesis, BigQuery, DataProc, Azure Data Lake etc.  
	- Minimum 2+ years of experience implementing SQL on Hadoop solutions using tools like Presto, AtScale and others
	- Minimum 3+ years of architecting data and building performant data models at scale for Hadoop/NoSQL ecosystem of data stores to support different business consumption patterns off a centralized data platform  
	- Minimum 3+ years of Spark/MR/ETL processing, including Java, Python, Scala, Talend; for data analysis of production Big Data applications
	- Minimum 3++ years of architecting and industrializing data lakes or real-time platforms for an enterprise enabling business applications and usage at scale
	- Minimum 2+ years of experience implementing large scale BI/Visualization solutions on Big Data platforms
	- Minimum 3+ years of experience implementing large scale secure cloud data solutions using AWS data and analytics services e.g. S3, EMR, Redshift
	- Minimum 2+ years of experience implementing large scale secure cloud data solutions using Google data and analytics services e.g. BigQuery, DataProc
	- Minimum 2+ years of experience building data management (metadata, lineage, tracking etc.)  and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud
	- Minimum 2+ years of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud
	- Minimum 2+ years of Re-architecting and rationalizing traditional data warehouses with Hadoop or NoSQL technologies on premise or transition to AWS, Google clouds
	- Experience implementing data wrangling and data blending solutions for enabling self-service solutions using tools such as Trifacta, Paxata
	- 4 years industry systems development and implementation experience OR Minimum of 3 years of data loading, acquisition, storage, transformation, and analysis
	- Minimum 2+ years of using Talend, Informatica like ETL tools within a Big Data environment to perform large scale metadata integrated data transformation
	- Minimum 1+ years of building Business Catalogs or Data Marketplaces on top of a Hybrid data platform containing Big Data technologies
	- Architect modern data solutions in a hybrid environment of traditional and modern data technologies such as Hadoop, NoSQL
	- Create technical and operational architectures for these solutions incorporating Hadoop, NoSQL and other modern data technologies
	- Implement and deploy custom solutions/applications using Hadoop/NoSQL
	- Lead and guide implementation teams and provide technical subject matter expertise in support of the following:
	- Designing, implementing and deploying ETL to load data into Hadoop/NoSQL
	- Security implementation of a Hadoop/NoSQL solutions
	- Managing data in Hadoop/NoSQL co-existing with traditional data technologies in a hybrid environment
	- Troubleshooting production issues with Hadoop/NoSQL  
	- Performance tuning of a Hadoop/NoSQL environment
	- Architecting and implementing metadata management solutions around Hadoop and NoSQL in a hybrid environment
+ skill set:
	- Experience with Apache Big Data technologies such as Hadoop, Spark, Hive, Flink, Kafka, Beam etc
		* Apache Hadoop: for distributed computing
		* Apache Spark:
			+ open-source unified analytics engine for large-scale data processing
			+ large-scale data analytics
		* Apache Hive:
			+ [data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage](https://hive.apache.org/)
				- [The Apache Hive™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage and queried using SQL syntax.](https://cwiki.apache.org/confluence/display/HIVE)
			+ [Apache Hive is a distributed, fault-tolerant data warehouse system that enables analytics at a massive scale.](https://aws.amazon.com/big-data/what-is-hive/)
			+ data warehouse software project built on top of Apache Hadoop for providing data query and analysis
		* Apache Flink:
			+ open-source unified stream-processing and batch-processing framework
			+ distributed streaming data-flow engine
			+ for dataflow programs, executed in a data-parallel and pipelined manner (or task parallel manner)
			+ pipelined runtime system that enables the execution of bulk/batch and stream processing programs
		* Apache Kafka:
			+ distributed event store and stream-processing platform
			+ provide a unified, high-throughput, low-latency platform for handling real-time data feeds
			+ provides the Kafka Streams libraries for stream processing applications
			+ [open-source distributed event streaming platform used by thousands of companies for](https://kafka.apache.org/):
				- high-performance data pipelines
				- streaming analytics
				- data integration
				- mission-critical applications
				- ["event streaming is the practice of capturing data in real-time from event sources like databases, sensors, mobile devices, cloud services, and software applications in the form of streams of events; storing these event streams durably for later retrieval; manipulating, processing, and reacting to the event streams in real-time as well as retrospectively; and routing the event streams to different destination technologies as needed. Event streaming thus ensures a continuous flow and interpretation of data so that the right information is at the right place, at the right time."](https://kafka.apache.org/intro)
		* Apache Beam: for defining and executing (via distributed processing back-ends) data processing pipelines for:
			+ ETL
			+ batch processing
			+ stream processing = continuous processing
	- Experience with messaging systems such as ActiveMQ
	- Join a passionate team and work with the latest technologies (Hadoop, K8s, Terraform, AWS, GCP to name a few)
+ skill set:
	- Backend development experience with a strong interest in work involving data pipelines, distributed systems, performance analysis, and/or large-scale data processing Experience with software engineering practices (e.g. unit testing, code reviews, design documentation)
	- Able to take on complex problems, learn quickly, and persist towards a good solution
	- Experience designing fault-tolerant distributed systems
	- Experience with data pipelines
	- Experience with Hadoop or other MapReduce-based architectures
	- Experience with Kafka, Druid or other Streaming Compute based technologies is a plus
	- Experience with ad tech is a plus
+ tech stack:
	- Netflix culture resonates with you.
	- You can communicate effectively with experts of all backgrounds.
	- You are an expert analyst and can pick up any tool (e.g. Tableau, D3) to get the job done.
	- You dream in SQL and Python (or other similar languages).
	- You are comfortable with Big Data technologies like Hadoop, Spark, Hive, Presto etc.
+ Expertise in SQL, programming (e.g. Python, Scala), ETL and data warehousing concepts at scale (TBs of data)
+ Expertise in broad technical skills spanning data access, data storage, data processing, and data visualization.  Skills include: SQL, logical / semantic data modeling, ETL and data warehousing concepts, programming languages (Python)
+ Build data tooling to enable data lake, data warehouse, and analytics workflows within the AWS cloud (S3, Redshift, DynamoDB, Spark, Kinesis, Kubernetes, etc.)
+ experience with API design
	- REST
	- OpenAPI Specifications
	- GraphQL
+ Spark and/or other big data architectures (Hadoop, MapReduce) in high-volume environments
+ ***Experience with large-scale, distributed data processing frameworks (e.g., Spark, Kafka, YARN, Tachyon, Mesos, etc.) is a plus***
	- Apache Spark:
		* open-source unified analytics engine for large-scale data processing
		* open-source unified engine for large-scale data analytics
	- Apache Kafka:
		* distributed event store and stream processing platform
		* open-source distributed event streaming platform, for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications
	- YARN, Apache Hadoop YARN:
		* split up functionalities of resource management and job scheduling/monitoring into separate daemons, via global resource manager (RM) and per-application application master (AM)
		* not yarn package manager
	- Tachyon
		* from Alluxio Inc., previously Tachyon Nexus
			+ improve Apache Spark performance
			+ reliable memory-centric distributed storage system
			+ Alluxio: open-source virtual distributed file system, VDFS
				- in the big data analytics stack, Alluxio is the data asbtraction layer in between the computation frameworks and (multiple) storage systems, which is accessible via a common interface
				- APIs for:
					* Hadoop HDFS
					* Amazon S3
					* FUSE
			+ open-source, distributed, fault-tolerant, in-memory file system to enable data sharing across frameworks and perform operations at memory speed
		* not open-source component library
		* not the parallel/multiprocessor ray tracing software
	- Mesos
+ Experience with working with and operating workflow or orchestration frameworks, including open source tools like Airflow and Luigi or commercial enterprise tools.
+ tech stack:
	- Well-versed in one or more of the following languages and functional programming in general: Scala, Java, Python, JavaScript
	- Expert in SQL and comfortable designing, writing and maintaining complex SQL based ETL.
	- Experience with building large-scale batch and real-time data pipelines; ETL design, implementation, and maintenance.
	- Experience with schema design and data modeling, and the analytical skills to QA data and identify gaps and inconsistencies.
+ Experience in working with large data sets and distributed computing tools (Hive, Redshift)
+ ***Programming skills sufficient to extract, transform, and clean large (multi-TB) data sets in a Unix/Linux environment.***
+ big data tools and stream-processing systems: Hadoop, Spark, Storm, Spark-Streaming
+ Extensive experience manipulating and analyzing complex data with SQL, Python and/or R. Knowledge of Google BigQuery and Java/Scala is a plus.
+ skill set:
	- As the Principal Data Engineer on the Platform team at Zignal Labs, you will get to use your Scala and Java experience to build a best-in-class distributed data and analytics infrastructure by leveraging open source technologies such as Apache Spark, Apache Storm, and Elasticsearch.  We use social media, news, blogs and other media sources to empower our users with key insights based on real-time analysis.
	- Solve complex real-time data collection & analysis problems with cutting edge technical solutions
	- Iterate on our high performance and scalable platform for massive data collection, real-time analytics, NLP, machine learning, and backend data services
	- Build high performance, scalable, real-time, server-side technologies
	- Write scalable code with extensive test coverage, working in a professional software engineering environment with source control, dev/stage/production release cycles, continuous integration, and deployment
	- Work closely with product management, design, quality assurance and operations teams to understand our customers' needs and effectively translate them to technical specifications
	- Lead projects from translating product requirements into architecture to production
	- Tech Stack:
		* Scala, Java, Python
		* Apache Spark, Spark Streaming, Databricks/Delta Lake, Apache Storm, Elasticsearch, Apache Nifi
		* Kafka, MongoDB, Redis
		* AWS
	- Bachelor's degree (or higher) in Computer Science, Engineering, or similar and/or relevant work experience
	- Experience providing technical leadership at the enterprise level for the design of information technology systems
	- Crafted and implemented operational data stores, as well as data lakes in production environments
	- Ability to analyze, diagnose and resolve complex architectural problems using industry standard engineering principles
	- Design and build data ingestion pipelines and ETL processing, including stream processing, while factoring in performance and cost
	- Identify and solve issues concerning data management to improve data quality
	- Clean, prepare and optimize data for ingestion and consumption
	- Experience solving performance problems with Lucene based search solutions like Elasticsearch or Solr
	- 9+ years experience in server-side/back-end full cycle product development in a production environment
	- 4+ years developing with Apache Spark, including Structured Streaming.   Experience with Databricks is a big plus
	- Knowledge of Scala or Java with exposure to or interest in Scala
	- Leads and mentors other team members
	- Provides partners with coaching and feedback in order to build effective teams
	- Provides effective support to cross-functional teams
+ skill set:
	- OLAP datastores:
		* Druid
		* ClickHouse
		* Scio
		* Flink
		* Spark
		* BigQuery
		* Parquet
		* Databricks
+ skill set:
	- As Scale's Analytics Engineer, you will spearhead building Scale's analytical and business-intelligence infrastructure. Scale's customers process millions of tasks through our APIs, and we're looking for a talented Analytics Engineer to build scalable solutions to support this growth. You will have widespread purview, with responsibility for understanding, mining, aggregating, and exposing data across the entire business to support timely and efficient decision-making and data exploration. You will also implement Scale's data warehouse, data mart, and business intelligence reporting environments, and help users transition their workflows to these systems.
	- Work with operations, finance, and engineering to drive the development of pipelines that provide single-source-of-truth foundational accuracy
	- Continually improve ongoing data pipelines and simplify self-service support for business stakeholders
	- Perform regular system audits, and create data quality tests to ensure complete and accurate reporting of data/metrics
	- 3+ years of relevant work experience in a role requiring application of data modeling and analytic skills
	- Ability to create extensible and scalable data schema and pipelines that lay the foundation for downstream analysis using SQL and Python
	- Experience with ETL tools and building / maintaining a data warehouse and data pipelines using tools such as DBT
	- Partner with operations and sales teams to automate manual workflows
	- Experience in using highly scalable data engineering technologies such as DBT, Airflow 
	- Experience in best practices in table partitioning/data sharding strategies and query optimization
	- The base salary range for this full-time position in our hub locations of San Francisco, New York, or Seattle, is $148,800 – $178,560. Compensation packages at Scale include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Scale employees are also granted Stock Options that are awarded upon board of director approval. You'll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.
+ skill set:
	- Foursquare's flexible building blocks include technology to maximize marketing impact and drive incremental real-world engagement (Attribution, Audience, Proximity, SDK); data to deeply understand points of interest and real-world behavior patterns (Places and Visits), and tools to conduct advanced analysis, data enrichment, unification and visualization (Studio).
	- Foursquare's Marketers Engineering team writes and operates the software which produces core data sets for our Marketers suite of products. These petabyte-scale pipelines process geospatial data for the purposes of marketing use cases, such as ad targeting and attribution. It's critical to this team's success that we have rich data sets to build our applications on top of, and this data is kept fresh, easy to explore, and simple to make changes. The engineers on this team work closely with application engineers to prove out variant approaches and introduce new functionality.
	- In the Data Software Engineer role, you will ship products with high visibility and strategic importance to Foursquare and contribute directly to the revenue. Our pipelines are written in a variety of programming languages and deployed to multiple orchestration platforms. The main technologies we work with are Spark, Amazon EMR, Ruby, Java, and Apache Airflow.
	- Write and operate the data pipelines which produce Foursquare's core data sets for our Marketers suite of products – Attribution and Targeting.
	- Document the expected and actual behavior of these pipelines, along with expectations for inputs and outputs.
	- Monitor data quality and freshness, with a focus on proactively evaluating the business impact of changes. Report regularly on the state of the data sets and the software which produces them.
	- Maintain a prioritized list of data questions and bugs which require further investigation. Escalate as needed to call attention to problems with the input data.
	- Evaluate new sources of data, and build new pipelines that combine our data in creative ways that drive customer value.
	- Participate in on-call rotation duties to ensure that data is correct and produced on-time, and to restore service when the pipelines are experiencing an outage.
	- 2-4 years of software development experience.
	- Professional experience with at least one of Hadoop MapReduce and/or Spark data processing pipelines.
	- Strong algorithms and data structures knowledge.
	- Professional experience scripting with the Unix/Linux command line or Python.
	- Experience with cloud computing service providers, such as AWS.
	- Experience with ***containerization technologies, such as Docker, Mesos or Kubernetes***.
	- Excellent written communication skills.
	- ***Your own unique talents! If you don't meet 100% of the qualifications outlined above, we encourage and welcome you to still apply!***
	- Experience with CI/CD systems such as Jenkins, Travis, TeamCity, and CircleCI.
	- Experience at marketing or ad-tech data companies: RTB / real-time bidding. DSP / demand-side platform.
	- Experience with geospatial data processing.
+ skill set:
	- Foursquare's flexible building blocks include technology to maximize marketing impact and drive incremental real-world engagement (Attribution, Audience, Proximity, SDK);  data to deeply understand points of interest and real-world behavior patterns (Places and Visits), and tools to conduct advanced analysis, data enrichment, unification and visualization (Unfolded Studio).
	- Our Data Platform team provides the infrastructure, tools, libraries, and APIs that power our data processing infrastructure. The goal of the team is to make engineers at Foursquare more effective and happier by offloading common problems from the product and content experts, enabling them to apply their skills and knowledge to their specific domain, while the Data Platform team works on problems that affect the company as a whole.
	- In this role, you will ship products with high visibility and strategic importance to Foursquare and contribute directly to revenue. Help us build and collaborate with Product, Engineering, and Data Science teams to create tools and processes to bring research and machine learning models to production.
	- Build tools and APIs that would be used by other FSQ Engineers
	- Build and maintain Foursquare's event streaming platform, Framework, and applications for data ingestion
	- Build resilient services and tooling which drive all of our offline processing of petabytes of data
	- Write test automation, conduct code reviews, and take end-to-end ownership of deployments to production
	- Participate in on-call rotation duties
	- What you'll need: If you have more or less experience than listed, please apply anyways and we will see if another role aligns better with your experience.
	- BS/BA in a technical field such as computer science or equivalent experience
	- 3+ year of experience in software development working with production-level code
	- Experience in one or more of the programming languages we use
	- Excellent communication skills, including the ability to identify and communicate data-driven insights
	- Experience with working in the cloud, preferably AWS
	- Strong algorithms and data structures knowledge
	- Comfort with Unix/Linux and the command line
	- Experience with Hadoop, Kafka, MapReduce, and/or Spark
	- Experience with AWS data processing services (EMR, Glue, Athena, …)
	- Experience with relational or document-oriented database systems
	- Prior software internship experience
	- ***Languages: Java, Scala, Python, Clojure, Ruby***
	- ***Tools for pipeline orchestration: Airflow, Luigi***
	- ***Frameworks: Spark, MapReduce, Scalding, Spring Boot***
	- ***Infrastructure: AWS, Hadoop, Kafka, Kubernetes, Docker***
	- ***Other technologies: Postgres, Hive, HBase, MongoDB***
+ skill set:
	- Has advanced experience with data warehousing, data modeling, and data ETL
	- Has hands-on familiarity with ***message queues (preferably Kafka) and one or more cloud provider (preferably AWS)***.
	- Familiarity with ***Hadoop, MapReduce, and Snowflake analytics*** are a plus
+ skill set:
	- Experience building and maintaining development pipelines with ***Jenkins, XL Release, QuickBuild*** (or similar) required.
	- Experience with web app internationalization and translation technologies like ***Smartling*** is strongly desired.
	- Experience with ***MySQL and SOLR*** is strongly desired.
+ ***Snowflake, AWS, Java, Solr, PHP***
+ skill set:
	- Open Source Infrastructure Engineer
	- Our company has its roots in the Python data science community. Our leaders have had significant involvement in the creation and maintenance of NumPy, SciPy, Jupyter, Spyder, Dask, Conda, Numba, Anaconda and PyData NumFOCUS. Our mission is to connect companies to open-source communities to create sustainable solutions that benefit the whole ecosystem.
	- We accomplish this mission by providing various services ranging from open-source software development to training and consulting. We believe in a culture of do-ers, learners, and collaborators. We are looking for people who are motivated, humble, curious, and respectful of others.
	- We are seeking a fully remote, experienced Open Source Infrastructure Engineer to join our team at Quansight. In this role, you will support Quansight's growing cloud and on-premises infrastructure and help make them more reliable, scalable, and efficient. You will also  address support issues from our clients and collaborators, explore emerging technologies in the Cloud and DevOps spaces, and design and implement cloud computing systems with the rest of our infrastructure team.
	- Contribute to nebari (https://nebari.dev), an open source Data Science platform built on JupyterHub, Dask, and other tools from the PyData ecosystem.
	- Participate in upstream open source communities we rely on (such as JupyterHub, BinderHub, Dask, etc.) in partnership with the established leaders of those communities.
	- Deploy and ensure the reliable operation of Quansight's and clients' infrastructure.
	- Collaborate with a fully distributed team - team members are expected to communicate and collaborate proactively to allocate effort and maximize the team's impact.
	- Experience using some form of infrastructure-as-code tooling (i.e., Ansible, Salt, Puppet, Terraform, etc.)
	- Experience with at least one major cloud platform (AWS, Azure, GCP)
	- Experience developing tools in a general purpose programming language (eg. Python)..
	- Experience with Continuous Integration and Continuous Delivery services (e.g., Circle CI, GitHub Actions)
	- Familiarity with software engineering best practices – including unit tests, code review, version control, production monitoring, etc.
	- Experience deploying and developing with Linux container-based technologies, such as Docker and Kubernetes.
	- Comfortable working independently and reaching out for feedback and support as needed.
	- Experience collaborating and coordinating work via online platforms, such as GitHub, GitLab, or BitBucket, and distributed revision control.
	- Ability to provide and constructively receive feedback.
	- Experience working on geographically distributed open-source projects.
	- Exposure to the Python Data Science stack - Pandas, Numpy, Dask, etc.
	- Experience with the Jupyter ecosystem and other tools for interactive computing.
	- Experience building and maintaining continuous deployment pipelines.
	- Experience with common data science methods, platforms, workflows, and infrastructures; with data management systems, practices, and standards; and the capacity to gain familiarity with new related topics.
+ skill set:
	- Experience in distributed data processing systems (Hive, Redshift, Presto, Snowflake, etc)
	- Breadth of knowledge around statistical methods including A/B testing, causal inference, experimentation, cluster-randomized testing
	- Familiarity with Snowflake, dbt, and ETL/reverse ETL tools.
+ Build and maintain robust data pipelines that ingest over 30TB of data each day.
+ skill set:
	- Data Platform Engineer
	- SHANGHAI /PLATFORM ENGINEERING – PLATFORM ENGINEERING // REMOTE
	- CertiK is a pioneer in blockchain security, leveraging best-in-class AI technology to protect and monitor blockchain protocols and smart contracts. Founded in 2018 by professors from Yale University and Columbia University, CertiK's mission is to secure the web3 world. CertiK applies cutting-edge innovations from academia to enterprise, enabling mission-critical applications to scale with safety and correctness.
	- Manage critical data platform services for the data lifecycle, including ingestion, transformation, management, delivery, and analytics. 
	- Build tools and libraries that ease new pipeline development and reduce delivery time.
	- Work towards increasing the robustness and fault tolerance on the platform processing large amounts of data.
	- Implement best practices and design patterns for different data solutions. 
	- Define tools and techniques to improve overall data observability and discoverability.
	- Troubleshoot and remediate issues with the data platform services and data pipelines.
	- Collaborate on cross-team Data Platform initiatives. 
	- Track and execute continuous improvements.
	- Experience with blockchain technologies.
	- Experience with data warehouse/data lake platforms such as Snowflake, Databricks, Redshift, or BigQuery.
	- Experience with database technologies such as Redis, Kafka, MongoDB, PostgresSQL, and MySQL.
	- Experience with data engineering tools such as airflow, dbt, etc. 
	- Familiarity working with data observability and data governance. 
	- Programming experience in Bash, Python, Golang, C++, or Java and in data query and manipulation with SQL. 
	- Excellent written and verbal communication skills in ENGLISH and CHINESE.
	- Experience with graph databases. 
	- Experience with data science tools and platforms such as Jupiter notebooks, Databricks, SageMaker, and Tensorflow. 
	- Understanding of Linux. 
	- Familiarity working with open source software community. 
	- Proclivity for automation and DevOps practices and tools such as Git and Terraform.
	- Broad exposure to at least one cloud platform: AWS, Google, Azure.
+ skill set:
	- Staff Software Engineer, Data Infrastructure
	- Come help us build the world's most reliable on-demand, logistics engine for delivery! We're bringing on experienced engineers to help us further our 24x7, global infrastructure system that powers DoorDash's three-sided marketplace of consumers, merchants, and dashers.
	- The Data Infrastructure team's mission is to provide reliable and scalable data orchestration, ingestion, and processing infrastructure that enables data users at DoorDash to deliver high-quality, trustable, and compliant data. You will report directly into the Data Infrastructure Engineering Manager. You must be located in the Bay Area or Seattle for this hybrid role. 
	- Build strong cross-functional partnerships across the core data platform, core infra, and core data engineering teams, and drive the roadmap for data orchestration, data ingestion, and egress at DoorDash. 
	- Lead a team of engineers, guiding and co-pairing to build data platforms at scale. This role will also have access to several Senior Staff and Principal engineers across the Data Platform as they will be interacting with and building integrations for multiple services within the Data Platform org. 
	- Help accelerate the adoption of the data lake by building near real-time data ingestion and egress framework, enabling self-serve ETL through full abstraction, and driving operational optimizations.
	- B.S., M.S., or PhD. in Computer Science or equivalent
	- 8+ years of experience with building data platforms at scale, specifically data orchestration and data ingestion platforms 
	- Experience leading xfn collaboration with partner teams, working with high levels of ambiguity, identifying opportunities, influencing roadmaps, and executing joint goals
		* ***xfn***: Cross-functional team
	- Prior experience in building open-sourced base data platforms such as Airflow, Spark, Kafka, Flink, & Debezium
		* Airflow
		* Spark
		* Kafka
			+ https://kafka.apache.org/
				- Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.
			+ https://en.wikipedia.org/wiki/Apache_Kafka
				- Apache Kafka is a distributed event store and stream-processing platform. It is an open-source system developed by the Apache Software Foundation written in Java and Scala. The project aims to provide a unified, high-throughput, low-latency platform for handling real-time data feeds. Kafka can connect to external systems (for data import/export) via Kafka Connect, and provides the Kafka Streams libraries for stream processing applications. 
			+ https://www.confluent.io/what-is-apache-kafka/
				- Apache Kafka is an open-source distributed streaming system used for stream processing, real-time data pipelines, and data integration at scale. Originally created to handle real-time data feeds at LinkedIn in 2011, Kafka quickly evolved from messaging queue to a full-fledged event streaming platform capable of handling over 1 million messages per second, or trillions of messages per day.
		* Flink
			+ https://en.wikipedia.org/wiki/Apache_Flink
				- Apache Flink is an open-source, unified stream-processing and batch-processing framework developed by the Apache Software Foundation. The core of Apache Flink is a distributed streaming data-flow engine written in Java and Scala.[3][4] Flink executes arbitrary dataflow programs in a data-parallel and pipelined (hence task parallel) manner.[5] Flink's pipelined runtime system enables the execution of bulk/batch and stream processing programs.[6][7] Furthermore, Flink's runtime supports the execution of iterative algorithms natively.
			+ https://flink.apache.org/
				- Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. Flink has been designed to run in all common cluster environments, perform computations at in-memory speed and at any scale.
			+ https://docs.bentoml.org/en/latest/integrations/flink.html
		* Debezium
			+ https://debezium.io/
				- Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong.
			+ https://github.com/debezium/debezium
				- Change data capture for a variety of databases.
				- Debezium is an open source project that provides a low latency data streaming platform for change data capture (CDC). You setup and configure Debezium to monitor your databases, and then your applications consume events for each row-level change made to the database. Only committed changes are visible, so your application doesn't have to worry about transactions or changes that are rolled back. Debezium provides a single model of all change events, so your application does not have to worry about the intricacies of each kind of database management system. Additionally, since Debezium records the history of data changes in durable, replicated logs, your application can be stopped and restarted at any time, and it will be able to consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely.
			+ https://hub.docker.com/r/debezium/connect
	- In-depth understanding of Big Data space 
	- Engage with or contribute to Big Data/ML-related open-source projects
	- Expertise with an open table format such as delta lake
+ skill set:
	- Senior Data Engineer (80-100% Zurich Hybrid)
	- You are passionate about  data architecture and integration, you love working on cloud systems? This job is for you:
	- Join our enthusiastic team and face the challenge to expand Open Systems unified data platform. As a Senior Data Engineer you will be part of the core development team of Open Systems processing structured and unstructured data of more than 6000 devices deployed across the planet. Together with data scientists and product owners you will discuss, shape, specify and implement solutions that ease the operation of more than 6000 devices deployed around the world, and provide intelligent insights into security-relevant data and processes.
	- You will join one of our small development teams that works with agile methods. The team will rely on you to focus on its goals and efforts as a team player while being able to work independently. At Open Systems we are passionate about what we do. We work in an environment in which innovative solutions, rapid development times, creativity and open communication are practiced and continuously fostered. The pursuit of technical advancement is at the center of our attention. You will be based at our office in Zurich (CH).
	- Data Architecture: Lead the design and development of complex data architectures and solutions to meet the evolving needs of the organization.
	- Data Integration: Lead efforts to integrate data from various sources, including APIs, databases, and external providers, into a unified and robust data ecosystem.
	- Microservices and Kubernetes: Architect, implement, and manage microservices-based applications in Kubernetes, ensuring scalability, reliability, and high availability.
	- Database Management: Take ownership of database management, including performance tuning, security, and scalability. Proficiency in both SQL and NoSQL databases is essential.
	- Data Governance: Establish and enforce data governance practices, ensuring data security, privacy, and compliance with industry regulations.
	- Monitoring and Optimization: Proactively monitor data pipelines and microservices, identify bottlenecks or issues, and implement optimizations for cost-efficiency and performance improvement.
	- Mentorship: Provide guidance and mentorship to junior data engineers, sharing best practices and promoting professional growth within the team.
	- You are experienced with Big Data topics, cloud infrastructure and distributed systems.
	- Knowledge with some of the following technologies from a previous job: Kafka, ELK stack, RDBMS, NoSQL, DevOps practises or Kubernetes
	- Experience with managing Infrastructure as a Service resources of public cloud providers (Azure, AWS, GCP,...) with Terraform.
	- You have a passion for sustainable software development and you gathered experiences in other technical positions already.
	- In-depth knowledge and experience of at least one programming language: Python, Go, Scala, Java
	- ETH, university or FH degree in Computer Science or equivalent
	- Fluent in English, German is a plus.
	- Knowledge of Linux operating systems
	- Understanding networking in general and the major internet protocols
	- Knowledge of network security concepts and practices
+ skill set:
	- As a Data Analytics Engineer, you will be responsible for designing, building, and maintaining our data analytics infrastructure. You will work with stakeholders throughout the firm to understand their data needs and requirements, and help them implement data-driven solutions to a wide variety of problems. This role is a great opportunity to work closely with the many teams throughout the company, including Product, Business, Finance, and Engineering.
	- Develop, manage, and maintain our data analytics infrastructure
	- Design and maintain ETL processes to ensure data quality and integrity
	- Combine data across multiple disparate sources
	- Build and maintain dashboards and reports to help stakeholders understand and utilize data
	- Move us towards a robust data platform with self-service capabilities for the entire team
	- A proven track record of developing and maintaining infrastructure for data analytics
	- Extensive experience with SQL
	- Appreciation for simplicity and pragmatism
	- A “roll up your sleeves” mentality and comfort with ambiguity
	- Passionate about making programming accessible to all
	- Experience designing and maintaining data warehouses
	- Experience with data orchestration tools (Airflow, Luigi, Dagster, etc.)
	- Experience with ETL tools and version control (DBT, Fivetran, etc.)
	- Experience working with consumer data at scale
	- Experience building a developer tool (it can be personal dev)
	- Proficiency in Python
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.

















###	DataOps


####	Notes about DataOps

DataOps is a set of practices, processes and technologies that combines an integrated and process-oriented perspective on data with automation and methods from agile software engineering to improve quality, speed, and collaboration and promote a culture of continuous improvement in the area of data analytics.

DataOps incorporates the Agile methodology to shorten the cycle time of analytics development in alignment with business goals.

DevOps focuses on continuous delivery by leveraging on-demand IT resources and by automating test and deployment of software. This merging of software development and IT operations has improved velocity, quality, predictability and scale of software engineering and deployment. Borrowing methods from DevOps, DataOps seeks to bring these same improvements to data analytics.

DataOps utilizes statistical process control (SPC) to monitor and control the data analytics pipeline. With SPC in place, the data flowing through an operational system is constantly monitored and verified to be working. If an anomaly occurs, the data analytics team can be notified through an automated alert.

DataOps is not tied to a particular technology, architecture, tool, language or framework.

Tools that support DataOps promote:
+ collaboration
+ orchestration
+ quality
+ security
+ access
+ ease of use



The volume of data is forecast to grow at a rate of 32% CAGR to 180 Zettabytes by the year 2025. 

DataOps seeks to provide the ***tools, processes, and organizational structures*** to cope with this significant increase in data. ***Automation streamlines the daily demands of managing large integrated databases,*** freeing the data team to develop new analytics in a more efficient and effective way. ***DataOps seeks to increase velocity, reliability, and quality of data analytics. It emphasizes communication, collaboration, integration, automation, measurement and cooperation between data scientists, analysts, data/ETL (extract, transform, load) engineers, information technology (IT), and quality assurance/governance.***




DataOps leadership principles:
+ Establish progress and performance measurements at every stage of the data flow. Where possible, benchmark data-flow cycle times.
+ Define rules for an abstracted semantic layer. Ensure everyone is "speaking the same language" and agrees upon what the data (and metadata) is and is not.
+ Validate with the "eyeball test":
	- Include continuous-improvement -oriented human feedback loops.
	- Consumers must be able to trust the data, and that can only come with incremental validation.
+ Automate as many stages of the data flow as possible, including:
	- BI
	- data science
	- data analytics
+ Using benchmarked performance information, identify bottlenecks and then optimize for them. This may require investment in commodity hardware, or automation of a formerly-human-delivered data-science step in the process.
+ Establish governance discipline, with a particular focus on two-way data control, data ownership, transparency, and comprehensive data lineage tracking through the entire workflow.
+ ***Design process for growth and extensibility. The data flow model must be designed to accommodate volume and variety of data.*** Ensure enabling technologies are priced affordably to scale with that enterprise data growth.”









####	Skill Sets about DataOps



Skill sets for DataOps:
+ skill set:
	- Familiarity with our core tools, including AWS, Kubernetes, Jenkins, OpenResty, Terraform, Python, ElasticSearch, Postgres, and Kafka.
	- You may have experience with Kubernetes Kafka, data warehouse, or Airflow.
+ Experience in Big data technology stack (Hadoop, Hbase, Sqoop, Hive, Spark, etc.).
+ Our platform is ever-evolving, but currently is a combination of Python, Java, Postgres, Kubernetes, Spark, Presto, Kafka, and Mongo
+ To bring visualization and easy-to-use data analysis tools to our users, our research and development teams work on full data processing cycle: from database's query processing, to data science (AI, machine learning, etc.), UI design, and cloud computing.
+ Experience with or exposure to Big Data (Hadoop/YARN, Spark, Nifi, Storm, Cassandra, Solr) is a definite plus.
+ Integrate our data pipeline with available Augmented Analytics models, tools, and applications.
+ Leverage and advance our query processing engine to build a data pipeline that enables the development of features and integration with available Augmented Analytics models, tools, and applications.
+ Preferred (but not essential) experience any Big Data technologies such as languages like R, Hadoop, Machine Learning and Data Lakes
+ Some of the technologies you’ll be working with include Apache Spark, Python, Terraform, Kafka, Azure EventHub, Vector DBs.
+ skill set:
	- Scala, Flask, Big Data or cloud technologies
	- hands-on technologists who are strong in software engineering fundamentals, Big Data, and DevOps
	- Intelligence Studio is a horizontally scalable, cross-cloud technology-agnostic platform built with trusted open source components like Kubernetes, Spark, Airflow, MLflow, and TensorFlow. It allows data scientists to focus on doing data science by taking care of essential concerns like data access, logging, configuration, resource negotiation, dependency management, orchestration, and testing.
	- This self-service, data science platform solution connects in with partners in a shared ecosystem, scales by usage, and has the building blocks to help our data scientists and clients move from creation to deployment of a data science project, at scale.
	- Recently, we implemented a multi-user cloud-based integrated development environment with code completion and debugging built-in. And now we're focused on building a fine-grained entitlements and access control system for big data.
	- Building software and integrations in a cloud-based Microservices environment for Big Data applications
	- We also use cloud software design, containerized Microservices & distributed caching, but you can learn this if you aren't familiar with it.
+ skill set:
	- Experience with open source data platforms including Hive/Flink/Spark, etc
	- Experience with highly scalable data platform/service (>TB/day level)
+ skill set:
	- Python 2.7, 3.7
	- SQL Server, MySQL, Memcached, Solr, Ansible, Linux
	- Kafka, RabbitMQ
	- React, GraphQL
+ skill set:
	- 5+ years experience developing data frameworks using Python
	- 5+ years of using SQL for data manipulation in a fast-paced work environment
	- Experience working with open source technologies like Kafka, Hadoop, Hive, Presto, and Spark, or similar
	- Experience building and optimizing ‘big data' data pipelines, architectures and data sets
	- Mastery of data warehousing development and fundamentals
	- Passion for business-oriented data development
+ skill set:
	- Experience with NoSQL databases (eg MongoDB, Redis) is an advantage
	- An advantage: experience with Docker / Rancher or Kubernetes and with Native Mobile Development or NativeScript / ReactNative knowledge
+ skill set:
	- Strong understanding of core Hadoop concepts including Yarn, MapReduce, Hive, Pig, Sqoop, HDFS
	- Experience implementing large scale data loading, manipulation, processing and exploration using a range of AWS based technologies such as Spark, Kinesis, Athena, RedShift, Postgres etc
	- Extensive experience in data profiling, source-target mappings, ETL development, SQL optimisation, testing and implementation
+ Familiar with big data processing tools such as ***Hadoop, Spark, HBase***
+ Working experience with large-scale data platform and pipelines such as Hadoop, Hive, Pig, MapReduce, Spark, Kafka, Flumes, etc.
+ Demonstrated track record working with data warehouse concepts.
+ Experience with at least one data warehousing platform (Redshift, Athena, Hive, Snowflake, etc.)
+ web analytics platforms such as Google Analytics, Appsflyer or Mixpanel
+ skill set:
	- Experience with distributed data processing systems like Spark and Hadoop
	- Familiarity with interactive data visualization using tools like D3.js
+ Experience with: Large scale distributed computing, Database internals, Big Data engines e.g. Spark, Hadoop
+ You are comfortable with Big Data technologies like Hadoop, Spark, Hive, Presto etc.
+ skill set:
	- Docker container orchestration platforms like Kubernetes or Mesos
	- Databases and key value stores like MySQL, MongoDB, or Redis
	- Distributed streaming platforms like Kafka or AWS Kinesis
	- Monitoring and alerting tools like Grafana and Sensu
	- React, Angular 1.5, Webpack
	- Relational databases (like PostgreSQL, MySQL)
	- Key Value stores (like Redis)
	- AWS services: AWS Lambda, Aurora, Elasticache, RDS, and other AWS services
+ skill set:
	- This role will be responsible for helping to define and provide the foundation for our next-generation data services.  With a strong focus on automation and elasticity, you will contribute to how our data infrastructure scales to support the overall growth of our platform, data products, and services. We are looking for someone that is passionate about automation, repeatability, quality, and knowledge sharing within a team environment.
	- Build and operate large-scale data infrastructure programs in a cloud environment  (performance, reliability, monitoring)
	- Write well-crafted, well-tested, readable, maintainable code
	- Participate in code reviews to ensure code quality and distribute knowledge, including Open-Source projects
	- Work closely and collaboratively in an Agile environment with our engineers and product teams to analyze issues and find new insights covering our business and operations
	- Day to day operational support of data infrastructure and services
	- 5+ years of relevant professional experience
	- Deep understanding of distributed systems principles (consistency and availability, liveness and safety, durability, reliability, fault-tolerance, consensus algorithms)
	- Strong understanding and experience AWS and cloud concepts (VPC, EC2, Route53, Kinesis, ECS, IAM, and others)
	- Experience writing infrastructure as code. (Terraform)
	- Experience bringing open-source software to production at scale.
	- Experience designing, implementing and debugging distributed systems that run across thousands of nodes
	- Hands-on experience deploying, debugging and maintaining JVM based applications.
	- Hands-on experience with Big Data ecosystem - Yarn, Hive, HDFS, Spark, Presto, Parquet, HBase
	- Experience working with and building real-time compute and streaming infrastructure - Kafka, Kinesis, Flink, Storm, Beam
	- Experience with workflow management (Airflow, Oozie)
+ Senior Software Engineer, Data Acquisition
	- The Data Acquisition team within the Pre-training organization at OpenAI is responsible for all aspects of data collection to support our model training operations. Our team manages web crawling and GPTBot services and works closely with Data Processing, Architecture, and Scaling teams. We are looking for a skilled Senior Software Engineer to join our Data Acquisition team.
	- Own and lead engineering projects in the area of data acquisition including web crawling, data ingestion, and search.
	- Collaborate with other sub-teams, such as Data Processing, Architecture, and Scaling, to ensure smooth data flow and system operability.
	- Work closely with the legal team to handle any compliance or data privacy-related matters.
	- Develop and deploy highly scalable distributed systems capable of handling petabytes of data.
	- Architect and implement algorithms for data indexing and search capabilities.
	- Build and maintain backend services for data storage, including work with key-value databases and synchronization.
	- Deploy solutions in a Kubernetes Infrastructure-as-Code environment and perform routine system checks.
	- Conduct and analyze experiments on data to provide insights into system performance.
	- BS/MS/PhD in Computer Science or a related field.
	- 5+ years of industry experience in software development.
	- Experience with large web crawlers a plus
	- Strong expertise in large stateful distributed systems and data processing.
	- Proficiency in Kubernetes, and Infrastructure-as-Code concepts.
	- Willingness and enthusiasm for trying new approaches and technologies.
	- Ability to handle multiple tasks and adapt to changing priorities.
	- Strong communication skills, both written and verbal.
	- Annual Salary Range: $310,000—$385,000 USD
+ skill set:
	- Data technology: Relational databases (like PostgreSQL, MySQL), Key Value stores (like Redis)
	- Container technology like Docker, and familiarity with Swarm/Kubernetes/Mesos
	- Distributed systems, including fault tolerant design, event sourcing and other distributed system architectural pattern
+ skill set:
	- Strong computer science fundamentals: data structures, algorithms, programming languages, distributed systems
	- Developing, deploying, and monitoring services on cloud infrastructure like Amazon
	- Understanding of modern application development and architecture
	- Understanding of DevOps principles such as fail early and often, The Three Ways, small batches, CI/CD
	- Software development methodology, like TDD and BDD
	- Distributed systems, including fault tolerant design, event sourcing and other distributed system architectural pattern
	- Container technology like Docker, and familiarity with Swarm/Kubernetes/Mesos
	- DevOps skills: Kubernetes, Docker, Terraform, Helm
	- Software design: Domain Driven Design, Design patterns
	- Data technology: Relational databases (like PostgreSQL, MySQL), Key Value stores (like Redis)
	- AWS services: AWS Lambda, Aurora, Elasticache, CloudFront, SNS, SQS, and other AWS services.
+ skill set:
	- 2+ years experience with R or Python
	- 2+ years experience with predictive modeling
	- Familiarity with data visualization in R or Javascript
	- Understanding of relational data or SQL
	- French is not required and all European languages are appreciated
	- Experience with PySpark, SparkR or Scala
	- Experience developing WebApps
	- Experience building APIs
	- Experience with HDFS and NoSQL databases (MongoDB, Cassandra, etc)
	- Construct end-to-end data flows from raw data to predictions
	- Crunch, analyze and investigate any kind of data
	- Explore new machine learning algorithms
	- Build attractive visualizations
	- Communicate results to non-technical colleagues and clients
	- Provide data science expertise to sales, marketing, and R&D teams
+ skill set:
	- Build automation around infrastructure components like MongoDB, PostgreSQL, Redis, and Kafka clusters.
	- Experience with Docker, Kubernetes, Prometheus, or other CNCF software is a big plus.
	- Extensive operational and architectural background in SQL and NoSQL technologies.
	- Experience with database design, caching, scalability, and network fundamentals.
+ skill set:
	- Java, Scala & Python
	- Kubernetes & Docker
	- Data analysis tools such as R
	- We rely on Big Data / Hadoop technologies such as Apache Spark, Impala and Amazon Redshift
	- Participate in Agile practices such as daily stands-ups, sprint planning and retrospectives
+ skill set:
	- Impala is a scalable and fast SQL query engine that runs directly on Hadoop and supports a wide range of analytic workloads, from subsecond interactive dashboards with hundreds of concurrent users to petabyte-scale rich data exploration.  Impala is currently supported by a large paying customer base, and is a key component of the Cloudera data platform. It is open sourced under the Apache 2.0 license and is developed publicly, including code reviews and bug tracking (see http://impala.apache.org/). It is distributed by Cloudera, MapR, AWS and Oracle among others.
	- Feel free to read our CIDR Paper on Impala: http://bit.ly/cidr15impala or http://pandis.net/resources/cidr15impala.pdf.
	- Knowledge of database concepts, RDBMS internals, and SQL is a strong plus
	- Knowledge of the Hadoop space, containers, or Kubernetes is a strong plus.
+ big data platform tools such as Hadoop, Hive, Druid, Kafka, Ambari, Spark
	- Hadoop
	- Hive
		* productivity platform
		* Apache Hive is a distributed, fault-tolerant data warehouse system that enables analytics at scale
			+ distributed storage based on SQL
	- Druid
		* Apache Druid is a high performance, real-time analytics database
		* Apache Druid is an open-source data store.
		* Apache Druid is a column-oriented, open-source, distributed data store.
	- Kafka
		* Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.
		- Apache Kafka is a distributed event store and stream-processing platform. The project aims to provide a unified, high-throughput, low-latency platform for handling real-time data feeds.
			* It is an open-source system developed by the Apache Software Foundation written in Java and Scala.
	- Ambari
		* The Apache Ambari project intends to simplify the management of Apache Hadoop clusters using a web UI. It also integrates with other existing applications using Ambari REST APIs.
		* The Apache Ambari project is aimed at making Hadoop management simpler by developing software for provisioning, managing, and monitoring Apache Hadoop clusters. Ambari provides an intuitive, easy-to-use Hadoop management web UI backed by its RESTful APIs.
	- Spark
+ skill set:
	- Modern databases like Cassandra, ElasticSearch, Redis, and Postgres.
	- Frameworks like Django, Tornado and the PyData stack (e.g. Pandas).
		* Django: Web framework for creating database-driven Websites
		* Tornado: scalable, non-blocking web server and web application framework
			+ for developing Web applications
		* PyData
			+ Pandas for data science
	- Running Kafka, Storm, Spark in production atop massive data sets.
	- Easy system management with Fabric and Chef.
		* Chef:
			+ Progress Chef (formerly Chef): configuration management tool
		* Fabric.js, a Javascript HTML5 canvas library
			+ Fabric OS, a firmware for Brocade Communications Systems's Fibre Channel switches
	- Parse.ly's data engineering team already makes use of modern technologies like Python, Storm, Spark, Kafka, and Elasticsearch to analyze large datasets.
+ skill set:
	- Building, maintaining and improving the modeling infrastructure using cutting edge tools including: Hadoop, PIG, Kafka, Flume, Ssamza, Zookeeper, PySpark, Elasticsearch, Python, Django
		* PIG
			+ Apache Pig: MapReduce programming tool for the Hadoop platform
		* Kafka
			+ Apache Kafka:
				- open-source distributed event streaming platform for:
					* high-performance data pipelines
					* streaming analytics
					* data integration
					* mission-critical applications
		* Flume
			+ Apache Flune:
				- service for collecting, aggregating, and moving large amounts of log data
				- distributed, reliable, and available software for efficiently collecting, aggregating, and moving large amounts of log data
				- simple and flexible architecture based on streaming data flows
				- robust and fault tolerant with tunable reliability mechanisms, and failover and recovery mechanisms
		* Ssamza
			+ Apache Samza:
				- build stateful applications that process data in real-time from multiple sources, such as:
					* Apache Kafka
				- near-realtime, asynchronous computational framework for stream processing
				- provides fault tolerance, isolation, and stateful processing
		* Zookeeper
			+ Apache Zookeeper
				- centralized service for maintaining configuration management information, naming, and providing distributed synchronization and group services.
				- server for enabling highly reliable distributed coordination
				- service for coordinating processes of distributed applications
		* PySpark:
			- Python API for Apache Spark
			- real-time, large-scale data processing in distributed environments
		* Django
			- high-level Python Web framework for rapid development/prototyping and clean, pragmatic design
			- follows the model-template-views (MTV) architectural pattern
	- Learning how to build and maintain an ETL pipeline for scalability and stability.
	- Supporting data analysis, mathematical modeling, machine learning and data mining for price testing and its optimization
	- Explore and employ external data sets, finding them, adding them to the system, adjusting and reformatting/cleaning up so that they can be consumed by our infrastructure. Developing models and machine-based understanding of interactions between external datasets and client data.
+ You know your way around SQL-like databases (e.g. PostGres, Impala, Hive) and even better if have experience with Spark and other big data platforms.
+ skill set:
	- Familiarity in data storage (e.g. MySQL, MyRocks, HBase, Memcached, Redis, etc), traffic handling (e.g. DNS, CDN, load balancing, etc) or infrastructure orchestration (Ansible, terraform, docker, Kubernetes, etc)
	- Familiarity with AWS services (e.g. EC2, S3) or other public cloud services.
	- Operational experience in database systems e.g. MySQL, Memcache, Redis and NoSQL systems
	- Operational experience with Linux operating system internals, filesystems, disk/storage technologies and networking
	- Experience with scripting languages (e.g. shell script)
	- Experience with capacity planning for web scale systems
+ skill set:
	- Familiarity with Hadoop, Map/Reduce, Spark, and distributed computing
	- Understanding of data pipeline architectures (e.g. Lambda, Kappa)
	- Database hands-on experience (MySQL, MongoDB, couchdb, ElasticSearch, etc.)
	- Knowledge of real-time data pipelines (e.g. Kafka and Spark Streaming)
	- Experience with continuous integration and deployment workflows
	- Experience with Docker, AWS/Azure/On-Prem deployments, and networking
+ skill set:
	- Extensive hands on experience with administering some of the following: HBase, Impala, Spark, EMR, Hive on Tez or Presto
	- Experience operating large scale Hadoop clusters running Cloudera distribution
	- Operational mindset with ability to do Problem, SLA and Incident Management
	- Experience installing and managing Kafka is good to have
	- Experience managing infrastructure in AWS using EMR
	- Experience with SQL and Python(Boto3 Library)
	- Experience with AWS products including EC2, S3, RDS, ElastiCache, ElasticSearch, Kinesis, Lambda, etc
	- Exposure to Big Data on AWS (DataPipeline, Batch, AWS Glue, S3, EMR/EC2)
	- Hands on expertise in AWS (S3, EMR, EC2, Hadoop, Hive, Spark, Kafka, Storm, Druid, Cassandra, Columnar Databases and Graph Databases like DSE Graph is huge plus.
+ Ansible: it's not that bad, and helps us move quickly, but any configuration management tool is applicable.
	- Ansible is a suite of software tools that enables infrastructure as code. It is open-source and the suite includes software provisioning, configuration management, and application deployment functionality.
	- Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems.
	- No matter your role, or what your automation goals are, Ansible can help you demonstrate value, connect teams, and deliver efficiencies for your organization. Built on open source, Red Hat® Ansible® Automation Platform is a hardened, tested subscription product that offers full life cycle support for organizations. Explore how Ansible can help you automate today—and scale for the future.
	- Ansible® is an open source, command-line IT automation software application written in Python. It can configure systems, deploy software, and orchestrate advanced workflows to support application deployment, system updates, and more.
	- Ansible's main strengths are simplicity and ease of use. It also has a strong focus on security and reliability, featuring minimal moving parts. It uses OpenSSH for transport (with other transports and pull modes as alternatives), and uses a human-readable language that is designed for getting started quickly without a lot of training.
+ skill set:
	- Stitch is a cloud data ingestion platform... We power data infrastructure for thousands of businesses.
	- Stitch is made up of these main components:
		* Source integrations - lots of them! - that stream data out of SaaS applications, databases, and filesystems
		* A high-volume data pipeline, moving hundreds of billions of records per month
		* Destination loaders that efficiently import data into cloud systems like Redshift, Snowflake, and BigQuery
		* A mid-tier and UI that tie it all together
	- Our backend services are written in Clojure and Python, and our front-end is written in React. We use MySQL and PostgreSQL to manage the state of our system. The entire system runs on Amazon Web Services (EC2, RDS, ELB, VPC, and more).
	- [Simple, Composable, Open Source ETL; Singer powers data extraction and consolidation for all of your organization's tools.](https://www.singer.io/)
	- https://github.com/singer-io
	- Destination loaders that efficiently import data into cloud systems like Redshift, Snowflake, and BigQuery
	- Our backend services are written in Clojure and Python, and our front-end is written in React. We use MySQL and PostgreSQL to manage the state of our system. The entire system runs on Amazon Web Services (EC2, RDS, ELB, VPC, and more).
+ skill set:
	- data expertise:
		* manage data pipelines
			+ Spark
			+ Flink
		* data lakes and data warehouses
			+ Snowflake
			+ Hive
		* authored queries
			+ SQL
		* used workflow management
			+ Airflow
			+ Luigi
		* maintain data infrastructure to support these
+ Set of skills:
	- Experience with modern programming languages (Java, Scala, Go, TypeScript)
	- Database / Data Storage experience (SQL / MySQL, MongoDB, DynamoDB)
	- Interest in Infrastructure Tooling (Docker, Nomad, Consul, Vault, Prometheus)
+ skill set:
	- On the Blaize AI Studio Team, we don't just model data, we build and help assemble custom datasets, manage production edge and cloud deployments, and identify production issues. We are looking for someone to help us continue our evolution and who can work with small amounts of imperfect data and generate reliable results. 
 	- Our Deep Learning Research Engineer will be working both independently and with a wide range of people at Blaize. We are looking for a set of skills including strong AI/ML experience with practical and use-able software engineering practices and languages (git, docker, Java and/or C++, Python).  You should have been involved in at least 1 or more projects reaching production state.
 	- Co-Ownership of an entire Deep Learning (DL) project(s).
 	- Working with Executive and Product leadership to evolve and define roadmap.
 	- Identifying what kind of data and how much data to generate to get desired results.
 	- Adding to Blaize AI Studio's state-of-the-art (SOTA) toolbox.
 	- Using small datasets to generate impressive results.
 	- Relentlessly staying on top of the state of the art in computer vision and related areas.
 	- Bachlor's degree in Applied Science/Mathematics or Engineering
 	- 4 years of relevant experience or an equivalent combination of experience and education.
 	- Leadership positions external from AI/ML.
 	- Awareness of software engineering best practices with hands-on experience (Java, C++, Python).
 	- Cloud (Azure, H2O, AWS, etc) production model management experience.
 	- Experience with data preparation or end-to-end AI-based application building.
 	- Experience publishing patents or peer-reviewed papers.
 	- Taken an existing model and increased performance through a variety of methods such as:
		* pruning
		* quantization
		* finetuning
		* retraining
		* runtime environments
	- Worked with PyTorch and/or Tensorflow for development, ONNX or C++ for deployment
	- Implemented state of the art papers.
	- Deployed a model with aggressive inference speed requirements.
+ skill set:
	- Experience with automation tools and configuration-as-code (CloudFormation, Ansible, Puppet, Chef, Vagrant, etc.)
	- Experience working with either AWS or GCP services such as compute, databases, VPCs, networking, permissioning and storage
+ skill set:
	- You have worked with Relational databases like MySql, Postgres and understand partitioning, sharding, as well as NoSQL databases such as mongoDB/Couchbase etc.
	- You should be at ease with maintaining cloud instances on AWS, Rackspace, Digital Ocean and the like, and you should be at home with provisioning tools like Puppet or Ansible. Experience with Docker in production would be prized.
+ skill set:
	- design and implement efficient ranking algorithm at high throughput and scalable search engine
	- analyze search and document data using SQL and Hive on Spark, S3, and ElasticSearch
	- understanding and experience for query expansion and rewrite techniques such as synonyms, auto complete, speel correction, query optimization, and query-to-query similarity
	- understanding of search ranking quality evaluation and experience with metric-driven search ranking tuning techniques
	- understanding of knowledge graphs for document understanding and ranking
		* experience with graph DB, such as Neo4j, ArangoDB, OrientDB
	- experienced working in a fast-paced environment in an agile/scrum environment with focus on robust design, architecture, TDD, rapid experimentation, A/B testing, and metrics
	- big data frameworks, such as map-reduce, Spark, Pig, Hive
+ skill set:
	- Big Data platforms e.g. Cloudera, Hortonworks MapR
	- Big Data Analytic frameworks and query tools such as: HDINsight, Spark, Storm, Hive, Impala
	- IoT protocols, gateways, queues, messaging hubs such as IoT Hub, MQTT, XMPP, CoAP, etc.
	- IoT development experience on at least one of the industry leading platforms (Azure IoT, AWS IoT, GE Predix, Siemens Mindsphere, PTC Thingworx, SAP Leonardo, GCP)
	- Streaming data tools and techniques such as Apache Kafka, Azure Streaming Analytics, AWS Kinesis
+ skill set:
	- Minimum 1 year of building and coding applications using at least two Hadoop components – MapReduce, HDFS, Hbase, Pig, Hive, Spark, Scoop, Flume, etc
	- Minimum 1 year coding one of the following: Python, Pig programming, Hadoop Streaming, HiveQL
	- Minimum 1 year understanding of data modelling & data pipeline design: iterative data pipeline development from raw, curated, integrated to published data, with fit for use data modelling on Hadoop and NoSQL platforms
	- Minimum 1 year of experience implementing large scale cloud data solutions using Cloud Service Providers:  AWS data services (e.g. EMR, Redshift, GLUE) or Azure (Data Lake Store/Analytics, SQL Data Warehouse) or Google Cloud Platform Google Cloud (Big Data:  Big Query, Big Insights)
	- Minimum 1 year of experience delivering an operational Big Data solution using one or more of the following technologies: Hadoop, HortonWorks, Cloudera, Cassandra
	- Minimum 1 year of experience throughout the SDLC of a Hadoop implementation technologies including HortonWorks, Cloudera, Hive, Pig, MapReduce 
	- Minimum 1 year of experience throughout the SDLC of a HortonWorks, Cloudera, Cassandra / Hbase implementation 
	- Minimum of a Bachelor's Degree or 3 years IT/Programming experience
	- Minimum 1 year of experience developing REST web services
	- Industry experience (financial services, resources, healthcare, government, products, communications, high tech)  
	- Experience leading teams
	- Machine Learning tools, interfaces & Libraries: R, R-Studio, Spark R, sparklyr, MLlib, H2O etc.  
	- Experience with other tools, databases and Apache projects: Google BigQuery, Presto, Drill, Kylin, OpenTSDB, Spark Streaming
	- Enterprise data integration, BI and analytics platforms: Informatica, Talend, InfoSphere, SAS, RevoR, QlikView, Qlik Sense, Tableau, Spotfire, D3.js
	- Processing frameworks & programming tools: Spark (Scala/Python/Java), Kafka, Flink
	- Client facing skills: ability to build trusted relationships with client stakeholders and act as a trusted adviser
+ skill set:
	- You will join a team of highly talented Engineers and Data Scientists, with your main focus being to write highly performant and scalable code that will run on top of our Big Data platform (Spark/Hive/Impala/Hadoop). As such, you will work closely with the Data Science team to support them in the ETL process (including the cohorts building efforts).
	- Working in a cross-functional team
	- Building scalable and high-performant code
	- Mentoring less experienced colleagues within the team
	- Implementing ETL and Feature Extractions pipelines
	- Monitoring cluster (Spark/Hadoop) performance
	- Working in an Agile Environment
	- Refactoring and moving our current libraries and scripts to Scala/Java
	- Enforcing coding standards and best practices
	- Working in a geographically dispersed team
	- Working in an environment with a significant number of unknowns – both technically and functionally.
	- BSc or MSc in Computer Science or related field
	- Strong analytical and problem-solving skills with personal interest in subjects such as math/statistics, machine learning and AI
	- Solid knowledge of data structures and algorithms
	- Experience working in an Agile environment using Test Driven Development (TDD) and Continuous Integration (CI)
	- Experience refactoring code with scale and production in mind.
	Proficient in Scala, Java and SQL
	- Strong experience with Apache Spark, Hive/Impala and HDFS
	- Familiar with Python, Unix/Linux, Git, Jenkins, JUnit and ScalaTest
	- Experience with integration of data from multiple data sources
	- Experience with NoSQL databases, such as HBase, Cassandra, MongoDB
	- Experience with any of the following distributions of Hadoop - Cloudera/MapR/Hortonworks.
	- Other functional Languages such as Haskell and Clojure
	- Big Data ML toolkits such as Mahout, SparkML and H2O
	- Apache Kafka, Apache Ignite and Druid
	- Container technologies such as Docker
	- Cloud Platforms technologies such as DCOS/Marathon/Apache Mesos, Kubernetes and Apache Brooklyn.
+ skill set:
	- Partner with engineering leadership to buildout data driven roadmap items to address performance in critical areas
	- Established performance test environments and frameworks
	- Experience evangelizing performance engineering techniques within a data driven engineering culture
	- Deep hands on experience with JVM tuning techniques
	- Supported efforts in performance testing and improvement in common JavaScript frameworks (Angular, React, JQuery)
	- Experience with Ruby (JRuby) and JavaScript
	- Extremely well versed in solving data access performance challenges across SQL data stores
	- Experience in AWS and other cloud providers when exploring different approaches to performance engineering
	- Experience with distributed architectures
	- Passionate about driving a performance engineering culture
+ Expert knowledge working with Spark and other distributed data technologies (e.g. Hadoop, Presto, Flink, Druid) for building efficient & large scale data pipelines.
+ data management tools in on a big data plate form such as Atlas, Ranger, Knox
	- Atlas
		* scalable and extensible set of core foundational governance services
		* provides support for enterprise data ecosystem
		* open metadata management and governance capabilities for organizations, build catalog of data assets, classify and govern assets, collaboration capabilities
	- Ranger
		* framework to enable, monitor, and manage comprehensive data security across the Hadoop platform
	- Knox
		* Samsung Knox: enterprise mobile security platform
		* for mobile device management, MDM
+ Tools: Slurm, Docker, Grafana.
	- Slurm: resource management and job scheduler, for distributed computing
	- Grafana
		* open-source analytics and monitoring solutiojn for each database
		* interactive data visualization platform
		* often compared with Splunk
+ skill set:
	- Our leaders have had significant involvement in the creation and maintenance of NumPy, SciPy, Jupyter, Spyder, Dask, Conda, Numba, Anaconda and PyData NumFOCUS.
	- We are seeking a fully remote, experienced Open Source Infrastructure Engineer to join our team at Quansight. In this role, you will support Quansight's growing cloud and on-premises infrastructure and help make them more reliable, scalable, and efficient. You will also  address support issues from our clients and collaborators, explore emerging technologies in the Cloud and DevOps spaces, and design and implement cloud computing systems with the rest of our infrastructure team.
	- Contribute to nebari (https://nebari.dev), an open source Data Science platform built on JupyterHub, Dask, and other tools from the PyData ecosystem.
	- Participate in upstream open source communities we rely on (such as JupyterHub, BinderHub, Dask, etc.) in partnership with the established leaders of those communities.
	- Deploy and ensure the reliable operation of Quansight's and clients' infrastructure.
	- Collaborate with a fully distributed team - team members are expected to communicate and collaborate proactively to allocate effort and maximize the team's impact.
	- ***Experience using some form of infrastructure-as-code tooling (i.e., Ansible, Salt, Puppet, Terraform, etc.)***
	- Experience with at least one major cloud platform (AWS, Azure, GCP)
	- Experience developing tools in a general purpose programming language (eg. Python)..
	- ***Experience with Continuous Integration and Continuous Delivery services (e.g., Circle CI, GitHub Actions)***
	- Familiarity with software engineering best practices – including unit tests, code review, version control, production monitoring, etc.
	- ***Experience deploying and developing with Linux container-based technologies, such as Docker and Kubernetes.***
	- Comfortable working independently and reaching out for feedback and support as needed.
	- Experience collaborating and coordinating work via online platforms, such as GitHub, GitLab, or BitBucket, and distributed revision control.
	- Ability to provide and constructively receive feedback.
	- While this is a remote position, we are looking for candidates with significant time overlap with US Central and Eastern time zones due to the location of many of our infrastructure team members and collaborators
	- Experience working on geographically distributed open-source projects.
	- ***Exposure to the Python Data Science stack - Pandas, Numpy, Dask, etc.***
	- Experience with the Jupyter ecosystem and other tools for interactive computing.
	- Experience building and maintaining continuous deployment pipelines.
	- ***Experience with common data science methods, platforms, workflows, and infrastructures; with data management systems, practices, and standards; and the capacity to gain familiarity with new related topics.***
+ skill set:
	- The Patrick J McGovern Foundation (PJMF) is seeking an experienced, multi-faceted and self-driven Software Development Engineer (SDE). This role sits within the Data Solutions team and will be directly engaged with the development, deployment and maintenance of data and AI products that will drive positive social impact around the world. The charter of the Data Solutions team is to identify, develop and deploy strategic data and AI solutions, focused on unlocking opportunities and addressing broad challenges the social good sector is facing now, and in the near future. The SDE is responsible for full stack development of cloud solutions that are based around ML model predictions, using a rapid prototyping development approach. We are a small, high performance team and in many ways function as a startup. As such, the ideal candidate will be someone who can develop an end-to-end solution around which our ML products will be deployed.
	- Work closely with the Technical Product Manager, along with partners and end-users, to understand their challenges in order to build effective and safe products
	- Understand end-user needs to build applications that can solve their challenges
	- Prototype, develop, test and deploy highly reliable, safe and scalable full stack solutions
	- Ability to develop frontend and backend applications to support and integrate with our data and AI solutions
	- Monitor and maintain application performance, functionality, scalability and security
	- Develop secure, modularized, well-documented and reusable code
	- Employ rapid prototyping techniques to quickly develop and iterate on product deployment and fast integration of end-user feedback loop
	- Integrate necessary data technologies, platforms, tools, and 3rd party tools needed for product deployment and functionality
	- Ensure appropriate maintenance, bug fix and feature requests are resolved
	- Create appropriate system diagrams and documentation
	- Experience - Demonstrated experience in full stack development and deployment
	- Technologies - ***Strong programming experience with Python, Scala, Java, Javascript or similar languages. Strong production experience with using cloud services and infrastructure, containerization (Docker) and orchestration (Kubernetes) tools. Experience with CI/CD, software bug tracking, version control and feature request management, using tools like Jenkins, Jira, GitHub, etc. Experience with build systems (make, gradle, etc) and package management (pip, etc). Experience with SQL database systems such as MySQL, PostgreSQL, etc and NoSQL systems such as MongoDB, DynamoDB, HBase, etc***
	- Learning - This role will require an individual with an appetite for (quickly) learning and applying different technologies, programming languages, and techniques needed to build the required solutions
	- Communication - Ability to communicate effectively with cross-functional teams, engineers, partners and end-users. Excellent written and verbal communication skills to technical and non-technical audiences. Excellent technical writing and documentation skills
	- Teamwork - Effective team player who understands the responsibility every individual brings to the table and how to encourage and drive results from each team member
	- High Performance - Ability to go outside your comfort zone to learn new technologies and methodologies to ensure successful and timely completion of product development
	- Results-oriented - Highly organized and detail-oriented, self-driven and able to adapt to learning and implementing new technologies, and creative in solving issues as they arise
	- Cultural alignment - An advocate for social progress; interest in emerging technologies and their ability to advance societal outcomes
	- Work Eligibility - Applicants must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time
	- Extensive knowledge & experience with Git, Linux system administration, Kubernetes/Docker, ML data pipelines, databases (SQL, NoSQL, RDS, CloudSQL, DynamoDB, Redshift, etc.), cloud services (at least AWS and/or GCP), and distributed systems
	- Ability to code in multiple languages (Python and SQL; R, Java, or others as well)
	- Strong communication and problem-solving skills with the ability to discuss projects with colleagues who have limited knowledge of ML/DevOps techniques and tools
	- Ability to oversee and provide input regarding infrastructure design and maintenance
+ skill set:
	- Analytics Engineer
	- As Scale's Analytics Engineer, you will spearhead building Scale's analytical and business-intelligence infrastructure. Scale's customers process millions of tasks through our APIs, and we're looking for a talented Analytics Engineer to build scalable solutions to support this growth. You will have widespread purview, with responsibility for understanding, mining, aggregating, and exposing data across the entire business to support timely and efficient decision-making and data exploration. You will also implement Scale's data warehouse, data mart, and business intelligence reporting environments, and help users transition their workflows to these systems.
	- Work with operations, finance, and engineering to drive the development of pipelines that provide single-source-of-truth foundational accuracy
	- Continually improve ongoing data pipelines and simplify self-service support for business stakeholders
	- Perform regular system audits, and create data quality tests to ensure complete and accurate reporting of data/metrics
	- 3+ years of relevant work experience in a role requiring application of data modeling and analytic skills
	- Ability to create extensible and scalable data schema and pipelines that lay the foundation for downstream analysis using SQL and Python
	- Experience with ETL tools and building / maintaining a data warehouse and data pipelines using tools such as DBT
	- Partner with operations and sales teams to automate manual workflows
	- Experience in using highly scalable data engineering technologies such as DBT, Airflow 
	- Experience in best practices in table partitioning/data sharding strategies and query optimization
+ skill set:
	- Full Stack Engineer - Public Sector
	- Scale AI is seeking a highly skilled and motivated Full Stack Engineer to join our dynamic Federal Engineering team. As a part of this team, you will play a critical role in delivering high-impact AI-powered mission solutions for government customers. Our scalable and high-performance platform forms the foundation for these solutions, and your expertise will be instrumental in designing and implementing systems that can handle billions of data points with exceptional performance.
	- Design and implement scalable backend systems for Federal customers, leveraging Scale's modern and cloud-native AI infrastructure.
	- Collaborate with cross-functional teams to define and execute the vision for backend solutions, ensuring they meet the unique needs of government agencies operating in secure environments.
	- Develop distributed systems, data-intensive applications, and machine learning infrastructure to enable real impact for mission owners.
	- Build robust and reliable backend systems that can serve as standalone products, empowering customers to accelerate their own AI ambitions.
	- Participate actively in customer engagements, working closely with stakeholders to understand requirements and deliver innovative solutions.
	- Contribute to the platform roadmap and product strategy for Scale AI's Federal business, playing a key role in shaping the future direction of our offerings.
	- Design and implement scalable backend systems for Federal customers, leveraging Scale's modern and cloud-native AI infrastructure.
	- Collaborate with cross-functional teams to define and execute the vision for backend solutions, ensuring they meet the unique needs of government agencies operating in secure environments.
	- Develop distributed systems, data-intensive applications, and machine learning infrastructure to enable real impact for mission owners.
	- Build robust and reliable backend systems that can serve as standalone products, empowering customers to accelerate their own AI ambitions.
	- Participate actively in customer engagements, working closely with stakeholders to understand requirements and deliver innovative solutions.
	- Contribute to the platform roadmap and product strategy for Scale AI's Federal business, playing a key role in shaping the future direction of our offerings.
	- Collaboration and Communication: Excellent interpersonal and communication skills to effectively collaborate with cross-functional teams, stakeholders, and customers. Ability to clearly articulate technical concepts to non-technical audiences and foster a collaborative work environment.
	- Adaptability and Learning Agility: Willingness to embrace new technologies, learn new skills, and adapt to evolving project requirements. Ability to quickly grasp and apply new concepts and stay up-to-date with emerging trends in software engineering.
+ skill set:
	- Foundation Models Lead
	- Scale AI is the leading provider of expert data and human feedback to power RLHF for most of the Large Language Models available today. Scale also partners with many companies to help evaluate the LLMs and, in turn, drives model improvement by providing data to improve them - forming a virtuous cycle. This forms the foundation of an AI ecosystem and sets the bar for the data-centric AI movement. We are looking for the key Foundation Model Lead to seed and grow our team. Your core focus will be on advancement of LLMs - you will lead our efforts to partner with the largest companies building LLMs and help drive their improvement. If you are excited about shaping the future of the AI movement in a data-centric way, we would love to hear from you! 
	- Apply state of the art models developed internally and from the community, use them in production to solve problems for our customers and data labelers. 
	- Work with product and research teams with the largest LLM providers to identify opportunities for improvement in our current product line and for enabling upcoming product lines.
	- Work closely with customers - some of the most sophisticated ML organizations in the world - to quickly prototype and build new deep learning models targeted at language and multi-modal inputs.
	- 5+ years of model training, deployment and maintenance in a production environment.
	- Strong skills in computer vision, NLP, or deep learning.
	- Solid background in algorithms, data structures, and object-oriented programming.
	- Strong programming skills in Python, experience in Tensorflow or PyTorch.
	- Strong written and verbal communication skills. 
	- Rapidly prototype and test cutting edge techniques like prompt engineering, instruction tuning, chaining, DSP, RLHF and more.
	- Architect, train and deploy LLMs
	- Obsessed with foundation models
	- Experience with deep learning with large scale video processing. 
	- Published research in areas of machine learning at major conferences and/or journals. 
	- Experience working with cloud technology stack (eg. AWS or GCP) and developing machine learning models in a cloud environment
	- Experience working on recommendation engines 
+ skill set:
	- AIML - Senior Data Infrastructure Software Engineer, Machine Learning Platform and Technology
	- The Data Infrastructure group within the AI/ML organization powers the analytics, experimentation and ML feature engineering that powers the Machine Learning technologies we all love in our Apple devices. Our mission is to provide cutting edge, reliable and easy to use infrastructure for ingesting, storing, processing and interacting with data while keeping Apple's users' data private and secure.
	- Are you a passionate about building scalable, reliable, maintainable infrastructure and solving data problems at scale? Come join us and be part of the Data Infrastructure journey.
	- 12+ years of experience in software engineering with deep knowledge in computer science fundamentals.
	- Strong in data structures and algorithms. Must write good quality code with test cases and review PR's in fast faced environment.
	- Expert in one or more functional or object-oriented programming languages (Scala, Java)
	- Fluent in at least one scripting or systems programming language (Python, Bash and Go etc.)
	- Experience or knowledge in distributed data systems like Hadoop, Spark, Kafka or Flink.
	- Experience or knowledge in public cloud is a big plus, preferably AWS.
	- Strong collaboration and communication (verbal and written) skills to work with diff
	- The role involves managing petabytes of data for machine learning applications and designing and implementing new frameworks to build scalable and efficient data processing workflows and machine learning pipelines. The successful candidate will be responsible for ensuring complete data lineage and legal workflow integration while optimizing performance and scalability. You will also be responsible for monitoring the performance of the system, optimizing it for cost and efficiency, and solving any issues that arise. This is an exciting opportunity to work on cutting-edge technology and collaborate with cross-functional teams to deliver high-quality software solutions. The ideal candidate should have a strong background in software development, experience with public cloud platforms, and familiarity with distributed databases.
	- Familiarity with distributed databases, such as DynamoDB, MongoDB, or Cassandra.
	- Experience with containerization and orchestration technologies, such as Docker and Kubernetes
+ Experience with AWS Services such as Amazon S3 EC2 EKS / Kubernetes
+ skill set:
	- AIML - Machine Learning Data Infrastructure Engineer, Data & Machine Learning Innovation
	- As part of Apple's AI and Machine Learning org, we encourage and create groundbreaking technology for large-scale ML systems, computer vision, natural language processing, and multi-modal understanding. The Data and Machine Learning Innovation (DMLI) team is looking for a passionate Machine Learning Engineer to explore new methods, challenge existing metrics or protocols, and develop new insightful practices that will change how we understand data and overcome real-world ML challenges. Are you excited to work on some of the most ambitious technical challenges in the field? Your role will involve collaborating closely with machine learning researchers, engineers, and data scientists. Together, we will spearhead groundbreaking research initiatives and develop transformative products designed to build a significant impact for billions of users worldwide.
	- Demonstrated expertise in machine learning with a passion for data-centric machine learning.
	- Experience with natural language processing (NLP), and large language models, such as BERT, GPT, or Transformers.
	- Staying on top of emerging trends in LLMs.
	- Strong programming skills and hands-on experience using the following languages or deep learning frameworks: Python, PyTorch, or Jax.
	- Strong problem-solving and communication skills.
	- 5+ years of experience with developing and evaluating ML applications, and demonstrated experience in understanding and improving data quality.
	- Demonstrated publication record in relevant conferences (e.g. ***ACL, EMNLP, NeurIPS, ICML, ICLR***, etc) is a plus.
	- As a Machine Learning (ML) Engineer, you will be entrusted with the critical role of innovating and applying innovative research in ML to tackle complex data problems. The solutions you develop will significantly impact future Apple products and the broader ML development ecosystem. You will work with a multidisciplinary team to actively participate in the data-model co-design and co-development practice. Your responsibilities will extend to the design and development of a comprehensive data curation framework. You will also build robust model evaluation pipelines, integral to the continuous improvement and assessment of ML models. Additionally, your role will entail an in-depth analysis of collected data to underscore its influence on model performance. Furthermore, you will have the opportunity to showcase your groundbreaking research work by publishing and presenting at premier academic venues. Your work may span a variety of topics, including but not limited to: Designing and implementing semi-supervised, self-supervised representation learning techniques for growing the power of both limited labeled data and large-scale unlabeled data. Developing evaluation protocols centered on the end-to-end user experience, with a focus on anticipating potential failure modes, edge cases, and anomalies. Employing data selection techniques such as novelty detection, active learning, and core-set selection for diverse data types like images, 3D models, natural language, and audio. Uncovering patterns in data, setting performance targets, and using modern statistical and ML-based methods to model data distributions. This will aid in reducing redundancy and addressing out-of-distribution samples.
	- Ph.D/MS degree in Machine Learning, Natural Language Processing, Computer Vision, Data Science, Statistics or related areas.
	- The base pay range for this role is between $170,700 and $300,200, and your base pay will depend on your skills, qualifications, experience, and location.
+ skill set:
	- GitHub is looking for engineers to join our Data Infrastructure team. You'll be part of a team building and deploying large scale data and object storage for the world's largest code hosting platform
	- The Data Infrastructure team is highly distributed and we thrive in an environment of remote work and asynchronous communication. As a member of our team, you'll always be challenged by interesting and novel problems that have real impact on how the world builds software.
	- Responsibilities:
		* Build services and systems that empathetically and pragmatically meet real operability needs of GitHub developers
		* Use data to understand the availability, reliability, and sustainability of our infrastructure
		* You will respond to the needs of users and of other developers at GitHub.
		* Work closely with other teams from across the organization
	- Minimum Qualifications:
		* Experience building and deploying large, complex distributed systems with an eye toward reliability.
		* Proficiency in Golang, Python, and/or Ruby.
		* You take a pragmatic approach to decision making and design choices.
	- Preferred Qualifications:
		* Experience building highly available services at scale.
		* You have developed and scaled services in Go.
		* Experience diagnosing and resolving complex multi-system performance problems.
		* Experience with Docker and container orchestration systems.
+ skill set:
	- GitHub is looking for engineers to join the Compute Foundation team within our Data Center Engineering organization. You will focus on the systems and tools that enable our engineers to operate and scale the world's largest code hosting platform. You will help maintain our Kubernetes clusters and automation framework, optimize operating systems for use in our environment, and deploy systems at large scale around the world.
	- The Data Center Engineering team is highly distributed and you will thrive in an environment of remote work and asynchronous communication. You're expected to have strong written communication skills and be able to develop working relationships with coworkers in locations around the globe.
	- As an engineer at GitHub you'll always be challenged to solve interesting and novel problems that have real impact on how the world builds software.
	- Responsibilities:
		* Design and implement automation systems requirements.
		* Build performant and efficient packet processing systems for Internet and service traffic.
		* Cultivate open source projects developed by GitHub and build things you are proud to share.
		* Work closely with networking and facilities teams to design and support our global data center presence.
	- Minimum Qualifications:
		* Experience automating large, complex distributed systems with an eye toward reliability.
		* Proficiency in Golang, Python, and/or Ruby.
		* Experience diagnosing and resolving complex multi-system performance problems.
		* You take a pragmatic approach to decision making and design choices.
	- Preferred Qualifications:
		* Familiarity with configuration management software such as Puppet, Chef, Ansible, or Salt.
		* Upstream contributions to relevant open source projects (i.e. Kubernetes, Nomad, Linux kernel).
		* Experience with virtualization, bare metal deployment, or network engineering.
+ big data platform tools such as Hadoop, Hive Druid, Kafka, Ambari, Spark, Zeppelin
+ skill set:
	- Databases / Data warehousing
	- Writing complex SQL
	- Strong Microsoft Excel skills
	- Experience with Big Data platforms such as Hadoop
	- Experience with other reporting/visualization tools such as Tableau
	- Experience with monitoring and tracking tools such as  Splunk, NewRelic, Adobe/Google Analytics
+ skill set:
	- Build large-scale batch and real-time data pipelines with data processing frameworks like Scalding, Scio, Storm, Spark and the Google Cloud Platform.
	- Leverage best practices in continuous integration and delivery.
	- Help drive optimization, testing and tooling to improve data quality.
	- Collaborate with other engineers, ML experts and stakeholders, taking learning opportunities that will arise every single day.
	- Work in cross functional agile teams to continuously experiment, iterate and deliver on new product objectives.
	- You are pursuing a Bachelor's or Master's degree or a bootcamp certification in Computer Science or Computer Engineering or a related field of study.
	- You've dabbled in high volume data, preferably with distributed systems such as Hadoop, BigTable, and Cassandra.
	- You've had exposure to data modeling, data access, and data storage techniques.
	- You have an interest in agile software processes, data-driven development, reliability, and responsible experimentation.
	- You understand the value of collaboration within teams.








































##	Applied Machine Learning & Data Science Roles in Other Domains




For the ***transportation industry***, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.










For the ***management consulting market***, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.











For the ***K-12 (kindergarten to grade 12) education market***, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.














For the ***higher education market***, these are the skill sets for applied machine learning and data science roles, and instructor positions for data science.
+ skill set:
	- Experience using native APIs from higher ed core systems (SIS, ERP, LMS) a plus
		* MIS, such as: ***student information systems, SIS***, student management systems, school administration software, school administration system
		* enterprise resource planning, ERP
			+ business intelligence
				- customer relationship management, CRM, customer services
				- sales:
					* invoicing
					* order placement
					* order scheduling
					* shipping
			+ e-commerce, electronic commerce
				- product lifecycle management, PLM
					* planning
					* optimizing manufacturing capacity and material resources
					* manufacturing resource planning, MRP
						+ material requirements planning, MRP
				- supplier relationship management, SRM
					* maximize cost savings with support for the end-to-end procurement and logistic processes
			+ enterprise asset management
				- corporate performance and governance
				- human resource
			+ industrial distribution, logistics, supply chain management, SCM
			+ accounting
				- financial operations
				- regulatory compliance
		* learning management systems, LMS
	- 3+ years' experience with enterprise level data integration working with multiple systems simultaneously; Including extracting data utilizing API integration from a variety of platforms, performing data mapping, data transformation, and loading data to the target system
+ skill set:
	- Throughout the year, instructors will work on lecturing the course, curriculum development for new and existing courses, hosting office hours, managing a Teaching Assistant, assist with marketing, and others on an hourly basis.
	- Leading course discussions
	- Providing personalized support to students
	- Managing a Teaching Assistant
	- Hosting office hours
	- Improving the quality of our curriculum
	- Participating in course marketing activities
	- Is a data scientist with outstanding knowledge of and experience in Python, Calculus, Linear Algebra, Probability, Statistics and various Data Science concepts and algorithms which include supervised and unsupervised learning, dimensionality reduction, exploratory data analysis, and programming best practices
	- Is equally passionate about data science and teaching
	- Strong communication skills
	- Preferably has teaching experience alongside data science
	- Approaches problems with a design perspective
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.








For the ***real estate market***, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.









For the ***waste management market***, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.











For the ***health care industry***, including health care informatics, health care analytics, health care management and hospital management, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- Advanced level programming skills in Python, ideally developed from experience working on long-term commercial projects, including significant experience using SciPy and machine-learning packages (Numpy, Pandas, scikit-learn, etc) for the development of maintained components. Additional experience using PySpark a big plus.
	- Ability to integrate and scale solutions that involve large data sources in SQL databases and/or distributed systems such as Hadoop, as well as considerable experience deploying at scale on cloud technologies such as AWS, GCP, Azure.
	- A set of software-development values that ensures high-quality, readable and maintainable code is produced within an open and collaborative environment.
	- A pragmatic approach in scope and design, seeking simple iterative solutions wherever possible to shorten the time-to-value of work.
	- Knowledge of supervised machine learning methods, such as regularised regressions, ensemble tree classifiers (e.g. xgboost), Support Vector Machines, deep learning, etc.
	- Additional experience developing in C++, R, Java, Scala, Java, JavaScript, or advanced ability user of shell scripting commands (grep, sed, awk, etc).
	- A demonstrable interest (e.g. public GitHub repo, or online course completion) in one of the following machine learning libraries (or equivalents): TensorFlow, Spark MLLib or CRAN packages for machine learning.
	- Knowledge of healthcare / life science issues involving Real-World Evidence.
+ skill set:
	- software engineering
	- big data analytics framework
	- product innovation
	- services and applications
	- communicating with industrial and academic experts
	- machine learning
	- statistics
	- interested in personalized medicine
	- strong interest in industry projects
	- data mining
+ skill set:
	- IBM Research Lab in Mulhuddart, Dublin, Ireland.
	- AI for Health and Social Care team
	- state-of-the-art in AI and Healthcare Informatics.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.







For the ***media industry***, including mass media and social media, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.








For the ***hospitality industry***, including the tourism market, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






For the ***telecommunication industry***, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.










For the ***electric power industry***, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
















For the ***construction industry***, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.







For the ***fashion industry***, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.









For the ***entertainment industry***, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.









For the ***music industry***, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.









For the ***manufacturing industry***, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.










For the ***regulatory compliance market***, and regulatory enforcement and inspection/auditing market, these are the skill sets for applied machine learning and data science roles.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.




























#	Corporate Research Labs



+ DoorDash Labs
+ Netflix Research
	- https://research.netflix.com/
	- Machine Learning
		* As the world's leading Internet television network with over 160 million members in over 190 countries, our members enjoy hundreds of millions of hours of content per day, including original series, documentaries and feature films. We invest heavily in machine learning to continually improve our member experience and optimize the Netflix service end-to-end. As researchers, we innovate using machine learning in many areas where we prototype, design, implement, evaluate, and productionize models and algorithms through both offline experiments and online A/B testing.
		* Machine learning impacts many exciting areas throughout our company. Historically, personalization has been the most well-known area, where machine learning powers our recommendation algorithms. We're also using machine learning to help shape our catalog of movies and TV shows by learning characteristics that make content successful. We use it to optimize the production of original movies and TV shows in Netflix's rapidly growing studio. Machine learning also enables us to optimize video and audio encoding, adaptive bitrate selection, and our in-house Content Delivery Network that accounts for more than a third of North American internet traffic. It also powers our advertising spend, channel mix, and advertising creative so that we can find new members who will enjoy Netflix.
		* Using machine learning pervasively across Netflix brings many new challenges where we need to push forward the state-of-the-art. This means coming up with new ideas and testing them out, be it new models and algorithms or improvements to existing ones, better metrics or evaluation methodologies, and addressing the challenges of scale. Our research spans many different algorithmic approaches including causal modeling, bandits, reinforcement learning, ensembles, neural networks, probabilistic graphical models, and matrix factorization.
	- Machine Learning Platform: https://research.netflix.com/research-area/machine-learning-platform
		* Accelerating and Democratizing Machine Learning Innovation
		* In practice, large-scale applied Machine Learning (ML) requires substantial infrastructure and systems engineering investment. Although we're most well-known for early work in personalized recommendations, the sophistication and breadth of ML algorithms and applications at Netflix have grown substantially over the last few years. Today our main challenge is to scale machine learning in heterogeneous language environments across several domains and at all stages of a project's lifecycle, including ad-hoc exploration, preparing training data, model development, and robust production deployment.
		* We need to do this at the scale of hundreds of millions of global streaming members, whose viewing habits, preferences, and contexts change over time. Content, studio, and marketing applications, which are being reimagined with machine learning, bring their own unique platform requirements. To meet these business and research needs, we need to innovate on the platform infrastructure itself, such that we are able to carefully orchestrate a continuous cycle of learning, inference, and observation while also maintaining high system reliability. Our journey continues as we seek to find new ways to scale with our member base as well as the ever-growing need for ML at Netflix.
+ Toyota Research Institute, TRI







Generic skill sets for research scientists:
+ [OpenLabNotes – An Electronic Laboratory Notebook Extension for OpenLabFramework](https://doi.org/10.1515/jib-2015-274)
	- Electronic laboratory notebooks (ELNs)
+ skill set:
	- Take research from an initial idea all the way to a merged PR in our open source libraries.
	- Speak to the Rasa community (developers who use our libraries) to help prioritize our research roadmap, and assess the impact of the research we've shipped.
	- Design and conduct experiments that bring us closer to our vision.
	- Collaborate on research papers.




















##	EDA Research







###	EDA + Related Research with Alibaba Group


+ Using HW/SW Mechanisms to Improve Performance of remote Heterogeneous Systems
	- Alibaba is an e-commerce and AI company. We generate enormous data and consume huge amount of computation and storage resources every day. It is critical for Alibaba to keep on improving data center design given the emerging of powerful accelerator computation clusters.
	- We would focus on:
		* 1. Analyze different AI workloads in distributed GPU clusters, study their computation and network requirement
		* 2. Based on current remote accelerator technique, improve its efficiency via hardware/software solutions
		* 3. Apply the technique to real workload
	- Requirement:
		* 1. PHD candidate, experienced with distributed heterogeneous systems
		* 2. It's a plus if candidate worked with deep learning algorithms
		* 3. it's a plus if candidate has top conference publications
+ Last mile of datacenter as a computer -- local protocol and semantics based ASIC/FPGA cloud
	- Developers and customers prefer to use heterogeneous compute resources with a set of local server access protocol and semantics. We need to find talents to do research and prototyping with a specific local API on an ASIC or FPGA chip.
+ Emerging Accelerator Architecture, Programming Model, and Optimizations
	- The emerging hardware accelerator architectures, such as process-in-memory (PIM) and neuromorphic computing,  have shown great potential to speed up AI/ML and data-heavy applications. This research aims to investigate these non-traditional architecture designs and their performance implications for domain-specific applications in Alibaba datacenters and ecosystem. It will study the emerging architecture's programming model for usability and explore the software-hardware co-design strategies (e.g. reinforcement learning based architecture space exploration, architecture-aware compression and sparsity exploitation) and optimization trade-offs to maximize the performance.
+ Execution engine optimization based on GPUs and other modern hardware
	- Targeting Maxcompute SQL engine, we'd like to import modern hardware technology (such as GPU, FPGA etc) to model and improve the core operators of the distributed execution engine, optimize the system performance on specific scenes at last.
+ Performance/Power/Area (PPA) Modeling & Analysis
	- The ***Computing Technology Lab of Alibaba Damo Academy*** focuses on advanced research topics in computing, memory/storage, and interconnect technologies that can revolutionize today's computing systems with holistic innovations ranging from system architectures to VLSI designs, to enable new computing capabilities for improving energy efficiency and performance across multiple application domains, including both high-performance and embedded computing.
+ Research on Domain Specific Architecture
	- As the end of Dennard's scaling and Moore's Law running out of steam, the traditional architecture for general-purpose processors can no longer meet the requirements of high performance and low energy consumption for various emerging applications. To allow the computing to have higher performance/energy efficiency, Domain Specific Architecture (DSA) has become a popular solution. However, there are many challenges in the DSA design. For example, the definition of the scope of Domain, trade-off between specialization and general-purpose, instruction set design, compiler design and optimization, memory wall, ultra-low-power design, micro-structure design and optimization, etc. This internship Project is a thorough and detailed study of the DSA to address these challenges.
	- The Computing Technology Lab focuses on advanced research topics in computing, memory/storage, and interconnect technologies that can revolutionize today's computing systems with holistic innovations ranging from system architectures to VLSI designs, to enable new computing capabilities for improving energy efficiency and performance across multiple application domains, including both high-performance and embedded computing.
+ Research on Cloud Server Architecture
	- Perform profiling/modeling and evaluation of workloads for our cloud server, design and optimize server architecture including but not limited to: CPU, cache/memory, storage and accelerators.
+ Research on algorithms/architectures of the next-generation AliNPU for training
	- AliNPU targeting for neural network training is a key component of Alibaba's AI Chip strategy. To design an architecture surpassing the best of the AI training chips, such as GPU and TPU, we must look into all aspects from algorithms to HW architecture, for the potential computational efficiency improvements.
	- The works may focus on one or a few of the following directions：
		* 1. Algorithm innovations that may improve the system efficiency, and the experiments.
		* 2. The analysis of the theoretic bounds and/or the proof with regards to the algorithm innovations.
		* 3. Experimental HW architecture designs, simulations and their PPA analysis.
+ Hyper-scale cloud datacenter's compute resource pool and management platform prototype
	- Compute pools will be widely deployed in hyper-scale cloud datacenter. Alibaba Infrastructure AI Ops Platform (TIANJI) team is now actively seeking talents to work on research in this area.
+ Research on optimization of AI accelerator
	- Nowadays high performance computing has become one of the hot topics of AI research. The research aims on optimizing power dissipation and energy efficiency of AI accelerators targeting various of AI applications, providing high quality computation support for AI applications.
	- The research topics include:
		* 1. Research on computation pattern of various AI applications to look for bottleneck
		* 2. Research on AI accelerator architectures, implementations to improve performance and energy efficiency
		* 3. Codesign AI accelerator (SW/HW) and application to maximize the performance of accelerator)
+ Accelerating Machine Learning Applications on Heterogeneous Computing Architectures
	- This research aims to optimize ML applications on heterogeneous accelerators such as GPUs, FPGAs, and/or ASICs. S/he will conduct analysis and exploration on various performance bottlenecks in the full software/hardware stack, including ML algorithm improvement, model level transformation (e.g. compression, sparsity, data parallelization), and domain-specific architecture innovations, in order to dramatically boost the ML application's performance.
+ skill set for Senior Research Scientist, Design Automation:
	- NVIDIA Research is seeking leading researchers in the areas of VLSI electronic design automation (EDA) to contribute to the development of future high-performance and mobile computing systems. You should have a strong track record of research excellence; systems-building experience; a broad perspective across areas including EDA algorithms and software, machine learning, and VLSI chip design methodology. Specific areas of research interest include but are not limited to applications of supervised learning, unsupervised learning, reinforcement learning and GPU acceleration to EDA algorithms.
	- Apply machine learning and GPU acceleration to EDA software and ASIC and VLSI design tool flows.
	- Research and develop creative and innovative EDA software and algorithms.
	- Collaborate with circuits, VLSI, and architecture team members in research and product teams.
	- Publish and present your original research, speak at conferences and events
	- Collaborate with external researchers and a diverse set of internal product teams.
	- PhD or equivalent experience in Electrical Engineering, Computer Engineering or related field (or equivalent experience).
	- 3+ years of relevant research experience with a strong research record, well-referenced publications and/or patents.
	- You should display a strong background in EDA algorithms and software development, machine learning, along with knowledge of VLSI, circuits, IC design, and/or computer micro-architecture fundamentals.
	- Experience with C, C++, Python, and scripting languages.
	- Background with commonly used machine learning frameworks (PyTorch, Tensorflow).
	- Experience with CUDA and GPU computing
	- Strong communication skills needed. Being a creative and dynamic presenter is a huge advantage.
+ skill set for Research Scientist, Design Automation - New College Grad.
	- We are now looking for a Research Scientist – Design Automation
	- NVIDIA's invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined modern computer graphics, and revolutionized parallel computing. More recently, GPU deep learning ignited modern AI — the next era of computing — with the GPU acting as the brain of computers, robots, and self-driving cars that can perceive and understand the world. Today, we are increasingly known as “the AI computing company.” We're looking to grow our company, and build our teams with the smartest people in the world. Would you like to join us at the forefront of technological advancement?
	- NVIDIA Research is seeking leading researchers in the areas of VLSI electronic design automation (EDA) to contribute to the development of future high-performance and mobile computing systems. You should have a strong track record of research excellence; systems-building experience; a broad perspective across areas including EDA algorithms and software, machine learning, and VLSI chip design methodology. Specific areas of research interest include but are not limited to applications of supervised learning, unsupervised learning, reinforcement learning and GPU acceleration to EDA algorithms.
	- Apply machine learning and GPU acceleration to EDA software and ASIC and VLSI design tool flows.
	- Research and develop creative and innovative EDA software and algorithms.
	- Collaborate with circuits, VLSI, and architecture team members in research and product teams.
	- Publish and present your original research, speak at conferences and events
	- Collaborate with external researchers and a diverse set of internal product teams.
	- Pursuing Ph.D in EE or related with a strong research record, well referenced publications and / or patents.
	- You should display a strong background in EDA algorithms and software development, machine learning, along with knowledge of VLSI, circuits, IC design, and/or computer micro-architecture fundamentals.
	- Experience with C, C++, Python, and scripting languages.
	- Background with commonly used machine learning frameworks (PyTorch, Tensorflow).
	- Experience with CUDA and GPU computing
	- Strong communication skills needed. Being a creative and dynamic presenter is a huge advantage.
































##	Computer Architecture Research




***Resources***
+ [HiPEAC](https://www.hipeac.net/)
	- For computer architecture, compiler design, and related areas.
	- [HiPEAC Jobs](https://www.hipeac.net/jobs/#/)






+ skill set for Computer Architecture, Design Space Exploration:
	- Conduct fundamental research on new directions in computing systems
	- Develop academic research partnerships and cooperation with leading universities and professors in the area
	- Work with internal research colleagues and academic research partners to achieve new breakthroughs in research and innovation
	- Produce and present research papers at internationally leading conferences and events
	- Produce white papers on current developments and future directions in computing systems
	- Where appropriate, contribute insight and research expertise to committees and other organizations that are looking to establish new industry standards and platforms
	- Contribute to the research and academic community through service such as conference program committee membership, membership of journal editorial boards etc.
	- PhD in an area related to computing systems architecture, or equivalent research experience in industry
	- Record of publishing research papers in the area of computing systems architecture
	- Candidates should have research experience in computing systems, and be familiar with at least one of the following areas:
		* Design Space Exploration (DSE) Frameworks
		* Hierarchical DSE
		* Microarchitecture DSE
		* Architectural Models, Templates and Generators
		* Generator Methodology
		* Design Space Sampling
		* Constraint-Based DSE
		* Reusable Designs
		* System-Technology Exploration
		* Hardware-Software Co-Design and Co-Optimization
	- Strong interpersonal skills and ability to work productively in a research environment






























##	Hardware Security Research














##	Formal Verification Research & Logical AI Research


***Resources***:
+ [SAT Live!](https://www.satlive.org/)
+ [Formal Land (Arae SARL)](https://formal.land/)














##	Machine Learning Research & Deep Learning Research







###	Machine Learning Research with Alibaba Group

+ Building an innovative and systematic AI benchmarks platform
	- Currently in Alibaba Group, deep learning and related applications have been employed in various business departments. Tmall, Alitrip, Taobao, Ant Financial and other departments are making extensive use of emerging deep learning technologies to continuously improve application and algorithms and enhance the consumer experience. On the one hand, Alibaba's engineering teams design, experiment and deploy different deep learning algorithms and applications every day. On the other hand, deep learning requires a lot of computational power, which also puts higher requirements on the computational power of the hardware and their adaptability to the application. How to balance the demand and supply relationship between these two and integrate the solution into a systematic platform product? How to automatically and systematically evaluate the computional power of an AI hardware? How to evaluate the advantages and disadvantages of a hardware for usage in an application and give customer recommendations through a systematic platform? These are the challenges we are currently dealing with and we need to solve. Recently we have launched the AI Matrix product (through aimatrix.ai website), but it is still in the early stage of the product. In the future, we need more people who have the same understanding as us and are willing to involve in solving these problems. Let's contribute our own strength and make the AI Matrix as an effective systematic platform and an impactful technical brand.
	- [AI Matrix](https://aimatrix.ai/en-us/)
	- https://github.com/alibaba/ai-matrix









##	Computer Vision Research




+ skill set:
	- NVIDIA is searching for outstanding applied research manager to spearhead our Computer Vision efforts. Computer Vision is a core component of NVIDIAs platforms from Drive AV to Isaac autonomous Robotics to Clara for Healthcare to Maxine streaming and broadcast and beyond. The ideal candidate is an established thought leader in academic or industry with deep experience in vision, human understanding, publishing and presenting at industry and academic conferences, and hands-on implementation. This role requires high-level knowledge of multiple areas within production workflow and tools, Deep Learning, network optimization, and vision systems. Come join a diverse applied research group that works on hard and meaningful problems; that consistently publishes at top venues in graphics, computer vision, and artificial intelligence; and that values real impact on NVIDIA products and the industry at large.
	- Start an applied research team focused on Computer Vision specifically targeted on Video Understanding
	- Recruit, build and lead a small applied research team with diverse skills across research, high performance computing, hardware acceleration, and system software
	- Define and execute a multi-year applied research agenda
	- Work with product groups to identify short and medium term technology gaps, transfer technology
	- Identify and close gaps between research and product teams
	- Prove out potential in existing research for use in product. Improve robustness and performance
	- Implement experiments and research prototypes in C++, Python, CUDA, and other domain-appropriate tools
	- Influence research initiatives across the company and in the field
	- Protect strategic inventions with patents
	- Publish and present findings in top-tier venues
	- A Ph.D. or comparable research experience or equivalent experience in Computer Science/Engineering or a related field
	- 10+ years of relevant work experience
	- 3+ years of experience leading a team
	- Excellent knowledge of theory and practice in computer graphics, cloud/distributed computing, ray tracing, and machine learning
	- Expertise with programming systems such as C++, Python, CUDA, and deep learning frameworks such as TensorFlow and PyTorch
	- Demonstrated team/management leadership in research, applied research, or product teams
	- A track record of research excellence demonstrated in publications at leading conferences and journals and other research artifacts such as software projects
	- Great presentation and interpersonal skills














##	Compiler Design & Program Analysis (or Software Analysis) Research














##	Quantum Computing Research





###	Quantum Computing Research with Alibaba Group

+ Quantum Algorithm for Near-term Quantum Devices
	- A general-purpose fault-tolerant quantum computer will require millions of physical qubits and millions of quantum gate operations. With quantum computers of significant size now on the horizon, we should understand how to best exploit the initially limited abilities and how to develop and run useful quantum algorithms within the limited circuit depth of intermediate size quantum devices with limited error correction.
+ Research in Practical Applications of Quantum-Safe Communication
	- Quantum communication may refer to quantum cryptography, quantum teleportation, and quantum entanglement. Among those, quantum key distribution (QKD) is one of the most practical applications in recent years. Quantum cryptography takes the advantage of the laws of quantum physics to protect data,
	- Currently, the most significant problems in practical quantum cryptography systems include: high-speed quantum random number generation, long-distance fiber quantum key distribution with high key generation speed, co-fiber transmission of classical and quantum optical signals, as well as practical commercialization and stabilization.
	- Our project aims to study these critical issues in quantum cryptography system for practical applications. Due to the transmission loss and dark count, the bottleneck for its practical application lies in the trade-off between high speed key generation rate and long transmission distance. In order to solve these problems, one potential solution is to design more efficient telecommunication protocol to exceed the theoretical up bound of the generation rate. Meanwhile, the project will also focus on the study and practical solutions for quantum random number generation, post-quantum cryptography algorithm, the migration of classical and quantum networks, etc












#	Academic/University Research Labs


##	U.S. Academic/University Research Labs




+ Johns Hopkins University
	- Johns Hopkins University Applied Physics Laboratory, Johns Hopkins APL












