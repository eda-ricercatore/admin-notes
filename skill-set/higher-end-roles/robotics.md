#	Robotics


##	Notes About Robotics


Robot classifications include:
+ autonomously guided robots, robots with sliding autonomy, remote-operated robots (telerobotics)
+ behavior-based robotics, BBR, or behavioral robotics
+ mobile robots, and stationary robots





Types of mobile robots, or 
+ uncrewed vehicles, or unmanned vehicles
	- remote controlled vehicles, remote-control vehicles, or remote guided vehicles
	- autonomous vehicles, ***autonomous robots***, automated guided vehicles, automatic guided vehicles, AGV, autonomous mobile robots, AMR
		* helicams, remote-controlled mini helicopters
		* unmanned aerial vehicles, UAV, unmanned aircraft systems, UAS
			+ remotely-piloted aircrafts, RPA
			+ unmanned-aircraft vehicle systems, UAVS, remotely piloted aerial vehicle, RPAV, remotely piloted aircraft system, RPAS
		* unmanned underwater vehicles, UUV, underwater drones
			+ autonomous underwater vehicles, AUVs
				- underwater gliders
			+ remotely operated underwater vehicles, ROUVs, ROVs
			+ Unmanned Surface Vehicles, USVs, Unmanned Surface Vessels, USVs), Autonomous Surface Vehicles, ASVs, Uncrewed Surface Vessels, USVs, or colloquially drone ships
	- i.e., not all unmanned ground vehicles (UGVs) are autonomous.
		- UGVs can be remotely controlled by people.





This document does not include agriculture robotics, which information is provided in the agricultural technologies document.



Interesting topics in robotics:
+ cloud robotics
	- applications:
		* assistive robots
		* autonomous mobile robots
		* cloud medical robots
		* industrial robots
+ cognitive robotics
+ evolutionary robotics
+ fog robotics
	- as an architecture which consists of storage, networking functions, control with fog computing closer to robots
+ remote control animals, bio-robots, or robo-animals
+ robot ethics, roboethics
+ robot navigation
	- robot localization
		* self-localisation
		* path planning
		* map-building and map interpretation
		* simultaneous localization and mapping, SLAM
			+ acoustic SLAM
			+ audio-visual SLAM
			+ bio-inspired SLAM
			+ collaborative SLAM
			+ extended Kalman filter (EKF) for SLAM, EKF SLAM
			+ GraphSLAM
	- vision-based navigation
		* acoustic navigation
		* inertial navigation
		* indoor navigation
		* radio navigation
+ self-reconfiguring modular robots, self-reconfigurable modular robots, modular self-reconfiguring robotic systems
	- architectures
		* chain architecture
		* hybrid architecture
		* lattice architecture
	- types of reconfiguration
		* deterministic reconfiguration
		* stochastic reconfiguration
	- designs of modules
		* heterogeneous modular robot systems
		* homogeneous modular robot systems
	- mechanism reconfigurability
		* inter-reconfigurability
		* intra-reconfigurability
		* nested-reconfigurability
+ soft robotics





reactive programming = asynchronous dataflow programming
+ functional reactive programming, FRP, is based on the building blocks of functional programming
	- map
	- reduce
	- filter
	- applications of FRP, by simplifying problems via the explicit modeling of time, include:
		* graphical user interfaces, GUI, development
		* robotics
		* games
		* music






##	Companies that Engineer Robots



+ Agility Robotics
+ Boston Dynamics
+ Hanson Robotics
+ Tesla
+ Xiaomi











##	Generic Sets of Skills in Robotics


Generic sets of skills in robotics:
+ ***OpenCV Ceres, ROS, PyTorch***
+ skill set:
	- Android
	- Zephyr
	- Linux
	- Renode
	- RISC-V
	- TensorFlow
	- Caffe
	- OpenCV
	- Singularity
	- KiCad
	- Docker
	- ROS
+ skill set:
	- We are looking for a Research Scientist, Robotics - New College Graduate:
	- NVIDIA’s invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined modern computer graphics, and revolutionized parallel computing. More recently, GPU deep learning ignited modern AI — the next era of computing. With the GPU acting as the primary computing device, robots can now perceive and understand the world around them. Today, NVIDIA has transformed into “the AI computing company.” We're looking to grow our company, and build our teams with the smartest people in the world working on diverse aspects of AI. Join us at the frontier of technological advancement!
	- Robotics is an increasingly exciting field, influenced heavily by recent advances in hardware acceleration through devices such as the modern GPU. These advances have enabled tremendous progress in several areas of robotics, including manipulation, visual recognition, real-time tracking, and learning-based control. Robots are getting increasingly proficient at building 3D maps of their environments, detecting and tracking objects and people as they move through the world, learning controllers from realistic simulation, and understanding commands provided via gestures and natural language.
	- While our ultimate goal is to reach human-level dexterity, perception, and adaptability, we still have a long way to go. To enable the next generation of robots that can robustly operate in the physical world and interact with people in a natural way, progress is still needed in multiple domains: perception, planning, learning, and control. Moreover, even more importantly, the integration of these individual contributions into complete robot systems opens new challenges.
	- Toward this goal, the NVIDIA Robotics Research Lab brings together a diverse, interdisciplinary research team working on core robotics topics ranging from control, perception, machine learning, common sense reasoning, task planning, human-robot collaboration, and critical related areas such as deep learning for computer vision, natural language processing and decision making.
	- The lab focuses on fundamental research questions in robotics and lab members are encouraged to publish their research and open source their code. The lab hosts numerous internships every year to foster education and communication, and the team is encouraged to collaborate broadly with institutions outside of NVIDIA, both academic and industrial. NVIDIA is well known for its team culture, and lab researchers are able to closely interact with others within the company who are experts in broad subtopics such as computer vision, computer graphics, GPU computing, AI and Deep Learning, self-driving cars, and physics-based simulation.
	- Robot manipulation, robot control, reinforcement learning, computer vision, human-robot interaction, deep learning, physics-based simulation, neuro symbolic reasoning, and natural language processing.
	- Pursuing PhD in Robotics, Computer Science, Engineering or related field.
	- 3+ years of relevant research or work experience
	- Knowledge of theory and practice of robotics, or a related area with a strong interest in connecting your work to robotics scenarios.
	- A track record of research excellence with your work published in top conferences and journals such as Robotics (RSS, ICRA, IROS, CoRL, T-RO, IJRR), Machine Learning (NeurIPS, ICML, ICLR, AAAI, JMLR), Computer Vision (CVPR, ICCV, ECCV, TPAMI) and Language (ACL, EMNLP, NAACL).
	- Exceptional programming skills in Python, and deep learning frameworks such as Tensorflow and Pytorch. Fluency in C/C++; CUDA and robotics frameworks such as ROS is a plus.
	- Strong communication and interpersonal skills are required along with the ability to work in a dynamic, research focused team. A demonstrated history of mentoring junior engineers and interns is a huge plus.
	- Are you dedicated, upbeat and dynamic with excellent analytical ability? Are you a researcher or an engineer passionate and highly motivated about solving complex problems? If so, you may be a perfect fit for NVIDIA!
+ skill set:
	- Experience with Robotics perception
	- At Starsky, the Perception team is responsible for processing sensor information and making it available to the other teams in a clean and consistent format. The models and algorithms developed aim to achieve robust real time detection and tracking of our truck and other objects in the local environment, including lane lines, vehicles, and pedestrians.
	- As a Robotics Perception Engineer, you will be responsible for filtering, fusing and post-processing the outputs of different deep learning models and sensors. You will apply state of the art tracking and fusion algorithms which are robust to sensor noise and environmental variability. This requires working with teams across the driving stack to scope requirements and understand the strengths and limitations of different modules.
	- Background in linear algebra, probability, 3D geometry
	- Experience with multi-camera sensor fusion and camera-radar sensor fusion
	- Experience with real time tracking of objects and lanes
	- Experience with real time mapping and localization
	- Experience with camera and radar sensor calibration
	- Ability to write efficient real time algorithms in C++
	- Experience in developing on linux environment
	- 2+ years experience in C++/Python development in a fast paced production environment
	- 2+ years experience in perception system of mobile robots
	- Experience with ROS
	- Experience in sensor noise analysis
	- Experience in machine learning/deep learning
+ Background in linear algebra, probability, 3D geometry and abstract problem solving skills
+ skill set:
	- Experience developing, troubleshooting, tuning and managing hardware systems including:
		* LIDARs
		* Standard or Depth Cameras
		* Light systems
		* IMUs, encoders or other odometry methods
	- Experience designing/developing one or more of the following software systems/algorithms:
		* Mapping, Localization, and/or SLAM
		* Robot perception, Sensor calibration and/or fusion
		* Motion planning and/or Autonomous navigation
		* Production level configuration, log and system management
		* Remote monitoring and control
		* Performance verification and monitoring
		* Test automation of combined software and hardware components
		* Automated release pipelines
+ skill set:
	- Develop and maintain scalable codebase used to calibrate sensors and actuators used on a robot system including:
		* Camera: Intrinsic, Extrinsic, White-balance calibration of both standard and fisheye cameras
		* Time-of-Flight cameras
		* Lidar
		* IMU
		* Odometry
	- Improvement of existing calibration processes and procedures
	- Develop calibration methods for new sensors added to robot
	- Hands-on deployment of calibration fixtures at contract manufacturing line
	- Hands-on calibration of robot system to validate new calibration processes
	- Assist mechanical, electrical and other teams to design fixtures needed for calibration
	- Work with manufacturing and field engineers to debug field issues related to calibration
	- Work with hardware and software teams to provide well calibrated robot system
	- Good C++, C and python coding skills
	- 2 years of industrial experience
	- Previous experience with extrinsic calibration of at least two of the following sensors: RGB Camera, ToF Camera, Lidar, Odometry, IMU
	- Understanding of standard camera calibration methods
	- System level understanding of how calibration affects robot performance
+ We preferred students experienced in the use of ROS (Robot Operating System) and simulation engines such as Unity3D and Unreal Engine 4.
+ skill set:
	- ROS
	- Gazebo, open-source 3-D robotics simulator
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.

















##	Sets of Skills For Unmanned Ground Vehicles, UGVs


Notes:
+ Not all unmanned ground vehicles (UGVs) are autonomous.
	- UGVs can be remotely controlled by people.





Sets of skills for unmanned ground vehicles (UGVs):
+ skill set:
	- This role is focused on delivering the best in localization performance from our sensors.
		* By localization, it refers to:
			+ [(generic) navigation](https://en.wikipedia.org/wiki/Navigation)
			+ [Robot navigation](https://en.wikipedia.org/wiki/Robot_navigation)
				- By extension, it involves:
					* self-localisation
					* [path planning](https://en.wikipedia.org/wiki/Motion_planning)
					* map-building and map interpretation
	- Candidates should have extensive experience working with raw navigation data. You should be very comfortable with estimation theory and have implemented complex filters in practice. Real world experience with RTK, Integer Ambiguity Estimation and other high precision techniques are a huge plus.
		* RTK could refer to [real-time kinematic positioning](https://en.wikipedia.org/wiki/Real-time_kinematic_positioning)
		* [integer aperture estimation = integer ambiguity resolution](https://sciencetrends.com/integer-aperture-estimation-presence-biases/)
	- [Inertial Measurement Unit](https://en.wikipedia.org/wiki/Inertial_measurement_unit) Algorithms, [Extended Kalman Filter (EKF)](https://en.wikipedia.org/wiki/Extended_Kalman_filter), [Visual Odometry](https://en.wikipedia.org/wiki/Visual_odometry), Gnss, RTK-GPS
		* [global navigation satellite system (GNSS)](https://en.wikipedia.org/wiki/Satellite_navigation)
			- Or, satellite navigation, or satnav system.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.





###	Sets of Skills For Autonomous Road Vehicles



Sets of skills for autonomous road vehicles:
+ skill set:
	- NVIDIA is seeking deep learning research / engineering interns to join the AV perception research team. The team consists of a group of dynamic AI applied researchers and engineers and is committed to build industry-grade deep learning to take autonomous vehicle (AV) perception into production, we work on fundamental advances in scientific methods to enabling scaling-up the entire perception for the autonomous driving stack. We are looking for highly motivated individuals to work in the areas of deep learning, optimization and computer vision. Our interns have the unique opportunity to make algorithmic contributions to core products and apply their ideas at a very large scale. As an intern, you will conduct applied research related to one of the meaningful research topics mainly related to perception for autonomous driving. You may also have the opportunity to publish in premier conferences in the fields of Machine Learning and perception.
	- In order to scale-up current AI-algorithms, we need to learn from datasets orders of magnitude larger than existing ones which is a very challenging task. Our team at NVIDIA is dedicated to developing new algorithms to explore the vast amount of collected data to improve AI-based applications such as AV.
	- Efficient data selection to improve learning and scaling-up training sets including active learning and mining strategies.
	- Network interpretability to predict network failures and to design novel algorithms to continuously learn from data and from failures.
	- Efficient training and inference to minimize training time and enable inference in embedded platforms.
	- Synthetic to real domain adaptation.
	- To learn more about our high-level goals visit: https://atscaleconference.com/videos/scale-2018-keynote-inside-nvidias-ai-infrastructure-for-self-driving-cars/
	- You will be responsible for conducting applied research to advance the performance of our codebase applied to perception for autonomous vehicles. Research is done in areas related to large scale learning including semi-supervised deep learning, active learning, deep network architecture search, parameter optimization and modeling, domain adaptation, or life-long learning. You may have opportunities to influence the progress of the field by producing publications.
	- Contribute to integrating novel algorithms into core applications to enable a better generation of autonomous vehicles, coding in Tensorflow to facilitate the integration into our codebase.
	- Collaborate and increase the performance of existing perception-based systems for AV.
	- Pursuing BS, MS, or Ph.D. in Computer Science, with a focus in Deep Learning, Artificial Intelligence or related fields.
	- Expertise in Computer Vision and Deep Learning.
	- Strong mathematical background and ability to analyze results.
	- Excellent Tensorflow and python programming skills to bring ideas into production systems.
	- A dedication to bring your work to completion and see your work having a worldwide impact.
	- A self-motivated and good teammate with good communication and social skills.
	- Publication or experience in fields related to machine learning, analytics, large-scale systems, statistics, and mathematics.
	- Currently enrolled in a Ph.D. program in CS or Math.
	- First author publications in top-tier peer-reviewed conferences such as NeurIPS, ECCV, ICML, CVPR, ICCV.
	- Research or software engineering experience confirmed via internships, relevant work experience or code competitions.
+ skill set:
	- Knowledge of robotics concepts and tools (ROS)
	- Understanding of and ability to implement machine learning methods, particularly for applications in autonomous vehicle decision making and prediction
	- Experience in production C++ development
+ tech stack:
	-  Solid knowledge in control theory, especially model predictive control
	- Experience in one or more of the following areas:
		* Robust control
		* Adaptive control
		* Nonlinear control
		* State estimation
		* Parameter estimation
		* Model identification
		* Optimization
	- Experience in one or more of the following areas:
		* Control theory
		* Motion planning
		* Optimization
		* Formal logic
		* Game AI development
	- Experience with sensors: cameras, lidars, ultrasonic, etc.
	- Computer vision experience, image processing experience
+ skill set:
	- As a core member of our engineering team, the State Estimation Engineer will derive and implement novel real-time pose estimation algorithms. You will need to drive R&D to then execute algorithms to solve large-scale mapping. You will closely collaborate with other engineers to develop algorithms for in-situ and in-factory multi-sensor calibration. Familiarity with multiple sensors such as GPS, IMU, camera, and wheel odometry needed. 
	- MS or PhD in Robotics, Machine Learning, Computer Science, Electrical Engineering or a related field
	- Intuitive understanding of classical ML, Linear Algebra, Stochastic Processes, Geometric Computer Vision and Optimization (Convex, Nonlinear)
	- Deep experience in one or more areas: Kalman Filter and its variants, MAP, Sequential Monte Carlo (particle filter), Nonlinear Least squares, IRLS or MHT
	- Strong C++ programming and software design skills
	- Familiarity with multiple sensors such as GPS, IMU, camera, and wheel odometry
	- Experience deploying an estimator for say SLAM/VIO in a real application
	- Understanding of numerical stability, sensor modeling and system/noise identification
	- Understanding of theoretical shortcomings in modern algorithms and how to overcome them
+ skill set for Senior Research Scientist, Autonomous Vehicle Research:
	- We are now recruiting top Research Scientists in Autonomous Vehicle Research.
	- AI-powered autonomous vehicles that can learn, reason, and interact with people are no longer science fiction. Self-driving cars, autonomous delivery vehicles, and autonomous construction vehicles, among others, are getting increasingly close to widespread deployment. However, fundamental research questions still need to be addressed in order to achieve full vehicle autonomy. For instance, how can we: Remove the traditional barriers among perception, prediction, and planning in order to improve overall system performance? Equip autonomous vehicles with online and offline assurances that meet the standards for safety-critical systems? Ensure that autonomous vehicles work seamlessly in new places?
	- These are some of the exciting questions that the newly-established NVIDIA Autonomous Vehicle Research Lab will be tackling. The lab will bring together a diverse, interdisciplinary research team working on core topics in vehicle autonomy, ranging from perception and prediction to planning and control, as well as critical related areas such as decision making under uncertainty, deep learning, reinforcement learning, and the verification and validation of safety-critical AI systems. The lab will focus on basic research; lab members will be encouraged to publish their work and open-source code. NVIDIA is well known for its team culture, and lab researchers will be able to closely interact with others within the company who are experts in perception systems, machine learning, and robotics. There is an opportunity to make a strong impact on products, while having the freedom and bandwidth to conduct ground-breaking publishable research.
	- Designing and implementing cutting-edge techniques in the field of vehicle autonomy, having an opportunity to define your own research.
	- Publishing your original research and speaking at conferences and events.
	- Collaborating with other research team members, a diverse set of internal product teams, and external researchers.
	- Transferring technology you've developed to relevant product groups.
	- PhD or equivalent experience in Robotics, Computer Science, Computer Engineering or related field.
	- 4+ years of relevant research experience in the field of vehicle / robot autonomy.
	- Strong knowledge of theory and practice of vehicle / robot autonomy, or a related area with a strong interest in connecting your work to autonomous vehicles.
	- A track record of research excellence with your work published in top conferences and journals such as RSS, ICRA, IJRR, NeurIPS, ICML, CVPR, TAC, etc., and other research artifacts such as software projects.
	- Exceptional programming skills in Python; C++ and parallel programming (e.g., CUDA) are a plus.
	- Knowledge of common machine learning frameworks such as PyTorch and Tensorflow.
	- Strong communication and interpersonal skills are required along with the ability to work in a dynamic, research-focused team. Experience with mentoring junior engineers and interns is a huge plus.
+ skill set:
	- We are now recruiting top Research Scientists in Autonomous Vehicle Research.
	- AI-powered autonomous vehicles that can learn, reason, and interact with people are no longer science fiction. Self-driving cars, autonomous delivery vehicles, and autonomous construction vehicles, among others, are getting increasingly close to widespread deployment. However, fundamental research questions still need to be addressed in order to achieve full vehicle autonomy. For instance, how can we: Remove the traditional barriers among perception, prediction, and planning in order to improve overall system performance? Equip autonomous vehicles with online and offline assurances that meet the standards for safety-critical systems? Ensure that autonomous vehicles work seamlessly in new places?
	- These are some of the exciting questions that the newly-established NVIDIA Autonomous Vehicle Research Lab will be tackling. The lab will bring together a diverse, interdisciplinary research team working on core topics in vehicle autonomy, ranging from perception and prediction to planning and control, as well as critical related areas such as decision making under uncertainty, deep learning, reinforcement learning, and the verification and validation of safety-critical AI systems. The lab will focus on basic research; lab members will be encouraged to publish their work and open-source code. NVIDIA is well known for its team culture, and lab researchers will be able to closely interact with others within the company who are experts in perception systems, machine learning, and robotics. There is an opportunity to make a strong impact on products, while having the freedom and bandwidth to conduct ground-breaking publishable research.
	- Designing and implementing cutting-edge techniques in the field of vehicle autonomy, having an opportunity to define your own research.
	- Publishing your original research and speaking at conferences and events.
	- Collaborating with other research team members, a diverse set of internal product teams, and external researchers.
	- Transferring technology you've developed to relevant product groups.
	- Pursuing PhD or equivalent experience in Robotics, Computer Science, Computer Engineering or related field.
	- 4+ years of relevant research experience in the field of vehicle / robot autonomy.
	- Strong knowledge of theory and practice of vehicle / robot autonomy, or a related area with a strong interest in connecting your work to autonomous vehicles.
	- A track record of research excellence with your work published in top conferences and journals such as ***RSS, ICRA, IJRR, NeurIPS, ICML, CVPR, TAC***, etc., and other research artifacts such as software projects.
	- Exceptional programming skills in Python; C++ and parallel programming (e.g., CUDA) are a plus.
	- Knowledge of common machine learning frameworks such as PyTorch and Tensorflow.
	- Strong communication and interpersonal skills are required along with the ability to work in a dynamic, research-focused team. Experience with mentoring junior engineers and interns is a huge plus.
+ skill set:
	- We are now hiring interns for our DriveIX team, with a preferred start in August or September. Join our DriveIX team and help build the real-time, cost-effective computing platform driving our success in this exciting and quickly growing field. Intelligent machines powered by AI computers that can learn, reason and interact with people are no longer science fiction. Today, a self-driving car powered by AI can meander through a country road at night and find its way. An AI-powered robot can learn motor skills through trial and error. This is truly an extraordinary time. The era of AI has begun.
	- As a Software Intern on our Copilot team, you will be working on research, design and implementation of software features in the DriveIX and intelligent assistant. You will use machine learning, deep learning and computer vision techniques combined with rules-based domain specification to provide monitoring, communication/interaction and external perception capabilities using multiple different type of sensors and inputs on embedded platforms.
	- Pursuing BS/MS degree in Computer Science/EE or related
	- You have strong fundamentals in embedded systems, programming and SW design
	- Strong knowledge of ML/DL techniques, algorithms and tools with exposure to memory networks, CNN, RNN and LSTM and/or Computer Vision
	- Have shown ability to harness existing data, acquiring and labeling of new data and managing related work flows.
	- Excellent fluency with C/C++ and Python
	- You strongly believe that prototyping is the right way to prove the idea
	- Image, sentiment and object classification experience is highly desired
	- Experience with one of the following: dialog systems and conversational platforms, computer vision, signal processing
	- A familiarity with GPU computing (CUDA, OpenCL, OpenACC)
	- Background with Dockers and Kubernetes
	- Familiarity with TensorRT
	- Worked with variety of vision, depth and audio sensors
	- Worked on programming automotive CAN bus
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.




####	Car Companies


Car companies that manufacture electric cars:
+ Tesla
+ Toyota
+ Stellantis
+ Volkswagen, VW
+ Ford
+ BMW
+ GM
+ Honda
+ Nissan
+ Kia
+ Hyundai
+ Subaru


Other car companies:
+ Mercedes
+ Mazda









###	Sets of Skills For Delivery Robots


Delivery robots, such as sidewalk robots and delivery drones, are used for:
+ food delivery
+ grocery delivery
+ hospital delivery
+ package delivery
+ room service robots



Sets of skills for delivery robots:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






















##	Sets of Skills in Medical Robotics


Medical robotics includes:
+ surgical robotics
+ rehabilitation robotics
	- part of assistive technology, AT, or adaptive technology
	- part of occupational therapy, OT
+ biorobotics
+ telepresence robotics
+ pharmacy automation
+ companion robotics
+ disinfection robotics
+ disabled robotics
	- disability robots
		* part of assistive technology, AT, or adaptive technology
			+ ["Adaptive technology and assistive technology are different. Assistive technology is something that is used to help disabled people, while adaptive technology covers items that are specifically designed for disabled people and would seldom be used by a non-disabled person. In other words, assistive technology is any object or system that helps people with disabilities, while adaptive technology is specifically designed for disabled people. Consequently, adaptive technology is a subset of assistive technology. Adaptive technology often refers specifically to electronic and information technology access."](https://en.wikipedia.org/wiki/Assistive_technology)
			+ to address mobility impairments
			+ to address visual impairments
			+ to address hearing impairments
			+ personal emergency response systems
			+ accessibility software
			+ to support augmentative and alternative communication
			+ to support cognitive impairments
			+ to support eating impairments
			+ computer accessibility
			+ supported by home automation
				- ***assistive domotics***, or ***home automation for the elderly and disabled***
+ other facets of health care robotics




Sets of skills in ***medical robotics***, includes ***surgical robotics***:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.


















##	Sets of Skills in Industrial Robotics


Sets of skills in industrial robotics:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.


















###	Sets of Skills in Construction Robotics


Construction robots are a subset of industrial robots used in the construction industry.


Sets of skills in construction robotics:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.



















##	Sets of Skills in Kitchen Automation, Automated Restaurants, Robotic Restaurants


Sets of skills in kitchen automation, automated restaurants, robotic restaurants:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






##	Sets of Skills in Service Robotics

Service robotics include:
+ domestic robotics
+ scientific robotics
	- autonomous scientific robots
+ event robotics
	- engage with clients and event attendees





Sets of skills in service robotics:
+ Working on the robot's navigational systems for mapping, localization, path planning, obstacle detection and avoidance. Our robots are designed to work safely and reliably alongside shoppers and employees during normal store hours.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.













###	Sets of Skills in Domestic Robotics, Home Automation, Domotics, Smart Homes



Domestic Robotics
+ educational robotics, see following subsubsubsection.
+ entertainment robots
+ home automation, domotics, smart homes




Sets of skills in domestic robotics, home automation, domotics, or smart homes:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






####	Sets of Skills in Educational Robotics


Sets of skills in educational robotics:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.















##	Sets of Skills in Nanorobotics


Sets of skills in nanorobotics:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.











##	Sets of Skills in Collaborative Robotics


Sets of skills in collaborative robotics, cobots, which have direct human robot interaction (HRI) within shared spaces and human-robot collaboration, and social robots:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.























###	Sets of Skills in Swarm Robotics



Swarm robotics is based on [artificial swarm intelligence](https://en.wikipedia.org/wiki/Swarm_intelligence).




Sets of skills in swarm robotics:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






















##	Sets of Skills in Animatronics


Animatronics refers to mechatronic puppets, and are used in films, TV shows, and theme parks.




+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
























##	Sets of Skills in Machine Vision



["Machine vision (MV) is the technology and methods used to provide imaging-based automatic inspection and analysis for such applications as automatic inspection, process control, and robot guidance, usually in industry. Machine vision refers to many technologies, software and hardware products, integrated systems, actions, methods and expertise. Machine vision as a systems engineering discipline can be considered distinct from computer vision, a form of computer science. It attempts to integrate existing technologies in new ways and apply them to solve real world problems. The term is the prevalent one for these functions in industrial automation environments but is also used for these functions in other environment vehicle guidance."](https://en.wikipedia.org/wiki/Machine_vision)
+ Machine vision is distinct from computer vision, but can be overlapping/intersecting.




Sets of skills in Machine Vision:
+ skill set:
	- Expertise in image and video processing, computational photography, single and multiview geometry, keypoint extraction, description, association, etc.
	- Experience in efficient large-scale numerical optimization
	- Experience in the area of camera calibration, SLAM, point cloud processing are highly desired
	- Publication records in leading conferences such as CVPR, ICCV, ECCV, NIPS, ICML or PAMI is a plus
+ Experience in Computer Vision / Computational Geometry / Structure from Motion / SLAM
+ skill set:
	- A fascination with the PoseNet research, for pose estimation, since its release in 2015.
	- Fundamental understanding of Bundle Adjustment or Non-Linear Optimization.
	- PhD or exceptional MSc involving 3D-Reconstruction, SLAM, Camera Calibration or Computational Geometry from a top ranking university or lab.
	- Geometry from Vision is at the heart of Scape Technologies. As a research engineer on the Scape Technologies team, you will take a key role in designing and building the pipeline for cloud-based 3D-reconstruction and real-time global localization. This will require implementing and building upon existing research in Structure-from-Motion, Dense 3D-reconstruction, Camera Calibration and SLAM.
	- This can range from non-linear optimization to efficient graph traversal, considering optimized computational parallelization.
	- Making sure that Scape's large scale reconstruction and localization pipeline is the most efficient in the world.
	- We are looking for curious and enthusiastic computer vision scientists who are keen on working on moonshot projects.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






















