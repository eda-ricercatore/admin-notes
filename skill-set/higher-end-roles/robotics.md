#	Robotics


##	Notes About Robotics


Robot classifications include:
+ autonomously guided robots, robots with sliding autonomy, remote-operated robots (telerobotics)
+ behavior-based robotics, BBR, or behavioral robotics
+ mobile robots, and stationary robots





Types of mobile robots, or 
+ uncrewed vehicles, or unmanned vehicles
	- remote controlled vehicles, remote-control vehicles, or remote guided vehicles
	- autonomous vehicles, ***autonomous robots***, automated guided vehicles, automatic guided vehicles, AGV, autonomous mobile robots, AMR
		* helicams, remote-controlled mini helicopters
		* unmanned aerial vehicles, UAV, unmanned aircraft systems, UAS
			+ remotely-piloted aircrafts, RPA
			+ unmanned-aircraft vehicle systems, UAVS, remotely piloted aerial vehicle, RPAV, remotely piloted aircraft system, RPAS
		* unmanned underwater vehicles, UUV, underwater drones
			+ autonomous underwater vehicles, AUVs
				- underwater gliders
			+ remotely operated underwater vehicles, ROUVs, ROVs
			+ Unmanned Surface Vehicles, USVs, Unmanned Surface Vessels, USVs), Autonomous Surface Vehicles, ASVs, Uncrewed Surface Vessels, USVs, or colloquially drone ships
	- i.e., not all unmanned ground vehicles (UGVs) are autonomous.
		- UGVs can be remotely controlled by people.





This document does not include agriculture robotics, which information is provided in the agricultural technologies document.



Interesting topics in robotics:
+ cloud robotics
	- applications:
		* assistive robots
		* autonomous mobile robots
		* cloud medical robots
		* industrial robots
+ cognitive robotics
+ evolutionary robotics
+ fog robotics
	- as an architecture which consists of storage, networking functions, control with fog computing closer to robots
+ remote control animals, bio-robots, or robo-animals
+ robot ethics, roboethics
+ robot navigation
	- robot localization
		* self-localisation
		* path planning
		* map-building and map interpretation
		* simultaneous localization and mapping, SLAM
			+ acoustic SLAM
			+ audio-visual SLAM
			+ bio-inspired SLAM
			+ collaborative SLAM
			+ extended Kalman filter (EKF) for SLAM, EKF SLAM
			+ GraphSLAM
	- vision-based navigation
		* acoustic navigation
		* inertial navigation
		* indoor navigation
		* radio navigation
+ self-reconfiguring modular robots, self-reconfigurable modular robots, modular self-reconfiguring robotic systems
	- architectures
		* chain architecture
		* hybrid architecture
		* lattice architecture
	- types of reconfiguration
		* deterministic reconfiguration
		* stochastic reconfiguration
	- designs of modules
		* heterogeneous modular robot systems
		* homogeneous modular robot systems
	- mechanism reconfigurability
		* inter-reconfigurability
		* intra-reconfigurability
		* nested-reconfigurability
+ soft robotics





reactive programming = asynchronous dataflow programming
+ functional reactive programming, FRP, is based on the building blocks of functional programming
	- map
	- reduce
	- filter
	- applications of FRP, by simplifying problems via the explicit modeling of time, include:
		* graphical user interfaces, GUI, development
		* robotics
		* games
		* music






##	Companies that Engineer Robots



+ Agility Robotics
+ Boston Dynamics
+ Hanson Robotics
+ Tesla
+ Xiaomi











##	Generic Sets of Skills in Robotics


Generic sets of skills in robotics:
+ ***OpenCV Ceres, ROS, PyTorch***
+ skill set:
	- Android
	- Zephyr
	- Linux
	- Renode
	- RISC-V
	- TensorFlow
	- Caffe
	- OpenCV
	- Singularity
	- KiCad
	- Docker
	- ROS
+ skill set:
	- Technical capability to create robust and well-tested C++ software
	- Familiarity with modern model predictive control and other advanced control techniques
	- Experience with adaptive control, system identification, and machine learning methods
	- Minimum of a Masters Degree in Robotics, Computer Science, Mathematics, Physics or equivalent with 3+ years experience
	- Knowledge of robotics systems (ROS, PCL) is preferred
+ skill set:
	- We are looking for a Research Scientist, Robotics - New College Graduate:
	- NVIDIA’s invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined modern computer graphics, and revolutionized parallel computing. More recently, GPU deep learning ignited modern AI — the next era of computing. With the GPU acting as the primary computing device, robots can now perceive and understand the world around them. Today, NVIDIA has transformed into “the AI computing company.” We're looking to grow our company, and build our teams with the smartest people in the world working on diverse aspects of AI. Join us at the frontier of technological advancement!
	- Robotics is an increasingly exciting field, influenced heavily by recent advances in hardware acceleration through devices such as the modern GPU. These advances have enabled tremendous progress in several areas of robotics, including manipulation, visual recognition, real-time tracking, and learning-based control. Robots are getting increasingly proficient at building 3D maps of their environments, detecting and tracking objects and people as they move through the world, learning controllers from realistic simulation, and understanding commands provided via gestures and natural language.
	- While our ultimate goal is to reach human-level dexterity, perception, and adaptability, we still have a long way to go. To enable the next generation of robots that can robustly operate in the physical world and interact with people in a natural way, progress is still needed in multiple domains: perception, planning, learning, and control. Moreover, even more importantly, the integration of these individual contributions into complete robot systems opens new challenges.
	- Toward this goal, the NVIDIA Robotics Research Lab brings together a diverse, interdisciplinary research team working on core robotics topics ranging from control, perception, machine learning, common sense reasoning, task planning, human-robot collaboration, and critical related areas such as deep learning for computer vision, natural language processing and decision making.
	- The lab focuses on fundamental research questions in robotics and lab members are encouraged to publish their research and open source their code. The lab hosts numerous internships every year to foster education and communication, and the team is encouraged to collaborate broadly with institutions outside of NVIDIA, both academic and industrial. NVIDIA is well known for its team culture, and lab researchers are able to closely interact with others within the company who are experts in broad subtopics such as computer vision, computer graphics, GPU computing, AI and Deep Learning, self-driving cars, and physics-based simulation.
	- Robot manipulation, robot control, reinforcement learning, computer vision, human-robot interaction, deep learning, physics-based simulation, neuro symbolic reasoning, and natural language processing.
	- Pursuing PhD in Robotics, Computer Science, Engineering or related field.
	- 3+ years of relevant research or work experience
	- Knowledge of theory and practice of robotics, or a related area with a strong interest in connecting your work to robotics scenarios.
	- A track record of research excellence with your work published in top conferences and journals such as Robotics (RSS, ICRA, IROS, CoRL, T-RO, IJRR), Machine Learning (NeurIPS, ICML, ICLR, AAAI, JMLR), Computer Vision (CVPR, ICCV, ECCV, TPAMI) and Language (ACL, EMNLP, NAACL).
	- Exceptional programming skills in Python, and deep learning frameworks such as Tensorflow and Pytorch. Fluency in C/C++; CUDA and robotics frameworks such as ROS is a plus.
	- Strong communication and interpersonal skills are required along with the ability to work in a dynamic, research focused team. A demonstrated history of mentoring junior engineers and interns is a huge plus.
	- Are you dedicated, upbeat and dynamic with excellent analytical ability? Are you a researcher or an engineer passionate and highly motivated about solving complex problems? If so, you may be a perfect fit for NVIDIA!
+ skill set:
	- At Toyota Research Institute (TRI), we’re working to build a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We’re dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life. Through innovations in AI, we’ll help...
		* Develop vehicles incapable of causing a crash, regardless of the actions of the driver.
		* Develop technology for vehicles and robots to help people enjoy new levels of independence, access, and mobility.
		* Bring advanced mobility technology to market faster.
		* Discover new materials that will make batteries and hydrogen fuel cells smaller, lighter, less expensive and more powerful.
		* Develop human-centered AI systems to augment (not replace) human decision making to increase the quality of decisions (e.g. mitigate cognitive biases) and/or to facilitate faster innovation cycles.
	- Our work is guided by a dedication to safety – in both what we research and how we perform our research our goal is to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies. Over half of our technical team carries PhD degrees. We’re continually searching for the world’s best talent ‒ people who are ready to define the new world of mobility with us!
	- We strive to build a company that helps our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve our goals. Come work with TRI if you’re interested in transforming mobility through designing technology for safer cars, enabling the elderly to age in place, or designing alternative fuel sources. Start your impossible with us.
	- TRI is assembling a world-class team to develop and integrate innovative solutions that enable a robot to perform complex, human-level mobile manipulation tasks, navigate with and among people, and learn and adapt over time.  The team will develop, deploy, and validate systems in real-world environments, in and around homes.
	- The team will be focused on heavily leveraging machine learning to marry perception, prediction, and action to produce robust, reactive, coordinated robot behaviors, bootstrapping from simulation, leveraging large amounts of data, and adapting in real world scenarios.
	- TRI has the runway, roadmap, and expertise to transition the technology development to a product that impacts the lives of millions of people.  Apply to join a fast moving team that demands high-risk innovation and learning from failures, using rigorous processes to identify key technologies, develop a robust, high quality system, and quantitatively evaluate performance.  As part of the team, you will be surrounded and supported by the significant core ML, cloud, software, and hardware expertise at TRI, and be a part of TRI's positive and diverse culture.
	- Responsibilities
		* Develop, integrate, and deploy algorithms linking perception to autonomous robot actions, including manipulation, navigation, and human-robot interaction
		* Invent and deploy innovative solutions at the intersection of machine learning, computer vision, multi-sensor perception, and simulation for understanding human environments and humans, in and around homes
		* Invent novel ways to create, label, and use large, possibly distributed datasets, using self-supervision, active learning, simulation, and real-world adaptation
		* Be part of a team that fields systems, performs failure analysis, and iterates on improving performance and capabilities
		* Follow software practices that produce maintainable code, including automated testing, continuous integration, code style conformity, and code review
	- Qualifications
		* M.S. or Ph.D. in an engineering related field
		* A strong track record in inventing and deploying innovative perception algorithms to robotic systems in real-world environments
		* Expertise and experience in areas such as object detection, classification, segmentation, and tracking, sensor fusion, state estimation, local 3d mapping and reconstruction, person detection, and human pose estimation
		* Expertise and experience in applying deep learning to perception problems
		* Strong software engineering skills, preferably in C++, and analysis and debugging of robotic perception algorithms
		* A team player with strong communication skills, and a willingness to learn from others and contribute back to the robotics community with publications or open source code
		* Passionate about seeing robotics have a real-world, large-scale impact
+ skill set:
	- Experience with Robotics perception
	- At Starsky, the Perception team is responsible for processing sensor information and making it available to the other teams in a clean and consistent format. The models and algorithms developed aim to achieve robust real time detection and tracking of our truck and other objects in the local environment, including lane lines, vehicles, and pedestrians.
	- As a Robotics Perception Engineer, you will be responsible for filtering, fusing and post-processing the outputs of different deep learning models and sensors. You will apply state of the art tracking and fusion algorithms which are robust to sensor noise and environmental variability. This requires working with teams across the driving stack to scope requirements and understand the strengths and limitations of different modules.
	- Background in linear algebra, probability, 3D geometry
	- Experience with multi-camera sensor fusion and camera-radar sensor fusion
	- Experience with real time tracking of objects and lanes
	- Experience with real time mapping and localization
	- Experience with camera and radar sensor calibration
	- Ability to write efficient real time algorithms in C++
	- Experience in developing on linux environment
	- 2+ years experience in C++/Python development in a fast paced production environment
	- 2+ years experience in perception system of mobile robots
	- Experience with ROS
	- Experience in sensor noise analysis
	- Experience in machine learning/deep learning
+ Background in linear algebra, probability, 3D geometry and abstract problem solving skills
+ skill set:
	- Experience developing, troubleshooting, tuning and managing hardware systems including:
		* LIDARs
		* Standard or Depth Cameras
		* Light systems
		* IMUs, encoders or other odometry methods
	- Experience designing/developing one or more of the following software systems/algorithms:
		* Mapping, Localization, and/or SLAM
		* Robot perception, Sensor calibration and/or fusion
		* Motion planning and/or Autonomous navigation
		* Production level configuration, log and system management
		* Remote monitoring and control
		* Performance verification and monitoring
		* Test automation of combined software and hardware components
		* Automated release pipelines
+ skill set:
	- Develop and maintain scalable codebase used to calibrate sensors and actuators used on a robot system including:
		* Camera: Intrinsic, Extrinsic, White-balance calibration of both standard and fisheye cameras
		* Time-of-Flight cameras
		* Lidar
		* IMU
		* Odometry
	- Improvement of existing calibration processes and procedures
	- Develop calibration methods for new sensors added to robot
	- Hands-on deployment of calibration fixtures at contract manufacturing line
	- Hands-on calibration of robot system to validate new calibration processes
	- Assist mechanical, electrical and other teams to design fixtures needed for calibration
	- Work with manufacturing and field engineers to debug field issues related to calibration
	- Work with hardware and software teams to provide well calibrated robot system
	- Good C++, C and python coding skills
	- 2 years of industrial experience
	- Previous experience with extrinsic calibration of at least two of the following sensors: RGB Camera, ToF Camera, Lidar, Odometry, IMU
	- Understanding of standard camera calibration methods
	- System level understanding of how calibration affects robot performance
+ We preferred students experienced in the use of ROS (Robot Operating System) and simulation engines such as Unity3D and Unreal Engine 4.
+ skill set:
	- ROS
	- Gazebo, open-source 3-D robotics simulator
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.

















##	Sets of Skills For Unmanned Ground Vehicles, UGVs


Notes:
+ Not all unmanned ground vehicles (UGVs) are autonomous.
	- UGVs can be remotely controlled by people.





Sets of skills for unmanned ground vehicles (UGVs):
+ skill set:
	- This role is focused on delivering the best in localization performance from our sensors.
		* By localization, it refers to:
			+ [(generic) navigation](https://en.wikipedia.org/wiki/Navigation)
			+ [Robot navigation](https://en.wikipedia.org/wiki/Robot_navigation)
				- By extension, it involves:
					* self-localisation
					* [path planning](https://en.wikipedia.org/wiki/Motion_planning)
					* map-building and map interpretation
	- Candidates should have extensive experience working with raw navigation data. You should be very comfortable with estimation theory and have implemented complex filters in practice. Real world experience with RTK, Integer Ambiguity Estimation and other high precision techniques are a huge plus.
		* RTK could refer to [real-time kinematic positioning](https://en.wikipedia.org/wiki/Real-time_kinematic_positioning)
		* [integer aperture estimation = integer ambiguity resolution](https://sciencetrends.com/integer-aperture-estimation-presence-biases/)
	- [Inertial Measurement Unit](https://en.wikipedia.org/wiki/Inertial_measurement_unit) Algorithms, [Extended Kalman Filter (EKF)](https://en.wikipedia.org/wiki/Extended_Kalman_filter), [Visual Odometry](https://en.wikipedia.org/wiki/Visual_odometry), Gnss, RTK-GPS
		* [global navigation satellite system (GNSS)](https://en.wikipedia.org/wiki/Satellite_navigation)
			- Or, satellite navigation, or satnav system.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.





###	Sets of Skills For Autonomous Road Vehicles



Sets of skills for autonomous road vehicles:
+ Familiarity with modern planning approaches including randomized search methods and trajectory optimization
+ Solid work experiences with state-of-the-art mapping and localization algorithms
+ skill set:
	- 4+ years of embedded software applications development, debug, deployment (including drivers development)
	- Superior knowledge of RTOS-based software systems and/or Embedded Linux
	- Comfortable with parallel paradigms (notions of pthread and/or OpenCL/Cuda)
	- Agile methodology ; Git, continuous integration, test driven development
	- Experience of AUTOSAR architecture is valuable
	- Knowledge of Computer Vision libs (OpenCV, OpenVX) and Machine learning technology (TensorFlow, Caffe) would be a plus
	- Knowledge of application middleware (e.g. ROS)and communication layers (TCP/UDP, DDS) would be a plus
+ skill set:
	- SLAM SOFTWARE ENGINEER (SENSOR FUSION)
	- Research and develop algorithms for sensor fusion and object association across multi-sensor modalities such as one or more cameras, IMU, radars, and lidar sensors.
	- SLAM prototyping and vehicle testing
	- Implement and integrate robotics algorithms into software using C++ and Python
	- Sensor fusion and software development using IMU, Radar, camera, and Lidar
	- Participate in brainstorming activities related to SLAM application project(s)
	- Support software development
	- Work with large field-testing data to continuously iterate/improve algorithm
	- Proficient in C/C++, comfortable in Python is a MUST
	- PhD or Masters student in CS, CE, EE, ME, or similar disciplines
	- Hands on experience with Linux
	- Understanding of basic Path Planning & Perception algorithms
	- Understanding of Kalman filters and particle filters.
	- One year of experience in robotics software development
	- Ability to multitask effectively in a dynamic environment
	- Strong debugging, problem-solving and analytical skills
	- Excellent interpersonal, written and oral communications skills
	- Passion for learning new software tools and languages
	- Robot Operating System (ROS) experience
	- Expertise in computer vision and machine learning
	- Experience programming for interfacing between devices, such as analog signal processing and sensor reading via serial ports
	- Embedded software programing experience with mobile GPU, DSP
	- The ideal candidate will have a passion for generating new ideas, be a proactive and quick learner, and be able to demonstrate creativity and innovation.
+ skill set:
	- EMBEDDED SOFTWARE ENGINEER (VISION)
	- Design and optimize application software architectures and frameworks for real-world performance while matching or exceeding customer requirements.
	- Design and profile efficient mechanisms to improve utilization on computers with multiple heterogeneous hardware engines.
	- Working on areas such as component abstraction layers, inter-process data sharing and communication, and process scheduling.
	- Collaborate with hardware, platform, testing, performance and algorithmic teams
	- MS or higher in computer engineering, computer science or related engineering fields, with 2+ years of experience or equivalent experience
	- Excellent C and C++ programming skills
	- Strong scripting skill with Python
	- Experience designing, developing and debugging multithreaded/distributed applications like multimedia systems, game engines, etc.
	- Solid understanding on QNX, Linux, Android, and/or other real-time operating systems.
	- Thrive on designing low latency, highly performant code
	- Excellent communication and analytical skills.
	- Self-motivated and a great teammate
	- Understanding of embedded and high efficiency software architectures
	- Experience with large frameworks like used in ROS, android etc.
	- Experience on developing software in heterogeneous architectures, including GPUs and other types of accelerators.
	- Be hands-on and work well within a team of algorithm, software and hardware engineers, with a significant level of detail orientation and a penchant for data organization and presentation
	- Knowledge of automotive systems, notably ADAS or SLAM systems
	- Embedded software programing experience with mobile GPU, DSP
	- The ideal candidate will have a passion for generating new ideas, be a proactive and quick learner, and be able to demonstrate creativity and innovation.
+ robotics engineering:
	- Background in multiple of the following: SLAM, mapping, localization, calibration, sensor fusion, tracking, scene understanding, robotic systems.
	- Experience in multiple of the following: non-linear optimization, 3D geometry, state estimation.
	- Experience with advanced algorithms, data structures and working with real sensor data.
	- Experience with Python and developing in the Linux and/or Mac OS environment.
	- Familiarity with real-time, multi-process and multi-threaded coding.
	- Strong C++ development skills.
	- Be an essential part of a team of engineers and scientists developing state-of-the-art estimation algorithms used for a variety of tasks, including calibration, localization and tracking.
+ skill set:
	- Familiar with the basics of lidars, radars, cameras, and ultrasonic systems.
	- Are familiar with Physics-based modeling and simulation of sensor systems (eg, link budget analysis, wave propagation, sensor noise sources, etc.).
	- At least 1 year of experience in radar, lidar, or camera modeling and/or evaluation.
	- Familiarity with test and calibration processes for autonomous vehicle sensors.
	- Familiarity with EVT, DVT, and PVT processes for sensor bring-up and validation as well as FMEA principles.
		* EP, Proto (early prototype) -> minimum viable product, MVP
		* EVT, Engineering Validation Test - validate functional scope
		* DVT, Design Validation Test - stabilize functional scope
		* PVT, Production Validation Testing - adapt the production
		* EVT -> DVT -> PVT -> mass production of MVP
+ Familiarity with modern planning approaches including randomized search methods and trajectory optimization
+ skill set:
	- As a Research Engineer in computer vision/deep learning, you will be developing the “eye” of our vehicles. This includes designing, training, and evaluating perception solutions, specifically, large scale image/LIDAR data classification, segmentation, tracking, etc. You will also research and apply state-of-the-art computer vision algorithms into production.
	- Ph.D in Computer Science or a related field
	- Strong programming skills in C/C++
	- Strong mathematics and analytical skills
	- Work experience in deep learning platforms such as Caffe or Tensorflow
	- Domain knowledge and implementation experience with Lidar/Visual SLAM/Odometry.
+ Installation, setup and calibration of MOCAP system, binocular cameras
+ skill set:
	- Extensive knowledge in Communication Protocols (USB, CAT5/6, CAN, UART, I2C, SPI)
	- Minimum 2 years of experience with python, C++, able to debug various applications, e.g: proprietary software and third-party software
	- Enrolled in EPN program (if not enrolled must be willing to enroll)
		* The Employer Pull Notice (EPN) program enables commercial and government organizations to monitor the driving records of employees who drive for them.
		* The Employer Pull Notice (EPN) program enables commercial and government organizations to monitor the driving records of employees who drive for them. By monitoring their employees' driving records, organizations can: Ensure that each driver has a valid driver's license. Recognize problem drivers or driving behavior.
	- Minimum 2 years of experience working with one or more of the following sensors: cameras, radars, lidars, IMU/GNSS
+ skill set:
	- Work with experts in the field of self driving vehicles on software architecture and design, system and module design, evaluation metrics, specification and implementation of test and regression frameworks.
	- Work with experts in machine learning to design and implement the state of the art deep learning and machine learning algorithms to solve open questions such as behavior prediction, decision making, and computer vision with real road test data.
	- Optimize software to run robustly under tight run-time constraints.
	- Implement user friendly tools to mine useful data from road test logs, evaluate performance, and solve real road test issues.
	- Master in Computer Science, or at least 2 years of equivalent industry experience in similar technical fields.
	- Solid understanding of data structures, algorithms, parallel computing, code optimization and large scale data processing.
	- Experience in applied machine learning including data collection and analysis, evaluation and feature engineering.
	- Expertise in C++/Python.
	- PhD in Deep Learning, Machine Learning, Robotics, Natural Language Processing, or similar technical field of study.
	- ***Experience in applying ML/DL for behavior prediction, imitation learning, motion planning.***
	- Experience in deploying deep learning algorithms for real time applications, with limited computing resources.
	- Experience in convex optimization, computational geometry or linear algebra.
	- Experience in GPU/CUDA/TensorRT
	- Experience with TensorFlow
+ Domain knowledge in LiDAR/visual SLAM/odometry
+ skill set:
	- As a Senior Software Engineer in Compute Performance, you will be developing technologies to accelerate leading applications in autonomous driving fields within computer vision, ML/DL, mapping and localization, planning and prediction.
		* Identifying key applications for current and future autonomous driving problems and performing in-depth analysis and optimization to ensure the best possible performance on current and next-generation compute architectures.
		* Collaborating closely with diverse groups in Pony.ai including both hardware and software to optimize and craft core parallel algorithms as well as to influence the next-generation compute platform architecture design and software infrastructure.
	- BS/MS or Ph.D in computer science, electrical engineering or a related discipline.
	- Strong programming skills in C/C++.
	- Good knowledge of the fundamentals of computer architecture, including data caching, memory system, SIMD instruction sets, and compiler code generation.
	- Good understanding of hardware performance, regarding CPU or GPU execution model, threads, registers, cache, cost/performance trade-off, etc.
	- Experience with profiling, benchmarking and validating performance for complex computing architectures.
	- Experience in optimizing the utilization of compute resources, identifying and resolving compute and data flow bottlenecks.
	- Strong communication skills and ability to work cross-functionally between software and hardware teams
	- Experience with parallel programming, ideally CUDA, OpenCL or OpenACC.
	- Experience in computer vision, machine learning and deep learning.
	- Strong knowledge of software design, programming techniques and algorithms.
	- Strong mathematical fundamentals, including linear algebra and numerical methods.
	- Good knowledge of common deep learning frameworks and libraries.
+ skill set:
	- Knowledge of robotics system (ROS, PCL) is preferred
	- Familiar with a certain deep learning framework, such as TensorFlow, MXNet, Caffe, Torch, etc., and have a deep understanding of deep learning.
	- Experience in algorithm development of autonomous driving systems, such as lane line recognition, obstacle recognition and tracking, etc.;
	- Familiar with computer vision related algorithms such as image segmentation, target detection and tracking;
	- Experience in large data set processing and familiarity with real time systems
+ skill set:
	- Responsible for research on perception algorithms of autonomous driving systems, including but not limited to: image target detection and segmentation, recognition, and tracking algorithm development; visual positioning, pose estimation, depth estimation, and 3D reconstruction algorithm research and development;
	-  Familiar with commonly used computer vision and machine learning algorithms, with excellent mathematical ability; master the basic algorithms of image processing, familiar with camera models, multi-view geometry, optimization and other theories
	- Have experience in the development of autonomous driving systems, including but not limited to lane line recognition/obstacle recognition and tracking/multi-view stereo/visual positioning/three-dimensional reconstruction, etc.;
+ skill set:
	- Develop automotive standard software for vehicle-level autonomous controls.
	- Improve and deliver reliable software through requirements generation, continuous integration, automated testing, issue tracking, and code reviews
	- Develop and test communication interfaces to vehicle systems, sensors, and other hardware components.
	- Design fail-operational strategies and architecture for redundant systems.
	- Develop fault diagnostics and prognosis for safety critical hardware components.
	- Work with component suppliers to calibrate and test sensors and actuators.
	- Support simulation, bench and in-vehicle testing
	- Support technical discussion with OEM and component suppliers and partners.
	- Advanced Degree in Computer Science, Electrical Engineering, Mechanical Engineering, Mechatronics, or related disciplines.
	- Experience with automotive standard (e.g. AUTOSAR, MISRA) software C/C++ development in the Linux environment.
	- Experience with automotive control system development, instrumentation, and calibration tools.
	- Understanding of the design and application of vehicle systems (e.g. steering, braking, and powertrain)
	- Knowledge of system identification, dynamics, and controls
	- Experience with automotive embedded and real-time control systems including OS and architecture
	- Experience with automotive communication protocols (CAN, CAN FD, and Automotive Ethernet) and electrical architectures.
	- Knowledge of autonomous driving software stack or advanced driver assistance features
	- Experience with systems engineering processes and formal requirements management systems.
+ skill set:
	- NVIDIA is seeking deep learning research / engineering interns to join the AV perception research team. The team consists of a group of dynamic AI applied researchers and engineers and is committed to build industry-grade deep learning to take autonomous vehicle (AV) perception into production, we work on fundamental advances in scientific methods to enabling scaling-up the entire perception for the autonomous driving stack. We are looking for highly motivated individuals to work in the areas of deep learning, optimization and computer vision. Our interns have the unique opportunity to make algorithmic contributions to core products and apply their ideas at a very large scale. As an intern, you will conduct applied research related to one of the meaningful research topics mainly related to perception for autonomous driving. You may also have the opportunity to publish in premier conferences in the fields of Machine Learning and perception.
	- In order to scale-up current AI-algorithms, we need to learn from datasets orders of magnitude larger than existing ones which is a very challenging task. Our team at NVIDIA is dedicated to developing new algorithms to explore the vast amount of collected data to improve AI-based applications such as AV.
	- Efficient data selection to improve learning and scaling-up training sets including active learning and mining strategies.
	- Network interpretability to predict network failures and to design novel algorithms to continuously learn from data and from failures.
	- Efficient training and inference to minimize training time and enable inference in embedded platforms.
	- Synthetic to real domain adaptation.
	- To learn more about our high-level goals visit: https://atscaleconference.com/videos/scale-2018-keynote-inside-nvidias-ai-infrastructure-for-self-driving-cars/
	- You will be responsible for conducting applied research to advance the performance of our codebase applied to perception for autonomous vehicles. Research is done in areas related to large scale learning including semi-supervised deep learning, active learning, deep network architecture search, parameter optimization and modeling, domain adaptation, or life-long learning. You may have opportunities to influence the progress of the field by producing publications.
	- Contribute to integrating novel algorithms into core applications to enable a better generation of autonomous vehicles, coding in Tensorflow to facilitate the integration into our codebase.
	- Collaborate and increase the performance of existing perception-based systems for AV.
	- Pursuing BS, MS, or Ph.D. in Computer Science, with a focus in Deep Learning, Artificial Intelligence or related fields.
	- Expertise in Computer Vision and Deep Learning.
	- Strong mathematical background and ability to analyze results.
	- Excellent Tensorflow and python programming skills to bring ideas into production systems.
	- A dedication to bring your work to completion and see your work having a worldwide impact.
	- A self-motivated and good teammate with good communication and social skills.
	- Publication or experience in fields related to machine learning, analytics, large-scale systems, statistics, and mathematics.
	- Currently enrolled in a Ph.D. program in CS or Math.
	- First author publications in top-tier peer-reviewed conferences such as NeurIPS, ECCV, ICML, CVPR, ICCV.
	- Research or software engineering experience confirmed via internships, relevant work experience or code competitions.
+ skill set:
	- At Toyota Research Institute (TRI), we’re working to build a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We’re dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life. Through innovations in AI, we’ll help...
		* Develop vehicles incapable of causing a crash, regardless of the actions of the driver.
		* Develop technology for vehicles and robots to help people enjoy new levels of independence, access, and mobility.
		* Bring advanced mobility technology to market faster.
		* Discover new materials that will make batteries and hydrogen fuel cells smaller, lighter, less expensive and more powerful.
		* Develop human-centered AI systems to augment (not replace) human decision making to increase the quality of decisions (e.g. mitigate cognitive biases) and/or to facilitate faster innovation cycles.
	- Our work is guided by a dedication to safety – in both what we research and how we perform our research our goal is to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies. Over half of our technical team carries PhD degrees. We’re continually searching for the world’s best talent ‒ people who are ready to define the new world of mobility with us!
	- We strive to build a company that helps our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve our goals. Come work with TRI if you’re interested in transforming mobility through designing technology for safer cars, enabling the elderly to age in place, or designing alternative fuel sources. Start your impossible with us.
	- TRI's Safety and Systems Engineering team is applying systems engineering principles to protect the safety of the public and our employees as we test advanced vehicle automation systems. Leveraging methodologies from high-reliability industries such as aerospace, medical robotics, and automotive functional safety, we ensure our systems are thoroughly tested and are equipped with robust onboard real-time monitoring systems. We're looking for phenomenal systems engineers who are passionate about improving the lives of millions through the safe development of autonomous systems. No prior robotics experience is necessary, although it doesn't hurt.
	- Responsibilities:
		* Develop requirements for autonomy features, fault monitoring and self-diagnostics, including analyses such as FMEA, FTA, and similar
		* Work with and between multiple technical teams to implement effective verification of system features, including nominal, fault injection, fail-safe, fail-operational, and edge-case scenarios
		* Work collaboratively with cross-functional teams to create clear system definitions and specifications to accelerate software development
		* Develop processes in collaboration with stakeholders from various technical teams to facilitate the development, testing, and improvement of autonomous systems
		* Drive research into innovative systems engineering solutions tailored for the development and deployment of safe autonomous systems
	- Required Qualifications:
		* Master’s degree or Ph.D. in a technical discipline such as Aerospace Engineering, Mechanical Engineering, Electrical Engineering, or Computer Science
		* 6+ years of experience working in Systems Engineering or Functional Safety roles
		* Practical working knowledge of systems engineering processes and in-depth familiarity with the activities mapped to various stages of the V model
		* Experience with development of behavioral and system level requirement and tracing them to the appropriate type and amount of V&V activities
		* Strong verbal and written communication skills and people skills
		* Strong understanding of common software performance issues and tradeoffs
		* Familiarity with software and the ability to read code (C/C++ and Linux)
	- Preferred Qualifications:
		* Familiarity with automated driving hardware such as sensors, compute, etc. and software such as AI, Machine Learning algorithms, etc.
		* Familiarity with requirements management software (Jama, Polarion, DOORs, or similar)
+ skill set:
	- At Toyota Research Institute (TRI), we’re working to build a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics and materials science. We’re dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life. Through innovations in AI, we’ll...
		* Develop vehicles incapable of causing a crash, regardless of the actions of the driver.
		* Develop technology for vehicles and robots to help people enjoy new levels of independence, access, and mobility.
		* Bring advanced mobility technology to market faster.
		* Discover new materials that will make drive batteries and hydrogen fuel cells smaller, lighter, less expensive and more powerful.
	- Our work is guided by a dedication to safety – in how we research, develop, and validate the performance of vehicle technology to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies. Over half of our technical team carries PhD degrees. We’re continually searching for the world’s best talent ‒ people who are ready to define the new world of mobility with us!
	- We strive to build a company that helps our people thrive, achieve work life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun start up environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve our goals. If you’re passionate about working with brilliant people to make cars safer, enable the elderly to age in place, or design alternative fuel sources, TRI is the place for you. ‒ Start your impossible with us.
	- TRI's Planning and Control team is building the decision-making, planning, and execution technology for the uncrashable Toyota. We are doing cutting edge research in the decision-making systems required for L5 autonomous driving, in addition to the exploration of highly dynamic control regimes and blended driver-machine control techniques to build the ultimate, fun, uncrashable car of the future. We are leveraging advances in AI, motion planning, and control theory to realize a scalable, verifiable system to solve the L5 driving problem in the long term, while making an immediate impact on society through our Guardian system in the short term.
	- Responsibilities:
		* Design and implement decision-making systems for L5 autonomous vehicles.
		* Develop cross-functional solutions between perception, prediction, and planning.
		* Develop verification and test strategies for the decision-making algorithms.
		* Analyze data from simulations, closed-course, and public road testing.
	- Qualifications:
		* 3+ years of experience in related positions.
		* PhD or Master's degree in Robotics, Computer Science or equivalent.
		* Proven track record of designing, implementing, and fielding robotic systems.
		* Strong C++ software development skills.
		* Familiarity with automated testing practices.
		* Strong communication skills and a team player.
	- Bonus Points:
		* Machine learning experience.
		* Experience with optimization and decision-making under uncertainty.
		* Proficiency in Python.
+ skill set:
	- Knowledge of robotics concepts and tools (ROS)
	- Understanding of and ability to implement machine learning methods, particularly for applications in autonomous vehicle decision making and prediction
	- Experience in production C++ development
+ skill set:
	- Familiarity with at least one of the following areas:
		* Deep learning for computer vision
		* Camera tracking (SLAM, VIO) and self-localization
		* Object detection and model-based tracking
		* 3D reconstruction and semantic scene understanding
+ tech stack:
	-  Solid knowledge in control theory, especially model predictive control
	- Experience in one or more of the following areas:
		* Robust control
		* Adaptive control
		* Nonlinear control
		* State estimation
		* Parameter estimation
		* Model identification
		* Optimization
	- Experience in one or more of the following areas:
		* Control theory
		* Motion planning
		* Optimization
		* Formal logic
		* Game AI development
	- Experience with sensors: cameras, lidars, ultrasonic, etc.
	- Computer vision experience, image processing experience
+ skill set:
	- As a core member of our engineering team, the State Estimation Engineer will derive and implement novel real-time pose estimation algorithms. You will need to drive R&D to then execute algorithms to solve large-scale mapping. You will closely collaborate with other engineers to develop algorithms for in-situ and in-factory multi-sensor calibration. Familiarity with multiple sensors such as GPS, IMU, camera, and wheel odometry needed. 
	- MS or PhD in Robotics, Machine Learning, Computer Science, Electrical Engineering or a related field
	- Intuitive understanding of classical ML, Linear Algebra, Stochastic Processes, Geometric Computer Vision and Optimization (Convex, Nonlinear)
	- Deep experience in one or more areas: Kalman Filter and its variants, MAP, Sequential Monte Carlo (particle filter), Nonlinear Least squares, IRLS or MHT
	- Strong C++ programming and software design skills
	- Familiarity with multiple sensors such as GPS, IMU, camera, and wheel odometry
	- Experience deploying an estimator for say SLAM/VIO in a real application
	- Understanding of numerical stability, sensor modeling and system/noise identification
	- Understanding of theoretical shortcomings in modern algorithms and how to overcome them
+ skill set for Senior Research Scientist, Autonomous Vehicle Research:
	- We are now recruiting top Research Scientists in Autonomous Vehicle Research.
	- AI-powered autonomous vehicles that can learn, reason, and interact with people are no longer science fiction. Self-driving cars, autonomous delivery vehicles, and autonomous construction vehicles, among others, are getting increasingly close to widespread deployment. However, fundamental research questions still need to be addressed in order to achieve full vehicle autonomy. For instance, how can we: Remove the traditional barriers among perception, prediction, and planning in order to improve overall system performance? Equip autonomous vehicles with online and offline assurances that meet the standards for safety-critical systems? Ensure that autonomous vehicles work seamlessly in new places?
	- These are some of the exciting questions that the newly-established NVIDIA Autonomous Vehicle Research Lab will be tackling. The lab will bring together a diverse, interdisciplinary research team working on core topics in vehicle autonomy, ranging from perception and prediction to planning and control, as well as critical related areas such as decision making under uncertainty, deep learning, reinforcement learning, and the verification and validation of safety-critical AI systems. The lab will focus on basic research; lab members will be encouraged to publish their work and open-source code. NVIDIA is well known for its team culture, and lab researchers will be able to closely interact with others within the company who are experts in perception systems, machine learning, and robotics. There is an opportunity to make a strong impact on products, while having the freedom and bandwidth to conduct ground-breaking publishable research.
	- Designing and implementing cutting-edge techniques in the field of vehicle autonomy, having an opportunity to define your own research.
	- Publishing your original research and speaking at conferences and events.
	- Collaborating with other research team members, a diverse set of internal product teams, and external researchers.
	- Transferring technology you've developed to relevant product groups.
	- PhD or equivalent experience in Robotics, Computer Science, Computer Engineering or related field.
	- 4+ years of relevant research experience in the field of vehicle / robot autonomy.
	- Strong knowledge of theory and practice of vehicle / robot autonomy, or a related area with a strong interest in connecting your work to autonomous vehicles.
	- A track record of research excellence with your work published in top conferences and journals such as RSS, ICRA, IJRR, NeurIPS, ICML, CVPR, TAC, etc., and other research artifacts such as software projects.
	- Exceptional programming skills in Python; C++ and parallel programming (e.g., CUDA) are a plus.
	- Knowledge of common machine learning frameworks such as PyTorch and Tensorflow.
	- Strong communication and interpersonal skills are required along with the ability to work in a dynamic, research-focused team. Experience with mentoring junior engineers and interns is a huge plus.
+ skill set:
	- We are now recruiting top Research Scientists in Autonomous Vehicle Research.
	- AI-powered autonomous vehicles that can learn, reason, and interact with people are no longer science fiction. Self-driving cars, autonomous delivery vehicles, and autonomous construction vehicles, among others, are getting increasingly close to widespread deployment. However, fundamental research questions still need to be addressed in order to achieve full vehicle autonomy. For instance, how can we: Remove the traditional barriers among perception, prediction, and planning in order to improve overall system performance? Equip autonomous vehicles with online and offline assurances that meet the standards for safety-critical systems? Ensure that autonomous vehicles work seamlessly in new places?
	- These are some of the exciting questions that the newly-established NVIDIA Autonomous Vehicle Research Lab will be tackling. The lab will bring together a diverse, interdisciplinary research team working on core topics in vehicle autonomy, ranging from perception and prediction to planning and control, as well as critical related areas such as decision making under uncertainty, deep learning, reinforcement learning, and the verification and validation of safety-critical AI systems. The lab will focus on basic research; lab members will be encouraged to publish their work and open-source code. NVIDIA is well known for its team culture, and lab researchers will be able to closely interact with others within the company who are experts in perception systems, machine learning, and robotics. There is an opportunity to make a strong impact on products, while having the freedom and bandwidth to conduct ground-breaking publishable research.
	- Designing and implementing cutting-edge techniques in the field of vehicle autonomy, having an opportunity to define your own research.
	- Publishing your original research and speaking at conferences and events.
	- Collaborating with other research team members, a diverse set of internal product teams, and external researchers.
	- Transferring technology you've developed to relevant product groups.
	- Pursuing PhD or equivalent experience in Robotics, Computer Science, Computer Engineering or related field.
	- 4+ years of relevant research experience in the field of vehicle / robot autonomy.
	- Strong knowledge of theory and practice of vehicle / robot autonomy, or a related area with a strong interest in connecting your work to autonomous vehicles.
	- A track record of research excellence with your work published in top conferences and journals such as ***RSS, ICRA, IJRR, NeurIPS, ICML, CVPR, TAC***, etc., and other research artifacts such as software projects.
	- Exceptional programming skills in Python; C++ and parallel programming (e.g., CUDA) are a plus.
	- Knowledge of common machine learning frameworks such as PyTorch and Tensorflow.
	- Strong communication and interpersonal skills are required along with the ability to work in a dynamic, research-focused team. Experience with mentoring junior engineers and interns is a huge plus.
+ skill set:
	- We are now hiring interns for our DriveIX team, with a preferred start in August or September. Join our DriveIX team and help build the real-time, cost-effective computing platform driving our success in this exciting and quickly growing field. Intelligent machines powered by AI computers that can learn, reason and interact with people are no longer science fiction. Today, a self-driving car powered by AI can meander through a country road at night and find its way. An AI-powered robot can learn motor skills through trial and error. This is truly an extraordinary time. The era of AI has begun.
	- As a Software Intern on our Copilot team, you will be working on research, design and implementation of software features in the DriveIX and intelligent assistant. You will use machine learning, deep learning and computer vision techniques combined with rules-based domain specification to provide monitoring, communication/interaction and external perception capabilities using multiple different type of sensors and inputs on embedded platforms.
	- Pursuing BS/MS degree in Computer Science/EE or related
	- You have strong fundamentals in embedded systems, programming and SW design
	- Strong knowledge of ML/DL techniques, algorithms and tools with exposure to memory networks, CNN, RNN and LSTM and/or Computer Vision
	- Have shown ability to harness existing data, acquiring and labeling of new data and managing related work flows.
	- Excellent fluency with C/C++ and Python
	- You strongly believe that prototyping is the right way to prove the idea
	- Image, sentiment and object classification experience is highly desired
	- Experience with one of the following: dialog systems and conversational platforms, computer vision, signal processing
	- A familiarity with GPU computing (CUDA, OpenCL, OpenACC)
	- Background with Dockers and Kubernetes
	- Familiarity with TensorRT
	- Worked with variety of vision, depth and audio sensors
	- Worked on programming automotive CAN bus
+ skill set:
	- Since antiquity, when sea routes and land routes were perilous for people and goods, having up to date and highly accurate maps have been a requirement for safe travel. These maps were patchworks of military sketches, captain logs, and merchant updates, and over the centuries became more and more detailed. In an era of growing vehicle automation, having up-to-date and highly accurate maps is equally critical to ensuring safe vehicle operation both on the highway and on surface roads. Yet map building remains an extensive and highly manual process, meaning real-time high definition map updates often propagate through to the user with a delay of months or years from the date when they were collected, rendering them useless beyond limited driver-assist functions. It is time for a new paradigm.
	- At TRI, our work is guided by a dedication to safety – in how we research, develop, and validate the performance of vehicle technology to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies. Over half of our technical team carries Ph.D. degrees. We’re continually searching for the world’s best talent ‒ people who are ready to define the new world of mobility with us!
	- We strive to build a company that helps our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun start-up environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve our goals. Come work with TRI if you’re interested in transforming mobility through designing safer cars, enabling the elderly to age in place, or designing alternative fuel sources. Start your impossible with us.
	- The Automated Mapping Platform (AMP) team is responsible for developing a new high definition mapping cloud platform by integrating sensor data from vehicles and global imagery from satellites. It is an open software platform based on a contribution model: participating developers accept that vehicles deploying their application or software contribute anonymized sensor data to the platform. In return, every developer has easy, safe, open and sustainable access to high definition maps from across industries, fleets, and carmakers. One-stop-shop open APIs that allow developers to focus on building software. No need to worry about specific map implementations and maintenance, just pull down the data needed whenever it is needed. Updated maps will use mainstream camera data, the map update and building process will be increasingly automated, and satellite imagery will help build out a global road network where vehicles are not present in sufficient numbers to support a data pipeline.
	- The role of the Data Fusion, Automated Mapping Platform (AMP) team is to process and fuse sensor and camera data from diverse vehicle sources with a high definition map developed using aerial and satellite imagery. This team will act as a bridge between the Automated Mapping Platform team at TRI-AD in Tokyo and the Localization and Mapping team at TRI. The expected output will be an accurate, scalable, semantic HD map of the world.
	- Responsibilities:
		* Collaborate with other software engineers and research scientists to develop state-of-the-art localization, mapping and data fusion algorithms for autonomous vehicles.
		* Support the development of large data sets and data pipelines for system training and evaluation.
		* Develop high-quality software designs that allow for both high-performance and maintainable software
		* Live and breathe the software practices that produce maintainable code, including automated testing, continuous integration, code style conformity, and code review.
		* Create and improve services and systems to generate map data based on algorithms developed in house based on probe, aerial and satellite imagery
		* Create services and products that serve world-scale data
		* Involved in the process of maintaining the map database at nationwide/worldwide scale
		* Educate those around you to the ways of good coding practices
	- Qualifications:
		* Ph.D., M.S. or B.S. in Computer Science or a related field
		* 2-8 years experience in related role
		* Strong organizational and communication skills; great teammate.
		* Strong C++ or Python software development skills.
		* Strong understanding of distributed and parallel computing. Familiarity with automated testing practices. Proficiency in linear algebra, probability, statistics.
		* Experience with OpenGL, Qt, or other visualization tools a plus. Experience in Robotics, SLAM, AI, or Computer Vision a plus.
		* Experience in map updating/management and operation in real production, in large-scale operation and real-time processing
		* Experience in map installation or usage in in-vehicle units (eg. knowledge of maps based on NDS or HD-MAP in navigation/ADAS/AD systems)
		* Experience in map generation/update pipeline, including database handling and migration
		* Experience in developing massive data collection & management system bringing to bear a modern cloud vendor infrastructure
		* Experience in large-scale operations and developing real-time processing platforms
		* Experience in developing distributed systems and their operation
		* Excellent communication and people engagement skills
		* Business-level English (No Japanese required)
		* Working knowledge of typical agile tools (Git, Jenkins, Docker, JIRA, Confluence, etc)
		* Understanding of Agile/Scrum methodology. Experience of agile a plus.
+ skill set:
	- At Toyota Research Institute (TRI), we’re working to build a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We’re dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life. Through innovations in AI, we’ll help...
		* Develop vehicles incapable of causing a crash, regardless of the actions of the driver.
		* Develop technology for vehicles and robots to help people enjoy new levels of independence, access, and mobility.
		* Bring advanced mobility technology to market faster.
		* Discover new materials that will make batteries and hydrogen fuel cells smaller, lighter, less expensive and more powerful.
		* Develop human-centered AI systems to augment (not replace) human decision making to increase the quality of decisions (e.g. mitigate cognitive biases) and/or to facilitate faster innovation cycles.
	- Our work is guided by a dedication to safety – in both what we research and how we perform our research our goal is to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies. Over half of our technical team carries PhD degrees. We’re continually searching for the world’s best talent ‒ people who are ready to define the new world of mobility with us!
	- We strive to build a company that helps our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve our goals. Come work with TRI if you’re interested in transforming mobility through designing technology for safer cars, enabling the elderly to age in place, or designing alternative fuel sources. Start your impossible with us.
	- Our Machine Learning (ML) team is looking for world-class research scientists and engineers to turn Toyota's data advantage into an AI advantage. As the #1 car maker in the world with 100 million cars on the road today, we can learn from massive amounts of data to realize safe automated driving on a global scale. Our team's mission is to use all the data to identify and solve open research problems on the critical path to automated driving. We are working on some of the hardest challenges in the area of perception (e.g., scene understanding, 3D vision, tracking), prediction (e.g., handling uncertainty, predicting human behavior, trajectory forecasting), planning (e.g., understanding and reacting to human intent, multi-agent modeling), and general machine learning (e.g., self-supervised learning, imitation learning, active learning, multi-task learning, domain adaptation, robustness to the heavy tail of edge cases, efficient deep learning, large scale distributed training). We invent new Deep Learning algorithms that can leverage massive amounts of data (labeled or not), experimentally showing state-of-the-art performance (both in internal benchmarks and public ones, publishing at top Machine Learning and Computer Vision conferences and collaborating with our university partners). We work closely with other teams at TRI to transfer and ship our most successful algorithms and models towards world-scale long-term autonomy.
	- As a Machine Learning Engineer, you will contribute to state-of-the-art machine learning infrastructure and relevant software (e.g. distributed training, continuous model integration, data management, and evaluation at unparalleled scale). You will implement cutting-edge deep learning models accelerating model training time, improving performance, and tackling open problems together with research scientists. Last but not least, you will deploy your algorithms and models in our self-driving test vehicles and beyond. Responsibilities and required qualifications are as follows:
	- Responsibilities
		* Build machine learning models using deep learning techniques for computer vision tasks such as semantic segmentation, object detection, video understanding, etc.
		* Address large scale challenges in the machine learning development cycle, especially around distributed training in the cloud and data engineering.
		* Manipulate high-volume, high-dimensionality, structured data from driving logs for training and testing deep networks.
		* Produce high quality tested code that enables large scale research and can be transferred to physical robots deployed in the real world.
		* Stay up to date on the state-of-the-art in Deep Learning ideas and software, in collaboration with our Research Scientists.
		* Work in a multidisciplinary team and collaborate with other teams across the company.
		* Present results in verbal and written communications, including potentially at top international conferences.
	- Qualifications
		* Bachelor's Degree in Computer Science, Math, Physics or related field.
		* Proficient in Python and Unix is a minimum. Additional knowledge of C++ / CUDA is a plus, experience with AWS as well.
		* Good software engineering skills, grounded in principled best practices.
		* Clear grasp on basic Linear Algebra, Optimization, Statistics, and Algorithms.
		* Deep Learning and Computer Vision expertise not required - but recommended. Familiarity with PyTorch or other deep learning frameworks is a bonus.
		* You are passionate about ML, both large scale engineering and research challenges, especially in the space of Automated Driving. 
		* You are a reliable team-player. You like to think big and go deeper. You care about openness and delivering with integrity.
	- Basic Requirements:
		* Bachelors with at least 4-5 years of experience; Masters with at least 2 years of experience; PhD with at least 1 year of experience
		* Strong software engineering practices in Python with machine learning experience in a production setting. 
		* Deep Learning Expertise: Experience training deep-learning models in an end-to-end fashion and writing custom layers/operations.
		* Experience working with Pytorch, Tensorflow or other modern deep learning frameworks. 
		* Multi-view geometry and multi-modal reasoning: Familiar with multi-sensor geometry (sensor intrinsics, extrinsics), multi-modal sensor fusion, point cloud processing etc.
		* Familiar with PyData eco-system including numpy, scipy, pandas, sklearn etc and comfortable with development in Linux. 
	- Bonus points:
		* Written custom neural-network (NN) layers / CUDA operations that use Pytorch/TensorFlow (share snippets if you can).
		* Implemented state-of-the-art models from research papers (share code/repos if you can).
		* Experience with large-scale distributed training, NN optimization (distillation, quantization, compression). 
		* Experience with perception, prediction, and/or planning stacks for robotics/AVs.
		* Publication in robotics/ML/CV conference (ICRA, IROS, IV, 3DV, CVPR, ECCV, ICCV, ICML, NeurIPS).
+ skill set:
	- At Toyota Research Institute (TRI), we’re working to build a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We’re dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life. Through innovations in AI, we’ll help...
		* Develop vehicles incapable of causing a crash, regardless of the actions of the driver.
		* Develop technology for vehicles and robots to help people enjoy new levels of independence, access, and mobility.
		* Bring advanced mobility technology to market faster.
		* Discover new materials that will make batteries and hydrogen fuel cells smaller, lighter, less expensive and more powerful.
		* Develop human-centered AI systems to augment (not replace) human decision making to increase the quality of decisions (e.g. mitigate cognitive biases) and/or to facilitate faster innovation cycles.
	- Our work is guided by a dedication to safety – in both what we research and how we perform our research our goal is to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies. Over half of our technical team carries PhD degrees. We’re continually searching for the world’s best talent ‒ people who are ready to define the new world of mobility with us!
	- We strive to build a company that helps our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve our goals. Come work with TRI if you’re interested in transforming mobility through designing technology for safer cars, enabling the elderly to age in place, or designing alternative fuel sources. Start your impossible with us.
	- Our Machine Learning (ML) team is looking for world-class research scientists and engineers to turn Toyota's data advantage into an AI advantage. As the #1 car maker in the world with 100 million cars on the road today, we can learn from massive amounts of data to realize safe automated driving on a global scale. Our team's mission is to use all the data to identify and solve open research problems on the critical path to automated driving. We are working on some of the hardest challenges in the area of perception (e.g., scene understanding, 3D vision, tracking), prediction (e.g., handling uncertainty, predicting human behavior, trajectory forecasting), planning (e.g., understanding and reacting to human intent, multi-agent modeling), and general machine learning (e.g., self-supervised learning, imitation learning, active learning, multi-task learning, domain adaptation, robustness to the heavy tail of edge cases, efficient deep learning, large scale distributed training). We invent new Deep Learning algorithms that can leverage massive amounts of data (labeled or not), experimentally showing state-of-the-art performance (both in internal benchmarks and public ones, publishing at top Machine Learning and Computer Vision conferences and collaborating with our university partners). We work closely with other teams at TRI to transfer and ship our most successful algorithms and models towards world-scale long-term autonomy.
	- As a Machine Learning Data Engineer, you will contribute to state-of-the-art machine learning data infrastructure and relevant software specific to data management, data analysis, and data mining at unparalleled scale. You will implement robust software and data pipelines for a tremendous amount of data, and analyze large scale data for the practical scenarios of autonomous driving. Last but not least, you will deploy your algorithms and systems to explore the meaningful scenarios in our data sea and beyond. Responsibilities and required qualifications are as follows:
	- Responsibilities:
		* Address large scale challenges in the machine learning development cycle, especially around cloud and data engineering.
		* Manipulate high-volume, high-dimensionality, structured data from driving logs for training and testing deep networks.
		* Build a robust data platform that enables ML practitioners to build and maintain their own data pipelines and datasets.
		* Stay up to date on the state-of-the-art in Deep Learning ideas and software, in collaboration with other divisions in the company.
		* Solve challenging problems with cutting edge design and algorithms.
		* Work in a multidisciplinary team and collaborate with other teams across the company.
	- Basic Requirements:
		* Bachelor's Degree in Computer Science, Math, Physics or related field with at least 4-5 years of experience; Masters with at least 2 years of experience; PhD with at least 1 year of experience
		* Strong software engineering practices with machine learning experience in a production setting.
		* Clear grasp on basic Linear Algebra, Optimization, Statistics, and Algorithms.
		* Experience with pipeline orchestration tooling (e.g. Airflow, AWS Step Function, Metaflow, KubeFlow, etc).
		* Proficient in Python, SQL and Git.
		* Experience with AWS, Azure or GCP. 
	- Nice to have:
		* Experience with data analysis, data munging and relative machine learning skills.
		* Experience with building end-to-end ML workflows (Data Mining → Data Preparation → Modeling)
		* Strong knowledge of ML dataset management (data + annotations) and exposure to dataset versioning tools such as DVC.
		* Experience with ML data annotation pipeline, RESTful APIs, Apache Spark.
		* Exposure to perception, prediction, and/or planning stacks for robotics/AVs.
		* Experience in AV or Automotive industry
+ skill set:
	- Lead a team to research future trends of technologies, generate corporate level Autonomous System Safety Assurance Technology Strategy and Roadmap. Identify and formulate real-world safety problems provided by domain experts as machine learning problems, and clarify requirements.
	- Analyze the real site data and design/implement novel machine learning algorithms for auto healing network and automotive solution.
	- Organize cutting-edge AI Safety related technology research, such as SOTIF, Safety and Security combined engineering. Develop well defined AI safety methodologies and best practices.
	- Work closely with a group of domain experts and researchers from different Huawei product lines to integrate as well as fine-tune algorithms into complex system platforms. Identify, initiate, manage and direct collaborations with research institutions such as universities and other partners.
	- Shape the safety assurance approach for Huawei to address the functional decomposition of Autonomous Driving (AD), ADAS solutions and smart manufacturing.Foster a forward-looking safety culture focused on proactive engagement and issue prevention.
	- Ph.D degree in mathematics, computer science or related areas, have several articles published in the AI top conference or journal. Preferably with a proven background in AI system modeling or formal verification work background is a plus.
	- Capability to problem formalizations (problem framing) which model the real-world problem into abstract mathematically precise problem model. Demonstrated ability to achieve goals in an innovative and fast-paced environment.
	- 3+ years of relevant experience in the architecture definition, verification, analysis, design and certification of safety elements and systems for Autonomous Driving platforms and ADAS is preferred.
	- Deep understandings on details of various supervised/unsupervised learning algorithms and have in-depth understanding of deep neural networks including CNN, RNN, LSTM, GRU etc.
	- Expertise on modern systems engineering, hardware/software architectures requirements management practices and associated process management, Demonstrate deep familiarity with MBSE and Experience with Modeling language is preferred.
	- Familiar w/ Functional Safety standard ISO 26262 and/or IEC 61508 is a plus, documented by a relevant certification authority is a plus.,Good understanding and hands-on experience of related best-known design methods and standards in the industry, such as AUTOSAR, SOTIF, IEC 61508, automotive SPICE.
	- Fluent in English or know Chinese is a plus.
+ skill set:
	- Deep learning and SLAM, 3D Vision and/or 3D sensing
	- Audiovisual Technology Lab in Huawei Munich Research Center is developing innovative technologies on media sensing, processing and coding, and computer graphics.
	- Deep learning has brought great progress in visual perception. Real-time visual sensing, localization and mapping algorithms are the basis for spatially intelligent systems such as augmented reality or autonomous robotics. This position is targeting at the intersection between visual localization, mapping and deep learning.
	- The research objective is to propose and study breakthrough solutions combing deep learning and SLAM which enable applications such as real-time robot navigation or augmented reality. There will be opportunities to publish your research into relevant international conferences. The PhD candidate has the possibility to attend the international conference and present the developed technologies to the international community.
	- Develop advanced solutions for visual-inertial localization, SLAM etc. by fusing visual and inertial information from multiple cameras, IMUs, and other sensors
	- Develop advanced solutions for computer vision problems
	- Apply optimization and deep learning to SLAM, computer vision problems
	- Develop the prototypes and implement the innovative solution on a reference software
	- Generate papers and technical reports if possible.
	- You have recently completed or will soon complete your master studies in electrical engineering, information technology, computer science, mathematics or physics
	- You have a deep interest in the topics related to deep learning, or computer vision, SLAM or 3D sensing
	- You enjoy working in a team and you like to collaborate with researchers to develop creative solutions
	- You are fluent in English (written and spoken)
	- Excellent software skills
+ skill set:
	- Huawei Consumer Cloud Services is committed to providing users with a range of secure, rich, and high-quality services through device-cloud collaboration and by adopting a distinct Internet-based approach. We provide leading cloud services.
	- We are currently looking for a Deep Learning Research Scientist ( Maps Search/Routing/Traffic/ETA/Datamining) for Huawei Map to join Huawei Mobile Services based in our Research Center in Zurich.
	- Responsible for pre-research and breakthrough of map core algorithms, and archive more than 30% better performance over current industry best practices
	- Research directions can be selected: road conditions, ETA, route planning, map search
	- Master's degree or PhD in Computer Science, Mathematics, or a related technical field of study.
	- Strong ability of commonly used machine learning algorithms, including Learning To Rank, Deep Learning;
	- Familiar with Linux platform, proficient in C / C ++ programming, Python, Shell or other scripting languages;
	- Can combine AI technology with the needs of the map field;
	- Solid experience in road conditions, ETA and navigation
	- Publication(s) in top-tier academic conferences or journals in related fields
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






###	Sets of Skills For Electric Cars or Vehicles



Sets of skills for electric cars/vehicles:
+ skill set:
	- At Toyota Research Institute (TRI), we’re working to build a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We’re dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life.
	- We strive to build a company that helps our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve your goals. Come work with TRI if you’re interested in transforming mobility through designing technology for safer cars, enabling the elderly to age in place, or designing alternative fuel sources. Start your impossible with us.
	- The long-term vision of TRI’s Accelerated Materials Design and Discovery (AMDD) program is to accelerate the development of truly emissions-free mobility. Realizing this vision will require the development of new materials and devices for batteries, fuel cells, and more. Our aim at TRI is to merge advanced computational materials modeling, new experimental data, artificial intelligence, and automation to dramatically accelerate the materials design and discovery process. Our focus is on developing tools and capabilities to enable this acceleration. In addition to the research work of the internal team, we collaborate closely with a dozen universities and national labs. AMDD aims to develop and translate the newest technologies into practice, both within Toyota and the open research community more broadly.
	- We are looking for an experienced software engineer to build a prototype platform that integrates battery manufacturing data and machine learning models, with an interface accessible to manufacturing engineers. The candidate will have responsibility for scoping and developing the platform, in collaboration with the program team. The team members will cover software engineering, machine learning, and battery manufacturing. This project aims to make a significant contribution to battery manufacturing for electric vehicles.
	- We welcome you to join a unique team of scientists and engineers dedicated to enabling a sustainable future. We all grow working alongside other great people and constantly learn new skills together at the interface of materials science and AI. You will combine your individual research with the rest of the teams’ and our collaborators to add software development capability to R&D informatics. We have a high degree of autonomy which gives us the freedom to select challenges to address, play to our strengths and pursue the solutions we believe in. 
	- We'd love to hear from you if you have:
		* BS/MS in computer science or equivalent
		* 5+ years’ experience in software development
		* Proficient in coding in multiple languages (C, Java, Python, etc.)
		* Excellent communication skills.
		* Experience with platform development for informatics systems.
	- It’s a bonus if you:
		* A strong interest in vehicle electrification
		* A desire to work in an R&D setting, with a diverse group of scientists and engineers.
		* Project management experience and familiarity with Agile methodologies.
		* UI/UX experience.
		* We are currently working from home, but when we get back in the office you will be working in our headquarters in Los Altos, CA.















####	Car Companies


Car companies that manufacture electric cars:
+ Tesla
+ Toyota
+ Stellantis
+ Volkswagen, VW
+ Ford
+ BMW
+ GM
+ Honda
+ Nissan
+ Kia
+ Hyundai
+ Subaru


Other car companies:
+ Mercedes
+ Mazda









###	Sets of Skills For Delivery Robots


Delivery robots, such as sidewalk robots and delivery drones, are used for:
+ food delivery
+ grocery delivery
+ hospital delivery
+ package delivery
+ room service robots



Sets of skills for delivery robots:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






















##	Sets of Skills in Medical Robotics


Medical robotics includes:
+ surgical robotics
+ rehabilitation robotics
	- part of assistive technology, AT, or adaptive technology
	- part of occupational therapy, OT
+ biorobotics
+ telepresence robotics
+ pharmacy automation
+ companion robotics
+ disinfection robotics
+ disabled robotics
	- disability robots
		* part of assistive technology, AT, or adaptive technology
			+ ["Adaptive technology and assistive technology are different. Assistive technology is something that is used to help disabled people, while adaptive technology covers items that are specifically designed for disabled people and would seldom be used by a non-disabled person. In other words, assistive technology is any object or system that helps people with disabilities, while adaptive technology is specifically designed for disabled people. Consequently, adaptive technology is a subset of assistive technology. Adaptive technology often refers specifically to electronic and information technology access."](https://en.wikipedia.org/wiki/Assistive_technology)
			+ to address mobility impairments
			+ to address visual impairments
			+ to address hearing impairments
			+ personal emergency response systems
			+ accessibility software
			+ to support augmentative and alternative communication
			+ to support cognitive impairments
			+ to support eating impairments
			+ computer accessibility
			+ supported by home automation
				- ***assistive domotics***, or ***home automation for the elderly and disabled***
+ other facets of health care robotics




Sets of skills in ***medical robotics***, includes ***surgical robotics***:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.


















##	Sets of Skills in Industrial Robotics


Sets of skills in industrial robotics:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.


















###	Sets of Skills in Construction Robotics


Construction robots are a subset of industrial robots used in the construction industry.


Sets of skills in construction robotics:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.



















##	Sets of Skills in Kitchen Automation, Automated Restaurants, Robotic Restaurants


Sets of skills in kitchen automation, automated restaurants, robotic restaurants:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






##	Sets of Skills in Service Robotics

Service robotics include:
+ domestic robotics
+ scientific robotics
	- autonomous scientific robots
+ event robotics
	- engage with clients and event attendees





Sets of skills in service robotics:
+ Working on the robot's navigational systems for mapping, localization, path planning, obstacle detection and avoidance. Our robots are designed to work safely and reliably alongside shoppers and employees during normal store hours.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.













###	Sets of Skills in Domestic Robotics, Home Automation, Domotics, Smart Homes



Domestic Robotics
+ educational robotics, see following subsubsubsection.
+ entertainment robots
+ home automation, domotics, smart homes




Sets of skills in domestic robotics, home automation, domotics, or smart homes:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






####	Sets of Skills in Educational Robotics


Sets of skills in educational robotics:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.















##	Sets of Skills in Nanorobotics


Sets of skills in nanorobotics:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.











##	Sets of Skills in Collaborative Robotics


Sets of skills in collaborative robotics, cobots, which have direct human robot interaction (HRI) within shared spaces and human-robot collaboration, and social robots:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.























###	Sets of Skills in Swarm Robotics



Swarm robotics is based on [artificial swarm intelligence](https://en.wikipedia.org/wiki/Swarm_intelligence).




Sets of skills in swarm robotics:
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.






















##	Sets of Skills in Animatronics


Animatronics refers to mechatronic puppets, and are used in films, TV shows, and theme parks.




+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
























##	Sets of Skills in Machine Vision



["Machine vision (MV) is the technology and methods used to provide imaging-based automatic inspection and analysis for such applications as automatic inspection, process control, and robot guidance, usually in industry. Machine vision refers to many technologies, software and hardware products, integrated systems, actions, methods and expertise. Machine vision as a systems engineering discipline can be considered distinct from computer vision, a form of computer science. It attempts to integrate existing technologies in new ways and apply them to solve real world problems. The term is the prevalent one for these functions in industrial automation environments but is also used for these functions in other environment vehicle guidance."](https://en.wikipedia.org/wiki/Machine_vision)
+ Machine vision is distinct from computer vision, but can be overlapping/intersecting.




Sets of skills in Machine Vision:
+ skill set:
	- Expertise in image and video processing, computational photography, single and multiview geometry, keypoint extraction, description, association, etc.
	- Experience in efficient large-scale numerical optimization
	- Experience in the area of camera calibration, SLAM, point cloud processing are highly desired
	- Publication records in leading conferences such as CVPR, ICCV, ECCV, NIPS, ICML or PAMI is a plus
+ Experience in Computer Vision / Computational Geometry / Structure from Motion / SLAM
+ skill set:
	- A fascination with the PoseNet research, for pose estimation, since its release in 2015.
	- Fundamental understanding of Bundle Adjustment or Non-Linear Optimization.
	- PhD or exceptional MSc involving 3D-Reconstruction, SLAM, Camera Calibration or Computational Geometry from a top ranking university or lab.
	- Geometry from Vision is at the heart of Scape Technologies. As a research engineer on the Scape Technologies team, you will take a key role in designing and building the pipeline for cloud-based 3D-reconstruction and real-time global localization. This will require implementing and building upon existing research in Structure-from-Motion, Dense 3D-reconstruction, Camera Calibration and SLAM.
	- This can range from non-linear optimization to efficient graph traversal, considering optimized computational parallelization.
	- Making sure that Scape's large scale reconstruction and localization pipeline is the most efficient in the world.
	- We are looking for curious and enthusiastic computer vision scientists who are keen on working on moonshot projects.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.













##	Sets of Skills in Humanoid Robots


+ skill set:
	- At Toyota Research Institute (TRI), we’re working to build a future where everyone has the freedom to move, engage, and explore. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We’re dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life, through innovations in AI and robots.
	- Our work is guided by a dedication to safety – in both what we research and how we perform our research, our goal is to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who bring invaluable leadership, experience, and ideas from leading industry and academic institutions. We are actively involved with the broader academic community and promote the sharing of research outcomes through publications, funding, and open-source software. We’re continually searching for the world’s best talent ‒ people who are ready to define the new world of mobility with us!
	- We're building a company helping people to thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve your goals. Come work with TRI to enable the elderly to age in place. Start your impossible with us.
	- Our team melds complementary research and engineering expertise in soft robotics, physical human-robot interaction, humanoid systems, software development, education, entertainment, consumer electronics, and user-centered design. We are developing human-centered hardware and algorithms for putting highly compliant, sensing robotic systems to work in the domestic setting, and innovating manipulation skills that physically support and amplify older adults and ensure continued independent living.
	- TRI has the runway, roadmap, and expertise to transition the technology development to a product that impacts the lives of millions of people. Join a fast-moving team that demands high-risk innovation and learning from failures, using rigorous processes to identify key technologies, develop a robust, high-quality system, and quantitatively evaluate performance. As part of the team, you will be surrounded and supported by the significant core ML, cloud, software, and hardware expertise at TRI, and be a part of TRI's positive and diverse culture.
	- Responsibilities:
		* Develop, integrate, and deploy algorithms for motion planning and control in highly cluttered spaces, planning for rich-contact tasks and dexterous manipulation
		* Develop and integrate control algorithms that exploit tactile feedback and multi-modal sensing in constrained domestic environments
		* Invent and deploy innovative solutions at the intersection of machine learning, soft-robotics, tactile sensing, manipulation, human interaction, and simulation for performing useful, human-level tasks, in and around homes
		* Co-invent novel ways to engineer and learn robust, real-world behaviors, incorporating optimization, planning, reactive control, self-supervision, active learning, learning from demonstration, simulation and transfer learning, and real-world adaptation, etc.
		* Work closely with Human-Robot Interaction researchers in understanding human needs and applications
		* Follow best practices producing maintainable code, including automated testing, continuous integration, code style conformity, and code review
	- Qualifications:
		* M.S. or Ph.D. in an relevant technical field OR equivalent industry experience
		* A strong background with motion planning methods, specifically contact-aware planning methods, for multi-DoF dexterous manipulation in cluttered and constrained environments
		* Strong software engineering skills, preferably in C++ and Python, and in analysis and debugging of autonomous robotic systems
		* A standout colleague with strong communication skills, and an ability to learn from others and contribute back to the robotics community with publications or open source code
		* Passionate about assisting and amplifying older adults and those in need through domestic human-robot collaboration and physical assistance innovation
	- Additional experience or knowledge in any of the following areas:
		* Reactive planning and control, coordinated whole-body control, dexterous manipulation, grasp planning, and human interaction
		* Application of machine learning to robotics, including reinforcement, imitation, and transfer learning
		* Tactile sensing, modeling soft-contact, and in soft robotics
		* Integration of multi-modal sensing into planning and control and in development of sensor fusion methods
		* Mobile and/or legged locomotion in constrained environments
+ skill set:
	- At Toyota Research Institute (TRI), we’re building a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We’re building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy better life through innovations in AI.
	- Our work is guided by a dedication to safety – in both what we research and how we perform our research to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies. Over half of our technical teams carry PhD degrees. We’re continually searching for the world’s best talent ‒ people who are ready to define the new world of mobility with us!
	- Our company strives to help our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you'll have opportunity to enjoy the best of both worlds ‒ a fun environment with forward-thinking people solving tough problems and the financial backing to optimally achieve our goals. Come work with TRI and redefine mobility through crafting technology for safer cars, enabling the elderly to age in place, or designing alternative fuel sources. Start your impossible with us.
	- Our HASTEN (Helping Aging Society: Tactile Embodied Nudging) team bridges complementary research and engineering expertise in physical human-robot interaction, soft robotics, humanoid systems, software development, educational & entertainment electronics, and user-centered design. We're working on highly compliant tactile “bubble” sensors and algorithms to put them to human-centered use, and innovating ways to physically support and amplify older adults with domestic manipulation skills, ensuring safe independent living respective to fall prevention. We envision development of contact-based guarding interaction algorithms that enable our bubblized soft robot to physically support an individual person and maintain their desired level of support by continuing to learn over time, using large amounts of data from contact-rich, critical interactions between our robot’s body, people, and the world.
	- Responsibilities:
		* Find opportunities for novel contact guard-based human-robot interactions derived from user needs of aging society
		* Collaborate cross functionally with roboticists, software engineers, and user experience researchers
		* Invent /Deploy innovative solutions at the intersection of hands-on, physical contact-based human-robot interaction, soft-robotics, tactile sensing, machine learning, and simulation for physically assisting humans in homes
		* Follow software practices producing maintainable code, including automated testing, CI, code style conformity, review
		* Develop and run experiments on real hardware
	-Qualifications:
		* M.S. or Ph.D. (Robotics, Computer Science, HCI, Biomedical/Biomechanical Engineering, Human Factors, or related) OR equivalent practical experience
		* Expertise in physical contact guard assistance and interaction with humans and technical knowledge of human neuromechanical modeling and human body movement modeling
		* Experience with motion capture recording/motion analysis; familiarity with human biomechanics modeling software (OpenSim, AnyBody, etc.)
		* Expertise/Experience in machine learning around user behavioral modeling, adapting to individual user’s preference and preference changes over time
		* System integration experience around complex, open-ended, multi-functional projects
		* Strong software engineering skills (C++ /Python preferred) and analysis/debugging autonomous robotic systems
		* Prior work emphasizing user needs finding and User-centered Design process, including formative and summative user studies with end-users
		* Experience with qualitative and quantitative user research, including developing user study materials, IRB application, facilitation and interviewing, management of Personally Identifiable Information (PII), and statistical analysis
		* Strong communicator and ability to learn from others and contribute back to robotics community with publications and open source code
		* Passion for seeing robotics help humans and have a real-world, large-scale impact 
	- Additional experience/knowledge in some or all of the following areas:
		* Experience working with older adults, specifically recording/analyzing gait
		* Experience in tactile sensing, modelling soft-contact, soft robotics
		* Experience applying machine learning to robotics, including around reinforcement, imitation, transfer learning
		* Experience integrating multimodal sensing into planning and control and development of sensor fusion methods.
		* Knowledge of optimization and sampling based planners for physical, reactive planning and control, trajectory optimization, coordinated whole-body control
		* Comfortable using Adobe Illustrator, Adobe Xd, Sketch, or a similar for task flows, wireframes, mockups
		* Comfortable using Adobe Premiere or similar software to produce stimuli or concept videos
		* Appetite to learn across functions

















































