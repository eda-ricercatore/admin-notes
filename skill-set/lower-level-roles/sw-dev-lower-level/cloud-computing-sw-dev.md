#	Cloud Computing Software Development

This set of skill sets is for software development roles in cloud computing.



##	Notes on Cloud Computing

Notes on cloud computing:
+ ***as a service***, ***aaS***, ***XaaS***, ***anything as a service***
	- business model for ***something*** presented to internal or external customer ***as a service***
		* service offerings are:
			+ API-driven
			+ controlled via Web console in a user's Web browser
	- types of delivery, cloud computing delivery models, or business models:
		* development as a service, DaaS
			+ Web-based, community shared tool set
				- compare to locally installed software development tools in traditional (non-cloud computing) delivery of software development tools
		* banking as a service, BaaS
			+ provision of banking products (current accounts and credit cards) as a service to non-bank third parties through APIs
			+ banking as a platform, BaaP
				- provided on top of Infrastructure as a Service, IaaS, model
				- FinTech SaaS
					* provides atomic and composite software-based financial services that are available on-demand
			+ integrated banking as a service, BaaS, structure
				- larger portfolio of services reduces risk of failure than single service provider
				- efficient end-to-end proposition
		* blockchain as a service, BaaS
			+ provide businesses with cloud-based solutions to build, host, and use their own blockchain apps, smart contracts, and function on the blockchain infrastructure developed by a vendor
		* car as a service, CaaS, vehicle as a service, VaaS
			+ electric vehicle as a service, ?aaS
		* edge as a service, EaaS
		* encryption as a service, EaaS
		* energy as a service, EaaS
		* evaluation as a service, EaaS
		* games as a service, GaaS
		* identity as a service, IDaaS
		* IT as a service, ITaaS
			+ operational model for IT service providers to provide IT services to businesses
		* logging as a service, LaaS
			+ IT archtectural model for centrally ingesting and collecting any type of log files coming from any given source or location, such as:
				- servers
				- applications
				- devices
			+ managed service provider (MSP) environment
				- managed services as an alternative to break/fix model and on-demand outsourcing model
		* lighting as a service, LaaS, light as a service
			+ service-based business model in which light service is charged on a subscription basis rather than via a one-time payment
		* mobility as a service, MaaS
			+ via a joint digital channel that enables users to plan, book, and pay for multiple types of mobility services (or vehicles that users can get a ride in to their destination)
				- carpool companies
				- ridesharing companies
				- bicycle-sharing systems, bicycle-sharing programs, public bicycle schemes, public bike share schemes (or PBS schemes)
				- scooter-sharing systems
				- carsharing services, car sharing services, or car clubs
				- "pop-up" bus services
				- on-demand car services
					* from self-driving cars, autonomous cars, driver-less cars, robotic cars, or robo-cars
		* monitoring as a service, MaaS
		* mass personalization as a service, MPaaS, personalization as a service, PaaS
		* payment as a service, PaaS
			+ SaaS-based connection to group of international payment systems
		* ***quality assurance as a service***, ***QAaaS***
		* ***recovery as a service***, ***RaaS***, ***disaster recovery as a service***, ***DRaaS***
			+ RaaS/DRaaS architectural models:
				- to-cloud RaaS/DRaaS
					* source application: primary private data centr of users
					* backup/recovery target: cloud
				- in-cloud RaaS/DRaaS
					* source application: cloud
					* backup/recovery target: cloud
				- from-cloud RaaS/DRaaS
					* primary/production application, or data, or source: cloud
					* backup/recovery target: private data center
		* ***robot as a service***, ***RaaS***, ***robotics as a service***
			+ cloud computing service that facilitates seamless integration of robot and embedded devices into Web and cloud computing environment
			+ subset of Internet of Intelligent Things, IoIT
				- subset of Internet of Things, IoT
			+ cyber-physical systems consist of:
				- computational and communication core
				- physical elements that can interact with the physical world
				- autonomous decentralized system, ADS
					* components are designed to operate independently in a loosely coupled manner, so that the overall goal of the system is met
					* share data through content-oriented protocol
						+ data transmission on enterprise service bus, ESB
					* based on a decoupled architecture
					* autonomous decentralized service system, ADSS
						+ based on service-oriented architecture, SOA
			+ subscription-based contract for industrial or service robots
			+ Visual IoT/Robotics Progamming Language Environment, VIPLE
			+ uses service-oriented architecture, SOA, for:
				- service providers:
					* each RaaS cloud unit hosts a repository of preloaded services
					* developer/client can deploy new services into, or remove services from, a robot
					* services can be used by a robot, or shared with other robots
				- set of applications deployed:
					* developer/client can compose new applications/functionalities based on services in and outside the RaaS cloud unit
				- service brokers:
					* each client can look up available services and applications in the directory of the RaaS cloud unit
					* developer/client can compose a new application/functionality based on the services available in and outside the RaaS cloud unit
					* available services and applications are hierarchically organized in the directory of the RaaS cloud unit, so that their discovery can be facilitated
+ *content as a service, CaaS, or managed content as a service, MCaaS*
	- provide content on demand to service consumer via Web services that are licensed under subscription
+ *big data business models*:
	- answers as a service, AaaS
		* cloud-based software tools for to answer questions about data sets???
	- information as a service, Info-aaS
		* cloud-based software tools for extract or create information from data???
	- **data as a service, DaaS**
		* cloud-based software tools for working with data
			+ data management in data warehouse
			+ data analysis with business intelligence
		* remote desktop virtualization:
			+ regarding virtual desktop infrastructure, VDI:
				- application virtualization
					* application streaming
					* remote desktop services
					* desktop virtualization
					* workspace virtualization
				- user virtualization, or user profile management systems
				- **desktop as a service, DaaS**
					* cloud-hosted virtual desktops
					* more automation
					* multi-tenancy
					* desktop virtualization
	- **database as a service, DBaaS**
		* database runs on a cloud computing platform, and access to the database is provided as a service
			+ address scalability and high availability of the database
		* Web-based design construct where cloud data is accessed through a defined API layer
		* deployment models:
			+ users run databases on the cloud independently
			+ use ***virtual machine image***
			+ purchase access to database service
			+ maintain cloud database provider
	- **knowledge as a service, KaaS**
		* knowledge models, such as knowledge graphs, based on:
			+ decision trees
			+ association rules
			+ neural networks
		* related to:
			+ content as a service, CaaS
			+ data as a service, DaaS
	- **models for differentiating data, information, and knowledge**:
		* **DIKW pyramid**
			+ represent structural and functional relationships between:
				- data
				- information
				- knowledge
				- wisdom
			+ DIKW hierarchy
			+ wisdom hierarchy
			+ knowledge hierarchy
			+ information hierarchy, information pyramid
			+ data hierarchy
		* need to handle explicit knowledge and tacit knowledge
+ *security as a service, SECaaS*
	- service provider integrates security services into corporate infrastructure on a subscription basis more cost effectively than most individuals and coporations can provide on their own, in terms of total cost of ownership
	- security services include:
		* authentication
		* anti-virus detection and mitigation
		* anti-malware/spyware detection and mitigation
		* intrusion detection, intrusion management
		* penetration testing
		* security information and event management, SIEM
			+ security event management
		* business continuity and disaster recovery, BCDR, or BC/DR
		* continuous monitoring
		* data loss prevention, DLP
		* email security
		* encryption
		* identity and access management, IAM
		* network security services
			+ managed security services, MSS
				- + managed security service providers, MSSP
		* security assessment
		* vulnerability scanning
		* Web security
+ cloud-based integration
	- system integration business delivered as a cloud computing service that addresses:
		* data
		* process
		* service-oriented architecture, SOA
		* application integration
	- ***integration platform as a service***, ***iPaaS***, cloud-based iPaaS integration model:
		* suite of cloud computing services that enable customers to develop, execute, and manage/govern integration flows between disparate applications
			+ shift for business to business (B2B) from electronic data interchange (EDI) and value-added network (VAN)
			+ leads to the creation of new cloud-based business process management tools that don't require integration layers (provided as a separate service via )
+ ***Messaging as a Service (MaaS)***
+ ***Infrastructure as a Service, IaaS***
+ ***Platform as a Service (PaaS)***
+ ***Software as a Service (SaaS)***
+ ***Mobile "backend" as a Service, MBaaS, or Backend as a Service, BaaS***
+ ***Serverless Computing or Function-as-a-Service (FaaS)***





















##	Generic Skill Sets for Cloud Computing -based Software Development




+ We are ***cloud agnostic*** and run our infrastructure and systems on Azure, AWS, as well as dedicated servers.
+ OpenStack:
	- Dashboard (Horizon)
	- Compute Service (Nova)
	- Networking (Neutron)
	- Object store (Swift)
	- Identity service (Keystone)
	- Metering & Data Collection Service (Ceilometer)
	- Orchestration (Heat)
	- Bare Metal Provisioning Service (Ironic)
	- Container Orchestration Engine Provisioning (Magnum)
	- Computable object storage (Storlets)
	- Deploys OpenStack using OpenStack itself (Tripleo)
	- Billing and chargebacks (Cloudkitty)
	- Optimization Service (Watcher)
	- Distributed SDN controller (Dragonflow)
	- OpenStack Networking integration for containers (Kuryr)
	- NFV Orchestration (Tacker)
	- Networking Automation for Multi-Region Deployments (Tricircle)
	- Command-line interface for all OpenStack services (Openstackclient)
	- Instances High Availability Service (Masakari)
	- Lightweight OCI containers (LOCI)
	- EC2 API proxy (EC2API)
	- Official Python SDK for OpenStack APIs (Openstacksdk)
	- Block Storage (Cinder)
	- Image service (Glance)
	- Big Data Processing Framework Provisioning (Sahara)
	- Application Catalog (Murano)
	- Containers Service (Zun)
	- Puppet modules to deploy OpenStack (Puppet-openstack)
	- Clustering service (Senlin)
	- Event, Metadata Indexing Service (Panko)
	- Root Cause Analysis service (Vitrage)
	- Load balancer (Octavia)
	- Accelerators resource management (Cyborg)
	- Deploys OpenStack in containers using Helm (Openstack-helm)
	- OpenStack Storage integration for containers (Fuxi)
	- Client library for interacting with OpenStack clouds (Shade)
	- Database as a Service (Trove)
	- Shared filesystems (Manila)
	- DNS service (Designate)
	- Key management (Barbican)
	- Governance (Congress)
	- Software Development Lifecycle Automation (Solum)
	- Deploys OpenStack in containers using Ansible (Kolla-ansible)
	- Monitoring (Monasca)
	- Workflow service (Mistral)
	- Functions Service (Qinling)
	- RPM package specs to deploy OpenStack (RPM-packaging)
	- Messaging Service (Zaqar)
	- Ansible playbooks to deploy OpenStack (Openstack-ansible)
	- Benchmark service (Rally)
	- Application Data Protection as a Service (Karbor)
	- Backup, Restore, and Disaster Recovery (Freezer)
	- Packaging-rpm (Packaging-rpm)
	- Indexing and Search (Searchlight)
	- Deploys OpenStack in containers using Charms and Juju (Openstack-charms)
	- Resource reservation service (Blazar)
	- Alarming Service (Aodh)
	- Ansible playbooks using ironic (Bifrost)
	- Chef cookbooks to deploy OpenStack (Chef-openstack)
	- EC2 API compatibility layer for OpenStack (Ec2-api)
	- Python Software Development Kit (Python SDK)
	- Ansible playbooks and roles for deployment (OpenStackAnsible)
+ view DevOps as ***configuration as code***:
	- Experience with ***configuration as code***; Puppet, SaltStack, Ansible, or Chef.
+ ***network operations center, NOC.***
	- A network operations center (NOC, pronounced like the word knock), also known as a "network management center", is one or more locations from which network monitoring and control, or network management, is exercised over a computer, telecommunication or satellite network.
+ Expertise using AWS services like CloudWatch, CodeBuild, CloudTrail, Athena, ECS, EC2, IAM, Lambda, and CloudFormation
+ Experience developing and deploying systems on cloud infrastructure such as Kubernetes, Consul, and Vault
+ Experience with Cloud based services, Microservices a Cloud Computing class or similar experience
+ knowledge of various issues in the field of cloud engineering (virtualization, scalability, load balancing, failovers, distributed computing power, cloud deployments, monitoring, log processing)
+ skill set:
	- continuous integration/delivery (CI/CD) methodologies and practices
	- develop open-source, scalable simulation and virtualization environments
	- contribute to open-source frameworks
	- design cloud infrastructure
	- distributed CI/CD constructions
	- cloud engineering:
		* virtualization
		* scalability
		* load balancing
		* failovers
		* distributed computing power
		* cloud deployments
		* monitoring
		* log processing
	- orchestration tools
+ skill set:
	- Modernizing Kafka to make it infinitely scalable, elastic, and globally replicated
	- Building out best in class stream processing solutions like Kafka Streams and KSQL to perform rich, real time, transformation and querying of data in Kafka
	- Revolutionizing how data pipelines are built through Kafka Connect
	- Running all of the above in our very own elastic, scalable cloud offering
+ ZABBIX, Python, API, Ansible, Terraform, and AWS cloud.
	- Zabbix is an open-source software tool to monitor IT infrastructure such as networks, servers, virtual machines, and cloud services.
	- Ansible is a suite of software tools that enables infrastructure as code.
	- Terraform is an infrastructure-as-code software tool created by HashiCorp.
+ skill set:
	- Sr Principle Software Engineer - Cloud Platform
	- Splunk is on a journey to be a SAAS data analytics platform. We have built platform 1.0 hosting Splunk developed application verticals like security, observability, IT Ops and others. It’s still early days, plenty of technology to be created and new challenges emerge every week. A person in this role can help us find directional alignment, influence simplicity of designs and create iterative value without getting bogged down by “everything else” that needs to get done. You know how to prioritize ruthlessly under internal/external pressures while keeping an eye on the prize. We can find domain experts comfortable in their prior experience to apply on the job, we can also get generalist not afraid to tinker with anyones closely held beliefs but what we really want is someone who uses the right tools for the right occasion. We value technology leaders who elevate the whole ecosystem around them (people, process and product) while building cool technology needed for the day. You are completely at ease with deeply understanding and driving business requirements, at times generating them as needed. You can influence from early engineers to senior VP’s from product and engineering. You are equally comfortable hands on and know when to go deep to advance a project and when to delegate and let the team take over. If you thrive in managed chaos and like to bring order, you will find yourself right at home. Some specific areas we are building in the platform:
	- Unified metering and billing services for the platform as we shift towards consumption based pricing for our product portfolio
	- Platform infrastructure to create finer granularity for cost of services across the platform for static and dynamic resource consumption
	- Hybrid connectivity services to bridge on-prem and cloud worlds for a number of interesting use case like a single pane of glass to view and remedy security incidents
+ Fluency with developing and operating services running on Linux and cloud infrastructure (we use Heroku, AWS, and GCP)
+ skill set:
	- C3.ai, Inc. (NYSE:AI) is a leading provider of Enterprise AI software for accelerating digital transformation. C3 AI delivers a family of fully integrated products: C3 AI® Suite, an end-to-end platform for developing, deploying, and operating large-scale AI applications; C3 AI Applications, a portfolio of industry-specific SaaS AI applications; C3 AI CRM, a suite of industry-specific CRM applications designed for AI and machine learning; and C3 AI Ex Machina, a no-code AI solution to apply data science to everyday business problems. The core of the C3 AI offering is an open, model-driven AI architecture that dramatically simplifies data science and application development. Learn more at: www.c3.ai
	- We are looking for a seasoned and motivated Software Engineers to build the next generation AI platform scaling to several petabyte level data volumes.
	- As a member of C3 AI's growing platform team, you will be responsible for the entire software engineering lifecyle, i.e design, document, build, test, maintain. As one of the core teams, this role is integral to the success of the company. A successful candidate will thrive in a fast-paced, highly collaborative environment and demonstrate an ability to execute precisely and quickly. The ideal candidate will have a passion for finding elegant solutions to complex problems.
	- Role Responsibilities:
		* Design and develop various features in the next generation C3 AI PaaS AI suite
		* Design and develop data pipelines that can handle petabyte level data scale and more
		* Develop core fundamental distibuted system components like distributed stream processing engine, distributed queueing, distributed batch processing, cluster management, etc.
		* Design and develop abstraction over existing datastores & cloud infrastructure in an innovative way E.g. Key value stores like cassandra / hbase, sql stores like postgres / mysql, file systems like s3 / azure blob store / hdfs, cloud infrastructure like AWS / Azure / GCP
		* Handle large data infrastructure platform and driving stability through automated monitoring, alerting, and actions.
		* Work closely with software engineering & product management teams to gather requirements and deliver a top quality product following the agile software development methodology
	- Minimum Qualifications
		* BS in Computer Science or related technical field, or equivalent industry experience
		* 2+ years of relevant experience 
		* Strong communication and interpersonal skills
		* Systematic problem-solving approach coupled with a strong sense of ownership and independence
		* Strong understanding of Computer Science fundamentals ( Algorithms, Data Structures)
		* Must be proficient in expert level programing in Java or Javascript or Python.
		* Experience with Aws / Azure / GCP Cloud Platform
		* Skilled in robust, highly available large-scale, distributed SaaS systems.
		* Familiarity with Big Data systems like Apache Spark / Hadoop / Distributed Systems
		* Experience with security technologies (SSO, SAML, Okta etc).
		* Proactive work ethic - self starter
	- Preferred Qualifications
		* Experience with modern container orchestration systems: e.g. Kubernetes, Mesos, DC/OS, Swarm
		* Experience with building scalable and reliable data pipelines
		* Experience with integration of data from multiple data sources
+ tech stack:
	- Security and privacy
	- Virtualization and container technologies (e.g., Xen and Docker)
	- Cloud services (e.g., AWS and Azure)
	- Distributed programming tools (e.g., Hadoop, Cassandra, and ZooKeeper)
	- In-home wireless network protocols (WiFi, Bluetooth, Zigbee, and Z-wave)
	- Systems for machine learning training and inference (Tensorflow, MXNet, Caffe etc)
	- Storage systems
+ skill set:
	- Senior Software Engineer - Backend (Remote)
	- The Splunk Analytic Apps team follows a lean process that focuses on empowering our engineers. Our Platform is an analytics-driven SIEM that solves a wide range of security analytics and security operations use cases like security monitoring, advanced threat detection, compliance, and incident investigations.
	- We need strong engineers to address the next set of data challenges that include real-time streaming data processing, cloud migrations, and integration of disparate and distributed data sources. That's where you come in!
	- As a Senior Software Engineer, you will be able to connect with customers and learn about their experiences, you will get a first-person view of the state of the art Security Operations Centers, and you will collaborate with product management to define and craft new products that streamline analysts' investigations.
	- You will work with the team to develop insightful user experiences for the data analytics platform. You will deliver these features to meet the ever-increasing scalability, performance, and security requirements; while designing and developing with an eye on reliability and high availability.
	- Own and be accountable for the design and development of multiple features in the ultra-high performance system, processing immense amounts of data.
	- Pay extra attention to non-functional requirements (Performance, Scalability, Reliability, High Availability).
	- Achieve a deep knowledge of our product architecture, usage patterns, and real-world deployment scenarios to develop an understanding of which solutions will bring value to our customers.
	- Scale and performance of the product using Splunk platform innovations, open-source, and cloud tools and technologies.
	- Work in an Agile environment and follow scrum practices.
	- Receive guidance from Principal Engineers, Architects for current and strategic features.
	- Partner with leaders from architecture, engineering management, and product management on project requirements, designs, and development plans.
	- Help identify and develop ways to improve our team's productivity and efficiency by expanding on our existing tools and processes.
	- Collaborate with members of our team on the design and implementation of frameworks and backend components.
	- Keep product quality top of mind by creating automated tests for the software that you help create.
	- Become well versed in core Splunk technologies as they apply to application development.
	- Mentor junior engineers and interns as they develop their application development skills.
	- 7+ years of software engineering experience focused on application development.
	- Programming experience using languages such as Python, Java, C/C++, or similar languages.
	- A solid grasp of data structures, algorithms, and RESTful APIs.
	- A deep understanding of scalable distributed web applications using open-source or proprietary technologies.
	- Solid understanding of relational databases' (Postgres).
	- Experience collaborating with design, engineering, and DevOps teams.
	- Proponent of test-driven development (TDD) and understanding of CI/CD technologies.
	- Experience with secure coding practices.
	- Experience with an agile software development model.
	- Experience working on high performance, high volume analytics software.
	- Ability to develop software on Linux, Unix, and Windows systems.
	- Familiar with backend application development frameworks such as Django or CherryPy.
	- Familiarity with orchestration and cloud stack and technologies like K8s, Kinesis, Kafka.
	- Demonstrated ability to learn new technologies quickly.
+ experience working with common cloud technologies, such as:
	- Hashistack (Nomda, Terraform, Vault, etc)
	- Kubernetes
	- Docker
	- AWS
	- Azure
+ skill set:
	- Senior Software Engineer, Observability Metrics & Analytics (Remote)
	- Join us in developing a distributed, realtime, multi-tenant streaming analytics platform that allows customers and developers to analyze massive amounts of data from a multitude of devices, operating systems, logs, metrics, traces and more in a scalable and reliable way.
	- Splunk's Observability team is seeking an exceptional Engineer to join our team to design and develop the sophisticated SaaS products to analyze and alert on data in a fast, scalable and reliable way.
	- This is a highly visible position within the Observability team at Splunk. You will be tasked with driving major technical initiatives that will have a huge impact on how customers use data.
	- You are passionate about building, observing and operating distributed systems at scale in production.
	- You understand the challenges and trade-offs to be made when building and deploying systems to production.
	- You have a solid foundation in computer science, with strong competencies in operating systems, networks, data structures, algorithms, distributed systems and software design
	- Excellent problem solving, collaboration and communication skills, both verbal and written
	- A demonstrated capability for creative thinking, intellectual and entrepreneurial exploration
	- Experience developing, debugging, and performance tuning highly concurrent systems
	- Ability to lead complicated technical decisions and mentor other junior engineers
	- Solid knowledge and production programming experience in at least one of Java/C++/Go
	- Mastery of test driven development, developing different levels of automated tests, such as unit test, functional test, integration test, system test, or performance / load test
	- Experience with real-time data pipelines is highly desirable
	- 8+ years of industry experience with a proven track record of ownership and delivery (or Masters and 6 + years related experience or PhD and 3+ years experience)
	- 2+ years experience in stream processing platform, such as Flink, Storm, Spark, or equivalent
	- 2+ years experience using a messaging system, such as Apache Kafka, Pulsar or equivalent
+ skill set:
	- Sr Software Engineer - Cloud Infrastructure
	- Splunk’s Cloud Infrastructure organization builds robust and resilient auto-scaling platform solutions for hosting Splunk's enterprise software. The teams are fast-paced, high-velocity, and use state-of-the-art technology. The focus is always on automation, solving complex challenges that span across multiple groups within Splunk, ensuring smooth and expedient services to Splunk users.
	- Splunk's Cloud Infrastructure team helps scale and secure our new global SaaS offerings.  We need experienced Software Engineers (various levels) to help lead, design and build the internet traffic management systems that will power Splunk’s next generation SaaS platform.
	- We have a substantial AWS and Kubernetes presence of large-scale containerized systems. This is an incredible opportunity to utilize your existing cloud experience and drive the growth of the Splunk Cloud.
	- Develop and deploy software that will help drive improvements towards the availability, performance, efficiency, and security of Splunk’s services. Technologies include L4/L7 Networking,  DNS, Load Balancers, API Gateways, Kubernetes, and TLS infrastructure for securing network communication.
	- Work with Cloud providers on integrating their networking products into our ecosystem. You will be developing and extending a control plane to scale and secure cloud networks on various cloud computing platforms (Amazon AWS, Google Cloud Platform, Microsoft Azure).
	- Drive for automation. You are passionate about adopting and mastering new technologies that will help you automate routine tasks and free up time for innovation. You will be utilizing a variety of languages used in systems programming, ranging from Go/Python to Terraform.
	- Knowledge of technical excellence. You'll routinely use continuous delivery, testing and security best practices.
	- Operational excellence. Data excites you and you make decisions based on numbers rather than assumptions.
	- You have experience building cloud native applications in an agile manner using DevOps concepts and principles.
	- Experience having designed, implemented and released distributed SaaS and/or On-prem applications to a large customer base.
	- Have designed and developed APIs and micro services and released them using automated CI/CD pipelines.
	- Have experience working with one or more of the public cloud providers i.e. AWS, Azure or GCP
	- Have distributed systems design experience and integrate multiple systems using enterprise integration patterns and standard methodologies.
	- You are proficient in coding in Python/Go.
	- Ability to coach/mentor junior engineers on the team, provide technical direction, perform design/code reviews and champion engineering best practices.
	- 5+ years of relevant industry experience; Bachelor’s degree in Computer Science, Computer Engineering or equivalent work experience.
	- Opportunities to develop and grow as an engineer. We are always expanding into new areas, working with open-source projects and contributing back, and exploring new technologies.
	- A team of incredibly capable and dedicated peers, all the way from engineering to product management and customer support.
	- Breadth and depth. You are interested to work on an area that dynamically scales to meet the needs of Splunk’s cloud offering. You want to go deep into optimizing how we automate every manual process and tedious task we encounter.
	- Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe that mentors help both sides of the equation.
	- A stable, collaborative, and supportive work environment. We work in an open environment, work together to get things done, and adapt to the changing needs for the team. We keep it real by being open and honest. We are a collaborative team that understands the value in open communication—it's how we interact with our customers.
	- Balance. We don't expect people to work 12 hour days. We want you to be successful outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and commitment, and believe that balance helps cultivate a positive environment.
	- Fun. We have frequent group outings and team building events. We are committed to having every employee want to give it their all, be respectful and a part of the family, and have a smile on their face while doing it.
+ skill set for RoCE Network Technology Engineer
	- Research and construct the RoCE network in the cloud computing system.
		* RoCE
	- Study the ecosystem and application models of the RoCE network.
	- Research algorithms for congestion control and delay reduction in the large-scale RoCE network.
	- Implement the RoCE network in the storage network, big data and AI platforms, and tenant VMs.
	- Deploy the RoCE network on a large scale.
	- General knowledge of the system and architecture of the InfiniBand network protocol stack
		* InfiniBand network protocol stack
	- Broad knowledge of application scenarios of the RDMA system, such as HPC, big data and AI, storage, and SAP, as well as RoCE deployment and isolation solutions in virtualization scenarios
		* RDMA system
	- Understanding of RDMA programming frameworks and ecosystems, such as IB-verbs and Libfabric
		* IB-verbs
		* Libfabric
+ skill set:
	- The Futurewei Cloud Networking team is responsible for the design and implementation of Futurewei's Next Generation Cloud Virtual Network services including Virtual Private Cloud, Elastic Load Balancer, and Elastic IP, among others. We are looking for experienced architects and full-stack software developers who are passionate about cloud technology and are eager to build world-class networking solutions for the public cloud from the ground up.  The job responsibilities, depending on your prior work experiences, are ranging from designing architecture of l3-l7 layer network infrastructure services, to ensure the architectural integrity and successful delivery including but not limited to the development, testing, and operation in support of Futurewei’s Cloud Networking system. If this challenge sounds like a good fit for you, please reach out to us. Let's together build something brand new and change the sky with Futurewei Cloud.
	- 8+ years of IT experience or 5+ years of experience with a large-scale public/private cloud provider
	- Excellent coding ability (preferably Java or C++) and problem-solving skills;
	- Familiarity with network virtualization, SDN, container, L3 and above; Network infrastructure service (VPC/LB/NAT/VPN, etc. ) design and development experience is highly preferred;
		* VPC
		* LB
		* NAT
		* VPN
	- Broad familiarity with modern concepts/algorithm/data structures in the area of distributed systems;
	- Great understanding of software development life-cycle;
	- Excellent written and verbal communication skills. Must be able to clearly articulate ideas and concepts to fellow engineers and management;
	- A true team player, willing to work within a multi-culture organization.
+ skill set:
	- Senior Software Engineer, Cloud Database (Remote, EMEA)
	- Grafana Cloud is our composable observability platform that integrates metrics, logs, and traces with Grafana. It allows our customers to leverage the best open source observability software – including Prometheus, Mimir, Loki, and Tempo – without the overhead of installing, maintaining and scaling their own observability stack
	- The Databases team owns the telemetry databases that are Mimir for metrics, Loki for logs, and Tempo for traces. All of our databases are OSS projects that we also offer as a Cloud service supporting Grafana Cloud and as an on-premise solution. They are multi-tenant distributed systems implemented in Go and running on Kubernetes across all major Cloud providers (GCP, Azure, AWS). We also have engineers working on Prometheus, Grafana Agent, and the Mimir proxies.
	- As a company we are remote-first and global, we embrace people of different experiences and backgrounds to build diverse teams where every person brings a new perspective to the software. Our tech stack is mostly made up of services written in Go, running on multiple Kubernetes clusters that leverage Google’s Cloud Platform.
	- Take an active role in influencing our roadmap and your own career objectives 
	- Work with your team to deliver new features, then use the results to iterate and improve.
	- Drive projects from initial ideation all the way to operations once it is in the hands of customers
	- Embrace our open-source culture and contribute to other projects that may not directly fall within your team’s scope
	- Design, build, operate, and maintain critical systems, owning the reliability, performance, and availability
	- Be a part of your team’s on-call rotations and take ownership of the services you’re running
	- Mentor and support other team members, participate in design discussions and collaborate with the team
	- Learn new skills by gaining a deeper understanding of our cloud product and our customers and getting to know the codebase of a large distributed system
	- As we are remote-first and our engineering organization is largely remote, we provide guidance and meet regularly using video calls, so an independent attitude and good communication skills are a must.
	- You are a motivated self starter with a bias towards action
	- You are customer focused. We build everything with our users in mind. You have a passion for creating intuitive products that fit customers’ needs 
	- Pragmatism. You are able to take on complex challenges and break them down to achieve tight learning loops: to analyze, design, and build modular solutions, deliver MVPs, gather data and feedback and then progress iteratively
	- Collaboration and communication: The smallest unit we have is a team. You’ll be working with your teammates in a fully remote setup. Good communication skills are a must
	- Solid experience with at least one programming language. We use Go, but if you have familiarity with Python, C, C++, Rust or similar then that translates well
	- Some experience with delivering projects from gathering requirements, brainstorming ideas all the way to shipping a product to the customer’s hands in a self-driven way
	- Some experience with developing software that runs in the Cloud or some experience with systems engineering
	- Experience writing clean, robust, and performant software that is easily maintained by others
	- Experience working with Kubernetes
	- Been a user of Grafana and Prometheus in operational roles (including on-call for your team at a previous employer or just using these tools on hobby/homelab projects)
	- Exposure to microservices architecture and distributed systems, or a desire to learn
	- Familiarity with being on-call and perfoming operations/SRE tasks or with the concept of infrastructure as code
+ skill set:
	- Software Engineer - Cloud
	- As a Software Engineer, you'll be part of Splunk’s core cloud platform and responsible for designing and developing Kubernetes operators that manage our Streaming, Messaging, Searching, Indexing workloads. Be part of a small closely-knit team in the Bay Area and have a large impact in crafting the team, technology, and a culture of excellence. You will be immersed in both microservices and core platforms as well as have exposure to the full portfolio of technology areas.
	- You are an expert in distributed computing, cloud-native software architecture/development, and efficient in-memory algorithms. Initiative, passion, and commitment are your soft currency. You are excited to take on roles that provide new growth and learning opportunities. Finally, you enjoy working with highly collaborative teams and have fun doing your stuff!
	- Design and develop algorithms/code for Splunk Enterprise roadmap for Cloud.
	- Collaborate in a CI / CD development model for cloud-native deployments.
	- Create high-quality distributed design and code and maintain it in cloud.
	- Analyze and improve performance, scalability, and reliability.
	- Brainstorm and influence technical decision-making for features and architecture turns.
	- Have fun and achieve your career goals.
	- 5 years of related experience with a technical Bachelor’s degree; or equivalent practical experience
	- Demonstrable foundation in data structures, algorithms, and software design for cloud-scale.
	- Familiarity and experience with Microservices Architecture & AWS
	- Familiarity in building cloud microservices and distributed systems in Golang.
	- Familiarity with agile development models for cloud-native architectures (Microservices, automated CICD, RESTful API’s SOA, etc) at cloud scale.
	- Knowledge of networking protocol stacks (TCP/IP, HTTPx, DNS).
	- Familiarity with Kubernetes, Docker, and AWS/GCP.
+ You have knowledge and experience with AWS services, like EC2, S3, etc.
+ skill set for Cloud File System Development Engineer:
	- Lead technical planning in the cloud file system domain, optimize the overall filesystem architecture, and improve the cloud file system competitiveness.
	- Improve file system competitive advantages, design and develop key features such as cross-AZ, active-active, and cross-region file system synchronization.
	- Participate in end-to-end delivery of cloud file services, covering phases such as requirement analysis, module design, development, and rollout. Communicate with the customer CTO about HUAWEI CLOUD file system solutions.
	- PhD in storage, and research background in file systems
	- Practical experience and extensive knowledge of mainstream distributed file system architectures
+ skill set for Cloud Computing Engineer:
	- Design and develop the PaaS platform system architecture of cloud computing, including containers, microservices, function computing, and middleware. Ensure efficient and secure running of the PaaS cloud platform, and strive to improve code quality, service performance, and user experience.
	- Participate in open-source projects in the PaaS domain, such as Kubernetes, Docker, Istio, and ServiceComb, and track new technologies and implementation of cloud computing PaaS.
		* Kubernetes
		* Docker
		* Istio
		* ServiceComb
	- Fully understand customer requirements and provide technical solutions to resolve problems.
	- Computer science or related major. Proficient in at least one programming language. Expertise in Go, Python, and Shell preferred
	- Expertise in cloud computing technologies such as Kubernetes, OpenStack, and Docker. Use or development experience preferred
	- Solid knowledge of distributed systems, cluster management, and SOA architecture technologies, as well as web frameworks and technologies. Experience with large-scale cluster O&M or distributed system software development preferred
	- Strong interest in technologies. Understanding of the architectures and technologies of mainstream commercial cloud service platforms at home and abroad. Successful experience completing cloud computing projects preferred
+ experienced with Memcached and Redis
+ domain-driven design, and service-oriented architecture
+ App Engine cloud computing platform
+ apply diverse tools and technologies to solve existing problems, such as: C\#, Go, Rust, Docker, Hashistack's Consul, Vault, and Nomad.
+ skill set:
	- Distinguished Engineer (Architect) Experiences Platform
	- You will play a critical role in being our innovative and passionate area lead architect that oversees the main front-end platform that powers splunk core platform.  You will help forge technical, design, product, and architecture direction for our hybrid strategy that stratifies cloud technologies with desktop web, native mobile, and future form factors that will connect the dots for success with our customers today.  You work across teams and organizations to ensure that the architecture and design are of high quality, stable, scalable and reliable. You will establish the technical architectural standards and drive the overall technical design and best engineering practices through design reviews, architecture reviews, hackathon activities, customer visits and engagement with Ecosystem Partners.
	- Be a Technical Area Lead working with 175+ engineers
	- Craft and execute the technical road map to develop the next generation hybrid cloud Application platform
	- Integrate outstanding architecture principles and goals into the team’s projects through designs, implementation strategies, and project sequence
	- Help grow, mentor, and shape engineering culture for engineering
	- Work with product managers early on to craft product definition so that it can be built in a flexible, extensible, and robust way.
	- Drive a culture of quality, technical curiosity, continuous improvement, and data-driven decision-making
	- 15+ years of software development, including extensive large scale front-end applications (native mobile, multi-tenant Web Applications), and SDKs
	- Hands on expertise in recruiting for top talent
	- In-depth understanding of application performance and work through high volume scalability issues
	- Prior experience with Splunk or a similar analytics solution
	- ***Experience in multi-year transformation initiatives and playing a critical role***
	- ***Experience in the visualization of large, sophisticated graph structures***
	- Experience working on open-source projects
	- Requires a minimum of 15 years of related experience with a technical bachelor’s degree; or 12 years and a technical Master’s degree; or a PhD with 8 years’ experience; or equivalent experience.
+ Experience with queueing and streaming systems like Kafka, RabbitMQ, etc
+ Production experience with AWS tools including at least some of the following: EC2, S3, Kinesis, CloudFormation, Redshift
+ skill set:
	- Familiarity with configuration management, particularly using Ansible + Napalm.
	- Comfortable working with Arista EOS and Juniper JunOS.
	- Expert-level exposure to IP routing, particularly with BGP, OSPF, and IS-IS.
	- Knowledge of MPLS, DWDM, and other backbone-related technologies
	- Experience in network segmentation strategies, BGP VPNs, VXLAN, and segment routing
+ skill set:
	- We are implementing a new master data management system within a new backend service API, using modern best practices such as REST, microservices, CI/CD, and polyglot persistence.
	- Our team is versatile, polyglot, and cross-functional. We work in Python, AWS, NodeJS, Scala, Elasticsearch, Informatica, Terraform, and much more. The team is geographically dispersed, and values transparent, collaborative communication and cooperation.
	- Ownership of platform and domain architecture for Enterprise Data Management systems and related components in the Customer Domain
	- Consulting and collaborating with all stakeholders to adequately understand requirements for software architecture and implementation.
	- Defining and drafting architecture artifacts, roadmaps, and program vision for consumption across technical and non-technical teams.
	- Evangelizing, defending, and adapting architecture decisions and direction according to business drivers
	- Define and consider the full lifecycle of software systems and components
	- Advise, mentor, educate, and influence teams across Autodesk
	- Continuous professional development, to ensure awareness and expertise in leading-edge best practices and evolving technology drivers and landscapes
	- Consciously monitoring implementation to ensure non-functional requirements such as availability, scalability, reliability, security, compliance, governance are all in place
	- 10+ years' experience delivering software with a strong focus on data, working throughout a cross-section of the software engineering spectrum (APIs, front-end, backend, security, authentication/authorization, data, service, persistence layers, automated testing, etc.)
	- Demonstrable experience as an architect for a large organization in major software domains (CRM, ERP, HR, etc.)
	- Extensive experience integrating software domains within an enterprise
	- Ready to apply and adhere to best practices and standard methodologies in software and architecture
	- Strong experience in API (REST/SOAP) and Pub/Sub architecture with hands on implementation experience at scale
	- Experience architecting for applications on cloud infrastructure (AWS, Azure)
	- Strong experience using and designing for relational/non-relational databases
	- Familiarity with a large cross-section of current software landscape
	- Not dogmatic about a particular approach and are ready to take the best idea in the room
	- A strong sense of ownership with a bias for action
	- Superior communication and cooperation skills
	- Ability to work independently and collaboratively across an organization
	- Confidence to lead and stand by recommendations in the face of challenges
	- Ready to try and take-on new technologies, ideas, and/or engineering challenges
	- Eagerness to learn and share knowledge with a good attitude
	- Experience with Master Data Management (MDM) theory and platforms
	- Experience with SAP and/or ERP systems
	- Experience with Salesforce and/or CRM systems
	- Experience with Compliance and Data governance (GDPR, SOX, etc.)
	- Experience implementing Domain Driven Design
	- Continued hands-on code-level expertise
+ skill set:
	- Content delivery network (CDN) experience
	- Experience with Amazon Web Services (i.e. EC2, S3, RDS, CloudFront, CloudWatch, Lambda, CloudFormation, etc.)
+ skill set:
	- Reduce RPO/RTO for our S3, RDS, Redis, MongoDB, etcd and PostgreSQL instances
	- Maintain/upgrade our Spinnaker + Kubernetes CI/CD pipeline, and the tooling that makes it all work, in a sane and reproducible way
	- Automate infrastructure deployments with CloudFormation and SaltStack to help us go multi-AWS region
+ skill set:
	- Experience working with either AWS or GCP services such as compute, databases, VPCs, networking, permissioning and storage
	- Experience with automation tools and configuration-as-code (CloudFormation, Ansible, Puppet, Chef, Vagrant, etc.)
	- Experience with continuous integration/delivery services
	- Experience with containerized code deployment
	- Experience with networking concepts and protocols
	- Experience managing large cloud infrastructures
	- Experience scaling and ensuring reliability of large SaaS or PaaS applications
	- Experience with orchestration frameworks such as Kubernetes or Mesos
	- Experience with security, systems, or application monitoring and metrics
	- Cloud application deployment and monitoring
	- Data visualization for the web (using D3 or similar)
	- Statistics and predictive modeling (using tools like pandas, scikit-learn, NumPy, SciPy, R, STATA)
	- Query optimization, database administration, analytics databases, and/or NoSQL
+ skill set:
	- Experience designing and operating very large Data Warehouses
	- Deep understanding and knowledge of AWS stack - Redshift, EMR, S3
		* AWE stack: cloud-computing platform.
		* Amazon Redshift:
			+ data warehouse
			+ massive parallel processing (MPP) data warehouse company
			+ large scale data set and database migrations
			+ cloud data warehouse
		* EMR:
			+ Amazon EMR, Amazon Elastic MapReduce
		* S3:
			+ Amazon S3, Amazon Simple Storage Service
				- store any type of object
				- storage for:
					* Internet applications
					* backups
					* disaster recovery
					* data archives
					* data lakes for analytics
					* hybridy cloud storage
	- Ability to work with search technologies such as Elasticsearch
	- Knowledge of graph databases such as AWS Neptune
+ skill set:
	- Design and implement practical networks and systems with both edge and cloud considerations
	- By connecting IoT devices and the cloud, we will build a practical system with an awareness of cost and scalability. Addresses issues that require rapid network and system design and implementation that take into account stability and ease of maintenance.
	- Communication Language: Japanese
	- Coding ability using Python
	- Basic knowledge about the Web and network
	- Knowledge or experience of AWS or GCP
+ skill set:
	- Improving the container execution environment in Kubernetes
	- In order to improve the container execution environment of the Kubernetes clusters (MN-2, MN-3) currently in operation at PFN, we will investigate and evaluate necessary peripheral technologies, propose system designs, and develop them. You'll work on one of these topics: faster container startup times, exploring how to safely use Filesystem in Userspace (FUSE) over Kubernetes, or replacing the container networking stack.
	- Communication Language: Japanese
	- Basic knowledge and experience of using container technology (Docker, etc.)
	- Basic knowledge of Kubernetes
	- Go programming experience
	- Knowledge of container runtime implementations and related specifications
	- Basic knowledge of computer networks (TCP/IP, Ethernet, etc.)
	- Knowledge and experience in container networking related technologies (CNI Plugin, BGP, eBPF, etc.)
+ skill set:
	- Help us iterate quickly and deliver high-quality software releases, on-time
	- Understanding of service based cloud architectures
	- Work closely with the software engineering, product management and customer support teams to design, deliver, and manage our services with high uptime
	- Implement monitoring, develop automated provisioning, and develop self-healing automation
	- Perform incident resolution and root cause analysis of critical outages
	- Experience with design and maintenance of a cloud based highly-available (HA) architecture
	- Experience with configuration management and monitoring tools
	+ skill set:
	- The Project Portfolio Analyst oversees the activities that support the company's most complex strategic projects by ensuring reporting and governance alignment, providing portfolio performance measurements and recommendations, and trending analytics. This position is responsible for the Portfolio's intake, supply and demand (resource management) methods, analytics and recommendations. Reporting responsibilities includes detailed analysis, dashboards and decision support updates (KPI's) and recommendations on a regular cadence. The Portfolio Analyst will at times provide project support to Project and Change managers.  This position reports to the Associate Director, Organization Engineering.
	- Owns and administrates the project collaboration toolset including project portfolio management software and various collaboration tools
	- Develops and maintains a project risk tracking mechanism to centralize risk tracking across the company's project portfolio
	- Drives agile governance process that maintains control and compliance but improves project team effectiveness and improves decision making
	- Assists in developing project management processes, tools and training as well as project status presentations and reports
	- Supports the strategic planning process and cross-functional business reviews to include development of in-depth analysis, executive presentations, and resource modeling
	- Owns the project idea intake process to ensure project goal and scope are clearly defined, reasonable budget and timelines are established and the project is resourced effectively to deliver the desired solution
	- Owns the resource planning process to include maintaining resource management information and resource utilization modeling
	- Generates, validates, distributes, archives and supports project management documentation and reporting collateral
	- Monitors quality assurance of project implementation across a large portfolio of business and process improvement projects by establishing, monitoring and reporting on metrics to determine whether projects meet quality, cost and schedule targets
+ search backends like ElasticSearch
+ skill set:
	- design and build MDF/IDF infrastructure
	- operational knowledge of DNS, DHCP, and IPAM management through Infoblox
	- good understanding of infrastructure security, zero trust, SAML IdP
	- experience of configuring OSPF, BGP routing protocols
	- automation experience with:
		* Ansible
		* Terraform
+ cloud services:
	- S3
	- DynamoDB/RDS
	- ElasticSearch
+ You will work with technologies like: AWS, Docker (Mesos/Kubernetes), HashiCorp tools (Terraform, Consul, Vault,...), Chef, Ansible, SQL and NoSQL databases, Nginx, ...
	- HashiCorp tools
		* Terraform: open-source infrastructure as code software tool, for automating infrastructure as code
			+ infrastructure as code: manage data centers via machine-readable definition files, rather than physical hardware configuration or interactive configuration tools
			+ infrastructure provisioning automation
			+ automate infrastructure on any cloud
		* Consul
			+ automate service networking across clouds
			+ automate networking for simple and secure app delivery across clouds
			+ provides:
				- service mesh
				- DNS-based service discovery
				- distributed KV storage, distributed key-value database, distributed key-value store
				- RPC, remote procedure call
				- event propagation
		* Vault
			+ manage secrets and protect sensitive data
			+ create and secure access to tokens, passwords, certificates, and encryption keys
			+ provides:
				- secrets management
				- identity-based access
				- encrypting application data
				- auditing of secrets for applications, systems, and users
	- Chef, rebranded as Progress Chef
		* configuration management
		* software suite, or software tool suite, for enabling infrastructure as code, IaC
	- Ansible
	- Nginx
	- continuous configuration automation, CCA
		* methodology/process for automating the deployment and configuration of settings and software for physical and virtual data center equipment
		* tools include:
			+ Ansible
			+ CFEngine
			+ Chef
			+ Otter
			+ Pulumi
			+ Puppet
			+ SaltStack
			+ Terraform
+ skill set:
	- infrastructure-as-code, in Terraform and AWS
	- AWS CloudFormation, SAM, CDK
+ skill set:
	- AWS technologies
		* S3
		* EKS
		* SageMaker
	- monorepo environment
		* Nix
		* Bazel
+ skill set:
	- designing cross-origin resource sharing (CORS) and cross-origin resource policy (CORP) models to securely embed dynamic content from SaaS on customer-controlled domains
	- instrumenting and optimizing performance to improve:
		* bundle sizes
		* time to interactive, TTI
		* time to first byte, TTFB
+ Experience with cloud APIs (e.g., a public cloud such as AWS, Azure, GCP or an advanced private cloud such as Google, Facebook)
+ skill set:
	- architect systems that deliver low latency experience in a high latency environment
	- develop long-lasting external API contracts with little obsoletion/obsolescence or sunsetting.
+ AWS cloud services: EC2, EMR, RDS, Lambda, Redshift
+ Expertise with AWS services such as EC2, IAM, S3, etc.
+ AWS services: EC2, Auto Scaling, Lambda, RDS
+ If you have a solid background in software engineering and are familiar with Cloud Services (e.g. AWS, Google Cloud, or others), Node.js, Terraform, or Kubernetes we would like to meet you.
+ skill set:
	- Solid experience in Scala/Java understanding of Microservices Architecture.
	- Experience with Amazon Web Services, Spark, Splunk, Docker, Grafana, Prometheus, NGNIX.
+ architect highly scalable microservices
+ Cloud Native Computing Foundation, CNCF
	- Open source contributions to CNCF projects
+ skill set:
	- Staff Software Engineer II
	- Confluent is pioneering a fundamentally new category of data infrastructure focused on data in motion. Have you ever found a new favorite series on Netflix, picked up groceries curbside at Walmart, or paid for something using Square? That’s the power of data in motion in action—giving organizations instant access to the massive amounts of data that is constantly flowing throughout their business. At Confluent, we’re building the foundational platform for this new paradigm of data infrastructure. Our cloud-native offering is designed to be the intelligent connective tissue enabling real-time data, from multiple sources, to constantly stream across the organization. With Confluent, organizations can create a central nervous system to innovate and win in a digital-first world.
	- We’re looking for self-motivated team members who crave a challenge and feel energized to roll up their sleeves and help realize Confluent’s enormous potential. Chart your own path and take healthy risks as we solve big problems together. We value having diverse teams and want you to grow as we grow—whether you’re just starting out in your career or managing a large team, you’ll be amazed at the magnitude of your impact.
	- As Staff Engineer II of the new Compute Platform, you will be working closely with the team and other key stakeholders to design, architect and build out our secure, multi-tenant, polyglot, Cloud-native Compute substrate to enable new business opportunities across Confluent Cloud (including Connect, kSQLdb, Kafka and more) . As a senior technical leader, you think strategically and you help drive end-to-end technical delivery from customer experience to scaling internal operations. You are not confined to the status quo and you leverage your expertise in Cloud-native, large-scale distributed systems to help take our platform to the next level. You worry about key operational aspects (availability, reliability, performance, monitoring, emergency response, capacity planning, disaster recovery) of our new Compute Platform, and you make sure that we have a highly-available, resilient and secure offering that our largest customers can rely on. If you love the hum of big data systems, thinking about how to make them run as smoothly as possible, and want to have a big influence on the architecture plus operational design points of this new product, then you will fit right in.
	- Be part of driving the overall technical charter for the new Compute Platform -- including, but not limited to cloud infrastructure, big data systems, and security
	- Work closely with product management and engineering management to build and drive the overall roadmap for Confluent’s Compute Platform to enable new business opportunities
	- Deliver high impact to the business by driving important technical initiatives in areas comprising (but not limited to) security, reliability, multi-tenancy, architectural direction, and major component refactor across organizational boundaries
	- Be as a strong technical leader and representative for engineering across the Connect organization
	- Lead the team and the product on aspects of product definition, architectural design, and delivery
	- 10+ years of experience in delivering scalable software solutions
	- Proven track record of leading the delivery of large-scale, highly available, low latency, high quality systems
	- Deep hands-on technical expertise in large scale systems engineering or distributed systems
	- Expertise in Container & Virtualization/Hypervisor technologies (firecracker/gVisor/ cloud-hypervisor/kata-containers, etc.)
	- Expertise in Cloud Native technologies including networking & security
	- Experience with Linux kernel technologies (kernel modules, cgroups/namespaces, eBPF, XDP, etc.) a plus
	- Expertise in Language Runtimes / VMs (JVM/WASM, etc.) a big plus
	- Experience in driving operational excellence for large, production services
	- Track record of providing technical leadership and mentorship
	- Track record of working collaboratively across teams and roles, including but not limited to product management, UX, and other engineering teams and leaders.
	- A smart, humble, and empathetic attitude
	- A strong sense of teamwork and are excited about team and company success
	- Drive and excitement about challenges of a fast-paced, innovative software startup environment
+ skill set:
	- Experience with technologies like Spring Boot, GraphQL, RDF, Neptune, Kafka, Cassandra, CockroachDB, and Elasticsearch
	- Experience building event/messaging systems using technologies like Kafka.
+ skill set:
	- Experience with Pub-Sub (Kafka), Stream Processing (Spark/Flink, etc.)
	- Expertise in solving large data challenges.
	- Experience with Cloud Computing platforms (AWS/Azure/GCP).
	- Background in building financial or payment solutions. Experience in leveraging ML is a plus.
+ skill set:
	- You have used big data technologies (i.e. Spark/MapReduce/Hadoop, etc.) at one point in your career, and have built web-scale data pipelines.
	- You have used SQL and reporting tools at one point in your career, and are analytically savvy.
	- The overall market range for roles in this area of Netflix is typically $310,000 - $1,200,000.
+ Amazon WebServices (AWS) such as Athena, Glue, DynamoDB and S3, RDS.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.











##	Software Development for Messaging as a Service (MaaS)



###	Notes about Messaging as a Service (MaaS)








###	Skill Sets for Messaging as a Service (MaaS)


+ skill set:
	- Software Engineer - Data Stream
	- The Splunk Messaging as a Service (MaaS) team is responsible for providing enabling technology that powers messaging, queueing and streaming for several products in the cloud and on-prem. You will be part of the team and work with other team members, engineering and Product Management to plan, develop and deliver various features and functionalities.
	- Design technical implementations for new features in Apache Pulsar. Implement new features &test & analyze performance of existing and new features. You'll help identify and fix bugs discovered during use and/or testing
	- You'll be writing unit tests, integration tests and collaborating with the Quality Assurance team to ensure features quality.
	- You'll collaborate and coordinate with Product Management team to implement features or fix bugs
	- Innovate and contribute to product road map
	- We hope that you have a passion for mentoring as you'll have the opportunity to lead software architecture and design processes.
	- 5 years of related experience with a technical Bachelor’s degree; or equivalent practical experience;
	- Ability to own a set of product/service features, connectors, tests and/or modules using primarily Java on Apache Pulsar infrastructure in Linux environment.
	- Excellent Java skills with distributed systems design and knowledge of OO programming practices.
	- Familiarity with container technology such as Docker and Kubernetes
	- Strong knowledge of shell scripts and/or Python.
	- Expert knowledge with the Unix/Linux environment.
	- Knowledge of docker/Kubernetes frameworks.
	- Excellent solid understanding of Apache Pulsar, RabbitMQ, or Apache Kafka.
	- In-depth understanding of modern SQL, NoSQL or NewSQL systems.
	- Strong knowledge on code repository and/or automation server tools.
	- Validated skills in load testing, performance tuning, monitoring and measuring.
	- Very clear computer science fundamentals, data structure knowledge and software engineering principles.
	- Passion for solving hard problems and exploring new technologies.
	- Excellent Team player with good communication and documentation skills.
+ skill set:
	- Software Engineer, Ingestion and Data Processing
	- Ingestion and Data Processing team is a dynamic technology group with a mission to be the primary data processing path for any type of data transformation and routing activity in near real-time. If you possess a passion for extraordinary technology and embrace the challenge of working at the frontier of what is possible in the industry today, then this position is for you. We are building state-of-the-art capabilities, real-time messaging and streaming systems, support tools, and automation instrumentation that will greatly impact how our customers successfully use data to improve their businesses performance, scalability, profitability, and market strategies. We have two teams in rapid growth:
		* Stream Processing Service (SPS) is built on top of Apache Flink, is a stream processing platform that allows customers to define stream processing pipelines without lower-level programming languages. SPS includes the ingestion, routing, and processing of unbounded data sets and reduces the time-to-insights from days to near-real-time. SPS is a critical component to enable our customers and their data to transition seamlessly to the cloud.
		* Messaging as a Service (Maas) is based on Apache Pulsar and provides a streaming event store for multiple sources arriving into Splunk Cloud. MaaS is a streaming message store that allows consumers to store, partition, and consume streaming events with high throughput and low latency. It aims to be the event streaming backbone for Splunk Cloud and is integral to the Data Processing ecosystem similar to the interaction between RAM and CPUs in computers.
	- Own and be accountable for the design and development of multiple features in the ultra-high performance system, processing massive amounts of data
	- Pay extra attention to non-functional requirements (Performance, Scalability, Reliability, High Availability etc.)
	- Be a role model that ensures the team is following Agile software development and quality standards
	- Regularly lead design and code reviews, and participate in architecture discussions
	- Help team estimate development work, often across a multiple sprint timelines
	- Understand the business use cases and contribute to product direction by prototyping innovative ideas
	- See opportunities for engineering improvements or directions, and evangelize these successfully
	- Receive guidance from principal engineers in their area on thinking beyond their current product features and more towards overall product architecture
	- Participate in customer engagements & partner concerns and drive overall resolution
	- Build healthy relationships with multi-functional teams
	- Work with product manager to influence product feature definition
	- Expertise on two or more mainstream programming languages, such as Go or Java
	- Expertise on developing and working with thoughtfully designed HTTP APIs, such as REST or GraphQL
	- Expertise on test-driven development, developing different levels of automated tests, such as unit test, functional test, integration test, system test, or performance / load test
	- Proficient with CI/CD, such as Jenkins, GitLab CI, or Bitbucket pipeline
	- Proficient with modern version control system, such as Git
	- Proficient with development on multiple operating systems, such as Linux or Unix
	- Able to learn new technologies quickly
	- Capable of coordinating and coaching the junior members in the team
	- Bachelor’s degree in Computer Science, Computer Engineering or equivalent
	- Experience with cloud technologies, such as AWS, Azure, or GCP. Ideally with certifications
	- Experience with container technologies, such as Docker. Ideally with container orchestration such as Kubernetes or Docker Swarm
	- Experience with stream processing platform, such as Flink, Spark or equivalent
	- Experience with messaging system, such as Apache Pulsar, Kafka or equivalent
	- Experience with leading or contributing to open source projects
+ Experience with large scale messaging systems like Kafka or RabbitMQ or commercial systems.
+ messaging systems, such as AWS SQS, AWS Kinesis, Kafka, or RabbitMQ, ZeroMQ
+ skill set:
	- Software Engineer, Messaging Platforms
	- The Messaging Platform group is at the heart of messaging at The New York Times. Our mission is to create and maintain multiple messaging platforms and capabilities that deliver the right message at the right time to foster deep connections with people trying to understand the world. This work is key to driving customer acquisition, engagement, and reader loyalty.
	- We do this by providing data-driven insights, user-friendly tooling, and cutting-edge technology that empowers our editorial and business teams to send highly personalized communications at the speed of breaking news.
	- We are looking for a software engineer to join our messaging optimization team. This team is focused on building resilient, scalable back-end systems with client-agnostic APIs for our in-house messaging platform as well as managing our 3rd party messaging platform, Responsys.
	- Contribute to the full development lifecycle of our products, performing activities related to design, development, testing, deployment, monitoring, and on-going support of our systems and capabilities.
	- Work with product & stakeholders to identify requirements and platform needs.
	- Design, implement, and document REST APIs inside a Go codebase.
	- Design and build integrations between internal data pipelines  and our 3rd party marketing platform, Responsys.
	- Automate workflows related to managing and updating data within the marketing platform.
	- Collaborate proactively and effectively within a distributed team.
	- Prioritize growth and development by learning the tools, resources, and processes that are used by the team; take ownership of personal improvement by regularly soliciting and incorporating feedback from others.
	- You will report to the Engineering Manager of the Messaging Optimization team.
	- 3+ years in building large scale software applications.
	- Experience with relational and/or NoSQL databases (e.g., MySQL, PostgreSQL, MongoDB).
	- Knowledgeable about cloud-based infrastructure and technologies (e.g., AWS, Azure, Google Cloud Platform).
	- Extensive experience with building backend systems, including REST APIs.
	- Unit/Integration testing experience.
	- Strong problem-solving skills, excellent communication and collaboration.
	- Experience integrating with martech tools & systems.
	- Experience with Go.
	- Experience with data engineering and data pipeline development.






























##	Software Development for Infrastructure as a Service (IaaS)



###	Notes on Infrastructure as a Service, IaaS

IaaS:
+ provides you with high-level APIs used to dereference various low-level details of underlying network infrastructure
	- backup
	- data partitioning
	- scaling
	- security
	- physical computing resources
+ A hypervisor runs the virtual machines as guests.
	- hypervisors include:
		* Xen
		* Oracle VirtualBox
		* Oracle VM
		* KVM
		* VMware ESX/ESXi
		* Hyper-V
+ Pools of hypervisors within the cloud operational system can support large numbers of virtual machines as well as the ability to scale services up and down according to customers' varying requirements.
+ provide virtual management of hardware/physical resources:
	- servers
	- networks
	- storage
	- system management
	- mitigate the need for:
		* local data center
		* heating or cooling of local data center
		* hardware maintenance of local data center
+ network as a service, NaaS
	- allow users to use software-defined network (SDN), programmable networking, and API-based operations to wide area network (WAN) services, and hybrid cloud and multi-cloud.
		* support for (multi-tenant) data center facilities, MTDCs
		* public cloud service providers (CSPs)
	- includes:
		* connectivity cloud
		* virtual private network, VPN
		* virtual network operation
			+ mobile virtual network operator, MVNO






###	Skill Sets for Infrastructure as a Service, IaaS




+ ***Infrastructure as Code (IaC)***:
	- ***Ansible***
	- ***Terraform***
	- https://en.wikipedia.org/wiki/Infrastructure_as_code
+ skill set:
	- 10+ Years of professional software engineering experience in building large-scale distributed systems
	- Strong hands-on experience in developing applications in one or more language stacks: Java, Python, Go
	- Strong experience in building platform-level shared libraries, frameworks, components, tools and services
	- Strong understanding of object-oriented programming, service-oriented architectures, microservices and design patterns
	- Strong hands-on experience in one or more of Containers and Container Orchestration frameworks: Docker, Kubernetes, Docker Swarm, Amazon ECS, Amazon EKS, AWS Fargate, etc.
	- Strong hands-on knowledge of one or more of Infrastructure-as-Code tools and technologies: Terraform, AWS CloudFormation, Packer, etc.
	- 3+ Years of experience in public cloud infrastructures: AWS preferred
	- Experience with Service Mesh, Service Discovery, Routing tools and technologies: Istio, Consul, ZooKeeper, zuul, linkerd, envoy, etc.
	- Experience with Metrics, Monitoring & Alerting tools: Catchpoint, Sensu, Prometheus, Nagios, Zabbix, InfluxDB, Graphite, Grafana, AWS CloudWatch, Datadog, etc.
	- Experience with APM tools: New Relic, Dynatrace, etc.
		* APM refers to:
			+ Application Performance Monitoring (APM)
			+ application performance management
			+ It does not refer to:
				- "Application Portfolio Management"
	- Experience with Log Management tools: ELK stack, Splunk, etc.
	- Experience with secrets management, certificates, encryption and keys: Vault, AWS KMS, etc.
	- Experience with CI/CD, DevOps and Pipeline-As-Code: Jenkins
	- Exposure to Configuration Management Tools: Chef, Puppet, etc.
	- Exposure to Function-as-a-Service, AWS Lambda, Serverless, etc.
	- Experience with Agile software development and Scrum methodology
	- Practice strong software development principles and best practices: Test-driven development (TDD), CI/CD, code refactoring, coding standards, etc.
+ BIM (Building Information Model)
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.


##	Software Development for Platform as a Service (PaaS)


###	Notes about Platform as a Service (PaaS)


Notes about Platform as a Service (PaaS):
+ also known as:
	- application Platform as a Service (aPaaS)
+ platform-based services that allow customers to carry out the following for a modular bundle based on a computing platform and a set of software applications (with a cardinality of at least one)
	- no infrastructure building or maintenance needed ensure the development and launch of the software applications
		* provision
		* instantiate
		* run
		* manage
	- allow software developers to do the following for software bundles:
		* create
		* develop
		* package
+ unified communications as a service, UCaaS
	- for enterprise communications
+ provide users with application platforms and databases as a cloud computing service
	- comparable to middleware in traditional (non-cloud computing) delivery of application platforms and databases




###	Skill Sets for Platform as a Service (PaaS)



+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.



##	Software Development for Software as a Service (SaaS)


###	Notes about Software as a Service (SaaS)


Notes about Software as a Service, SaaS:
+ security problems with SaaS
	- use of malware-as-a-service, MaaS, as a security threat
		* Reference:
			+ SplunkIncStaff2010
				- Splunk Inc. staff, "Malware-as-a-Service (MaaS)?", Splunk Inc., San Francisco, CA, June 10, 2010. Available online from *Splunk Inc.: Resources: Splunk Blogs -- Turn Data Into Doing: Categories: Security* at: https://www.splunk.com/en_us/blog/security/malware-as-a-service-maas.html; July 30, 2022 was the last accessed date.
+ software licensing and delivery model in whhich software is licenses on a subscription basis and is centrally hosted
	- Provides:
		* on-demand software
		* Web-based software
		* Web-hosted software
		* OpenSaaS
			+ Open-source software provided as SaaS
+ approaches of SaaS:
	- single instance
	- multi-instance
	- multi-tenant
	- flex tenancy




###	Skill Sets for Software as a Service (SaaS)


+ skill set:
	- Cloud SaaS Architect – Italy
	- Layout roadmap, design, plan, and implement scalable information technology solutions that meet current and future business needs together with the Platform Engineering Director
	- Build resilient system implementations to ensure information security, stability and availability of business applications
	- Work closely with the Site Reliability Engineering Team to maintain standard, reliable, and consistent system configurations across the company enterprise as appropriate
	- Monitor current and future technology trends and make recommendations of solutions and standards that meet the business needs and drives improvements
	- Lead any Proof of Concept projects required to thoroughly investigate architectural possibilities and strengthen arguments for their adoption
	- Develop and deploy software-as-a-service (SaaS) applications within popular public cloud platforms
	- Communicate architecture design decisions and impacts to key stakeholders
	- Understand of the current state of the art for infrastructure automation, continuous integration/deployment, SQL/NoSQL/NewSQL, networking, and cloud-based delivery models
	- 10+ years of overall IT/software development expert, in solution design and technical architecture
	- 5+ years of driving application architecture design specialist
	- You have 3+ years of experience with cloud computing solutions implementations – AWS preferred
	- Experienced in cloud computing based services architecture, technical design and implementations including Infrastructure as a Service (IaaS), Platform as a Service (PaaS) and Software as a Service (SaaS) delivery models
	- Experienced in Internet, Intranet, Extranet and client/server architectures
	- Experienced in how legacy and web-based systems interfaces, Application Programmable Interfaces (APIs) interact
	- A specialist of Systems Development Life Cycle (SDLC) methodology and coding methods/best practices
	- Able to design and implement reliable, scalable, high performing Web based solutions that meet the service levels associated with mission-critical Identity and Access Management based solutions
	- You have a strong knowledge of Security Architecture, Design and Operations. Together with LDAP, Active Directory, SAML, SPML, SSO, RBAC, and web protocols XML, SOAP, JSON, REST
	- Educated about software development security and cryptography
	- You know how to handle Java EE and other development frameworks, cloud/containarization technologies such as EC2, docker, Kubernetes
	- Proficient with various open source software and development tools and in one or more of Java, Go, Kotlin. You are also proficient in GIT
	- Expert and understanding of one or more different agile methodologies, including Scrum, XP, or SAFe
	- Curious about learning technology and problem solving
	- A 2+ years of SaaS implementation experience is strongly preferred
+ skill set:
	- Software Engineer - Cloud Computing Service
	- QuEra Computing is seeking a methodical and creative Software Engineer to collaborate on the design, build, and evolution of the system that is central to realizing the first neutral-atom quantum computer to be accessible via the public cloud.
	- QuEra Computing is a world-class team of physicists, engineers, and entrepreneurs focused on the challenges of developing, launching, operating and evolving a novel cloud-accessible  quantum computing service.
	- We are committed to harnessing the unique programmability and scaling advantages of the neutral-atom platform to achieve useful quantum advantage across a range of disciplines, applications, and customers.
	- To bring this new technology and programming model from the lab to the the world requires us to grow the depth and breadth of our collective skills and expertise.
	- You are not satisfied with mediocre cookie-cutter approaches. You thrive when challenged to step outside the familiar in order to design solutions that are tailored to user needs.
	- Your experience with event-based application models and event brokers affords you insight into how those models and technologies offer distinct architectural advantages, how they are best applied, and, just as important, when they are not good fits.
	- You are eager to practice your passion for domain-driven design and BDD by collaborating on an interdisciplinary team as we iterate on the solutions to customer problems that will benefit from the advantages of the neutral-atom quantum computing platform.
	- Your approach to writing code is informed by the DDD patterns that pertain to the relationships between bounded contexts as well as the insights you’ve gained in practicing design for testability.
	- You demonstrate the ethos of continuous improvement in your eagerness to discuss and apply lessons learned from successes and failures, past and present.
	- Design and Programming
		* functional programming: first-class functions, immutability, algebraic data types
		* TDD
		* BDD
		* DDD
			+ Bounded Contexts with Intention-Revealing Interfaces
			+ Shared Kernel, Partnership, Customer-Supplier, Anti-Corruption Layer, Separate Ways
			+ Ubiquitous Language
	- Application architecture
		* event stream processing
		* microservices
		* cluster databases
		* REST API
		* significant use of >2 AWS services in cloud apps
	- System architecture
		* applications that span cloud and on-prem
	- Security
		* role-based access control
		* encryption of data in flight and at rest
	- Languages
		* Kotlin or other language with strong functional constructs
		* Java interop
		* Julia
		* Python
	- Process
		* low-ceremony agile
		* CI
		* high-cadence delivery
	- For consideration, please submit your resume with a cover letter that highlights specific examples from your experience:
		* How you apply DDD, BDD, and design for testability to collaborate with colleagues across diverse disciplines to design, implement, and evolve high-quality custom software that solves specific customer problems.
		* Your use of event-brokers, which programming languages you used, and how that has informed your approach to design, modeling, and implementation of custom software systems.
		* How you have taken on the challenges inherent in a commitment to continuous improvement.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.




##	Software Development for Mobile "backend" as a Service (MBaaS), or Backend as a Service (BaaS)


###	Notes about Mobile "backend" as a Service, MBaaS, or Backend as a Service, BaaS


Mobile backend as a service (MBaaS), also known as "backend as a service",[1][2][3] is a model for providing web app and mobile app developers with a way to link their applications to backend cloud storage and APIs exposed by back end applications while also providing features such as user management, push notifications, and integration with social networking services.[4] These services are provided via the use of custom software development kits (SDKs) and application programming interfaces (APIs). 




###	Skill Sets for Mobile "backend" as a Service, MBaaS, or Backend as a Service, BaaS





+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.



##	Software Development for Serverless Computing or Function-as-a-Service (FaaS)


###	Notes on Serverless Computing or Function-as-a-Service (FaaS)

Notes on serverless computing or Function-as-a-Service, FaaS:
+ provides a platform allowing customers to develop, run, and manage application functionalities without the complexity of building and maintaining the infrastructure typically associated with developing and launching an app
+ Building an application following this model is one way of achieving a "serverless" architecture, and is typically used when building microservices applications.
+ allocate machine resources on demand
+ take care of servers on behalf of customers
+ serverless databases
	- Azure Data Lake, Azure Data Lake Analytics
	- Amazon Aurora
	- Oracle Autonomous Database, Oracle Autonomous Transaction Processing service
+ Examples of serverless computing or Function-as-a-Service, FaaS:
	- data processing
		* batch processing
		* stream processing
		* extract-transform-load, ETL
	- Internet of things, IoT, services for Internet-connected devices
	- mobile applications
	- Web applications




###	Skill Sets for Serverless Computing or Function-as-a-Service (FaaS)



+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.

















##	Skill Sets for Database as a Service (DaaS)


















