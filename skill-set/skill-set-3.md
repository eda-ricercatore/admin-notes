+ skill set:
	- Fluent in machine learning frameworks such as TensorFlow, PyTorch, Caffe, or Theano and libraries such as NumPy and pandas.
	- Passion for seeing research through from initial conception to eventual application.
	- Past experience with writing performant implementations of ML research.
	- Have experience working with CUDA, Docker and AWS platform (Lambda, S3, RDS, and/or EKS).
	- Have an artistic/creative practice of your own.
	- Have published high-impact machine learning research.
	- Have experience in a creative application (Unity, Photoshop, Blender, Processing, etc)
+ Experience with Hadoop/Hbase/Pig or MapReduce/Sawzall/Bigtable
+ topics in mathematics and statistics to learn:
	- Linear Algebra
	- Probability (e.g. Bayes' Theorem, Distributions, Conditional Expectations)
	- Multivariate Calculus (e.g. Integration, Multivariate Differentiation)
	- Unsupervised Learning (e.g. KMeans, mixture models)
	- Regression (e.g. Linear Regression, ANOVA)
	- Classification (e.g. Naive Bayes, Logistic Regression, SVM, Random Forests)
	- Numerical Analysis
	- NLP (e.g. Bag of Words, TF/IDF, Topic Modeling)
	- Time Series (e.g. AR, ARMA, ARCH, EMA)
	- Matrix Factorization (e.g. PCA, NMF)
	- Statistics (e.g., hypothesis testing, t-tests, p-values)
	- Experimental Design
+ skill set:
	- The Pocket Casts team is looking for an experienced full stack engineer to join our team in a full time capacity. If successful you'll be working on everything from our new web front ends to our rapidly expanding backend microservices.
	- At least 5 years of experience in server side programming languages such as Java or Kotlin.
	- Strong database skills, with knowledge of Cassandra or similar NoSQL databases a big plus.
	- Web development skills with HTML, Javascript and CSS.
	- Deep knowledge of Linux based terminal commands and processes.
	- Strong focus on unit testing and integration testing.
	- Communication and interpersonal skills are a must.
	- Interest and exposure to other programming languages and frameworks such as Kotlin, Vertx and Ruby on Rails.
	- Experience building servers and services at scale.
	- Front end development experience in React or similar Javascript frameworks.
	- Knowledge or experience with The Box, The Box II or The Box III Gavin Belson Signature Edition.
+ skill set:
	+ Hadoop
	+ OOZIE
	+ Hive
	+ HBase
	+ Druid
	+ Kafka
	+ Spark
	+ Storm
	+ ATS, or AWS???
	+ Java
	+ Jetty
	+ Kubernetes
	+ Docker
	+ MySQL
	+ Jenkins
	+ Git
	+ tools and technologies for CI/CD, configuration, monitoring and alerting management.
+ skill set:
	- We are a bunch of AI quants trying to change the retail investing game. No really, we are trying to change the investing world by challenging the existing paradigm for individuals like you. Why should ONLY the big investment banks and elite hedge funds have access to recent advancements in quantitative and AI investing? We are trying to help the average person invest and save through the power of AI. Why should someone like you be forced to settle? We don't think you should. Your money matters too!
	- We have a team-oriented culture built on mutual respect, integrity, accountability and doing the right thing. Trying to challenge the investment titans is serious, but we also try to have fun 24/7. It really is hard for us to contain our excitement about how AI can change the investing game for the retail investor. We never settle and are always hustling. Most importantly, we never stop dreaming and are ALWAYS looking to disrupt!
	- Creating consumer-facing financial products to help individuals invest and save better. With the help of smart algorithms, we think individual investors can realize some awesome returns in their portfolios. Stocks? ETFs? Options? Cryptocurrencies? We do it all and even more! Why throw darts at a stock market dart board? Let our AI algorithms crunch the numbers, so that individual investors like you can make the trade!
	- You will be joining the R&D team at Quantalytics AI Labs and will be working directly with the Founder/CEO to make sense of some wacky and super large Big Data sets that power our AI-powered financial tools. The Quantalytics AI Data Scientist will be looking at financial data, sentiment data, traffic data, blockchain data and other interesting alternative datasets to find hidden alpha to power our algorithms, models and content generation machines.
	- Who are you?
		* Love how Big Data and statistics are transforming investment markets
		* Excited about how AI technology can change the way people invest
		* Love coding
		* Believe Blockchain can change the world
		* Happy
		* Curious
		* Helpful
		* Accountable
		* Team Player
	- Personal Competencies:
		* Strong background in advanced statistics and financial engineering
		* Experience with Deep Learning and Reinforcement Learning
		* Fluent in Python and C++
		* Have experience with R, Julia and Golang
		* Experience with Deep Learning and Reinforcement Learning
		* Strong communication skills
		* Experience working as part of a remote team
		* Self-motivated, detail-oriented
		* Strong organizational skills
		* Document everything
		* A methodical approach to all tasks
		* Ability to prioritize workloads and meet deadlines
		* Fluent English speaker
	- Responsibilities:
		* Work directly with Founder/CEO to build new datasets for our AI models
		* Organized and structure raw datasets we use to help our AI models learn better and quicker
		* Architect and build AI investing algorithms for financial markets
		* Write high-performance code designed to scale
		* Able to take a design/proposal and carry it through to a thoughtful and polished end result with good test coverage
		* Take initiative to improve the software whenever you notice something lacking
		* Write documentation around features and operations to help share knowledge and save other developers time
		* Have the ability to learn and grow
	- Requirements:
		* 3-5 years years professional experience as a data scientist
		* Experience in financial markets is preferable
		* Extensive experience with Python and C++
		* Experience with R, Julia and Golang is preferable
		* Experience with API requests and pulling data
		* Passionate about using technology and big data to make investing easier
+ skill set:
	- Work with large, complex data sets. Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed. Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations.
	- Build and prototype analysis pipelines iteratively to provide insights at scale.
	- Develop comprehensive knowledge of TikTok data structures and metrics, advocating for changes where needed for product development.
	- Interact cross-functionally, making business recommendations (e.g., cost-benefit, forecasting, experiment analysis) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information.
	- Research and develop analysis, forecasting, and optimization methods to improve the quality of TikTok ads products.
	- 3+ years of relevant work experience, including expertise with statistical data analysis such as linear models, multivariate analysis, stochastic models, sampling methods.
	- Experience with statistical software (e.g. R, Python, MATLAB) and database languages (e.g. SQL)
	- Demonstrated leadership and self-direction. Willingness to both teach others and learn new techniques.
	- Demonstrated skills in selecting the right statistical tools given a data analysis problem. Effective written and verbal communication skills.
+ skill set:
	- Generate useful features from large amount of data
	- Apply supervised and unsupervised machine learning techniques, such as linear and logistic regression, decision trees, and k-means clustering
	- Develop segmentation models, classification models, propensity models, LTV models, experimental design, optimization models
	- Perform statistical analysis such as KPI deep dives, performance marketing efficiency, behavioral clustering, and user journey analytics
	- Curate audiences and inform engagement tactics to enable differentiated, relevant marketing touches across channels (social, email, in app, push)
	- Synthesize analytics and statistical approaches into easy-to-consume storylines, both visually and verbally, and provide indicated actions for executive audiences
	- Capture business requirements for data and analytic solutions and collaborate XFN to ensure business requirements align with business needs
	- Analyze creatives and surface insights that will help drive engagement and retention.
	- Support day-to-day collaboration with performance marketing to communicate insights and recommend data informed strategies
	- Experience building data science models (Regression, Decision Trees, K-Means, etc.)
	- Experience with large data sets and analytical tools, e.g. Hive, Spark)
	- Proficiency in scripting languages (SQL, Python, R, etc.)
	- Experience working with international partners in different time zones
+ skill set:
	- Develop cross-platform code using the latest industry-standard tools:
	- C++17, transitioning to C++20
	- Modern CMake
	- GoogleTest
	- GitLab CI
	- Build robust code within a strict test-driven development workflow.
+ skill set:
	- Experience in the development, test, deployment and administration of one of the following types of systems is preferred:
		* HDFS (with source-level familiarity);
		* Object storage systems;
		* Message queueing (MQ) systems, e.g., Kafka.
+ Experience in the development, test, deployment and administration of one of the following types of systems: Ngnix, Kubernetes, Docker, OpenStack, Hadoop, Spark, Flink, etc. is preferred
+ Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.)
+ Familiar with web technology stack like Spring, Flask, Gin, etc.
+ skill set:
	- Participate in the development of a large-scale Ads system for TikTok.
	- Participate in the development and iteration of Ads algorithms by using Machine Learning.
	- Partner with product managers and product strategy & operation team to define product strategy and features.
	- Solid programming skills, proficient in C/C++, good programming style and work habits;
	- Familiar with at least one mainstream deep learning programming framework (TensorFlow/Caffe/MXNet), familiar with its architecture and implementation mechanism;
	- Familiar with deep learning algorithms (CNN/RNN/LSTM, etc.);
	- Ability to solve problems independently, good sense of teamwork and communication skills;
	- Has experience with open sourced deep learning framework.
	- Familiar with main components for Ads system, including bidding, ranking and auction.
	- Experience in resource management and task scheduling with large scale distributed software (such as Spark and TensorFlow).
+ skill set:
	- You have a proven track record of statistical modeling / applied machine learning with a focus on churn prediction, LTV prediction, and customer behavioural clustering.
	- You have experience with A/B and Multivariate test design and implementation.
	- You're pragmatic. You value simple and effective solutions over complicated brain-melters.
	- You can take a complex concept and make it sound simple, using clear visual references to help.
	- You like taking on big challengesâ€”given the appropriate time and resources.
	- You're hungry to learn and embrace healthy debate.
	- You're empathic, enthusiastic, and collaborative.
	- You've are proficient building queries with SQL.
	- You have experience with AWS or other cloud systems.
	- You are an expert in Python or R, and have some experience in implementation (Scala/Java).
	- Having a working knowledge of Big Data technologies (e.g. Spark or Redshift) is a plus.
	- You're fluent in English and eager to work in a multicultural, international environment.
+ Have vast experience with schedulers like Kubernetes, Mesos/Marathon or similar with some sort of service mesh in use.
+ WebRTC
	- WebRTC (Web Real-Time Communication) is a free, open-source project that provides web browsers and mobile applications with real-time communication (RTC) via simple application programming interfaces (APIs).
+ Buildroot
	- Buildroot is a set of Makefiles and patches that simplifies and automates the process of building a complete and bootable Linux environment for an embedded system, while using cross-compilation to allow building for multiple target platforms on a single Linux-based development system. Buildroot can automatically build the required cross-compilation toolchain, create a root file system, compile a Linux kernel image, and generate a boot loader for the targeted embedded system, or it can perform any independent combination of these steps.
+ Our platform is ever-evolving, but currently is a combination of Python, Java, Postgres, Kubernetes, Spark, Presto, Kafka, and Mongo
+ Experience using different types of datastores such as Postgres, Mongo, Redis, and Elasticsearch
+ Practice disciplined software engineering (e.g. automated testing, code reviews, and writing beautiful, readable code).
+ skill set:
	- Build automation around infrastructure components like MongoDB, PostgreSQL, Redis, and Kafka clusters.
	- Experience with Docker, Kubernetes, Prometheus, or other CNCF software is a big plus.
	- Extensive operational and architectural background in SQL and NoSQL technologies.
	- Experience with database design, caching, scalability, and network fundamentals.
+ 3+ years of experience with ReactiveCocoa and MVVM a plus
+ Bonus points for experience / familiarity with front-end testing (Jest, Cypress, Selenium), Docker, Kubernetes, GCP/AWS, infrastructure automation (chef/puppet/ansible)
+ skill set:
	- Deep knowledge of TCP/UDP and IP routing
	- Knowledge of Linux internals, TCP/IP, DNS, Load Balancing technologies
	- Experience working with fault tolerant, highly available, high throughput, distributed, scalable systems
	- Knowledge of cloud compute technologies, network monitoring, data processing and analytics
	- Experience with datacenter monitoring, service oriented systems, micro-services
	- Experience with network automation, dynamic routing, SNMP, network telemetry
	- Exposure to Grafana, Prometheus, ElasticSearch and other distributed platforms
	- Aptitude to be a good team player and willingness to learn and implement new technologies as needed
+ skill set:
	- Own internal services like Kubernetes and Ceph clusters, create microservices like authentication providers and load balancers, product-related services like our deployment pipeline, and everything in between.
	- Write high-quality infrastructure-as-code that automates the provisioning, deployment, scaling, and monitoring of Squarespace's infrastructure and ensure that it is redundant and fast around the globe.
	- Understand database design, storage, caching, scalability, and network fundamentals.
+ 5+ years of experience building large-scale software and distributed systems in *nix environments and with technologies that run the internet such as TLS, HTTP (1/1.1, 2, QUIC/3), TCP,UDP, IP, anycast, multicast, and unicast routing.
+ Understanding of uncompressed video formats and codecs (e.g. HLS, MPEG-DASH)
+ Experience with Maya, Blender, Adobe Creative Suite/Creative Cloud.
+ skill set:
	- Demonstrated experience with Esri ArcGIS 10.x, cartographic design, graphic editing, and standard office applications.
	- Familiarity with ArcGIS Online, Tableau, and a statistical package (R, STATA, etc.)
	- Ability to work in a fast-paced environment under tight deadlines while producing quality content.
	- Strong organizational, interpersonal, oral and written communication skills.
	- Strong analytical skills, data lover, ability to think big picture strategy and navigate details to ensure accuracy.
	- Ability to participate in a 1-2-week field experience, which may involve domestic and/or international travel and overnight stays for up to 2 weeks.
+ Experience in Big data technology stack (Hadoop, Hbase, Sqoop, Hive, Spark, etc.).
+ Experience with a number of ML techniques and frameworks, e.g. data discretization, normalization, sampling, linear regression, decision trees, deep neural networks, etc
+ skill set:
	- High-demand large-scale production environments
	- BGP, MPLS, and RSVP configuration and management
	- Internal routing protocols such as ISIS and OSPF
	- Cloud deployments such as GCP and AWS
	- Multiple hardware platforms such as Juniper, Arista, and Cisco
	- Packet analysis and flow monitoring tools
	- Scripting in Python or equivalent to automate operational tasks
	- Strong documentation and interpersonal skills
+ skill set:
	- microservice architecture
	- Java
	- Rest Webservices
	- Agile software development methodology
	- Jenkins
	- Subversion
	- Splunk as a monitoring tool
	- New Relic application monitoring
+ skill set:
	- data architecture
	- big data stack environment, including Snowflake, EMR, EC2, S3, SQS, Lambda, Hadoop, Sqoop, Apache Spark, Hive, and Python
	- data warehousing and BI Solutioning
	- ETL analytics and reporting tools
	- Amazon Web Services
	- leading the technical design and implementation of data ingestion and integration
	- databases, including NoSQL, DynamoDB, and Teradata
	- Airflow Scheduler to build complex workflows
	- SQL and Linux / Unix shell scripting
	- performance tuning data pipelines
+ skill set:
	- monitoring tools including New Relic, Splunk, and SignalFX;
	- Apache Camel Messaging Services
	- JBoss
	- build tools, including ANT, Maven, and Gradle
	- UML
+ skill set:
	- data engineering
	- Amazon Web Services
	- Oracle
	- Hive / Spark
	- Hadoop
	- Python
	- Snowflake
	- Airflow
+ skill set:
	- Gather business requirements and create technical requirements for statistical analytics solutions.
	- Create data processing systems for production purposes.
	- Using established Nielsen development, testing and deployment practices, draft design documents that are presented to internal and external stakeholders.
	- Present material to internal department stakeholders.
	- Partner with the Software Engineering department to build best-of-class Cloud-based analytical solutions based on the Agile solutions development methodology.
	- Implement statistical and econometric models.
	- Analyze (i.e., to determine the quality of) econometric models, and implement and analyze supervised and unsupervised learning approaches.
	- Write modules for Nielsen analytics platform.
	- Prototype and design analytic methods.
	- Extract, and conduct quality assurance for, market research/marketing, economic and company data from different external and internal platforms.
	- Conduct research to identify new quality assurance measures.
	- Train and mentor (without supervisory authority) 1-2 Data Scientists.
	- Involves domestic travel, 1-2 times per year, for up to 2-3 days per trip.
	- Tools used include: SQL, Python, Pandas, Scikit Learn, R, Spark MLib and Scala.
	- Master's degree in statistics, mathematics, economics, or a related hard science, social science or engineering field with a quantitative focus, such as computer science or engineering, physics, chemistry or sociology (foreign equivalent degree acceptable) plus 3 years of experience in conducting data modeling and statistical analysis using large and complex (at least 10 GB) datasets (would also accept a Ph.D. in such a field plus 1 year of experience).
	- 3 years of experience (or 1 year of experience after a Ph.D.) in/with:
		* gathering data requirements for statistical, econometric and/or predictive analytics research that drives market research/marketing analytics product innovation and implementation
		* handling large volumes (at least 10 GB) of structured and unstructured data
		* Python and its libraries (such as Pandas, Numypy and/or SciKit Learn), SQL, Spark, and R, all via a Cloud-based platform (such as AWS and/or Azure)
		* 1 year of experience in/with: building efficient data processing pipelines for analytical systems; and Airflow
		* Must be willing to travel domestically, 1-2 times per year, for 2-3 days per trip.
+ skill set:
	- Scala, Flask, Big Data or cloud technologies
	- hands-on technologists who are strong in software engineering fundamentals, Big Data, and DevOps
	- Intelligence Studio is a horizontally scalable, cross-cloud technology-agnostic platform built with trusted open source components like Kubernetes, Spark, Airflow, MLflow, and TensorFlow. It allows data scientists to focus on doing data science by taking care of essential concerns like data access, logging, configuration, resource negotiation, dependency management, orchestration, and testing.
	- This self-service, data science platform solution connects in with partners in a shared ecosystem, scales by usage, and has the building blocks to help our data scientists and clients move from creation to deployment of a data science project, at scale.
	- Recently, we implemented a multi-user cloud-based integrated development environment with code completion and debugging built-in. And now we're focused on building a fine-grained entitlements and access control system for big data.
	- Building software and integrations in a cloud-based Microservices environment for Big Data applications
	- We also use cloud software design, containerized Microservices & distributed caching, but you can learn this if you aren't familiar with it.
+ skill set:
	- As a key member of the core platform engineering team, you will work directly with business and technical stakeholders to lead and execute projects including exploration of new languages, tools, technologies (such as Go, AWS Lambda, Aurora, ElastiCache, CloudSearch, etc), building new APIs and microservices, migration of existing services and data stores to the cloud, personalization and many more. While working on these projects you will be responsible for full life-cycle management, including requirements analysis, technical design, implementation, testing, documentation, deployment to production, and postproduction ownership.
	- Design and build services and applications at scale for tens of millions of users.
	- Profile and optimize browse and search algorithms over large datasets.
	- Contribute to architecture, design and implementation of next generation monetization and metadata delivery platform.
	- Contribute to development of new web and mobile applications and services.
	- Create technical specifications for new products, executing from start to finish and owning the quality of the service in production.
	- Create and enhance integrations with external partners like Amazon, Microsoft, Sonos, Tesla, and Google.
	- Maintain and extend heterogeneous environment, including our core .NET codebase and our set of services written in Go.
	- Maintain and extend API services, SDKs and developer documentation.
	- 7+ years of software engineering experience with an emphasis in modern web stacks, design, development and deployment of high volume web applications and APIs (millions of transactions per day).
	- Working knowledge of both relational and NoSQL database design and management (here at TuneIn we are using SQL Server, Aurora, Redis, DynamoDB, BerkeleyDB, Redshift and more).
	- Expertise with object-oriented languages such as Go, C#, Java, JavaScript or C++
	- History of building resilient, stateless, scalable, distributed and observable systems.
	- Experience with microservices, knowledge of modern cloud services (such as AWS or similar).
	- Practical perspective on software engineering discipline, focus on learning and delivering, and passion for high quality.
	- Great energy and enthusiasm with a positive, collaborative working style, clear communication and writing skills.  Enthusiasm for audio content preferred.
+ skill set:
	- TuneIn reaches nearly 70 MAUs and we have a relentless appetite for data: our listeners collectively generate tens of millions of events per hour at peak. We are a small data engineering team and our contributions have a profound impact on the success of the business: from shipping the next strategic insight to building the data-centric products that power our listeners' experiences - our Data Engineering team is the hub of TuneIn. Our environment currently includes Java, Python, Pandas, Go, microservices, AWS services like amazon redshift, kinesis, emr (hadoop, spark), s3, lambdas. Kubernetes, Docker and Spinnaker for deployment. As well as music station recommendation engines, and advancements in Discovery and personas.
	- Data pipelines are critical to TuneIn's success, powering many aspects of our analytics and supporting products. We are looking for data engineers who will build data applications to solve product problems. In this role, you'll partner closely with our data analysts and Product team to create the technology that generates and transforms data into applications, insights and experiences for our users.
	- Example Projects
		* Build and rewrite existing data pipelines using Java/Python/Go to improve efficiency and latency
		* Develop and automate ETL pipelines
		* Design data models for optimal storage and retrieval, and optimize the data architecture to meet critical product and business requirements
		* Improve data quality through anomaly detection by building and working with internal tools to measure data and automatically detect changes
		* Data Modeling and improving our existing data models for analytics
	- 5+ years of software Engineering experience, with an emphasis in the design, development and deployment of high volume data centric applications (millions of transactions per day)
	- Past experience developing and maintaining ETL pipelines
	- Working knowledge of both relational and NoSQL database design and management (here at TuneIn we are using  Redshift, DynamoDB and Aurora)
	- Past experience with cloud services (such as AWS or similar)
	- Expertise with any object-oriented languages such as Java, Go, Python
	- History of building resilient, stateless, scalable, distributed and observable systems
	- Demonstrated ability to analyze data sets to identify gaps and inconsistencies, provide data insights, and advance effective product solutions
	- Experience designing and deploying production systems with reliable monitoring and logging practices
	- Practical perspective on software engineering discipline, focus on learning and delivering, and passion for high quality
	- Great energy and enthusiasm with a positive, collaborative working style, clear communication and writing skills
	- Enthusiasm for audio content preferred
+ skill set:
	- 3+ years experience with the JVM and Scala (preferably) or another functional programming language
	- Experience working in high scale/distributed systems where high availability, low latency and scalability is key
	- Strong experience working with concurrent and asynchronous programming
	- Understanding of algorithms and data structure and how to apply them when designing and building systems
	- Experience with SQL/NoSQL systems such as MongoDB, DynamoDB, PostgresQL
	- Experience with Docker/Kubernetes
	- Experience with continuous deployment and testing
	- Working in a strongly typed language with compile time guarantees
	- Being able to pick the best tool to get the job done
	- Designing, developing, and deploying scalable services to support new and existing functionality
	- Working in an environment where testing, monitoring, and reliability are part of the development process
	- Collaborating and working closely within team/engineering as well as cross-functional teams
	- Working on systems that are used by millions of users every day
	- We are looking for a detail-oriented software engineer to join our backend services team.  Our team develops the core APIs that power the client applications used by millions of users daily. We primarily use Scala and deploy/run our code in Kubernetes. We also create and maintain some data pipelines to import/export data to other internal consumers. As part of our team, your responsibilities would include designing/building new features, maintaining high code quality via tests/code reviews/metrics, and keeping a focus on continuous improvement on all parts of the development process. Our team takes prides in having high quality code and developing in a principled fashion.
+ Experience with prototyping tools (Axure, InVision, Principle, Framer, etc)
+ skill set:
	- Creating and managing the stack of production tools and APIs that allow interaction with content objects and insights into key performance indicators.
	- Collaborating and coordinating with various engineering, content, and product teams: providing the glue between consumption and publication systems and users.
	- Participating in defining the technology road map and best practices across the engineering organization that support and advocate for transparency within the Content lifecycle.
	- Being a key contributor to our next-generation Content platforms.
	- In depth experience developing applications in Python
	- Experience with application frameworks/libraries such as Django or Flask and have experience with JavaScript frameworks such as Angular, React, or NodeJS
	- Ability to extract and translate needs and stories from stakeholders and existing codebases into actionable development.
	- Experience designing and implementing APIs needed for effective data visualization and interactions.
	- Experience with SQL/NOSQL systems such as MongoDB, Cassandra, Postgres, etc.
	- Experience with CI/CD pipelines and testing methodologies.
	- Experience with AWS stack is a plus.
	- Experience with big data engineering principles and technology stacks (eg., Kafka and distributed data processing) is a plus.
	- We are highly focused on using the right tools for the job, building decoupled flexible architectures, and committed to fostering ownership and responsibility to autonomous teams.
+ skill set:
	- We are looking for a detail-oriented software engineer to join our backend services team.  Our team develops the core APIs that power the client applications used by millions of users daily. We primarily use Scala and deploy/run our code in Kubernetes. We also create and maintain some data pipelines to import/export data to other internal consumers. As part of our team, your responsibilities would include designing/building new features, maintaining high code quality via tests/code reviews/metrics, and keeping a focus on continuous improvement on all parts of the development process. Our team takes prides in having high quality code and developing in a principled fashion.
	- Working in a strongly typed language with compile time guarantees
	- Being able to pick the best tool to get the job done
	- Designing, developing, and deploying scalable services to support new and existing functionality
	- Working in an environment where testing, monitoring, and reliability are part of the development process
	- Collaborating and working closely within team/engineering as well as cross-functional teams
	- Working on systems that are used by millions of users every day
	- Solid experience with the JVM and Scala (preferably) or another functional programming language
	- Experience working in high scale/distributed systems where high availability, low latency and scalability is key
	- Strong experience working with concurrent and asynchronous programming
	- Understanding of algorithms and data structure and how to apply them when designing and building systems
	- Experience with SQL/NoSQL systems such as MongoDB, DynamoDB, PostgresQL
	- Experience with Docker/Kubernetes
	- Experience with continuous deployment and testing
+ skill set:
	- Cloud engineering experience. AWS is preferred.
	- Experience working with Kubernetes/Docker. Flux and Helm experience is preferred.
	- Experience with tracing tools like Jaeger or Zipkin is preferred.
	- Experience with Observability technologies, like Data Dog, Prometheus, and Grafana is a big plus.
	- Treating cloud infrastructure as code by leveraging provisioning and configuration management tools such as Terraform and Ansible.
	- Comfortable using common CI/CD tools such as TravisCI, Jenkins and Flux for application and infrastructure automation tasks.
	- Providing engineers with the advice and tools they need to meaningfully monitor and alert on the services and features they develop, using tools like Prometheus/DataDog and PagerDuty.
	- Collaborating with teammates and working cross-functionally with different engineering teams.
	- Exploring and evaluating different open source tools.
	- Knowledge of GitOps processes for driving auditable and repeatable changes to infrastructure
+ skill set:
	- Experience working with Kubernetes/Docker. Flux and Helm experience is preferred.
	- Experience with tracing tools like Jaeger or Zipkin is preferred.
+ skill set:
	- We are looking for a detail-oriented software engineer to join our backend services team.  Our team develops the core APIs that power the client applications used by millions of users daily. We primarily use Scala and deploy/run our code in Kubernetes. We also create and maintain some data pipelines to import/export data to other internal consumers. As part of our team, your responsibilities would include designing/building new features, maintaining high code quality via tests/code reviews/metrics, and keeping a focus on continuous improvement on all parts of the development process. Our team takes prides in having high quality code and developing in a principled fashion.
	- Working in a strongly typed language with compile time guarantees
	- Being able to pick the best tool to get the job done
	- Designing, developing, and deploying scalable services to support new and existing functionality
	- Working in an environment where testing, monitoring, and reliability are part of the development process
	- Collaborating and working closely within team/engineering as well as cross-functional teams
	- Working on systems that are used by millions of users every day
	- 3+ years experience with the JVM and Scala (preferably) or another functional programming language
	- Experience working in high scale/distributed systems where high availability, low latency and scalability is key
	- Strong experience working with concurrent and asynchronous programming
	- Understanding of algorithms and data structure and how to apply them when designing and building systems
	- Experience with SQL/NoSQL systems such as MongoDB, DynamoDB, PostgresQL
	- Experience with Docker/Kubernetes
	- Experience with continuous deployment and testing
+ skill set:
	- Working on systems that are used by millions of passionate users every day
	- Working with data on the scale of hundreds of billions of records a year
	- Evangelizing best practices in software development
	- Working in an Agile development methodology and own data driven solutions end-to-end
	- Increasing efficiency and automate processes by collaborating with our SRE team to update existing data infrastructure (data model, hardware, cloud services, etc.)
	- Experimenting with frameworks in the Big Data ecosystem to identify the optimal approach for extracting insights from datasets
	- Designing platforms for building, launching and maintaining efficient and reliable data pipelines in production
	- Identifying performance bottlenecks in data systems and architect faster, more efficient solutions when necessary
	- Designing, developing, and owning new systems and tools to enable our consumers to understand and analyze the data more quickly
	- Solid experience writing well-abstracted, reusable code components in Python, Scala or similar languages
	- Cloud engineering experience (AWS preferred)
	- Experience using common CI/CD tools such as TravisCI, and Jenkins for application and infrastructure automation tasks
	- A self-starter who thrives in owning the products and platforms they develop
	- Experience ingesting, processing, storing, and querying large datasets
	- Experience with Spark, Kafka, or similar is a plus
	- Experience working in the Hadoop/Spark ecosystem is a plus
	- Experience with Docker/Kubernetes is a plus
+ Experience with big data engineering principles and technology stacks (eg., Kafka and distributed data processing) is a plus.
+ skill set:
	- Collaborating with business stakeholders to understand requirements and socialize solutions
	- Designing and implementing novel machine learning methods
	- Evaluating new paradigms for deploying machine learning models
	- Staying atop the most recent developments and best practices in a quickly changing field
	- A deep understanding of machine learning algorithms and statistics
	- Scientific or quantitative computing experience (Python, R, Spark)
	- Experience working with distributed datasets (Hadoop, Hive, Spark, SQL)
	- The ability to tell a story with data (large scale analysis, data visualization)
	- Experience writing production code (such as Python, Java, or Scala)
	- An understanding of best practices in software engineering (git, CI/CD, etc)
	- We strongly believe in being an active part of our community. We teach, write, give tech talks, release open source projects, and would love it if you also shared these passions. Take a look at a few of our recent blog posts to get an idea:
		* https://tech.iheart.com/mapping-the-world-of-music-using-machine-learning-part-2-aa50b6a0304c
		* https://tech.iheart.com/a-generative-model-for-track-playlists-4dba8b8515c
		* https://tech.iheart.com/ihrpi-a-simple-solution-to-python-package-management-874e373f5838
		* https://tech.iheart.com/real-time-music-recommendations-for-new-users-with-amazon-sagemaker-364b346d07db
+ skill set:
	- iHeartRadio is looking for a talented Data Engineer to help us in our data-driven mission to reshape the world of music and podcasts. You will work in a highly collaborative team of engineers, and alongside data scientists and analysts, to distill existing data processes, import new external data sources, and create complex data mashups. Your work will provide valuable insights and power important music data products. Expect to build high throughput data pipelines and improve the existing big data infrastructure. You will also improve performance, squash bugs, and increase visibility across the data ecosystem. You will have end-to-end ownership of your code, though ideally you also relish reviewing a good pull request. If you enjoy working with large sets of data and the challenges associated with them this is the role for you.
	- Working in an Agile development methodology and own data driven solutions end-to-end
	- Experimenting with various frameworks in the Big Data ecosystem to identify the optimal approach for extracting insights from out datasets
	- Identifying performance bottlenecks in data pipelines and architect faster, more efficient solutions when necessary
	- Creating new data warehouse solutions and define and demonstrate best practices in schema and table design in varied databases like Hive, Redshift, Spectrum etc.
	- Developing end-to-end batch and real time pipelines for large data sets to our Hadoop/Spark clusters, and bring summarized results back into a data warehouse for downstream business analysis.
	- Increasing efficiency and automate processes by collaborating with our SRE team to update existing data infrastructure (data model, hardware, cloud services, etc.)
	- Designing, building, launching and maintaining efficient and reliable data pipelines in production
	- Designing, developing, and owning new systems and tools to enable our consumers to understand and analyze the data more quickly.
	- Experience ingesting, processing, storing, and querying large datasets
	- Ability to write well-abstracted, reusable code components in Python, Scala or similar language(s)
	- Experience working in an Hadoop/Spark ecosystem
	- Experience with workflow managers and schedulers, such as Airflow
	- Ability to investigate data issues across a large and complex system by working alongside multiple departments and systems
	- A self-starter who thrives in owning the products and pipelines they develop
	- Experience with AWS big data technologies (S3, Redshift, EC2, RDS, EMR, Dynamo) is a plus
	- Experience with configuration management tools (Ansible, Chef, Puppet, etc) is a plus
	- Experience with streaming frameworks like Spark or Kafka is a plus  
+ skill set:
	- The Artificial Intelligence Center of SRI International is looking to fill a research position in the area of autonomous systems. SRI has a long history of innovative work in autonomy, commencing with the development of the first mobile robot (Shakey) back in the 1960s through more recent work on distributed AI for controlling large-scale robot teams, privacy-aware information managers, UAV controllers, and robots that learn from their environments.  
	- This position will focus on the development of innovative capabilities for autonomy, spanning both full and mixed-initiative autonomy models, as well as their deployment to challenging real-world problems. Responsibilities will include contributing to existing research projects through concept design, algorithm development, and evaluation; enhancing visibility of the lab through publishing and engagement with the broader research community; formulating new research directions; and collaborating within small teams to develop new projects related to autonomous systems.
	- The ideal candidate will have technical depth in the following areas:
		* Autonomy architectures
		* Automated planning and scheduling
		* Distributed AI / Multi-agent coordination
		* Machine learning, with particular focus on reinforcement learning
+ skill set:
	- Develop new imaging technologies that enhance visual communication on both handheld and wearable devices
	- Develop new technologies that make it easier for users to interact with devices and well as for devices to interact with other devices
	- Introduce major innovations that can result in product features or new areas of business
	- Collaborate with the researchers and engineers to make important product decisions
	- Develop skills to inspire and manage small or large groups of researchers and engineers
	- PhD in a technical field such as computer science or electrical engineering with expertise in computational imaging, computational photography, or computer vision
	- 3+ years of research or industry experience
	- Track record of innovative work in the area of computational imaging
	- Experience or familiarity with imaging optics, illumination techniques, image processing, computer vision and computer graphics
	- Ability to perform research that is justified and guided by business opportunities
	- Ability to thrive in a fast-paced, ever-changing work environment
	- Successful record of publication in top-tier international research venues
	- Collaborative, positive, and team-oriented mindset
	- Hands-on research experience and fast prototyping skills
	- We are looking for a highly innovative, motivated, and self-directed researcher. Working closely with other researchers and our engineering teams, you will tackle unique technical challenges such as developing techniques to enhance existing products, create new products, deploying algorithms to handle our scale, and improving the experience on Snapchat for millions of people every day. In addition to impacting the company via products, researchers are encouraged to publish their results in top-tier journals and conferences.
	- We're looking for a Research Scientist to join Snap's Computational Imaging Research Lab in NYC! The mission of the lab is to create hardware and/or software approaches to computational imaging that enable new photographic functionalities and experiences that go beyond what is possible with traditional cameras and image processing methods. Our goal is to empower our users with new tools that allow them to communicate with each other more efficiently and in more creative ways than possible today.
+ skill set:
	- We're looking for a Research Scientist to join Snap Inc! You'll work closely with our Research team to work on innovative problems that unlock new experiences for our users through computer vision, machine learning and graphics. Working closely with researchers and our engineering teams, you will develop technologies empowering our users and creators improving improving the experience on Snapchat for millions of people every day. In addition to impacting the company via products, researchers are encouraged to publish their results in top-tier journals and conferences.
	- Beyond the application and interviews, Research Scientist candidates should prepare to provide detailed supporting materials including a research statement, references, biography, and a 60-minute presentation during the evaluation process.
	- Invent novel technologies that enable new experiences for our users
	- Push the boundaries of what is possible in machine learning, computer vision, and graphics
	- Introduce major innovations that can result in product features or new areas of business
	- Collaborate with research and engineering teams to impact products
	- Contribute to the research community by publishing cutting edge research papers
	- PhD in a technical field such as computer science or equivalent experience
	- Experience in computer vision, machine learning, deep learning, graphics
	- Successful record of publication in top-tier international research venues (e.g. ICLR, AAAI, NeurIPS, CVPR, ECCV, ICCV, SIGGRAPH)
	- Programming experience in one or more of the following: Python, C, C++
	- 1+ years of industrial or academic experience beyond internships or post doctoral positions
	- Efficient and scalable algorithm design and problem solving skills
	- Experience with projects that could impact our products
	- Proven experience as a highly innovative, motivated, and self-directed researcher
	- Ability to perform research that is justified and guided by business opportunities
	- Ability to thrive in a fast-paced, ever-changing work environment
	- Excitement for tough technical challenges
	- Someone with a collaborative, positive, and team-oriented mindset
	- Hands-on experience and fast prototyping skills
	- Demonstrated ability in both research and development
+ skill set:
	- We're looking for a Research Scientist to join Snap Inc! The mission of the lab is to create hardware and/or software approaches to computational imaging that enable new photographic functionalities and experiences that go beyond what is possible with traditional cameras and image processing methods. Our goal is to empower our users with new tools that allow them to communicate with each other more efficiently and in more creative ways than possible today.
	- We are looking for a highly innovative, motivated, and self-directed researcher. Working from our New York, NY office, you work closely with other researchers and our engineering teams, you will tackle unique technical challenges such as developing techniques to enhance existing products, create new products, deploying algorithms to handle our scale, and improving the experience on Snapchat for millions of people every day. In addition to impacting the company via products, researchers are encouraged to publish their results in top-tier journals and conferences.
	- Beyond the application and interviews, Research Scientist candidates should prepare to provide detailed supporting materials including a research statement, references, biography, and a 60-minute presentation during the evaluation process.
	- Develop new imaging technologies that enhance visual communication on both handheld and wearable devices
	- Develop new technologies that make it easier for users to interact with devices and well as for devices to interact with other devices
	- Introduce major innovations that can result in product features or new areas of business
	- Collaborate with the researchers and engineers to make important product decisions
	- Develop skills to inspire and manage small or large groups of researchers and engineers
	- PhD in a technical field such as computer science, electrical engineering, or equivalent experience
	- 3+ years of research or industry experience
	- 5+ years of research or industry experience
	- Track record of innovative work in the area of computational imaging
	- Experience or familiarity with imaging optics, illumination techniques, image processing, computer vision and computer graphics
	- Ability to perform research that is justified and guided by business opportunities
	- Ability to thrive in a fast-paced, ever-changing work environment
	- Successful record of publication in top-tier international research venues
	- Collaborative, positive, and team-oriented mindset
	- Hands-on research experience and fast prototyping skills
	- Ability to lead small group of talented researchers to deliver on a high-impact research project
+ skill set:
	- We're looking for a Machine Learning Research Engineer to join Team Snapchat! As a member of the Augmented Reality Team, you will train state-of-the-art machine learning models. You will collaborate with researchers, engineers, and designers and find new ways to apply machine learning to create exciting products and breakthrough interactive experiences for 100s of millions of Snapchatters around the world.
	- Design and implement machine learning and computer vision solutions to be used by millions of Snapchatters
	- Develop deep architectures and optimization techniques for cutting-edge solutions
	- Create products that are used by millions of Snapchatters
	- Learn new techniques and stay on the cutting edge
	- Introduce major innovations that can lead to new product features or new areas of business
	- Work closely with other Snap teams to explore and prototype new product features
	- A proven passion for machine learning; you stay up-to-date with research and are excited about prototyping new ideas quickly
	- Knowledge of mathematics and deep learning foundations
	- Knowledge of basic computer vision algorithms
	- Communication, presentation, and interpersonal skills
	- Bachelor's Degree in a technical field such as computer science (or equivalent experience)
	- 3+ years of research or engineering experience in one or more of the following: generative models (GANs, VAE, Glow), segmentation, object detection, classification, tracking, or other related applications of machine learning
	- Industry or project experience with deep learning frameworks (e.g. PyTorch, TensorFlow, Caffe2)
	- Strong track record of software development in Python or C++
	- Master's degree or PhD in a related technical field
	- Experience developing real-time software for mobile applications
	- Examples of your work such as open source projects, blog posts, Kaggle contests, top conference or journal publications, etc.
	- Excitement about Snapchat and our products
+ skill set:
	- Weâ€™re looking for a Research Engineer to join Snap Inc! You'll work with a small group in Snap Inc.â€™s Research team focused on experimenting and deploying new user experiences.
	- Responsible for bringing ideas to life, you will be involved through the whole research process, from the design to the launch of a product. Our team develops new user experiences on both emerging and established platforms such as wearables, AR, voice, web, and mobile. Working closely with Research Scientists, you will develop prototypes that turn into scientific publications and transform those prototypes into real products that can impact millions of people every day.
	- Architect, design, and implement software research prototypes
	- Translate research prototypes into robust, lasting, and scalable products
	- Assist Research Scientists on existing projects and collaborate with them on ideating new ones
	- Iterate and learn new things quickly
	- Bachelor's degree in a technical field such as Computer Science or equivalent experience
	- 2+ years of full-stack software engineering experience in industry
	- Significant experience in Python, Java, C# and/or C++
	- Masters/PhD in a technical field such as Computer Science or equivalent experience
	- Experience with cloud platforms such as Google Cloud and/or AWS
	- Experience with Sketch, Figma and other design tools
	- Hands-on experience and fast prototyping
	- Demonstrated ability to build and ship software
	- A collaborative, positive, and team-oriented mindset
	- Experience building iOS and Android applications
+ skill set:
	- Weâ€™re looking for a Research Engineer - Deep Learning  to join Team Snapchat! As a member of the Augmented Reality team, you will train state of the art Machine Learning models. Working closely with the Research team, you will collaborate with engineers and designers and find new ways to apply machine learning to create exciting products and breakthrough interactive experiences for millions of Snapchatters around the world.
	- Design and implement machine learning and computer vision solutions to be used by millions of Snapchatters
	- Develop deep architectures and optimization techniques for cutting-edge solutions
	- Write production software used by millions of Snapchatters
	- Learn new techniques and stay on the cutting edge
	- Introduce major innovations that can lead to new product features or new areas of business
	- Work closely with other Snap teams to explore and prototype new product features
	- Master's degree in a technical field such as computer science or equivalent experience
	- Industry experience with applied machine learning
	- Experience of deep learning research
	- Experience with any one of segmentation, object detection, image classification, GANs, monocular depth estimation or a related field
	- Experience with a deep learning framework (e.g. TensorFlow, Caffe2, PyTorch)
	- Software engineering skills (Python)
	- A passion for machine learning; you stay up-to-date with research and are excited about prototyping new ideas quickly
	- Great communication, presentation, and interpersonal skills
+ skill set:
	- Software development with innovative deep learning and machine learning algorithms
	- Exploring immense data sets of information from images, videos, music, customer interactions, and marketing
	- Selecting features, building and optimizing classifiers using machine learning techniques
	- Enhancing data collection procedures to include information that is relevant for building analytic systems
	- Processing, cleansing, and verifying the integrity of data used for analysis
	- Analyze data from across Shutterstock including behavioral data with state of the art techniques to provide a better experience to customers
	- Creating automated anomaly detection systems and constant performance tracking
	- Working with data engineers, analysts and business partners to drive ideas from the rapid prototyping phase all the way through to serving and learning from live traffic at scale
	- 1+ years of experience with common toolkits, such as TensorFlow, Caffe, Torch/PyTorch
	- 1+ years of industry experience creating, deploying, and learning from production algorithm analysis
	- Experience in one or more areas: computer vision, information retrieval, natural language processing, or recommendation systems
	- Experience with software development best practices (version control, testing, code review, etc.)
	- Fluent in one or more general purpose programming languages including but not limited to Python, Spark, C, Java, Scala
	- Proficiency in using query languages such as SQL, Hive, Pig
	- Excellent applied statistics skills, such as distributions, statistical testing, regression, etc.
	- Complete understanding of common frameworks/models such as Inception, Faster R-CNN, YOLO, ELMo or BERT
	- BS or MS in Computer Science or equivalent experience
	- Notebook experience (Jupyter, Zeppelin, Databricks, etc.) to perform data analysis and algorithm development using Python
	- Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
	- Experience with graphics/visualization programming (CUDA, cuDNN)
	- Cloud computing experience
	- Experience with ML collaborative platforms/pipelines (MLflow, Neptune, Kubeflow, etc.)
	- Docker and/or Kubernetes exposure
	- Ph.D. in a related scientific field: Computer science, Physics, Math
+ skill set:
	- This role will be responsible for helping to define and provide the foundation for our next-generation data services.  With a strong focus on automation and elasticity, you will contribute to how our data infrastructure scales to support the overall growth of our platform, data products, and services. We are looking for someone that is passionate about automation, repeatability, quality, and knowledge sharing within a team environment.
	- Build and operate large-scale data infrastructure programs in a cloud environment  (performance, reliability, monitoring)
	- Write well-crafted, well-tested, readable, maintainable code
	- Participate in code reviews to ensure code quality and distribute knowledge, including Open-Source projects
	- Work closely and collaboratively in an Agile environment with our engineers and product teams to analyze issues and find new insights covering our business and operations
	- Day to day operational support of data infrastructure and services
	- 5+ years of relevant professional experience
	- Deep understanding of distributed systems principles (consistency and availability, liveness and safety, durability, reliability, fault-tolerance, consensus algorithms)
	- Strong understanding and experience AWS and cloud concepts (VPC, EC2, Route53, Kinesis, ECS, IAM, and others)
	- Experience writing infrastructure as code. (Terraform)
	- Experience bringing open-source software to production at scale.
	- Experience designing, implementing and debugging distributed systems that run across thousands of nodes
	- Hands-on experience deploying, debugging and maintaining JVM based applications.
	- Hands-on experience with Big Data ecosystem - Yarn, Hive, HDFS, Spark, Presto, Parquet, HBase
	- Experience working with and building real-time compute and streaming infrastructure - Kafka, Kinesis, Flink, Storm, Beam
	- Experience with workflow management (Airflow, Oozie)
+ skill set:
	- Minimum of 3+ years experience implementing large-scale production systems
	- Experience with Java or Scala build systems: maven, ant, sbt
	- OO design and implementation
	- Understanding of database design (SQL/noSQL)
	- Experience with multiple Apache Hadoop / Spark ecosystem applications, like: Spark, Hadoop, Hive, Zeppelin
	- Experience with Python
	- Experience building and operating at scale
	- Excellent analytical and problem solving skills
	- BS/MS in Math, Computer Science, or equivalent experience
	- Nosql data storage solutions
	- AWS
	- Continuous delivery
	- Microservice architectures
	- Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities
	- Implementing ETL process
	- Monitoring performance and advising any necessary infrastructure changes
	- Defining data retention policies
	- Create and maintain optimal data pipeline architecture,
	- Assemble large, complex data sets that meet functional / non-functional business requirements.
	- Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
	- Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS "big data" technologies.
	- Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
	- Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
	- Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
	- Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
	- Work with data and analytics experts to strive for greater functionality in our data systems.
	- Manage databases running on MySQL, MongoDB, Redis Technologies
	- AWS: EC2, EMR, RDS, Redshift.
	- Experience with big data tools: Hadoop, Spark, Kafka, etc.
	- Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
	- Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
	- Experience with AWS cloud services: EC2, S3, EMR, RDS, Redshift
	- Experience with stream-processing systems: Storm, Spark-Streaming, etc.
	- Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
	- RDS, DynamoDB
	- Microservices
	- Docker
	- Elastic caching (Redis, Memcached)
	- NodeJS, Python, Rails
	- Github
	- JIRA &amp; Confluence
	- Proficient understanding of distributed computing principles
	- Understanding of how to manage Hadoop clusters, with all included services
	- Ability to solve any ongoing issues with operating the cluster
	- Proficiency with Hadoop v2, MapReduce, HDFS
	- Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming
	- Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala
	- Experience with Spark and Scala
	- Experience with integration of data from multiple data sources
	- Experience with NoSQL databases, such as HBase, Cassandra, MongoDB
	- Knowledge of various ETL techniques and frameworks, such as Flume
	- Experience with various messaging systems, such as Kafka or RabbitMQ
	- Experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O
	- Good understanding of Lambda Architecture, along with its advantages and drawbacks
	- Experience with Nifi/Kylo.io, or other ETL tools, such as Cloudera/MapR/Hortonworks
	- Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
	- Experience building and optimizing "big data" data pipelines, architectures and data sets.
	- Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
	- Strong analytic skills related to working with unstructured datasets.
	- Build processes supporting data transformation, data structures, metadata, dependency and workload management.
	- A successful history of manipulating, processing and extracting value from large disconnected datasets.
	- Working knowledge of message queuing, stream processing, and highly scalable "big data" data stores.
	- Strong project management and organizational skills.
	- Experience supporting and working with cross-functional teams in a dynamic environment.
	- We are looking for a candidate with 3+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
+ skill set:
	- Our tech stack includes AWS, Docker, Django, REST, GraphQL, React, MySQL, Postgres, Elastic Search, Airflow, and other modern tools and frameworks. Our languages of choice are Python and Javascript. We don't expect you to be an expert in every platform, but we do expect that you have a solid foundation in computer science and have no problem mastering the technologies that we use today (and will adopt tomorrow). And, most importantly, while you may not have a background in biology, you must be passionate about Ginkgo's mission of making biology easier to engineer.
	- We're looking for a Senior Software Engineer who will design, develop, test, and deploy the software used by Ginkgo scientists to create these new organisms, conduct experiments, control lab robots, and analyze massive amounts of data. You'll collaborate with a team of talented and diverse engineers, product managers, experts in data analysis and bioinformatics, and, of course, your customers â€“ the dozens of biologists and chemists at Ginkgo.
	- Design and implement software solutions that address current needs of Ginkgo bioengineers. These solutions could be a microservice, standalone tool, user facing web application, data pipeline, etc.
	- Collaborate with your tech lead and product manager to define milestones and deliverables.
	- Work as a member of an agile team, attend scrum meetings, and review code produced by your peers.
	- Write automated tests for your solution and oversee its deployment.
	- Monitor the production environment to detect and address customers' issues.
	- Prototype new ideas, algorithms, and frameworks.
	- BS, MS, or PhD in computer science with 5+ years of industry experience
	- Proven track record in full-stack development
	- Experience with building distributed systems
	- Experience with code management systems, CI/CD, AWS, or any other cloud experience a plus
	- Familiarity with biology a plus
	- Previous startup experience a plus
	- Eagerness to work hand-in-hand with the Ginkgo's foundry team to architect the next generation of foundry for engineering organisms
+ skill set:
	- We're looking for a Software Solution Engineer who will work closely with Ginkgo scientists to understand their processes and quickly prototype and build the tools they need to create these new organisms, conduct experiments, control lab robots, and analyze massive amounts of data. You'll collaborate with a team of talented and diverse engineers, product managers, experts in data analysis and bioinformatics, and, of course, your customers â€“ the dozens of biologists and chemists at Ginkgo. To be successful at this role, you should have a strong background in biology and bioinformatics, combined with excellent software development skills.
	- Our tech stack includes AWS, Docker, Django, REST, GraphQL, React, MySQL, Postgres, Elastic Search, Airflow, and other modern tools and frameworks. Our languages of choice are Python and Javascript. We don't expect you to be an expert in every platform, but we do expect that you have a solid foundation in computer science and have no problem mastering the technologies that we use today (and will adopt tomorrow).
	- Design and implement software solutions that address the current needs of Ginkgo bioengineers. These solutions could be a microservice, standalone tool, user-facing web application, data pipeline, etc.
	- Collaborate with your product manager to define milestones and deliverables.
	- Work as a member of an agile team, attend scrum meetings, and review code produced by your peers.
	- Write automated tests for your solution and oversee its deployment.
	- Monitor the production environment to detect and address customers' issues.
	- Prototype new ideas, algorithms, and frameworks.
	- Desired Experience and Capabilities
	- Degree in computer science, biology, bioinformatics, or relevant field
	- Relevant internship or work experience
	- Working knowledge of next-generation sequencing and omics technologies
	- Practical understanding of scalable bioinformatics pipelines
	- Knowledge of distributed systems architecture
	- Eagerness to work hand-in-hand with Ginkgo's foundry team to architect the next generation of foundry for engineering organisms
+ First-hand technical experience in at least two of the following areas: bioinformatics; sequence analysis; comparative genomics; phylogenetics; NGS analysis; statistics; probabilistic modeling; machine learning; population genetics; metabolic engineering; or quantitative modeling of biological systems
+ skill set:
	- Collaborate within the team across product, design, product, infrastructure, strategy and engineering.
	- Mentor, learn and share knowledge with others along the way.
	- Have impact and have fun
	- Working outside your comfort zone
	- MS/PhD degree in Computer Science or related technical field or equivalent practical experience.
	- Experience with one or more general purpose programming languages including but not limited to: Java, C/C++ or Python.
	- Develop scalable solutions based on state-of-the-art machine learning and AI methodologies.
	- Develop prototypes and conduct experiments to evaluate the performance of ML/AI architectures/algorithms in large-scale industrial applications.
	- Have strong familiarity with leading machine learning and deep learning such as libraries such as TensorFlow, Caffe, Scikit-Learn, Scipy, Pandas, PyTorch and others.
	- You should be able to develop your own algorithms, loss functions, network architectures.
	- Prior publication record in top tier conferences in computer vision / machine learning is a major plus.
	- Write well-structured and re-usable code, design experiments and integrate solutions in larger production systems.
	- Experience shipping products strongly preferred
+ skill set:
	- The Think Tank Team is an interdisciplinary collective of researchers, designers, scientists and engineers located in Mountain View, CA. Our mandate is to explore whatâ€™s next for Samsung by applying bleeding-edge advances in software, machine learning, computer-human interaction, sensor and display technologies to solve real-world challenges that will transform usersâ€™ experiences in ways we can only just glimpse on the horizon today.
	- TTT began as a small team in 2012 and brought its first concept -- the Samsung Gear watch -- to market one year later. Since then we have released several projects such as the Beyond 3D/360/4k camera for AR/VR cinematography, the BotChef cooking robot, the Ballie personalized companion, and others. We work on a wide variety of time scales, advancing science and applying it to create new products and experiences that will impact the lives of millions.
	- Our team members represent a diverse skillset, including electrical engineering, computer engineering, signal processing, machine learning, computer vision, visual design, interaction design, industrial design, optics, physics, and more from institutions such as MIT, Caltech, Stanford, CMU, Oxford and others. We believe that the best way to show is to design and build prototypes, and that the best products come from teams collaborating to understand and solve a problem from multiple perspectives. We believe that design and creativity are core duties of every member of our team.
	- You must be passionate about creating new devices and technologies, and ready to learn on the fly, solve complex problems, work closely with others, and creatively approach design and engineering tasks at all scales. We believe a personâ€™s work speaks for itself, and welcome everyone with the right drive, attitude, and skills.
	- BS/MS/PhD degree in Computer Science or related technical field or equivalent practical experience.
	- 2 years of work experience in Machine Learning or Artificial Intelligence in real-world settings.
	- Strong C++ and/or Python skills.
	- Ability to rapidly prototype with leading ML frameworks.
	- Experience with current state-of-the-art methods from machine learning & deep learning libraries such as TensorFlow, Caffe, Scikit-Learn, Scipy, Pandas, Torch and others.
	- Experience with a multitude of machine learning methods such as SVMs, logistic regression, boosting, decision trees, clustering, HMMs etc.
	- Experience with CV libraries such as OpenCV
	- Experience in multiple forms of machine leaning, from the very simple to the most complex.
	- Experience in creation of novel custom features and pre-processing approaches to improve baseline algorithms. Work should go beyond using standard libraries.
	- Solid understanding of proper evaluation including folds, cross-validation and metrics.
	- Experience with one or more of the following: Natural Language Processing, GANs, autoencoders, Reinforcement Learning, CNNs, and others.
	- Flexibility to deal with rapidly changing environment.
	- Prior experience with signal processing from sensor data is a plus.
	- Participate in cutting edge research in machine intelligence and machine learning applications. Leverage expertise from ML research and develop novel predictive models/algorithms
	- Develop solutions and algorithms that can be applied in variety of real-world applications and devices.
	- Work closely with researchers and engineers from variety of disciplines to develop new algorithms, product concepts and core-technologies that will bring new business opportunities to Samsung.
+ Characterize full system (receiver and transmitter) performance as well as peripheral devices such as: RFIC transceivers, LNAâ€™s, PAâ€™s etc.  Characterization includes measuring essential parametrics such as sensitivity, power, EVM, linearity, etc.
+ Experience and appetite to engage with the tools needed to get the job done, including Sketch, Zeplin, Abstract, Framer, Flinto, JIRA and Confluence.
+ skill set:
	- Experience in advanced analysis & problem solving techniques including DOE, failure analysis, 8D problem solving, CpK, GR&R, PFMEA etc.,
	- Experience in production line development techniques including flow chart, cycle time calculation, UPH setup, line layout & balance, SOP, MVA calculation etc.,
+ skill set:
	- Our Spoken Language Understanding (SLU) team is building a speech-to-meaning engine that will add to our customersâ€™ ease of use and control as we continue to differentiate an end-to-end Sonos experience for them.
	- Develop new models and algorithms for SLU with a particular focus on the interface between the speech-to-text and the text-to-meaning engines
	- Write production-grade code to be deployed with the support of our software engineering and QA teams
	- Own the development process, from the conception of the models to their evaluation
	- MS in Computer Science, Machine Learning or equivalent
	- PhD in relevant field or 2+ years of experience in deployment of production-grade ML models
	- Strong coding skills in Python
	- Knowledge of Scikit Learn and either PyTorch or TensorFlow
	- Knowledge of basic models and techniques for Natural Language Processing
	- Excellent verbal and written communication skills (English)
	- PhD and/or track record of publications in NLP
	- Working knowledge of Rust
+ skill set:
	- You will be responsible for the training, the validation and the deployment of state-of-the-art speaker validation systems based on the most recent machine learning techniques. Since our speaker verification system must run locally on resource-constrained hardware, you will be faced with the challenging task of minimizing the system footprint while retaining high performance in both noisy and far field conditions. Additionally, you will work closely with the embedded software team to continuously improve optimization and inference strategies to contrast the prevailing cloud computing paradigm.
	- Experience in development, validation and implementation of deep learning models in either the acoustic or visual domains.
	- Experience with one or more general purpose programming languages (C++, Python etc) and with version control.
	- Knowledge of deep learning framework (TensorFlow or PyTorch)
	- MS / PhD in Computer Science or related technical field.
	- 2+ years of experience in deployment of machine learning models in production.
	- Ability to formalize, analyze and solve complex problems.
	- Excellent verbal and written communications skills in English.
	- Experience with face, speaker or landmark recognition
	- Experience in deploying machine learning for embedded systems
	- Previous experience working on verification or authentication tasks
	- Track record of published papers in peer-reviewed journals or conferences
	- Knowledge of Rust and/or Docker
+ skill set:
	- We are looking for a Senior Signal Processing Scientist to join our acoustic team in Paris and help us differentiate the end-to-end Sonos experience for customers.
	- You will be responsible for the audio signal processing stage that plays a fundamental role across all of our acoustic engines including wake word detection, speaker identification, and speech-to-text. Data augmentation and speech enhancement are crucial to ensure the robustness of the speech processing modules (in the presence of external noise, reverberation etc). As a Senior Signal Processing Scientist, you will work at the intersection of machine learning and digital signal processing. You will help our machine learning scientists improve the generalization ability of their models by developing state-of-the-art acoustic data augmentation techniques to enhance the size of our training datasets. Additionally, you will be in close contact with the DSP engineers to help them develop processing techniques specifically tailored to speech processing.
	- 2+ years experience in acoustic data augmentation (pitch and gain control, noise and room simulation etc) within the context of speech recognition.
	- Experience with Python and with version control.
	- MS / PhD in Computer Science, Electrical Engineering or related technical field.
	- Ability to formalize, analyze and solve complex problems.
	- Excellent verbal and written communications skills in English.
	- Track record of published papers in peer-reviewed journals or conferences
	- Experience with other general purpose programming languages (C++, Rust etc) and Docker
	- Knowledge of acoustic DSP techniques for speech enhancement (noise control, dereverberation, echo cancellation, beamforming etc)
	- Knowledge of Machine Learning, Deep Learning, and related frameworks (TensorFlow or PyTorch)
+ skill set:
	- Our Acoustic Modeling team is collaborating closely with our Machine Learning Engineering team to train, test, and deploy a state-of-the-art, deep-learning based system to transcribe voice into text. This critical work will add to our customersâ€™ ease of use and control as we continue to differentiate an end-to-end Sonos experience for them.
	- Train state of the art acoustic models
	- Minimize the model footprint while keeping high performance in both noisy and far field conditions
	- Manage, scale and optimize our Kaldi training pipeline (data management, infrastructure and metric tracking)
	- Experience with machine learning models applied to speech recognition (GMM-HMM, DNN-HMM, E2E models) and related algorithm (forward-backward, viterbi search, backprop, etc)
	- Python, C++
	- Good knowledge of Kaldi, and at least one other deep learning framework (Tensorflow, PyTorch)
	- MS / PhD in Computer Science or Machine Learning
	- At least two years of experience in deployment of machine learning models in production
	- Excellent verbal and written communication skills (English)
	- Experience using Docker
	- SQL, noSQL database
	- Rust
+ skill set:
	- Work on the core Ruby API & support Go microservices (Projects including Netlify Identity, Large Media, Analytics)
	- Supporting the build systems used for customer sites
	- Own features from code to production
	- Design services for better observability, availability, and fault tolerance
	- Work with support to address customer issues
	- Work cross-functionally to scope, design, and implement services
	- Backend services built in Go and Ruby
	- All services deployed in Kubernetes on Google Cloud
	- Work with databases like MongoDB and MySQL
	- Data pipelines built with Kafka, Zookeeper, Consul
	- Has experience building and maintaining highly available distributed systems
	- Solid proficiency in at least Go or Ruby on Rails at scale (Ex: multiple daily releases & 15k+ requests per second)
	- Experienced delivering product features
	- Is curious and open to learning new technologies and best practices
	- Thrives in a collaborative environment, working with others across multiple teams
	- Enjoys working with a diverse group of people with different expertise, working in distributed locations.
+ skill set:
	- Field tools like TargetSMART, NGP VAN, and EveryAction
	- Digital tools like ThruText, ThruTalk, ActionKit, and Google / Facebook ads
	- Data warehousing tools like Civis Platform
	- Dashboard tools like Periscope and Tableau
	- Familiarity with NGP-VAN required; Catalist and Targetsmart helpful, but not required
+ skill set:
	- Experience with C++11 and modern C++ style and idioms
	- Optimize existing and new C++ code to reduce memory consumption and to increase performance and scalability
	- Design and implement algorithms and solvers in C++ for transportation routing problems
	- Work with product engineers to diagnose root causes for incorrect software behavior and failures
	- Fix bugs in the existing C++ codebase
+ skill set:
	- Familiarity with pytest, unittest, or nose
		* Nose, a Python unit test framework
	- Experience with one or more of Cython, Jupyter Notebook widgets
+ C++/CX, Qt
+ skill set:
	- Knowledge of relational database technologies such as Oracle, SQL Server, SQLite, or Postgres
	- Understanding of cloud computing platforms and database services such as Amazonâ€™s Relational Database Service and Azure SQL Database
+ Three or more years of programming experience with data structures and algorithms in C++11/14/17
+ C++ and OpenGL/DirectX experience
+ Knowledge of integration of other enterprise systems (e.g., ERP, EAM, CRM, SCM)
+ skill set:
	- Administrative experience with one or more IaaS cloud platforms
	- Knowledge of user authentication protocols (basic, forms, Kerberos, NTLM, PKI), authentication systems (IWA, proprietary/custom token, SAML), and authorization concepts and systems (RBAC, OAuth)
	- Experience with â€œemerging technologiesâ€ such as IoT, big data analytics, containerization, AI/ML
	- Extensive experience with Esri software including ArcGIS Enterprise components, ArcGIS Enterprise geodatabases, and ArcGIS client applications (mobile and desktop applications)
	- Experience with modern software implementation patterns including service-oriented architectures and cloud environments and concepts such as single sign-on authentication or mobile application development patterns
	- Working knowledge of modern web technology; understanding of web servers, the HTTP protocol and methods, modern web browsers, developer tools, web proxies such as Fiddler, and the use of these technologies to troubleshoot web service and website functionality and performance.
	- Experience with programming languages; working knowledge of Python, JavaScript, PowerShell, and SQL and when and where they should be used and what they can accomplish
	- 4+ years of experience designing, implementing, and/or administering enterprise GIS solutions/systems that leverage the ArcGIS platform, specifically ArcGIS Enterprise components
	- Experience with relational database management systems, including SQL Server, PostgreSQL or Oracle, including knowledge of standard SQL usage and database design concepts such as views, triggers, and schemas
	- Understanding of enterprise geodatabase concepts in the ArcGIS platform, and where and why they are used for geospatial data workflows
	- Experience with operating system concepts: Windows environments, domain management, sharing and security of filesystems in Windows environments, Linux system administration concepts, and general conceptual understanding
	- Knowledge of networking concepts and topics such as firewalls, troubleshooting DNS entries, assessing network configuration and performance
	- Bachelorâ€™s or masterâ€™s in computer science, engineering, mathematics, GIS, or a related field, depending on position level
	- Design Effective Enterprise Systems
		* Asses and provide recommendations to customers related to the appropriate and effective use of ArcGIS software components
		* Provide actionable advice related to system design, performance implications, functional limitations, and any other topics that affect system design
		* Interface with solution architects and enterprise IT staff from a customer organization to explain and guide them through ArcGIS design decisions
		* Communicate technical concepts and ArcGIS platform capabilities to technical and non-technical audiences
	- Implement Advanced ArcGIS Enterprise Deployments
		* Deploy and configure ArcGIS Enterprise in a wide variety of environments across operating systems, cloud providers, security architectures, customer types, industries, and organizations
		* Configure ArcGIS Enterprise system to meet the customerâ€™s service level agreement including high availability, disaster recovery, and security needs
		* Plan and execute the migration of content from one ArcGIS Enterprise deployment to another, encompassing different architectures, deployment strategies, and software components
	- Assist with Technical Troubleshooting and Issue Resolution
		* Assist Esri customers with troubleshooting advanced ArcGIS Enterprise deployments
		* Assist with communicating troubleshooting guidance to related platform components such as storage, networking, security
	- Assess and Optimize Performance
		* Identify performance requirements and understanding from a customer perspective
		* Use Esri tools and industry standard tools to identify performance issues with maps, web services, databases, web applications, and other contexts
		* Provide recommendations to customers related to performance monitoring, management, and improvement across the entire ArcGIS system
	- Participate in a Technical Community
		* Participate in a technical community of advanced enterprise staff, sharing experiences; writing best practices documentation, technical guides, and helpful scripts; and participating in product direction discussions and recommendations
		* Work collaboratively with teammates to solve difficult technical challenges
+ Comfortable with tools such as: Amplitude, Segment Sources, Looker, Postgres, Graylog, Github, Datadog
+ skill set:
	- Work with large, complex data sets. Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed. Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations.
	- Build and prototype analysis pipelines iteratively to provide insights at scale.
	- Develop comprehensive knowledge of TikTok data structures and metrics, advocating for changes where needed for product development.
	- Interact cross-functionally, making business recommendations (e.g., cost-benefit, forecasting, experiment analysis) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information.
	- Research and develop analysis, forecasting, and optimization methods to improve the quality of TikTok ads products.
Qualifications
	- Master's degree in a quantitative discipline (e.g., Statistics, Operations Research, 2. Economics, Computer Science, Mathematics, Physics) or equivalent practical experience.
	- 3+ years of relevant work experience, including expertise with statistical data analysis such as linear models, multivariate analysis, stochastic models, sampling methods.
	- Experience with statistical software (e.g. R, Python, MATLAB) and database languages (e.g. SQL)
	- Demonstrated leadership and self-direction. Willingness to both teach others and learn new techniques.
	- Demonstrated skills in selecting the right statistical tools given a data analysis problem. Effective written and verbal communication skills.
+ skill set:
	- Experience with mobile app attribution platforms (e.g. Appsflyer/Tune/Adjust)
	- Experience working with very large data sets and distributed computing (Hive/Hadoop/MapReduce)
	- Experience working with social and digital media data and other marketing analytics tools (e.g. Google Analytics/Adobe Analytics/Amplitude)
+ Experience building data science models (Regression, Decision Trees, K-Means, etc.)
+ Demonstrated knowledge of Redis/MySQL/Elasticsearch/Druid/Spark Streaming.
+ Knowledge of sequence models and generative models.
+ Background in music information retrieval (MIR).
+ Proficient with parallel programming and performance optimization techniques such as NEON, OpenCL, OpenGL ES, Metal and Vulkan;
+ skill set:
	- Understand product objectives; Take full advantage of modern machine learning and information retrieval techniques to improve search experience;
	- Provide technical leadership to drive search strategy iteration including query understanding, recall & ranking, query recommendation, reliability, etc;
+ skill set:
	- Familiar with graphics APIs (OpenGL, DirectX, Metal, or Vulkan) and GPU architectures.
	- Knowledge of one or more UI frameworks (Qt, DirectUI, Electron, etc...)
+ skill set:
	- Achieve scaling, cropping, effects, filters and other pre & post processing functions based on OpenGLES and other graphics libraries;
	- Experience with the use of FFmpeg/OpenGL
	- Participated in NOI/ACM/TopCoder competition will be a big plus.
+ skill set:
	- Familiar with the use of multimedia architecture such as FFmpeg / directshow / AVFoundation;
	- Experience with graphics libraries such as OpenGL/Metal/Vulkan and mobile operation systems such as Android iOS
+ Publications in top conferences in areas such as MIR, machine learning or similar (e.g. ISMIR, ICML, ICLR, NeurIPS).
+ skill set:
	- Strong track record of research in related areas including but not limited to (preferring candidates with publications in top-tier venues such as CVPR, ICCV, ECCV):
		* 3D reconstruction (structure-from-motion, multi-view stereo, photometric stereo etc.)
		* Large-scale place recognition
		* Real-time simultaneous localization and mapping (SLAM) systems
		* 3D object pose estimation and tracking
		* 3D plane estimation and 3D primitive estimation
		* 3D scene parsing
		* Light field and panorama capture
		* Novel view synthesis and image-based rendering
		* Neural rendering
		* Lighting estimation
	- Experienced in implementing and optimizing complex and performance-critical systems.
	- Self-motivated and strong problem solving skills.
	- Collaborative work style.
+ skill set:
	- Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.).
	- Experience with performing data analysis, data ingestion and data integration.
	- Working industry experience with Big Data systems and projects.
	- Experience in building large scale distributed systems in a product environment.
	- Experience with ETL(Extraction, Transformation & Loading) and architecting data systems.
	- Experience with schema design and data modeling.
	- Experience in writing, analyzing and debugging SQL queries.
	- Experience in data privacy and security related projects.
	- Deep understanding of various Big Data technologies.
	- Passionate and self-motivated about technologies in the Big Data area.
	- Design and build data transformations efficiently and reliably for different purposes(e.g. reporting, growth analysis, multi-dimensional analysis).
	- Design and implement reliable, scalable, robust and extensible big data systems that support core products and business.
+ skill set:
	- Research and practical experience in one or more areas of computer vision, including but not limited to (preferring candidates with publications in top-tier venues such as CVPR, ICCV, ECCV):
		* Generative models, GAN (generative adversarial networks)
		* Image and video synthesis/manipulation
		* Unsupervised and weakly-supervised image/video representation learning
		* Object detection, recognition, segmentation, and tracking
		* Action recognition, event detection, video summarization
		* Image and video retrieval
		* Image and video enhancement
		* Image and video restoration
+ skill set:
	- Proven research and practical experience in one or more areas of image and video processing, including but not limited to (preferring candidates with publications in top-tier venues such as CVPR, ICCV and ECCV):
		* Optical flow
		* Image and video enhancement
		* Noise reduction
		* Image and video super-resolution
		* Image and video de-blur
		* HDR
		* Artifact removal (rain, haze, reflection)
		* Intrinsic images
		* Image and video editing
+ skill set:
	- Strong track record of research in related areas including but not limited to (preferring candidates with publications in top-tier venues such as SIGGRAPH, SIGGRAPH Asia, CVPR, ICCV, ECCV):
		* 3D modeling and geometry processing
		* Physically-based simulation
		* 3D reconstruction
		* Light field capture and rendering
		* Material and lighting estimation
		* Character animation
		* Rendering
		* Neural rendering
		* 3D deep learning
		* Image and video manipulation
	- Experienced in implementing and optimizing complex and performance-critical systems.
+ skill set:
	- User experience is at the forefront of how we create intuitive, innovative, and beautiful products that people love. We strive to learn and understand our usersâ€™ needs, behaviors, and emotions to gather insights that inform product strategy and design. Our UX teams include designers, researchers, content strategists, and engineers who are passionate about quality, usability, and simplicity. We work on collaborative teams to solve complex challenges and craft experiences that highlight our productsâ€™ unique capabilities and personalities.
	- User Experience Researcher (UXRs) in News Break plays a vital role in its principle of truly â€œuser-driven and user-focused product developmentâ€. In this role, you will use qualitative and quantitative methods to create understanding and empathy around user needs, stated and unstated, for your entire product team including UI designers, product managers, and engineers. You will do so by conducting primary research, exploring the behaviors and motivations of our users through methods like field visits, ethnography, surveys, usability testing, and logs analysis. Your research will help the team to identify experience problem and articulate it in a laserlike focused way. By working closely with cross functional teams and deeply involved in all stages of product development, you will help us create useful, usable, and delightful new products and features for people as well as continually innovating on our existing products. You will bring inspiration into the team through delivering compelling, written, in-person and visual presentations on your findings, in forms that include but not limited to user persona, segmented persona, user journey map, etc.
	- Conduct independent research on multiple aspects of products and experiences.
	- Collect and analyze user behavior through field visits, ethnography, surveys, benchmark studies, server logs and online experiments (A/B testing).
	- Work with Designers, Product Managers, Engineers and other UXRs to prioritize research opportunities in a fast-paced, rapidly changing environment.
	- Understand and incorporate complex technical and business requirements into research.
	- Advocate research findings to diverse audiences through written reports and in-person presentations.
	- Create user personas based on user segmentations.
	- Create User Journey Map to help the team understand different mood of the users.
	- Minimum Qualifications:
		* BA/BS degree in Anthropology, Human-Computer Interaction (HCI), Human Factors, Psychology, Sociology, or a related field or equivalent experience.
		* Experience with research design utilizing various methods including but not limited to usability studies, contextual inquiry, and surveys.
		* Relevant product research experience, either in an end-to-end, usability, or generative setting.
		* Ability to generate research insights to help product teams make confident decisions, and build empathy and intuition for our users
		* Experience to collaborate closely with cross-functional partners including Design, Data Science, Product Management, and Engineering
	- Preferred Qualifications:
		* Master's degree or PhD in a related field.
		* 5 years of relevant work experience within User Experience, Human-Computer Interaction, applied research setting, and/or product research and development.
		* Experience in a variety of product spaces, applied research and/or academic settings.
		* Proficiency in communicating user research findings with cross functional partners to drive impact.
		* Strong understanding of the strengths and shortcomings of different research methods, including when and how to apply them during the product development process.
+ skill set:
	- Develop highly scalable tools leveraging machine learning models to solve problems such as classification, clustering, topic modeling, natural language processing and recommendation
	- Develop in-house machine learning tools and pipelines to support fast experimentation of machine learning models
	- Work with other engineers to identify and solve machine learning problems
	- Minimum Qualifications
		* Experience in one or more of the following areas: machine learning, recommendation systems, deep learning and data mining
		* Expert knowledge in Java or Scala
		* Experience with scripting languages such as Perl, Python, and shell scripts
	- Preferred Qualifications
		* MS degree in Computer Science or related quantitative field with 3+ years of machine learning related work or research, or PhD degree in Computer Science or related quantitative field
		* Experience with machine learning frameworks such as TensorFlow, PyTorch or MxNet
		* Publications in trade journals such as JMLR or Machine Learning, or Presentations at related conferences such as ICML, NeurIPS, KDD, SIGIR and etc.
+ skill set:
	- Design and develop core backend software components; create and deploy new software solutions for the NewsBreak app:
		* Apply expertise and innovation to create new technology, such as the online serving pipeline and data platform, machine learning algorithm for user click prediction, and etc.
		* Analyze the latency problems of the backend software modules to develop solutions for parallelization; thus, improving the throughput of the online serving system.
		* Write, analyze, review, and rewrite programs, using workflow chart and diagram, and applying knowledge of computer capabilities, subject matter, and symbolic logic.
		* Write, update, and maintain computer programs or software packages to handle specific jobs such as tracking inventory, storing or retrieving data, or controlling other equipment.
		* Maintain both product level and system level code, primarily using Python, Java, and PHP, to meet the technical challenges and requirements.
		* Research and evaluate the feasibility of new technologies and provide direction on the application of modem natural language understanding techniques for the online serving system.
	- Perform offline and online validation tests:
		* Develop and execute verification and validation tests for the newly designed online serving backend software components and analyze the product performance to meet efficiency requirements.
		* Modify existing backend software components to correct errors; perform revisions, repairs, or expansions of existing programs to increase operating efficiency or adapt to new requirements.
		* Store, retrieve, and manipulate data for analysis of the online serving system capabilities and requirements, using MongoDB and HDFS.
	- Develop recommendation and phrase mining algorithms:
		* Design and develop advanced recommendation and phrase mining algorithms for user click prediction using machine learning algorithms such as Collaborative Filtering, Factorization Machine, DeepWalk and etc.
		* Make use of data analytical tools such as Kibana, Azkaban, Kubernetes and etc., to analyze user needs and software requirements to determine feasibility of the proposed design within time and cost constraints.
	- Provide other technical supports & draft related documentations:
		* Discuss with managerial, engineering, and technical personnel to clarify program intent, identify problems, and suggest changes for the overall online serving system, recommendation system, and the phrase mining algorithm.
		* Confer with systems analysts, engineers, programmers and others to obtain information on limitations and capabilities, performance requirements and interfaces of a certain feature.
	- Masterâ€™s degree in Computer Science, Computer Engineering or related plus 1 year experience.
+ skill set:
	- Responsibilities
		* Design, develop and support data pipelines, warehouses and reporting systems to solve business operations, users and product problems.
		* Create extract, transform, and load (ETLs) and reporting systems for new data using a variety of traditional as well as large-scale distributed data systems.
		* Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
		* Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
		* Designs data integrations and data quality framework.
		* Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.
	- Minimum Qualifications
		* BS or MS degree in Computer Science or a related technical field
		* Experience with one general purpose programming language (e.g., Java, C/C++, Python).
		* Experience in data processing using traditional and distributed systems (e.g., Hadoop, Spark, Dataflow, Hive, Impala, Airflow).
		* Experience designing data models and data warehouses and using SQL and NoSQL database management systems.
		* Experience in custom ETL design, implementation and maintenance.
		* Experience analyzing data to identify deliverables, gaps and inconsistencies.
	- Preferred Qualifications
		* Experience with more than one coding language.
		* Experience with SQL performance tuning and E2E process optimization.
		* Experience with designing and implementing real-time pipelines.
		* Experience with anomaly/outlier detection
		* Excellent communication, organizational, and analytical skills.
+ skill set:
	- Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business products.
	- Partner with Product and Engineering teams to solve problems and identify trends and opportunities.
	- Work on large scale data pipelines by leveraging different SQL/non-SQL technologies to build automated data analysis and dashboard.
	- 2+ yearsâ€™ experience doing quantitative analysis within a high-tech company. Startup is a plus
	- BA/BS in Computer Science, Math, Physics, Engineering, Statistics or other technical fields
	- Experience in SQL or similar programming languages
	- Experience with one general purpose programming language (e.g., Java, C/C++, Python)
	- Experience in data processing using traditional and distributed systems (e.g., Hadoop, Spark, Dataflow, Hive, Impala, Airflow)
	- Knowledge of statistics and machine learning
+ skill set:
	- Develop highly scalable tools leveraging machine learning models to solve problems such as classification, clustering, topic modeling, natural language processing and recommendation
	- Develop in-house machine learning tools and pipelines to support fast experimentation of machine learning models
	- Work with other engineers to identify and solve machine learning problems
	- Minimum Qualifications
		* Experience in one or more of the following areas: machine learning, data mining, computer vision, and natural language processing
		* Experience with machine learning frameworks such as TensorFlow, PyTorch or MXNet
		* Expert knowledge in C/C++ and Python
	- Preferred Qualifications
		* MS degree in Computer Science or related quantitative field with 3+ years of machine learning related work or research, or PhD degree in Computer Science or related quantitative field
		* Industry experience with developing and deploying machine learning models in production
		* Contributions to research communities/efforts, including publishing papers in machine learning (AAAI, ICLR, NeurIPS, ICML, KDD, CVPR)
+ skill set:
	- Develop highly scalable machine learning models to solve problems such as image/video classification, image/video content understanding and recommendation
	- Develop in-house machine learning tools and pipelines to support fast experimentation of machine learning models
	- Work with other engineers to identify and solve machine learning problems
	- Minimum Qualifications
		* Experience in one or more of the following areas: deep learning, computer vision, recommendation systems, and data mining
		* Experience with machine learning frameworks such as TensorFlow, PyTorch or MXNet
		* Expert knowledge in C/C++ and Python
	- Preferred Qualifications
		* MS degree in Computer Science or related quantitative field with 3+ years of machine learning related work or research, or PhD degree in Computer Science or related quantitative field
		* Industry experience with developing and deploying machine learning models in production
		* Contributions to research communities/efforts, including publishing papers in machine learning (AAAI, ICLR, NeurIPS, ICML, KDD, CVPR)
+ skill set:
	- Understand product specifications and user psychology
	- Conduct concept and usability testing and gather feedback
	- Create personas through user research and data
	- Define the right interaction model and evaluate its success
	- Develop wireframes and prototypes around customer needs
	- Find creative ways to solve UX problems (e.g. usability, findability)
	- Work with UI designers to implement attractive designs
	- Communicate design ideas and prototypes to developers
	- Keep abreast of competitor products and industry trends
	- Proven experience as a UX Designer or similar roles
	- Strong portfolio of design projects
	- Background in project management and research
	- Familiarity with interaction design and information architecture
	- Proficient in design software (e.g. UXPin, Balsamiq)
	- Knowledge of HTML/CSS; JavaScript is a plus
	- Problem-solving aptitude
	- Analytical mind with a business acumen
	- Excellent communication skills
	- BSc in Design, Computer Science, Engineering or a related field
+ skill set:
	- Every day, SmartNews analyzes millions of URLs to deliver the top articles that matter in near-real time to millions of users around the world. Our News Ranking team, along with our AI Foundation team, works on a range of recommendation and optimization problems, e.g. news feed ranking, push recommendation, search ranking/discovery, collaborative filtering, personalized recommendation, diversification to deliver the world's quality information to the people who need it.
	- Responsibilities: This is a hybrid of system engineering and machine learning role:
		* Propose machine learning initiatives to fuel our business growth, build end to end machine learning framework/solution to improve our KPI/metrics
		* Write server-side production code for applications that are robust and efficient
		* Develop machine learning algorithms, combining with rule-based optimization to deliver improvement in product metrics
		* Build recommendation and ranking algorithms for news articles
		* Develop toolings to make ML engineers to be more productive
		* Lead medium/large sized projects to improve news ranking
	- Minimum Qualifications
		* 3+ years of experience in designing and implementing machine learning algorithms, and applying them to real world problems
		* Solid Machine Learning background and deep understanding of certain domain of machine learning techniques, especially in natural language processing, recommendation systems, computer visions
		* Strong software development skills with proven record of shipping changes to production that improved product metrics with machine learning technologies
		* Able to have deep end-to-end understanding of sophisticated ranking systems and can proactively detect problems and make improvement suggestions
		* Good written and spoken communication skills, can work across functional teams
		* Expert coding abilities in multiple programming languages (e.g. Java, C++, Python, Scala)
		* MS or BS in computer science, mathematics, physics or other quantitative fields
	- Preferred Qualifications
		* Experience with cloud based architecture (e.g. Amazon Web Services)
		* Strong interest in news media and our mission
+ skill set:
	- Description
		* Founded in Tokyo in 2012, SmartNews has quickly become the go-to source of news for millions of users around the world, and a leading news aggregation mobile app. Our mission is bigger than simply aggregating news, and we are working to break through the filter bubble and deliver the worldâ€™s quality information to the people who need it. We are seeking a Director of Product Design with a â€œget-it-doneâ€ attitude and a passion to break through the filter bubble to lead our global design team.
		* As the Director of Product Design at SmartNews, you will lead by example and connect design vision and strategy to achieve the companyâ€™s goals through innovative user experiences. In this role, youâ€™ll be leading a globally distributed, highly motivated design team to create a one-of-a-kind news experience that will delight our users by delivering content thatâ€™s fresh, timely, and relevant. You will establish, maintain and represent the design teamâ€™s voice and partner with executive leadership across Product Management, Data Science, Engineering, Content, and Marketing.
		* You will report to the SVP of Product and have an opportunity to make a significant contribution to achieving our global mission of and taking SmartNews to the next level. Join us and make a difference!
	- Responsibilities
		* Establish design direction to drive product strategy and deliver company goals
		* Collaborate cross-functionally with stakeholders in product management, engineering, marketing, content, and ads to set the vision and strategic plan for the product roadmap, both short-term and long-term
		* Build, lead, manage, and mentor a globally-distributed design team
		* Empower design team to collaborate cross-functionally with product managers, engineers, marketing, and other members to execute the product roadmap
		* Establish and integrate a collaborative user centric design practice into the product development process
		* Lead a team through rigorous design reviews and iterations to align design and product strategy and execute detailed implementations that will deliver impact to company goals
		* Create and enhance a design system that unifies product and marketing experiences and speeds design and product development
		* Execute in a fast-paced and highly fluid environment and streamline complex problems into elegant solutions
	- Requirements
		* 10+ years of hands-on visual and interaction design experience executing and shipping mobile centric, consumer products
		* 7+ years in a management or leadership role in product design with direct reports
		* Design portfolio with examples of interactions and visuals across mobile applications
		* Experience in leading design strategy all the way from vision to concept to production
		* Experience growing scalable design process and practice within design teams
		* Excellent communicator with exceptional speaking and presentation skills. You are a storyteller at heart.
		* Possesses a hands-on, â€œroll up your sleeves,â€ action-oriented approach.
		* Ability to thrive in a dynamic, high-octane environment while juggling multiple projects at once, and comfortable with tight deadlines
		* Ability to bring cross-functional teams together to enable proficient and effective collaboration
		* Ability to provide clear, honest and objective feedback in order to continue raising the bar for the product and design team
		* Expert in the tools of the trade, e.g. Adobe CC, Sketch, Figma, and various design and prototyping software
		* Possesses high attention to detail and consistency
		* Responsive to feedback, capable of both receiving and giving constructive feedback with empathy
		* Passion for the news as a fourth pillar of democracy and belief in mission to create better understanding and accountability between people through delivery of quality information not based on filter bubble
	- Nice-to-haves
		* B.S. and/or M.S. degree
		* Knowledge of programming, mobile iOS or Android, or HTML/CSS/Javascript
		* Multidisciplinary background such as Psychology, Cognitive Psychology, Sociology, or Anthropology
		* Experience and familiarity with data science and analysis
		* Familiarity with Japanese language and culture. We have distributed teams at SmartNews, and while Japanese language skill is not necessary, it will help with context
+ skill set:
	- Responsibility: This is a hybrid of system engineering and machine learning role:
		* Write server-side production code for applications that are robust and efficient
		* Develop machine learning algorithms, combining with rule-based optimization to deliver improvement in product metrics
		* Build recommendation and ranking algorithms for news articles
		* Develop internal analytics tools
		* Rapid prototyping
	- Minimum Qualifications
		* 2+ yrs. experience in designing and implementing machine learning algorithms, and applying them to real world problems
		* Solid Machine Learning background and deep understanding of certain domain of machine learning techniques, especially in natural language processing, recommendation systems, computer visions
		* Solid software development skills with proven record of shipping changes to production that improved product metrics with machine learning technologies
		* Good written and spoken communication skills, can work across functional teams
		* Expert coding abilities in multiple programming languages (e.g. Java, C++, Python, Scala)
		* MS or BS in computer science, mathematics, physics or other quantitative fields
	- Preferred skill/experience
		* Experience with cloud based architecture (e.g. Amazon Web Services)
		* Strong interest in news media and our mission
+ skill set:
	- Responsibility
		* Research and core technology development for machine learning
		* The ability to solve issues ranging from fundamental algorithm development, implementation and optimization to deliver product metrics
		* In this position, you are expected to utilize your expertise on one or more of following R&D areas to provide cutting edge solutions or core technologies for SmartNews recommendation systems (Ads, News, etc)
		* General Machine Learning, Deep Learning
		* Natural Language Processing (entity recognition, categorization, text embedding, etc)
		* Computer Vision, Image Processing
		* Knowledge Graph
		* Recommendation, Collaborative Filtering Algorithms
		* Rapid prototyping and iterating
	- Minimum Qualifications
		* 2+ yrs. experience in designing and implementing machine learning algorithms, and applying them to real world problems
		* Solid Machine Learning background and good understanding of certain domain of machine learning techniques, especially in natural language processing, recommendation systems, computer visions
		* Good written and spoken communication skills, can work across functional teams
		* Strong coding abilities in multiple programming languages (e.g. Java, C++, Python, Scala)
		* MS in computer science, mathematics, physics or other quantitative fields
	- Preferred skill/experience
		* Ph.D Degree in computer science, mathematics, physics or other quantitative fields
		* Strong interest in news media and our mission
+ skill set:
	- Ability to optimize/debug hardest feature/model problems of the team
	- Have good record of publication in his/her domain of expertise
+ skill set:
	- Experience with open source data platforms including Hive/Flink/Spark, etc
	- Experience with highly scalable data platform/service (>TB/day level)
+ Capable of designing high quality frameworks/toolings to reduce redundancy and ineffectiveness across components/services
+ skill set:
	- SmartNews is a leading mobile app of news aggregation services. It analyzes millions of articles to deliver most engaging information with high quality in near-real time fashion to millions of users around the world. Our AI Foundation team is responsible to research and develop world-class AI algorithms that can be applied at large scale to accomplish our mission. It works on a range of content understanding, user modeling and recommendation problems, which include natural language processing tasks of classification, entity recognition, summarization, computer vision of image/video processing, collaborative filtering, etc. The team generally produce good content/user signals and state-of-art recommendation models to News Ranking/Ads Ranking team to deliver the world's high quality information to the people who need it.
	- Responsibilities
		* Set technical and research roadmap for AI Foundation or even company level machine learning roadmaps (at principal level) and able to lead its implementation
		* The ability to solve hardest issues of AI Foundation team from fundamental algorithm development, implementation and optimization to deliver product metrics
		* Lead cross-organizational projects to improve features/models that benefit company OKR
		* Set visions for companyâ€™s research direction to be industry leading in areas of personalized discovery and related areas
		* In this position, you are expected to utilize your industry leading expertise on one or more of following R&D areas to provide cutting edge solutions or core technologies for SmartNews recommendation systems (Ads, News, etc). At principal level, you are required to have overall understanding of corporate AI landscape, and set visions/roadmaps in its directions
		* General Machine Learning, Deep Learning
		* Natural Language Processing (entity recognition, categorization, text embedding, etc)
		* Computer Vision, Image Processing
		* Knowledge Graph
		* Recommendation, Collaborative Filtering Algorithms
		* Be great mentor to other machine learning scientists
		* Promote AI first culture and distill AI mindset across engineering teams (principal level)
	- Minimum Qualifications
		* 8+ years of experience in designing and implementing state-of-the-art machine learning algorithms, and applying them to real world problems
		* Industry leading expertise in certain domain of machine learning techniques, especially in deep learning, natural language processing, recommendation systems, computer visions
		* Long term track record of successfully deliver improvement of features/models to production systems with high impact by working across teams and organizations
		* Influential publications at top industry conferences/journals, well recognized in the industry for the domain of expertise
		* Strong mentors of senior machine learning scientists and able to grow them to the next level
		* Good written and spoken communication skills, can work across functional teams
		* Strong coding abilities in multiple programming languages (e.g. Java, C++, Python, Scala)
		* Ph.D in computer science, mathematics, physics or other quantitative fields
	- Preferred Qualifications
		* Strong interest in news media and our mission
		* Strong domain expertise in recommendation algorithms
+ skill set for aspects of software development or management:
	- infrastructure administration and security
	- user interface design, or user experience design
	- infrastructure management and provisioning
	- data pipeline development
	- product management and project tracking
	- product direction and high-level decision making
	- quality assurance
	- release management and/or distribution
	- sales, marketing, and/or business intelligence
	- software developing, computer programming, or coding
	- software or system architecture
	- resource and cost monitoring
+ computer (programming) languages surveyed in the "User Experience" survey for Google, Inc.:
	- C++/C
	- C\# or related frameworks (e.g., Xamarin)
	- Dart or related frameworks (e.g., Flutter)
	- Go
	- HTML or related frameworks (e.g., Cordova, Ionic, Sencha)
	- Java
	- JavaScript or related frameworks (e.g., React, React Native, Node.js, AngularJS)
	- Kotlin
	- Objective-C
	- PHP
	- Python
	- Ruby
	- Swift
+ cloud computing tasks:
	- analyzing big data
	- architecting cloud solutions
	- configuring and maintaining infrastructure for building and/or deploying code
	- configuring and/or managing security services and policies within an organization
	- configuring virtual environments and networking
	- deploying, managing, or monitoring machine learning pipelines
	- evaluating and/or deciding which products to use, including APIs
	- provisioning and/or managing storage (e.g., databases)
	- managing employees
	- managing or monitoring services in production
	- managing your organization's service costs and cloud expenditures
	- writing code for cloud-based applications or services
+ cloud computing platforms:
	- Alibaba Cloud
	- Amazon Web Services
	- Firebase
	- Heroku
	- IBM Cloud
	- Microsoft Azure
	- on-premise services
	- private Cloud
	- Rackspace
	- DigitalOcean
	- Google Cloud Platform
	- StackDriver
+ Google Cloud Platforms products:
	- App Engine
	- Cloud BigQuery
	- Cloud Bigtable
	- Cloud Build (formerly Container Builder)
	- Cloud Dataflow
	- Cloud Datalab
	- Cloud DataProc
	- Cloud Datastore
	- Cloud Firestore
	- Cloud Functions
	- Cloud Identity & IAM
	- Cloud Machine Learning
	- Cloud Memorystore
	- Cloud Pub/Sub
	- Cloud Spanner
	- Cloud SQL
	- Cloud Storage
	- Cloud Tasks
	- Compute Engine
	- Container Registry
	- GCP Games
	- Genomics
	- Google Maps
	- Hybrid Connectivity (e.g., HA VPN, Cloud Router, Interconnect)
	- IoT Core
	- Kubernetes Engine
	- Network Security (e.g., Cloud Armor, Cloud Security Command Center, DLP)
	- Network Services (e.g., Load Balancing and Content Delivery Networks)
	- StackDriver
	- TensorFlow
	- VPC Network (Shared VPC, VPC Peering)
+ Google Cloud Platform interfaces:
	- Cloud Console GUI via browser on desktop or laptop computer
	- Cloud Console GUI via browser on mobile device
	- Cloud Console mobile application
	- Firebase Console GUI
	- Google Cloud APIs (e.g., via HTTP requests, gRPC, Google Client Libraries)
	- Google Cloud Command Line Interface (CLI) (e.g., gcloud, gsutil, bq, cbt)
	- non-Google configuration management tools (e.g., Chef, Puppet)
	- non-Google CLIs (e.g., kubectl, MySQL)
	- non-Google GUIs (e.g., DataDog, New Relic, Splunk)
+ security tasks for cloud computing:
	- defining policies for assets and tracking performance
	- scanning and detecting security threats and incidents
	- responding to security threats and accidents
	- ensuring applications comply with secure coding requirements
	- managing accounts and defining permissions for cloud resources
+ Learning Management Systems (LMS):
	- Blackboard
	- Canvas
	- Desire2Learn (D2L) Brightspace
	- Google Classroom
	- Moodle or Moodlerooms
	- Pearson's Learning Studio / eCollege
	- Sakai
+ skill set:
	- SmartNews is a leading mobile app of news aggregation services. It analyzes millions of articles to deliver most engaging information with high quality in near-real time fashion to millions of users around the world. Our AI Foundation team is responsible to research and develop world-class AI algorithms that can be applied at large scale to accomplish our mission. It works on a range of content understanding, user modeling and recommendation problems, which include natural language processing tasks of classification, entity recognition, summarization, computer vision of image/video processing, collaborative filtering, etc. The team generally produce good content/user signals and state-of-art recommendation models to News Ranking/Ads Ranking team to deliver the world's high quality information to the people who need it.
	- Responsibilities
		* Set technical and research roadmap for AI Foundation or even company level machine learning roadmaps (at principal level) and able to lead its implementation
		* The ability to solve hardest issues of AI Foundation team from fundamental algorithm development, implementation and optimization to deliver product metrics
		* Lead cross-organizational projects to improve features/models that benefit company OKR
		* Set visions for companyâ€™s research direction to be industry leading in areas of personalized discovery and related areas
		* In this position, you are expected to utilize your industry leading expertise on one or more of following R&D areas to provide cutting edge solutions or core technologies for SmartNews recommendation systems (Ads, News, etc). At principal level, you are required to have overall understanding of corporate AI landscape, and set visions/roadmaps in its directions
		* General Machine Learning, Deep Learning
		* Natural Language Processing (entity recognition, categorization, text embedding, etc)
		* Computer Vision, Image Processing
		* Knowledge Graph
		* Recommendation, Collaborative Filtering Algorithms
		* Be great mentor to other machine learning scientists
		* Promote AI first culture and distill AI mindset across engineering teams (principal level)
	- Minimum Qualifications
		* 8+ years of experience in designing and implementing state-of-the-art machine learning algorithms, and applying them to real world problems
		* Industry leading expertise in certain domain of machine learning techniques, especially in deep learning, natural language processing, recommendation systems, computer visions
		* Long term track record of successfully deliver improvement of features/models to production systems with high impact by working across teams and organizations
		* Influential publications at top industry conferences/journals, well recognized in the industry for the domain of expertise
		* Strong mentors of senior machine learning scientists and able to grow them to the next level
		* Good written and spoken communication skills, can work across functional teams
		* Strong coding abilities in multiple programming languages (e.g. Java, C++, Python, Scala)
		* Ph.D in computer science, mathematics, physics or other quantitative fields
	- Preferred Qualifications
		* Strong interest in news media and our mission
		* Strong domain expertise in recommendation algorithms
+ skill set:
	- Responsibilities
		* Responsible to set technical direction of most impactful areas of news ranking team and drive its major projects as tech lead
		* Able to work across product and platform teams to orchestrate large scope projects that significantly improve news ranking and achieve key engagement KPIs
		* Design and develop frameworks to make ranking engineers of news ranking team to be productive
		* Lead design and implementation of machine learning algorithms, combining with rule-based optimization to deliver significant improvement in product metrics
	- Minimum Qualifications
		* 6+ years of experience in designing and implementing machine learning algorithms, and applying them to real world problems
		* Solid Machine Learning background and deep understanding of certain domain of machine learning techniques, especially in natural language processing, recommendation systems or computer visions
		* Have proven track record of hands-on design and coding experience in building and deploying multi-tier recommendation systems at scale
		* Able to have deep end-to-end understanding of sophisticated ranking systems and can proactively detect problems and make/implement improvement suggestions
		* Able to distill and solve hardest problems of news ranking team in expertise areas
		* Good written and spoken communication skills, can work across functional teams
		* Expert coding abilities in multiple programming languages (e.g. Java, C++, Python, Scala)
		* MS or BS in computer science, mathematics, physics or other quantitative fields
	- Preferred Qualifications
		* Strong interest in news media and our mission
		* Experience with news ranking
+ skill set:
	- Immuta's Data Platform
	- Python, Pandas, PySpark
	- Various Machine Learning Frameworks
	- Snowflake
	- Databricks
+ skill set and tasks of role:
	- Deeply understand the behaviors of Substack readers and writers
	- Explore, measure, and track metrics related to the growth of the Substack ecosystem
	- Derive denormalized tables to enable simplified analytics
	- Partner with product teams on developing key metrics and testing intuitions with data to inform better decision making
	- Develop data insights that can empower Substack writers to better understand their newsletters
	- Love analyzing problems with data and synthesizing results to tell the narrative of the product
	- Have expertise in SQL (we use ***Postgres + Snowflake***) and ***event-based analytics and metrics (Ã  la Segment)***
	- Understand growth funnels and how to measure them
	- Enjoy ***building dashboards (Sisense/Periscope Data)*** to memorialize findings and monitor key metrics
	- Believe that building canonical datasets can empower an organization
	- Have a proven track record of making meaningful impacts through data insights and discovery in past roles.
	- Nice to haves: ***Airflow/Luigi/other DAG tool experience***, Python, Node
+ skill set - Bonus points if you have experience with any of the following:
	- distributed systems
	- batch data processing
	- stream processing
	- database internals
	- query optimizers
	- query processing
	- data integration
	- recommender systems
	- information theory
	- knowledge graphs
+ A skills matrix of your expertise in using Google OR Tools, Python, C++, geospatial analysis, and related tools (geopandas, shapely, QGIS, postgis, etc.)
+ industrial robotic experience: KUKA, FANUC, or ABB.
+ skill set:
	- Vicarious aims to transform robotics by creating robots with human level performance on real-world manipulation tasks. We are passionate about changing the world with science and software, and we are looking for exceptional people to join us in that mission.
	- Our long term goal is to build machines that exceed human intelligence. We are passionate about changing the world with science and software, and we are looking for exceptional people to join us in that mission. Vicarious is working on solving the problems that will take us from the current state of the art to human-level AGI. We work on all components of the AI problem, including perception, concept learning, reasoning, and sensory motor systems, and beyond. Our underlying framework is a probabilistic graphical model that is inspired by the structure of the neocortex. You will join a small, tightly knit collective of extraordinary engineer scientists. Everyone works on our full stack, from algorithms to low level optimizations to GUI code and back.
	- Put your algorithm and math skills to work in solving the hardest problems in learning and inference in hierarchical models.
	- Make decisions about how to translate complex ideas to working solutions while keeping a keen eye for computation/accuracy/memory tradeoffs.
	- Design controlled experiments to show particular performance aspects of the systems and large scale experiments to show statistical robustness.
	- Write infrastructure software to scale our systems and data visualization routines to understand what is happening inside.
	- Keep yourself updated with advances in the field of machine learning and neuroscience.
	- The craftsmanship of building elegant algorithms and tight implementations are part of our company DNA. We work hard to maintain a codebase and a culture that are a joy to work in.
	- PhD or Masters in CS/EE or a related discipline or Masters in CS/EE with relevant research experience.
	- Strong machine learning fundamentals, including probabilistic graphical models
	- Experience building hierarchical vision systems and publishing relevant papers in CVPR/NIPS/ICML is a big plus.
	- Extensive programming skills, ideally in Python and C, and a track record of translating ideas into prototypes quickly.
	- Solid fundamentals in linear algebra, probability theory, signal processing, and optimization.
	- Experience developing and testing ideas in a large scale setting.
	- Experience with belief propagation and approximation methods.
	- Knowledge of biologically inspired models of vision.
	- Interest in neuroscience a plus.
	- Experience working in an interpreted environment like MATLAB or Mathematica also a plus.
	- Desired personal qualities:
		* Integrity
		* Ability to admit when wrong
		* Altruism
		* Fearlessness working outside your comfort zone
		* Patience with others
		* Described by others as the best researcher / engineer / thinker they know
		* Intellectual breadth
		* Sense of humor
+ Experience developing with ROS and related software such as MoveIt! and PCL
+ skill set:
	- Masters or PhD in a computer vision-related discipline (or equivalent professional experience), preferably in one of the following areas: probabilistic graphical models, approximate inference, combinatorial optimization, neural networks, object class and instance detection, pose estimation, 3D scene understanding and recognition from RGB-D imagery, 3D reconstruction, structure-from-motion, multi-view stereo, etc.
	- Strong publication record and/or industry experience in the above mentioned areas, in top-tier conferences such as NeurIPS, ICML, ICLR, AAAI, AISTATS.
	- Interest/background in algorithms with human-like abilities such as learning from small amounts of data and tight sensorimotor feedback.
	- Strong C++ and/or Python skills. Experience developing with OpenCV, TensorFlow, and PCL.
+ skill set:
	- Deep Learning Compiler Engineer
	- Habana Labs is a young and innovative company focused on developing purpose-built AI processors, disruptive solutions that will shape the future of AI and Deep Learning computing. Habana was founded in 2016 by successful entrepreneurs, launched its first AI Inference processor in 2018, its Training processor in 2019 and was acquired by Intel in December 2019.  The company now operates as an autonomous subsidiary of Intel.  Our vision to take AI processing from its current limits to the peak of its potential continues. We see challenges as opportunities, laser focus on execution and are determined to fulfill our vision to improve the quality of life, work and leisure with our AI solutions. We are looking for exceptionally smart people who believe that AI will change the world and would like to join us on our exciting journey!
	- We are looking for a hands-on compiler engineer to join the R&D Engineering team, with in-depth knowledge in one or more of programming languages, compilers and hardware architecture. Knowledge of ML/DL frameworks and machine learning would be an added bonus but is not required.
	- Roles and Responsibilities:
		* Explore solutions to challenging customer requirements through state-of-the-art compilation techniques
		* Put together, discuss and advocate design proposals for innovative ideas
		* Rapid prototyping and data-driven exploration of new ideas
		* Design and implement next-gen features in our compiler and runtime software stack
		* Tackle large scale optimization problems across novel architectures
		* Collaborate with peers in SW, Architecture and HW teams
	- BS with 6+ years of experience or MS with 4+ years of experience in Computer Science, Computer Engineering or similar field
	- 6 + years of experience C++ experience and software design skills
	- 3+ years of compiler engineering experience with one or more of
	- 2+ years of  experience building compilers using LLVM or equivalent
	- 2+ years of  Experience building/designing programming models and languages
	- 2+ years of  experience with loop optimizations (vectorization, unrolling, fusion, parallelization etc.)
+ skill set:
	- The Data Center Group (DCG) is at the heart of Intelâ€™s transformation from a PC company to a company that runs the cloud and billions of smart, connected computing devices. The data center is the underpinning for every data-driven service, from artificial intelligence to 5G to high-performance computing, and DCG delivers the products and technologiesâ€”spanning software, processors, storage, I/O, and networking solutionsâ€”that fuel cloud, communications, enterprise, and government data centers around the world.
	- In this position, you will develop compiler technology as the primary job function. You will design, develop, debug & test compiler software, e.g. advanced compiler optimizations and features specific for Intel Architectures, parallelization and vectorization through compilers, new programming language support. You might work directly with hardware design teams, companies and communities developing compilers and, participate in language and standard groups.
	- Bachelorâ€™s degree in Computer Science, Computer Engineering,  Electrical Engineering or a related discipline with 8+ years of experience or a Master's Degree in Computer science, Computer Engineering or Electrical Engineering with 6+ years of experience or a PhD in Computer Science, Computer Engineering, Electrical Engineering or a related field with 4+ years of experience.
	- 5+ years of experience with:
		* C/C++
		* object-oriented programming
		* data structures
		* compiler theory
	- 3+ years of experience with compiler development
	- 3+ years of experience with LLVM compiler development
	- Knowledge of x86 instruction set architecture and Advanced Vector Extensions (AVX)
	- Experience with vectorization and parallel programming models such as OpenMP and/or SYCL and/or GPU programming
+ skill set:
	- Intel Architecture, Graphics, and Software (IAGS) brings Intel's technical strategy to life. We have embraced the new reality of competing at a product and solution levelâ€”not just a transistor one. We take pride in reshaping the status quo and thinking exponentially to achieve what's never been done before. We've also built a culture of continuous learning and persistent leadership that provides opportunities to practice until perfection and filter ambitious ideas into execution.
	- In this position, you will develop compiler technology as the primary job function;  You will Design, develop, debug & test compiler software and programming languages e.g. advanced compiler optimizations and features specific for Intel Architectures, parallelization and vectorization through compilers, new programming languages support. May work directly with hardware design team, companies and communities developing compilers, participate in language and standard groups.
	- Master's Degree in Computer science or Computer Engineering or Electrical Engineering with 4+ years of experience or PhD in Computer Science, Computer Engineering or Electrical Engineering or a related field with 2+ years of experience.
	- 5+ years of experience with:
		* Experience in C/C++
		* object-oriented programming
		* data structures
		* compiler theory
	- 2+ years of experience with compiler development
	- 1+ years of experience with LLVM compiler development
	- Knowledge of x86 instruction set architecture and Advanced Vector Extensions (AVX)
	- Experience with vectorization and parallel programming models such as OpenMP and/or SYCL and/or GPU programming
+ skill set:
	- As part of the Hardware Team, you will work with our established team of physicists and engineers to scale and deploy our integrated photonic quantum computation platform. Further duties include designing and construction of production-grade components and establishing a supply chain for those components. You will be responsible for maintaining Xanaduâ€™s existing cloud-accessible quantum computers, as well as building new such devices and readying them for a production-level environment. The selected candidate will have a proven track record of accomplishments in optical hardware development.
	- Required Qualifications and Experience:
		* Undergrad or Masters in Engineering, Physics, or related discipline
		* Academic or industrial experience in photonic engineering
		* Strong understanding of photonics and electronics
		* Self-motivated and comfortable working in a fast-paced team environment
	- Preferred Qualifications and Experience:
		* 2+ years hands-on experience working in photonic engineering
		* Experience with lasers, modulators, and photodetection
		* Experience with EDA software, PCB fabrication and assembly
		* Experience designing mixed signal PCBs consisting of ADCs, DACs etc.
		* Experience with nonlinear optics, product development, and chip-integrated photonics an asset
+ skill set:
	- Xanadu is seeking a full-time Experimental Physicist to work within the hardware team (20+ physicists and engineers) to develop and optimize all aspects of their transition edge sensor technology and its integration with existing systems. This role involves full-stack systems-level product design, construction, prototyping, testing, and assembly of cutting-edge cryogenic photon number resolving detectors. In addition, candidates may be responsible for writing patents describing these devices and their capabilities, when applicable. Successful applicants will have a proven track record of the following:
	- Qualifications:
		* PhD in Experimental Physics, Electrical Engineering, or related relevant discipline
		* At least 1 year post-doctoral or industry experience (preferred)
	- Minimum Experience:
		* Experience working in a collaborative team-based development environment
		* Experience with independent operating of sub 1 Kelvin cryogenic fridges, preferably with either an adiabatic demagnetization refrigerator and/or dilution refrigerator
		* Experience installing apparatus intra cryostat and conducting cold measurements
		* Strong record of independently led projects
		* Experience automating and developing hardware control code for complex systems using Python
		* Experience with standard mechanical CAD design tools
	- Preferred Experience:
		* Custom PCB design and testing
		* Relevant experience in photonics, integrated optics or laser science
		* Experience with technical product development
+ skill set:
	- We are looking for a talented theoretical quantum error correction researcher to work with us towards building a fault-tolerant quantum computer. If you are interested in putting your expertise to use at the forefront of the quantum computing industry, then this is the perfect opportunity for you!
	- In this role, you will
		* Devise and develop new architectures for fault-tolerant photonic quantum computing.
		* Develop software tools required to implement and analyse quantum error correction protocols.
		* Collaborate with the researchers at Xanadu (including 40+ PhDs) to tailor fault-tolerant architectures to real-world photonic devices, and to inform the development of hardware towards fault-tolerance.
		* Write patents and peer-reviewed articles reporting advances where applicable.
	- Required qualifications and experience
		* PhD degree in Physics, Computer Science, Mathematics, Statistics, or a related technical field with a focus on quantum error correction and fault tolerance.
		* Demonstrated combination of strong problem solving skills, high creativity and attention to detail.
		* Demonstrated strong communication skills, especially in interdisciplinary teams.
		* Ability to operate in a fast-paced environment and manage multiple competing priorities.
	- Preferred qualifications and experience
		* Demonstrated interest and commitment toward understanding and collaborating with theory, simulation, and experimental teams.
		* Demonstrated ability at learning new research topics.
		* Familiarity with quantum optics and continuous variables.
		* Proficiency in working with python or other modern programming language.
+ skill set:
	- As part of Xanaduâ€™s Machine Learning team, the selected candidate will be responsible for working with a multidisciplinary team of machine learning experts and quantum algorithm developers to bring machine learning models into production.  They will develop, deploy, and maintain code, models, and pipelines leveraging various cloud providers and services; automate model training, testing, deployment, and monitoring; and design solution architectures for data driven applications.
	- Prospective applicants must have strong technical, programming, and mathematical skills. They must possess the ability to evaluate established methods and tools, learn new ones quickly, and apply their knowledge to solve practical problems. Applicants should be self-motivated and demonstrate the ability to successfully meet objectives. Familiarity with quantum computing is not essential for this position, but is a definite plus.
	- Basic Qualifications and Experience
		* MSc in Machine Learning, Mathematics, Computer Science, Physics,  Engineering, or a related field.
		* Experience building and deploying production-grade machine learning applications at scale.
		* Strong software engineering skills across multiple languages (Python, Scala, Java, C++, etc.)
		* Experience building and supporting development environments for Machine Learning/Data Science teams.
		* Experience with distributed computing frameworks like Spark, Dask, or Hadoop.
	- Preferred Qualifications and Experience
		* PhD in Machine Learning, Mathematics, Computer Science, Physics, Engineering, or a related field.
		* Solid mathematical understanding of machine learning, statistical modelling, probability theory, and linear algebra.
		* Experience with frontend and backend web application development.
		* Passionate about agile software processes, data-driven development, reliability, testing, and continuous delivery.
		* Familiarity with and experience working in a fast-growing technology start-up environment.
+ skill set:
	- As a Senior Software Developer you will help build a trustworthy AI platform to combat rogue quantum and classical AI. Xanadu is a full-stack quantum computing and advanced AI company. You will be involved in completely reshaping the nature of computation as we know it.
	- Requirements
		* Is able to take a technical leadership role.
		* Is comfortable working in cross-functional teams.
		* Is able to evangelize proper software development practises throughout the team.
		* Can work anywhere in the stack, from databases, to REST APIs and above.
		* Is comfortable working with a variety of open-source software including Nginx, Redis, and Postgres.
		* Understands the full lifecycle of software development, including version control, code review, testing, continuous integration, logging, documentation and debugging.
		* Is able to work productively on a geographically distributed team.
		* Is able to contribute to open-source projects at a high technical level.
		* Is curious and enthusiastic about new and unfamiliar technologies.
		* Pays careful attention to detail.
		* Has good communication skills and can express complex technical concepts in a clear and easy to understand way.
	- Qualifications
		* Has 4-8 years of experience working in the field.
		* Is proficient in Python.
		* Is adept at working with Linux.
		* Is comfortable working with Git and GitHub.
		* Is a generalist developer who is comfortable working in multiple languages.
		* Hands-on experience building large, fault-tolerant, distributed systems at scale.
		* Experience using Docker and deploying to cloud platforms like AWS or Google Cloud.
		* Working knowledge of front-end development technologies (HTML, CSS, JavaScript, and front-end web frameworks like React, Vue.js, or Angular).
		* Working knowledge of client-server architecture.
		* A basic understanding of machine learning and AI.
	- At Xanadu we primarily work with Python, but we use a variety of tools including C++, Postgres, Redis, Docker, CI pipelines, and multiple cloud platforms. We build using a distributed microservice model, and we are constantly exploring new technologies to add to our stack.
+ skill set:
	- As part of the Xanadu Software Team, you will be responsible for developing and maintaining PennyLane, an open-source framework for quantum machine learning, quantum computing, and quantum chemistry. Further duties include contributing to the development of a quantum cloud platform, and building and designing software and services with PennyLane. The selected candidate must possess the ability to learn advanced scientific and technical concepts quickly and with minimal direction. Strong technical skills and a demonstrated ability to learn new concepts is important for this position. Experience in both quantum computing and software development is essential.
	- Required Skills and Experience:
		* To succeed in this role, you should have the following:
		* Previous experience with software best practices, including continuous-integration pipelines, unit testing, code review
		* Experience working with several programming languages (most important are Python, C/C++)
		* Ability to understand and apply complex mathematical concepts
		* Demonstrated education or training in quantum computing
		* Familiarity with additional languages (i.e., Javascript, HTML, CSS)
		* Exposure/familiarity to machine learning/deep learning
		* Software development skills, demonstrated via a public online portfolio (i.e., GitHub account, contributions to open-source projects, etc.)
		* Self-motivated with a willingness to learn
		* Comfortable working in a fast-paced environment
		* High level of professionalism
	- Preferred Skills and Experience:
		* Expertise in quantum computing, as demonstrated by extensive coursework, thesis, or peer-reviewed publications
		* Experience with web development (frontend or backend)
		* Experience with numerical computation and high-performance computing
	- Qualifications:
		* BSc in Computer Science, Engineering, Physics, Math, or related field
		* MSc, PhD in Computer Science, Engineering, Physics, Math, or related field preferred
+ skill set:
	- Researcher - Quantum Machine Learning
	- You will join Xanaduâ€™s Software & Algorithms team, working with a world-class team of researchers to build the theoretical and practical foundations of quantum machine learning, variational quantum algorithms, and quantum differentiable programming. You will conceive, undertake, and supervise projects which have an outsized impact, helping to establish the fundamentals of an emerging new field. Your ideas will have lasting influence and be used by thousands of researchers, developers, and enthusiasts worldwide.
	- Skills and Experience:
		* To succeed in this role, you should have the following:
		* Expertise in the theory and practice of variational quantum algorithms and related fields like quantum chemistry, quantum optimization, etc.
		* Familiarity with recent developments and ideas in both quantum computing and in machine learning
		* Ability to make connections between different scientific fields, and successfully port ideas from one field to another
		* Skilled at using scientific software tools (e.g., Python) and quantum computing hardware to explore ideas and implement algorithms
		* Familiarity with limitations, restrictions, and imperfections in current quantum hardware devices and knowledgeable of mitigation practices
		* Experience supervising, mentoring, and collaborating with others on successful research projects
		* Proven ability to drive research projects from idea to execution
		* Comfort working in a fast-paced tech-focused work environment
		* High standards for scientific writing, both at a technical and a popular level
		* Strong team player
	- Qualifications:
		* 5+ years of experience working as a researcher in quantum computing or machine learning
		* PhD in Computer Science, Physics, Mathematics, Engineering, or Machine Learning with relevant postdoctoral experience preferred
		* Scientific track record in the topic area of quantum machine learning, as evidenced by recent publications
+ skill set:
	- Software Developer - Scientific Computing
	- Are you looking for an opportunity to contribute to the next revolution in computing technology? Do you want to take part in an exciting and rapidly growing new industry? Do you want to put your skills to use at the forefront of a cutting-edge field?
	- In this role you will develop highly optimized numerical code for simulating and benchmarking a variety of quantum computing devices. You will help translate high-level algorithms to run on a variety of computing architectures. You will help develop and optimize new parallelization techniques for simulating large quantum systems and algorithms designed for Xanadu's quantum computing platform and participate in the design and development of new simulation algorithms.
	- Required Skills and Experience:
		* To succeed in this role, you should have the following:
		* Strong experience programming in low-level languages (e.g., C, C++, Fortran)
		* Knowledge of CPU instruction sets, GPU programming, and compilation  
		* Experience with high-level scientific programming frameworks in Python
		* Ability to convert high-level language scripts to optimized low-level implementations  (e.g., C, C++, Fortran) with optimization (SIMD vectorization) and parallelization (OpenMP, threading)
		* Experience working with multiprocessing and parallelized code
		* Experience with development of numerical / approximation techniques
		* Experience with binding high-level scripting languages to low-level implementations
		* Ability to convert abstract descriptions of algorithms into efficient code implementations
		* Ability to aggressively optimize algorithm efficiency at every part of the computational stack
		* Ability to determine sensible tradeoffs between code being optimal, user-friendly, and easy to install
		* Experience with software engineering best practices: testing, continuous integration, version control, documentation, and code review
		* Familiarity with and experience working in a fast-growing technology start-up environment
		* Great communication skills; can express complex technical concepts in a clear and easy to understand way
	- Preferred Skills and Experience:
		* Familiarity with distributed computation
		* Experience with scientific computing on HPC, supercomputer, and cluster-grade hardware
		* Experience with scientific computing on commodity / cloud hardware (e.g., AWS)
		* Understanding of quantum computing and quantum simulation algorithms, including experience with tensor networks
		* PhD in Computer Science, Physics, Mathematics, or Engineering an asset
	- Qualifications:
		* 5+ years of experience working in related fields
		* BSc or MSc  in Computer Science, Physics, Mathematics, or Engineering with relevant industry experience preferred, or equivalent combination of education and experience
		* Proven track record delivering highly optimized numerical algorithms
+ skill set:
	- At Nextdoor, we believe in the transformative power of community. In the Business Intelligence team at Nextdoor, we believe in the transformative power of information, bringing together data from a wide variety of sources and making it digestable and actionable by everyone in the company. We are a lean but powerful team with diverse backgrounds and perspectives, because thatâ€™s what we seek out and respect in others. We collaborate cross-functionally to make the numbers available and clear, playing a key role in the companyâ€™s overall effort to foster stronger and healthier communities.
	- As Nextdoorâ€™s first Engagement Data Science Manager, youâ€™ll lead data science for all of our member-facing initiatives, including activation, retention, trust and safety, moderation, and much more. Youâ€™ll be the voice of data within engagement leadership, and youâ€™ll work with your team to bring value to Nextdoorâ€™s millions of members and help build stronger & safer communities. Youâ€™ll lead an agile, nimble data team, and youâ€™ll work with leaders across the business to inform Nextdoorâ€™s overall data strategy. Youâ€™ll directly contribute to growing and improving our core product, and will help lead us to the future of Nextdoor.
	- You should be excited to bring your experience and expertise every day in order to:
		* Lead, develop, and grow a team of 6-8 data scientists working in our engagement teams
		* Conduct in-depth analysis on Nextdoor data, analyzing neighborhood vitality, member experience, cross-platform initiatives, acquisition cycles, and new product development
		* Partner with cross-functional teams to support product development efforts (including product, design, engineering, marketing, operations, and finance) and manage and align priorities
		* Work on the leadership team to inform long-term business strategy and roadmaps
		* Develop and socialize best practices around metric development, A/B testing and experimentation, usage tracking and instrumentation
		* Drive self-service for our data platform by creating and documenting data structures and sets, SQL and data tools training, and dashboard development
		* Develop and share key strategic insights through data analysis, visualization, and story-telling
		* Work with the team to create and optimize statistical models and algorithms to help drive product and strategic decision-making
		* Care deeply about data quality and empowering employees to leverage data to help Nextdoor grow and succeed
	- What Youâ€™ll Bring to The House
		* Advanced degree in a quantitative field and 8+ years work experience in data science
		* 3+ years of people management
		* Experience working in consumer internet, especially social networks
		* Expert knowledge of SQL
		* Comfort working with large, complicated, evolving (and sometimes messy) data sets
		* Experience with distributed processing methods and ETL systems
		* Experience with with Python/Pandas, R, or some other computation analysis software, and experience building and deploying machine learning models
		* Experience effectively presenting insights and summarizing complex data to diverse audiences through visualizations and other means
		* Ability to understand, tackle, and communicate problems from both technical and business perspectives
		* Innate curiosity around finding meaningful insights that inform the way we think about and develop both our product and our business strategies
	- Bonus Points
		* Looker expertise
		* Experience with topics like feed ranking, content moderation, and community modeling
		* Youâ€™ve built a data team up from the ground and youâ€™re up for a challenge!
+ skill set:
	- As a Senior UX/UI Designer at Nextdoor, youâ€™ll design digital experiences that empower neighbors to build stronger communities and transform how people connect and engage with their local area. In this role, youâ€™ll define and deliver new experiences across multiple platforms as well as work cross-functionally to shape the future of the Nextdoor product as we continue to grow.
	- The Impact Youâ€™ll Make
		* If you want the challenge of fast-paced growth, the satisfaction of seeing your design work come to life, and the pride in helping grow a world-class design team, this is the place for you. Please include a link to your portfolio in addition to your resume and cover letter.
		* Youâ€™ll envision, design, and ship delightful, user-centered, cross-platform experiences that build the fabric of local communities around the globe.
		* Youâ€™ll be involved in all aspects of the product development for a major product area; from strategy, research, prototyping, concept to interaction design, to final QA and code tweaks right before launch.
		* Youâ€™ll participate in cross-functional brainstorms, discussions, design reviews and interesting and inspiring design team activities.
	- What Youâ€™ll Bring to The House
		* 7-10 years demonstrated experience shipping great consumer products in an agile environment, preferably including work on social networks, building social graphs, follow or relational models
		* 5-7 years demonstrated experience shipping great mobile products in an agile environment.
		* Comfort working across the product development spectrum: strategy, ideation, concept work, pixel-level details, and front-end development and implementation.
		* Fluency with both mobile and responsive web design principles and best practices.
		* A strong visual design sense and ability to design within, and help define, visual guidelines.
		* Ability to create rich interactive prototypes with Framer, Origami, or similar
		* Familiarity with HTML, CSS, JavaScript, Swift, Java, or Xcode
		* Youâ€™re deeply curious about how to empower neighbors to strengthen their communities, how local businesses enhance their communities, and about what makes different neighborhoods around the globe thrive.
+ front-end Web development skills:
	- Understanding of web services technologies such as SOAP, HTTP, and REST
	- Javascript/React programming language
	- Strong understanding of TypeScript/Flow and ES6, Jest and Webpack
	- Experience with CSS and Less/Sass (ability to write mixins, partials, functions, etc) and usage in large scale applications
	- Experience in modern technologies such as Graphql/D3.
+ data analyst skills:
	- A working knowledge of SQL, specifically involving coding your own queries and running programs on platforms such as Qubole
	- Experience with marketing tools such as Tableau, Sendgrid, Wordpress, Instapages, and PyCharm preferred
+ full-stack Web development:
	- Expertise in at least one server side web application language. Java or Python experience is a plus
	- Expertise in modern JavaScript/HTML/CSS. Experience with React is a huge plus
+ skills for back-end Web development (languages/frameworks):
	- Python/Django
	- Java
	- Golang
	- SQL
	- AWS
+ Android application software development:
	- Kotlin, MVI and GraphQL.
	- You make a point to test your obviously bug-free code with frameworks like JUnit, Mockito, and Espresso - just to be safe.
	- Expertise in Kotlin and leveraging its features to increase the safety and clarity of our codebase.
	- Familiar with modern networking stack, such as OkHttp, Retrofit, and GraphQL.
	- Passion for UI architecture best practices such as MVI and libraries including RxJava, MvRx, and Epoxy.
	- Familiar with architecting a large app for efficient modularization and dependency injection via Dagger and Gradle.
	- You think the only real Android phones are Pixels.
+ skill set:
	- At Nextdoor, machine learning is starting to transform our product through personalization, driving major impact across different parts of our platform including our newsfeed, our notifications, and our ads relevance. Our machine learning team is lean but hungry to drive even more impact and make Nextdoor the neighborhood hub for local exchange. We are scrappy and believe that ML will be an integral part of making Nextdoor valuable to our members. We also believe that ML should be ethical and encourage healthy habits and interaction, not addictive behavior. We are looking for great engineers who believe in the power of local community to empower our members to make their communities great places to live.
	- The Impact Youâ€™ll Make
		* You will be part of a scrappy and impactful team building data-intensive products, working with data and features, building machine learning models, and sharing insights around data and experiments. Some of the current products / projects you could work on include the newsfeed, ad relevance, search, notifications, trust and safety, and neighborhood vitality. You will build critical decision-making models for the product, enhancing the relevance and value of our products. Finally, you will help build the foundational patterns that ML engineers will use for years to come as we ramp up our effort to introduce machine learning into our platform.
		* Collect and gather datasets to build machine learning (ML) models that make real-time decisions for the Nextdoor platform
		* Analyze datasets and and use important features to build low-latency models for decisions that need to be made quickly
		* Deploy ML models into production environments and integrate them into the product
		* Run and analyze live user-facing experiments to iterate on model quality by measuring impact on business metrics
		* Collaborate with other engineers and data scientists to create optimal experiences on the platform
	- What Youâ€™ll Bring to The House
		* B.S. in Computer Science, Applied Math, Statistics, Computational Biology or a related field
		* 5+ years of industry/academic experience applying machine learning at scale.
		* Proven engineering skills. Experience writing and maintaining high-quality production code. Python experience a plus.
		* Ability to work with and analyze large amounts of data.
		* Ability to succeed in a dynamic startup environment.  
	- Bonus Points
		* Experience building ML products at large consumer-facing companies
		* Experience building ML products related to ads relevance or newsfeed products
+ skill set:
	- At Nextdoor, machine learning is starting to transform our product through personalization, driving major impact across different parts of our platform including our newsfeed, our notifications, our advertising, and our local ecosystem. Our machine learning team is lean but hungry to drive even more impact and make Nextdoor the neighborhood hub for local exchange. We are scrappy and believe that ML will be an integral part of making Nextdoor valuable to our members. We also believe that ML should be ethical and encourage healthy habits and interaction. We are looking for great engineers who believe in the power of local community to empower our members to make their communities great places to live.
	- The Impact Youâ€™ll Make
		* You will be part of a scrappy and impactful team building a scalable ML platform in a rapidly changing company. In this role, you will focus on developing the underlying data processing infrastructure to support the ML platform in collecting data, labeling data, and using data to monitor model performance. You will also build infrastructure to train, serve, and monitor ML models. Finally, you will be responsible for building platform-wide model features that the entire company can utilize in building ML models. As a result, you will be laying the foundation for a critical part of Nextdoorâ€™s mission.
	- What Youâ€™ll Bring to The House
		* B.S. in Computer Science, Math, Statistics, or a related field.
		* 5+ years of industry/academic experience building ML infrastructure at scale.
		* Proven engineering skills. Experience writing and maintaining high-quality production code.
		* Proficient in Python
	- Bonus Points
		* Experience using AWS to build data-intensive infrastructure: ECS, Kinesis, S3, Kafka, Spark, Druid, Flink
		* Experience building platforms around publically available ML platforms like Sagemaker, Kubeflow, MLflow, etc.
		* Experience serving models using a variety of ML model frameworks like Tensorflow, PyTorch, Sci-kit Learn, etc.
+ skill set:
	- Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, recommendation systems, targeting systems, ranking systems or similar
	- Use traditional ML techniques such as Probabilistic Graphical Models, SVMs, etc. along with the latest techniques from deep learning including graph neural networks
+ skill set:
	- As an SoC Generator Design Engineer, you will be joining a small team to architect, build and maintain configurable RTL generators for SoCs and SoC components such as DMA, NoC, cache, peripheral and security subsystems. You will work closely with verification, physical design, IP integration, software, FPGA and other teams to design, tape out and bring up multiple SoCs in a variety of vertical markets, as well as develop infrastructure and automation for SoC design and integration.
	- Develop reusable, scalable RTL generators in the Chisel hardware design language.
	- Create, deploy, support, and maintain frameworks for automating SoC and FPGA integration in Chisel.
	- Collaborate with verification engineers to bring-up and debug designs, ensuring conformance to specifications and full stimulus coverage.
	- Work with physical design engineers to satisfy design performance, power, and area requirements.
	- Document microarchitectural specifications and generator source code.
	- BS, MS, or PhD in Computer Engineering, Computer Science, or Electrical Engineering.
	- At least 2 years experience developing RTL in Verilog, SystemVerilog, or VHDL.
	- Strong written and spoken communication skills.
	- Interest in learning and developing new methodologies for SoC design in functional programming languages, eg Scala.
	- Experience with scripting languages such as Python, Bash, or Ruby.
+ skill set:
	- The SiFive Platform Engineering team is building an ambitious new infrastructure to support accelerated ASIC and FPGA design flows, IP delivery and SoC development - driving the next generation of SiFive's "Silicon at the speed of Software" mission. This infrastructure leverages state of the art compiler algorithms (built on open source MLIR and LLVM technologies), novel build system integration, and new Verilog RTL generation techniques.
	- Evolve, design and build new compiler intermediate representations for hardware design and tool flows.
	- Implement specific compiler optimization and lowering algorithms for chip design flows.
	- Implement state of the art mechanisms for hierarchical caching that crosscut compiler and build systems.
	- Participate in design discussions, planning, code review, documentation, open source processes, and other standard software practices.
	- Collaborate with hardware architects to develop the approach and design flows.
	- Manage your individual project priorities, deadlines and deliverables.
	- We are hiring for several positions with different levels of seniority, but require a minimum of 2 years of compiler engineering experience.
	- Strong oral and written communication skills, excellent team collaboration.
	- Experience with C++ programming and git-based development workflows.
	- Experience with Verilog and other chip design technologies is NOT required.
+ Notebook products:
	- Binder/JupyterHub
	- Databricks Collaborative Notebooks
	- Google Cloud Datalab Notebooks
	- Amazon Sagemaker Studio
	- Code Ocean
	- Google Cloud AI Platform Notebooks
	- IBM Watson Studio
	- Amazon EMR Notebooks
	- Kaggle Notebooks
	- Azure Notebooks
	- Paperspace/Gradient
	- Colab Notebooks
+ computing platforms for data science projects:
	- deep learning workstation: NVIDIA GTX, or LambdaLabs
	- cloud computing platform: AWS, Azure, GCP, hosted notebooks, ...
+ data visualization libraries and tools:
	- Ggplot/ggplot2
	- Seaborn
	- D3.js
	- Matplotlib
	- Bokeh
	- Plotly / Plotly Express
	- Altair
	- Geoplotlib
	- Shiny
	- Leaflet / Folium
+ machine learning frameworks:
	- JAX
	- TensorFlow
	- Caret
	- H20 3
	- Prophet
	- PyTorch
	- Tidymodels
	- Xgboost
	- MXNet
	- Keras
	- CatBoost
	- LightGBM
	- Scikit-Learn
	- Fast.ai
+ machine learning algorithms:
	- decision trees or random forests
	- evolutionary approaches
	- recurrent neural networks, RNN
	- Bayesian networks
	- linear or logistic regression
	- convolutional neural networks, RNN
	- transformer networks: BERT, gpt-3
	- gradient boosting machines: xgboost, lightgbm
	- dense neural networks: MLPs
	- generative adversarial networks, GANs
+ categories of computer vision methods:
	- image segmentation methods: U-Net, Mask R-CNN
	- general-purpose image/video tools: PIL, cv2, skimage
	- object detection methods: YOLOv3, RetinaNet
	- image classification, and other general purpose networks: VCG, Inception, ResNet, ResNeXt, NASNet, EfficientNet
	- generative networks: GAN, VAE
+ natural language processing, NLP, methods:
	- transformer language models: GPT-3, BERT, XLnet
	- encoder-decoder models: seq2seq, vanilla transformers
	- contextualized embeddings: ELMo, CoVe
	- word embeddings/vectors: GLoVe, fastText, word2vec
+ cloud computing platforms:
	- Oracle Cloud
	- Tencent Cloud
	- Google Cloud Platform, GCP
	- Amazon Web Services, AWS
	- Microsoft Azure
	- Salesforce Cloud
	- SAP Cloud
	- Alibaba Cloud
	- VMware Cloud
	- IBM Cloud / Red Hat
+ cloud computing products:
	- Microsoft Azure Container Instances
	- AWS Lambda
	- Amazon EC2
	- Amazon Elastic Container Service
	- Google Cloud Functions
	- Azure Functions
	- Google Cloud App Engine
	- Google Cloud Run
	- Azure Cloud Services
	- Google Cloud Compute Engine
+ machine learning products:
	- Google Cloud Vision AI
	- Amazon SageMaker
	- Google Cloud AI Platform / Google Cloud ML engine
	- Google Cloud Natural Language
	- Amazon Forecast
	- Amazon Rekognition
	- Azure Cognitive Services
	- Google Cloud Video AI
	- Azure Machine Learning Studio
+ big data products:
	- relational databases, data warehouses, data lakes
	- IBM Db2
	- MySQL
	- Oracle Database
	- Microsoft Azure Data Lake Storage
	- Amazon DynamoDB
	- PostgresSQL
	- Microsoft Access
	- MongoDB
	- Amazon RedShift
	- Google Cloud SQL
	- Google Cloud BigQuery
	- SQLite
	- Snowflake
	- Microsoft SQL Server
	- Amazon Athena
	- Google Cloud Firestore
+ business intelligence tools:
	- Domo
	- Tableau
	- Microsoft Power BI
	- Looker
	- Salesforce
	- SAP Analytics Cloud
	- TIBCO Spotfire
	- Sisense
	- Alteryx
	- Einstein Analytics
	- Google Data Studio
	- Qlik
	- Amazon QuickSight
+ categories of automated machine learning tools (or partial AutoML tools):
	- automated data augmentation: imgaug, albumentations
	- automated feature engineering/selection: tpot, boruta_py
	- automated model selection: auto_sklearn, xcessiv
	- automated model architecture searches: darts, enas
	- automated hyperparameter tuning: hyperopt, ray.tune, Vizier
	- automation of full ML pipelines: Google Cloud AutoML, H20 Driverless AI
+ specific automated machine learning tools, or partial AutoML tools:
	- H20 Driverless AI
	- Xcessiv
	- Google Cloud AutoML
	- Auto-Sklearn
	- Tpot
	- Auto-Keras
	- Auto_ml
	- Databricks AutoML
	- MLbox
	- DataRobot AutoML
+ tools for managing machine learning experiments:
	- Comet.ml
	- Trains
	- Guild.ai
	- Domino Model Monitor
	- Sacred + Omniboard
	- Polyaxon
	- TensorBoard
	- Weights & Biases
	- Neptune.ai
+ platforms for data science courses:
	- Udemy
	- DataCamp
	- Kaggle Learn Courses
	- Udacity
	- Cloud-certification programs: AWS, Azure, GCP
	- university courses, resulting in a university degree
	- Coursera
	- edX
	- Fast.ai
	- LinkedIn
+ tool or platform for data analysis:
	- basic statistical software, spreadsheets: Microsoft Excel, Google Sheets
	- advanced statistical software: SPSS, SAS
	- business intelligence software: Salesforce, Tableau, Spotfire
	- local development environments: RStudio, JupyterLab
	- cloud-based data software & APIs: AWS, GCP, Azure
+ media sources to learn data science:
	- Slack communities: ods.ai, kagglenoobs
	- YouTube: Kaggle YouTube, Cloud AI Adventures
	- journal publications: peer-reviewed journals and conference proceedings
	- email newsletters: Data Elixir, O'Reilly Data & AI
	- Course forums: forums.fast.ai, Coursera forums
	- Kaggle: notebooks, forums
	- Blogs: Towards Data Sciecne, Analytics Vidhya
	- Twitter: data science influencers
	- podcasts: Chai Time Data Science, O'Reilly Data Show
+ skill set:
	- Working with our automation team to improve tooling
	- Deploying network infrastructure to our globally-distributed data centers
	- Experience working with network vendor hardware/software including Arista, Cisco (IOS XR), or Juniper
	- Experience working with typical layer-2 and -3 protocols (e.g., BGP, OSPF, VRRP, IS-IS)
	- Experience supporting and troubleshooting global backbone networks
	- Experience working on, building, and troubleshooting large-scale datacenter networks
	- Understanding of peering and transit and their roles on the Internet
	- Understanding of overlay and underlay networking concepts
	- The ability to function independently on routine tasks and project work
	- Good Linux/UNIX skills. Experience in Python or similar language is a plus
	- Experience with network automation solutions including Ansible or Salt, NAPALM and OpenConfig is a plus
	- Experience with MPLS, specifically BGP-LU and RSVP-TE is a plus
+ skill set:
	- Experience deploying, scaling, and troubleshooting NodeJS, Python, and PHP applications in production
	- Knowledge of the CI/CD pipeline and GitHub repositories, actions, and deployment workflows
	- Growth mindset, with an unrelenting focus on improving your knowledge and skill set
	- Highly self-motivated with the ability to work independently and collaboratively with a high degree of autonomy in a remote work environment
	- Bonus: Experience troubleshooting basic and advanced Kubernetes issues, from pods and deployments to the control plane
	- Bonus: Experience troubleshooting one or more database engines: MySQL, MariaDB, PostgreSQL, Redis, MongoDB
+ skill set:
	- Troubleshooting and resolving technical support requests created by our customers spanning a growing range of container products and services, including Managed Kubernetes and Container Registry
	- Experience troubleshooting basic and advanced Kubernetes issues ranging from pods and deployments to the control plane
	- Knowledge of kubectl, community projects such as helm, istio, linkerd, prometheus, NGINX ingress-controller, and similar software and utilities used to manage deployments
	- Bonus: Certifications such as CKA and/or CKAD
		* Certified Kubernetes Application Developer (CKAD)
			+ From Cloud Native Computing Foundation (CNCF).
		* Certified Kubernetes Administrator (CKA)
			+ From Cloud Native Computing Foundation (CNCF).
	- Bonus: Experience with one or more database engines (MySQL, MariaDB, PostgreSQL, Redis, MongoDB)
+ skill set:
	- As a Data Engineer, you will join a growing Data Engineering team within our Engineering Services organization  that collaborates with decision-makers across the organization to catalyze business growth by providing insightful and actionable analysis, insights and data products. The Data Engineering team is hands-on with a wide variety of datasets, including user data, product behavior data, financial/payment data, upper-funnel marketing data, trust and safety data, and operational/infrastructure data, and is responsible for leveraging that data into usable analytical products by stakeholders across the company.
	- Develop and implement metrics and dimensions for powering analytical use cases across the company, incorporating a wide variety of data sources across the company at varying levels of complexity and scale
	- Focus on data quality of the data environment and data products being delivered to the business, and effectively communicate to internal user base regarding production status
	- Interface closely with data infrastructure, engineering and technical operations teams to ensure correctness and soundness of metrics built in the data environment and availability of data product services
	- Pioneer initiatives around data quality, integrity, security and governance
	- Work closely with data stakeholders across the company, both technical and non-technical, to understand evolving needs as more complex data models are introduced for reporting and data science
	- Bachelorâ€™s degree in Computer Science, Math, Statistics, Economics, or other quantitative field;  or equivalent experience.
	- Experience in custom ETL design, implementation and maintenance
	- Track record of developing in complex data environments and intelligence platforms for business users
	- Demonstrable ability to relate high-level business requirements to technical ETL and data infrastructure needs, including underlying data models and scripts
	- History of proactively identifying forward-looking data engineering strategies, utilizing appropriate technologies, and implementing at scale
	- Extensive hands-on experience with schema design and dimensional data modeling
	- Experience interacting with key stakeholders in different fields, interpreting challenges and opportunities into actionable engineering strategies
	- Experience with analytics databases like Snowflake, Redshift, or BigQuery.
	- Advanced SQL and relational database knowledge (MySQL, PostgreSQL) in addition to warehousing and dimension modeling
	- Experience scripting in Go or Python or a similar scripting language.
	- Effective communication and interpersonal skills
	- Experience implementing dimensional modeling in a configuration tool like dbt or LookML a plus
	- Experience designing and building dashboards in BI tools like Looker, Tableau, or PowerBI a plus.
	- Experience with job schedulers (Airflow, Luigi, Azkaban, etc.) a plus
+ skill set:
	- We are looking for a motivated, data-driven and results-oriented self-starter who is passionate about Growth Marketing to join our Revenue Marketing team. Our key focus is to accelerate Self-Service revenue across the entire customer journey - from new customer acquisition to retention and cross-sell / upsell. With a portfolio of hundreds of thousands of paying customers, you will lead insights at scale to find new user growth opportunities across Self-Service customer journey by helping more of our customers to discover the value of DigitalOcean through engaging, differentiated experiences. The focus will be on delivering engaging experiences for key high-value strategic initiatives and facilitating & enhancing Revenue Marketingâ€™s ability to engage with new audiences in new ways.
	- You will lead experimentation for the team, driving improvements in user acquisition, engagement and long-term growth at scale by measuring and optimizing new channels, platforms and strategic marketing initiatives - with a specific focus on helping our team identify key product and marketing levers for user growth - backed by systematic testing and optimization.
	- As a Data Scientist, your mission is to turn our data into insights and gain a deep understanding of our users to impact the strategy and direction of DigitalOcean. You will study user behavior, marketing strategies, markets, content, new features and bring data and insights into every decision we make. Above all, your work will impact how we think about user growth and how we can make DigitalOcean available and accessible for more people in the world.
	- Perform analyses on large sets of data to extract insights that will help drive DigitalOceanâ€™s strategy across the user funnel
	- Work cross-functionally with marketing, product, engineering, design and user research to propel DOâ€™s customer growth forward
	- Drive end to end execution of data science projects, from experimental design and analysis of test results to building predictive models and assisting engineers to productionize the model
	- Establish and maintain a culture of rigor and curiosity to drive tangible business impact
	- Proven experience with:
	- Large-scale data sets in both structured & unstructured formats
	- Causal inference & experimentation, time-series analysis, and building predictive models related to churn reduction or revenue expansion
	- Helping engineering teams move models from prototype to production
	- Experience with growth marketing for a tech company preferred
	- Coding skills (such as Python/R and SQL) and analytics tools experience (Segment, Looker, or similar tools)
	- Capacity and passion to translate business objectives into actionable analyses, and analytic results into business and product recommendations
	- Experience with international markets, growth marketing, web platforms or content marketing a plus
+ skill set:
	- Support and improve our customer Insights Platform by operating and extending the Open Source software we depend on (Prometheus, Thanos, Grafana).
	- Work closely with other product teams to enhance product offerings and improve our customer's observability.
	- Automate as much of the operational work as possible to allow time for innovation.
	- Working with exciting technologies such as Kubernetes, Prometheus/Thanos, Go, Docker, Kafka, ScyllaDB, and more.
	- Proficiency in at least one of the following languages: Go, C/C++, Java, Python, Ruby. We primarily use Go, but sometimes we need to extend systems written in other languages such as Java.
	- A willingness to dive into configuration management, deployment automation, and instrumentation.
	- An appreciation of SRE principles, along with utilizing data and automation to improve systems.
	- Excellent communication skills. We work intimately with product teams to ensure our customers have the observability they need to be successful on our platform.
	- We value development. You will work with some of the smartest and most interesting people in the industry. We are a high-performance organization that is always challenging ourselves to continuously grow. We maintain a growth mindset in everything we do and invest deeply in employee development through formalized mentorship, LinkedIn Learning tracks, and other internal programs. We also provide all employees with reimbursement for relevant conferences, training, and education.
