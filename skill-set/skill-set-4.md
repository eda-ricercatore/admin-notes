+ skill set:
	- The Center for Policing Equity uses evidence-based approaches to social justice problems and conducts research to create levers for social, cultural, and policy change.
	- Position Description
		* The Center for Policing Equity (CPE) is seeking a highly-skilled Research Associate with a passion for social justice to join our Science Program. The Research Associate will be responsible for co-developing, executing, and managing large-scale efforts to clean and standardize administrative data, as well as contributing to research projects and products. They will be expected to be adept at quantitative data wrangling and analysis and possess strong organizational and management skills. This position will report to the VP of Science.
	- Key Responsibilities
		* Collaborate with the VP of Science to refine and execute current data standardization protocols for CPE Science Program
		* Collaborate with the VP of Science to set agenda for continued expansion and improvement of CPE Science Program data infrastructure efforts
		* Perform data wrangling and restructuring tasks to prepare data for use in academic publications, presentations, and reports
		* Conduct advanced quantitative analyses of police behavioral data and supplemental data sources (demographic data, surveys, etc.)
		* Manage and support junior staff working on data standardization and analysis efforts, including providing guidance in use of R or other statistical software
		* Contribute to research articles and reports related to the intersection of law enforcement and racial equity, and support the VP of Science and CEO with high-priority, time-sensitive projects
		* Support optimization of workflows for research processes and products
		* Collaborate with data engineers, scientists, and analysts across the organization to improve efficiency and product integrity
		* Ensure team's adherence to data security and confidentiality protocols and support with writing of IRB protocols and amendments
	- Qualifications
		* Required:
			+ Master's degree in relevant social science or applied quantitative discipline (e.g., Criminology, Demography, Political Science, Sociology, Epidemiology, Social or Developmental Psychology, Data Science, Economics, Public Policy, Statistical Methods, or Public Health) plus 2+ years of relevant professional experience or bachelor's degree and 4+ years of relevant professional experience
			+ Excellent quantitative skills, including data management experience, descriptive statistics, and multivariate regression analyses; programming experience in R, Python, and/or Stata strongly preferred
			+ Strong organizational and management skills
			+ Comfortable working independently, as well as collaboratively on a research team
			+ Self-started; motivated; innovative; entrepreneurial
			+ Passionate about social justice issues
		* Preferred:
			+ Experience working with large-scale administrative data sets
			+ Experience with geospatial analysis and mapping using R or Python
			+ Experience and interest working with diverse analytic methodologies (e.g., longitudinal data analysis, multilevel modeling, survey data analysis)
			+ Experience contributing to peer-reviewed social science scholarship
			+ Expertise and/or training in data security and ethics; experience writing and/or socializing IRB protocols for data security is a plus
			+ Experience managing junior staff in conducting data analyses or research
			+ Knowledge of publicly-available national data sets on public health, economic well-being, or related domains
+ skill set:
	- The Center for Policing Equity (CPE) is looking for a skilled Data Analyst for our Compstat for Justice Program (C4J) with an unwavering passion for social justice issues. C4J is a new initiative aimed at providing recommendations and strategic services to law enforcement agencies (LEAs) in support of their efforts to reduce racial disparities in policing outcomes within the communities they serve.
	- The Data Analyst will be an integral part of CPE's C4J service delivery model. They will analyze data collected from partner law enforcement agencies (LEAs) to conduct analyses to identify department needs and perform ongoing analyses to aid the department in implementing recommendations. Additionally, the Data Analyst will be responsible for continuously iterating on the 'Needs Assessment' and C4J Implementation frameworks based on data and insights gathered from each C4J development site. This position will report to the Senior Director of C4J.
	- Key Responsibilities
		* Perform data pre-processing/wrangling tasks to prepare the data for analysis
		* Use quantitative and qualitative data to answer C4J research questions
		* Execute on the data analyses required for the Needs Assessment phase of C4J
		* Documenting all code developed to conduct the analyses
		* Produce compelling data visualizations
		* Design and run regression models and provide interpretation of the results
		* Conduct quality assurance checks to ensure there are no errors in the analyses or the interpretation of the output
		* Conduct meticulous quality control and record-keeping procedures to ensure the highest levels of data integrity
		* Translate findings into recommendations, strategy, and change management practices for partner agencies to employ
		* Conduct project post-mortem and lead continual process improvement for data analysis following each C4J implementation
	- Qualifications
		* Bachelor's degree required; specialization in Mathematics, Statistics, Physics, Computer Science, Economics, Finance, or other quantitative fields is preferred
		* 5+ years of experience working in a Data Analyst, Business Analyst or similar role with a focus on performing advanced regression techniques, to include multivariate regression, multilevel (hierarchical) modeling, and Bayesian inference
		* Possess end-to-end data expertise including data sourcing, merging, cleaning, restructuring/wrangling, and visualization
		* Highly proficient in using R and/or Python for statistical programming
		* Ability to produce markdown notebooks with Jupyter and/or RMD/Knitr
		* Expertise in interpreting syntax across statistical software platforms (including, but not limited to, R, Python, SAS, Stata, and/or SPSS)
		* Ability to explain analysis findings in clear terms that can be understood by non-technical audiences
		* Experience producing interactive data visualizations to communicate findings (i.e. Tableau, R Shiny, Qlikview, D3.js, etc)
		* Comfort with collaboration across a geographically distributed team
		* Experience working with clients and managing internal and external relationships
		* Experience working with geographic data (GIS shapefiles; desired, but not required)
		* Familiarity with constructing SQL queries is a plus
+ skill set:
	- In this position, you will join a great team in Ampere Shanghai and work with top talents in the industry, make direct contribution to the popular open source communities like Linux kernel, QEMU, DPDK, OVS, FD.io, to measure, characterize and optimize network software infrastructures to lead network transformation in SDN/NFV, Cloud native, 5G, etc. to Ampere processors. You will have the opportunity to work on world leading technologies such as Arm CPU micro-architecture, Virtualization, Ethernet, Security & Crypto, etc.
	- Your daily work includes but not limited to system integrations, performance measurements and characterizations, software optimization and development and upstream into open source projects especially network software stacks that are important to cloud service providers for example DPDK, OVS, cloud native networking, etc. to enable the best performance on Ampere CPU chips.
	- Solid C programming skills and familiar with GNU Toolchain (GCC/MAKE/GDB)
	- Understanding of Linux/FreeBSD like system and Internals
	- Understanding of Arm Architecture, or other processor architectures
	- Strong desire to learn and strong problem solving skills
	- Great performance characterization and optimization skills
	- Great in spoken and written Chinese/English
	- Good knowledge of Virtualization and Container technologies
	- Solid knowledge on TCP/IP and Linux networking internals
	- Experience with open source development
	- Knowledge of Git or similar
	- Good understanding on SDN/NFV, Virtual Switching, cloud native
+ skill set:
	- We are looking for a CPU Architect to join a small but growing CPU group, advancing the art of high performance circuit design.  Ideal candidates will channel their creativity to contribute in cross-spectrum flow and methodology, working closely with circuit design architects. They will have high levels of flexibility to craft productivity improvement flows to make highly visible contributions.
	- The Ampere Architecture Group team turns ideas into reality. We are a group of technologists with tremendous experience shipping dozens of server products at multiple semiconductor companies. By listening to customers, driving industry standard protocols, and designing high-performance IPs and SoCs, Architects push products forward past the bleeding edge of microprocessor design. Architects are resourceful, and craft well-tuned designs to meet ecosystem requirements in a timely cadence, ultimately delighting Ampere’s cloud customers.
	- What You Will Do:
		* Define the design of a server-class microprocessor core
		* Define the design of a server-class SoC including mesh interconnect, PCIe subsystem, or memory subsystem
		* Craft workflows to understand pre-silicon behaviors of a SoC with hundreds of cores.
		* Understand the pipeline of ideas from research to workloads to ISA to microarchitecture to physical technology
		* Create and maintain technical documents including architecture specifications, implementation guides, and user guides
		* Collaborate with the team from product roadmap to design implementation
		* Balance features, performance and costs to create a solution with high value and optimal use of development and physical resources
		* Facilitate design development efforts, performance estimation, and performance analysis through methodology and hands-on contributions
		* Learn the CPU performance model from senior team members and helping to develop, deploy, and run microarchitecture studies for future products.
		* Work with microarchitecture designers in performing studies on current and future generation of CPUs.
		* Drive performance correlation of models using post-silicon measurement data or pre-silicon simulation results.
		* Collect silicon performance measurements and understanding how to vet data and filter anomalous results.
		* Run and report out on experiments characterizing performance of existing silicon, both pre-production and shipping silicon
		* Develop automated performance testing and data post-processing.
		* Develop visualization tools to assist in performance analysis.
		* Run micro-benchmarks and creating supporting models/relationships using the collected data
		* Develop spreadsheet macros to further prepare/present performance data in appropriate formats.
		* Investigate performance anomalies with help from senior performance architects.
		* Develop functional/performance model of the hardware in C++ or System C.
		* Fit curves and run trendline analysis using R.
	- What You’ll Bring:
		* Great communication skills, comfortable with reaching out and asking questions. This is the most important qualification!
		* Ability to learn and grow. Nobody around you will have the answers!
		* Knowledge of memory consistency models and coherency protocols
		* Firmware, hypervisor, and operating system design
		* Virtualization, dynamic power management
		* Utilization of semi-custom and custom logic design for high speed and low power
		* Application of machine learning techniques
+ skill set:
	- Experience with MDM solutions like Jamf, Intune, etc.
	- Experience with SAML based single sign-on solutions and SaaS tools such as Slack and Google Workspace (formerly GSuite/G Suite)
+ skill set:
	- We are looking for Software Engineer to help us grow our team. You will a part of a software engineering team who gets to design, develop robust and innovative Ampere’s Baseboard Management Controller (BMC) firmware/software stack for our customer reference designs. You will have an opportunity to work collaboratively with and learn from industry veteran designers and architects, firmware developers, vendors, quality assurance team, and open source community to create a breakthrough design for cloud computing manageability. Our engineers are excited about technology and innovation and channel that energy to deliver world-class products.
	- Develop Baseboard Management Controller (BMC) software and firmware for managing our ARM64 server reference designs
	- Participate in cross-functional project teams encompassing different technical disciplines including System Architects, SoC Firmware developers, Hardware designers, and Quality Assurance
	- Design and develop Bootloaders (U-boot, UEFI), Linux device drivers and kernel services to support various peripheral drivers such as USB, I2C, SPI, Ethernet, etc.
	- Implement manageability framework and protocols defined by standard bodies
	- Work with world-wide opensource communities for code review, bug fixes, and upstreaming work to the Linux and OpenBMC communities. Participate in ecosystem and developer programs for our platforms
	- Support Field Applications Engineers to drive Ampere Computing’s customers to production
	- Min 2-8 years of software development experience
	- Excellent C/C++ programming, Python and problem-solving skills. Intimate knowledge of software development process methodology
	- Background in embedded ARM bootloader programming, Linux kernel programming, kernel services and device driver development, Linux gcc and debug tools
	- Knowledge of low-level protocols including I2C, I3C, JTAG, SPI, eSPI, UART, PCIe
	- Experienced with board bring-up and device driver debugging. Capable of reading and understanding hardware digital schematics.
	- Proficient with source version control systems like Git, Review tools like Gerrit.
	- Good Vietnamese and English communications skills, both verbal and writing
	- Independent worker with excellent teamwork, decision making and growth mindset
	- Experience with Open Source Baseboard Management Controller (BMC) Software Stack (OpenBMC)
	- Experience in server manageability architecture, knowledge of industry standard initiatives such as Redfish and manageability protocols such as IPMI desirable
	- Experienced with Continuous Integration and Test Automation framework
	- Experienced with embedded Linux system development frameworks like Yocto, Buildroot, etc.
+ skill set:
	- We are looking for a senior SoC engineer who can leverage their understanding of system-level security goals to disseminate security requirements into the definition and development of ISA, platform, and firmware security capabilities for Ampere products spanning processors cores, IP, SoC, and platforms, while keeping up to date with the latest security threats and standards.
	- The Hardware Security Architect candidate will join a small but growing CPU architecture team, advancing the art of high performance SoC development targeted for data center customers. Ideal candidates will channel their passion for secure products to contribute in cross-spectrum flow and methodology, working closely with processor and SoC architects and software architects to enhance Ampere’s security solution end-to-end. They will have high levels of flexibility to craft productivity flows to make highly visible contributions.
	- The Ampere Architecture Group team turns ideas into reality. We are a group of technologists with tremendous experience shipping dozens of server products at multiple semiconductor companies. By listening to customers, driving industry standard protocols, and designing high-performance IPs and SoCs, Architects push products forward past the bleeding edge of microprocessor design. Architects are resourceful, and craft well-tuned designs to meet ecosystem requirements in a timely cadence, ultimately delighting Ampere’s cloud customers.
	- You will be the technical leader, at the heart of the solutions teams working closely with hardware SoC and IP development teams. Your role will be to understand security solutions at the system level and then provide expert input to product teams to help them understand and correctly implement their parts of the overall solution. This may include:
		* Collaborate across the company to guide the direction of platform security and develop a long-term security roadmap for our products, working with hardware, software, and field support teams.
		* Work with customers and partners to identify and address security issues and threats.
		* Own product-level security requirements and work with the solution teams and IP product teams to ensure product implementation.
		* Contribute to product design reviews via threat modeling. You will identify security needs, provide optimal design mitigations, and contribute to the security verification plans.
		* Engage with our ARM partners and be the expert in new security architecture features and provide guidance for integration into future Ampere products.
		* Deliver product-level proposals for how the security objectives will be implemented and provide guidance on appropriate design mitigations.
		* Analyze requirements, as well as software and integration approaches to identify vulnerabilities and solution architecture, design, and implementation flaws.
		* Provide security guidance and assistance throughout the development lifecycle ensuring Ampere solutions and IP products are specified, designed, developed, implemented, integrated, and tested to meet the requirements for product level security.
		* Stay up to date with the latest security threats, have a good understanding of the state of the art techniques spanning software and hardware developed to address those threats, and ensure the security objectives that are fed into product teams adequately reflect the needs of the product to mitigate relevant threats and continue to contribute to the external security community.
		* Assist in responding to high-priority issues or customer questions where your expertise can help.
	- What You'll Bring
		* Great communication skills, comfortable with reaching out and asking questions. This is the most important qualification!
		* Technical curiosity, and ability to learn and grow. Nobody around you will have all the answers!
	- Education
		* MSEE/MSCS with 8+ years of experience, or
		* PhD in EE/CE/CS with 5+ years of experience, concentrating in cybersecurity
	- Preferred Qualifications
		* Knowledge of Secure Development Lifecycles (SDLs), ideally as applied to semiconductor hardware
		* Extensive understanding of industry standard encryption, security protocols, and current ISA, SoC and System Software/FW mechanisms for mitigating typical security attacks for data center and computing platforms
		* Experience designing & testing SoC hardware and low-level software security
		* Knowledge of system security processes and standards and how these standards are incorporated into solution definition, design, development, and validation/verification activities
		* An understanding of how hardware and software security interact and influence one another
		* A natural inclination to persuade (not push) when introducing new concepts and processes
		* You have directly worked on several of the following:
		* System architecture for server platforms
		* SoC security architecture and security fundamentals including secure boot
		* Modern server manageability protocols
		* ARMv8 architectures and related security functionality
		* Cryptography algorithms and standards, including implementations and application
		* Security mitigations against physical attacks including fault injection and side channel attacks
		* Remote attestation mechanisms based on TPM or other solutions
		* Digital Rights Management (DRM) standards
		* Security threat modelling and penetration testing
		* Certification standards and compliance testing
		* Security testing on covert red team campaigns, or similar offensive security experience
+ skill set:
	- Design and develop DDR FW for 64-bit ARMv8 SoC processors
	- Work with HW design teams and bring up Pre-Silicon software support on HW models
	- Post-silicon bring up of DDR
	- Directly interact and address customer’s issue
	- Minimum of 12 years of experience with software development with C/C++ languages
	- Minimum of 2 years of customer interaction
	- Experience with 32-bit/64-bit ARMv8 processors is a plus
	- Experience with Firmware/BIOS/Linux software development
	- Experience with DDR FW
	- Familiarity with JEDEC specs
	- Experience with NVDIMM or persistent memory a plus
	- Experience with ACPI specifications
	- Experience with Non-uniform Memory Access (NUMA) with heterogenous memory configurations a plus
	- Strong ability to troubleshoot and perform root cause analysis. Proven ability to own problems to get them resolved.
	- Experience with customer interaction and issue diagnostic
	- Self-managed individual with excellent problem-solving skills
	- Good English communications skills, both verbal and writing
+ skill set:
	- SiFive is an idea-to-silicon company founded by the inventors of RISC-V to simplify the design and production of custom SoCs.
	- ***As the leading commercial provider of RISC-V processor IP, SiFive is on a mission to help engineers design custom chips for domain-specific solutions for many markets, including 5G, edge AI, enterprise networking, storage, and consumer devices.***
	- Industry-leading innovators, including six of the top ten semiconductor companies, are working with SiFive thanks to our proven success, deep expertise, and rich partner ecosystem. With SiFive’s rich IP ecosystem and accessible design platform, every market has access to the development of workload-focused hardware needed to design next-generation products.
	- As a SoC Architect at SiFive, you will be vital to SiFive's efforts to create silicon at the speed of software. You will create the basic collateral and specifications that can be reused across the SoC design ecosystem. In developing this collateral, you have the opportunity to innovate the use of a novel set of electronic design automation (EDA) tools, which will draw on modern compiling technology and other innovations to build SiFive’s SoC and core libraries.
	- The new SoC Architect will create and build new, highly configurable SoC designs, based on the open-specification RISC-V ISA for SiFive’s clients, who are taking on exciting state-of-the-art use cases such as autonomous driving, 5G, networking, wearables, or IoT. You will have a chance to define and design chips more quickly and for more devices than would be technologically possible at any other company.
	- We are reducing the time needed for chip design and verification with novel tools and methodologies, and we are looking for an architect who is as excited as we are about bringing new SoC designs to the market!
	- LOCATION: The ideal candidate for this position can work out of any of the SiFive worldwide offices in the US, France, India, or Taiwan.
	- Design multi-layered SoC architecture and responsible for integrating all of the components in a given customizable chip.
	- Develop the upcoming advanced platforms, which will connect multiple cores together on a chip, support large bandwidth, as well as new applications and workloads.
	- Design the IP blocks to be integrated into new SoCs (e.g. receivers, accelerators, transmitters, memory cache, I/O devices, power management, and IP subsystems).
	- Research and analyze emerging needs for new SoC architecture.
	- Collaborate with customers, including Fortune 500 companies and prominent start-ups, to tailor SoCs to their needs.
	- 8+ years’ experience in ASIC/SoC development and chip architecture definition.
	- MS or PhD in Computer Architecture or in a related field.
	- Familiarity with SoC components, such as UART, DDR, PCI Express, etc.
	- Basic knowledge of RTL design & SoC tool flows.
	- Basic understanding of foundry lib, IP, and process technology limitation.
	- Familiar with advanced CPU architectures and pipelines
	- Experience in SoC design flow, including spec definition, microarchitecture design, and performance modeling.
+ skill set:
	- Implementing infrastructure automation, metric collection, and impactful reporting to make data driven decisions.
	- Modern monitoring, metrics, and alerting using open source tools.
	- Improving and developing processes and best practices, maintaining documentation of the development environments.
+ skill set:
	- high-level programming languages, such as: Lisp (or Common Lisp), Go (or Golang), Erlang, Scala, or Clojure.
	- Experience in RPC API design and construction.
+ skill set:
	- You Are a Great Fit If:
		* You have experience building mission-critical, reliable, and performant systems.
		* You enjoy leading a high-level architecture discussion one moment, and then translating that discussion into reliable production code the next.
		* You prize the quality of the software that you write. You rigorously test and document software intended for production use, follow common language conventions and well-known patterns, and rely heavily on automation for testing and deployment.
		* You know how to design an API to avoid breaking changes, and how to migrate clients when it can’t be avoided.
		* You are knowledgeable about non-trivial parts of service design, such as distributed authorization, error handling, pagination, and versioning.
		* You are versed in best practices for tracing, monitoring, and logging for distributed services.
		* You work independently and are comfortable leading the design and implementation of a software package or service from high-level requirements.
	- Key Qualifications:
		* Fluency in all or most of Golang, Python, React, and SQL
		* Deep experience building and maintaining schema-driven, widely accessible web APIs (OpenAPI, GraphQL, gRPC/Protobuf)
		* Experience building and maintaining client-side SDKs and/or web frontend applications
		* Experience architecting, building, and deploying microservice architectures
	- Bonus Points If You Have:
		* Experience with deploying in Kubernetes and/or service mesh architectures
		* Experience with streaming systems (e.g. Kafka, Kinesis)
		* Experience in programming language and/or compiler development
		* Academic background in Computer Science, Electrical Engineering, or Physics
		* Knowledge of quantum computing and applications
+ skill set:
	- GitHub is looking for engineers to join our Data Infrastructure team. You'll be part of a team building and deploying large scale data and object storage for the world's largest code hosting platform
	- The Data Infrastructure team is highly distributed and we thrive in an environment of remote work and asynchronous communication. As a member of our team, you'll always be challenged by interesting and novel problems that have real impact on how the world builds software.
	- Responsibilities:
		* Build services and systems that empathetically and pragmatically meet real operability needs of GitHub developers
		* Use data to understand the availability, reliability, and sustainability of our infrastructure
		* You will respond to the needs of users and of other developers at GitHub.
		* Work closely with other teams from across the organization
	- Minimum Qualifications:
		* Experience building and deploying large, complex distributed systems with an eye toward reliability.
		* Proficiency in Golang, Python, and/or Ruby.
		* You take a pragmatic approach to decision making and design choices.
	- Preferred Qualifications:
		* Experience building highly available services at scale.
		* You have developed and scaled services in Go.
		* Experience diagnosing and resolving complex multi-system performance problems.
		* Experience with Docker and container orchestration systems.
+ skill set:
	- GitHub helps companies, organizations, and groups of individuals succeed by allowing them to build better software, together. The engineering organization is looking for a Product Data Analyst who will report into our Data Science group and closely partner with the Product organization to provide best in class analysis and insight generation to help our product managers make better decisions, faster. You’ll also interface with our Analytics Engineering team to put your findings “into production” to ensure that our customers receive ongoing benefits from your work at scale.
	- GitHub is an exciting place to work joining a tight-knit environment of technical and business-minded individuals. This role is an individual contributor role with significant growth potential.
	- Responsibilities
		* Work with Product owners to assess metric needs and turn them into relevant, synthesized consumable outputs
		* Embed in and build business understanding across product domains leading to effective cross collaborative partnership
		* Partner with our Analytics engineering team to develop solutions for ongoing product performance reporting that scale and reduce effort to outcomes
		* Develop and automate reports and iteratively build dashboards to provide insights at scale, solving for on-going analytical needs
		* Leverage relevant product data to track and inform objectives and goals with product partners
	- Minimum Qualifications
		* A Bachelor’s Degree in statistics, math, engineering, computer science, economics, business, or a related technical field.
		* 2+ years prior relevant experience in an Analytics role covering product or engineering
		* Strong intellectual curiosity and desire to understand different parts of GitHub’s product
		* Experience translating requirements into analysis questions that can be directly actioned
		* Expertise in writing SQL queries and working with multiple data sets to develop analytical solutions for defined business problems
		* Experience with engineering practices around analytical rigor and the ability to make reproducible your analyses
		* Demonstrated ability to synthesize and communicate analysis into insights that inform business decision making
		* Demonstrated willingness to both teach others and learn new analytical problem solving techniques
		* Demonstrated effective written and verbal communication skills
		* Ability to lead without authority and a strong sense of responsibility
	- Preferred Qualifications
		* Experience conducting statistical analysis using Python / R (or equivalent)
		* Experience developing and maintaining ETLs (Airflow experience is a big plus)
+ skill set:
	- GitHub is looking for engineers to join the Compute Foundation team within our Data Center Engineering organization. You will focus on the systems and tools that enable our engineers to operate and scale the world's largest code hosting platform. You will help maintain our Kubernetes clusters and automation framework, optimize operating systems for use in our environment, and deploy systems at large scale around the world.
	- The Data Center Engineering team is highly distributed and you will thrive in an environment of remote work and asynchronous communication. You're expected to have strong written communication skills and be able to develop working relationships with coworkers in locations around the globe.
	- As an engineer at GitHub you'll always be challenged to solve interesting and novel problems that have real impact on how the world builds software.
	- Responsibilities:
		* Design and implement automation systems requirements.
		* Build performant and efficient packet processing systems for Internet and service traffic.
		* Cultivate open source projects developed by GitHub and build things you are proud to share.
		* Work closely with networking and facilities teams to design and support our global data center presence.
	- Minimum Qualifications:
		* Experience automating large, complex distributed systems with an eye toward reliability.
		* Proficiency in Golang, Python, and/or Ruby.
		* Experience diagnosing and resolving complex multi-system performance problems.
		* You take a pragmatic approach to decision making and design choices.
	- Preferred Qualifications:
		* Familiarity with configuration management software such as Puppet, Chef, Ansible, or Salt.
		* Upstream contributions to relevant open source projects (i.e. Kubernetes, Nomad, Linux kernel).
		* Experience with virtualization, bare metal deployment, or network engineering.
+ skill set:
	- GitHub is seeking software engineering professionals to join its new SRE team. As a valued member of our close-knit team, you will bring your passion for building fault tolerant systems and reliable software to help us steward reliability as a feature throughout the organization. Your work will help us scale the world's largest code hosting platform.
	- Our charter is broad but our focus is to improve the availability, resilience, and sustainability of GitHub's products. We do this through architecture, technology, process, and partnerships with product teams.
	- Our SRE team is highly distributed; our work environment is one of remote work, asynchronous communication, trust, and respect. Through your strong written communication and software skills, you will develop meaningful working relationships with coworkers from around the globe.
	- The SRE role at GitHub is an opportunity to blend your system design, empathy, and software engineering skills on an ever-changing set of novel reliability challenges. Join us on this journey and have a meaningful impact on how the world builds software.
	- Responsibilities:
		* Exert technical influence to improve the reliability of our products and systems
		* Develop and maintain infrastructure products and software automation
		* Integrate with third-party solutions where it makes the most sense.
		* Work closely with our observability and chaos engineering teams.
		* Cultivate GitHub's open source projects and build things you are proud to share.
		* Steward reliability as a feature across the organization through concepts such as SLOs and service maturity.
	- Minimum Qualifications:
		* Comfort with the GNU/Linux operating system.
		* Experience with distributed systems with high availability requirements.
		* Exposure to system-level languages such as Go or C/C++.
		* Familiarity with configuration management software such as Puppet, Ansible, or Salt.
		* Familiarity with infrastructure services and sidecar patterns.
		* Experience balancing the service reliability, sustainability, and technical debt for services running at scale.
	- Preferred Qualifications:
		* Experience with highly available systems at scale.
		* Experience building infrastructure and automation.
		* Experience negotiating SLIs, SLOs, and SLAs with product owners.
		* Success in a remote work environment.
		* Incident response and/or incident management experience.
		* Exposure to CNCF projects such as Kubernetes or Prometheus.
+ skill set:
	- GitHub is looking for engineers to join the Traffic Engineering team within our larger Data Center Engineering organization. You will focus on the systems and tools that enable our engineers to operate and scale the world's largest code hosting platform. You will help maintain our edge and internal traffic and service load balancers, design and implement DDoS mitigation systems, and help improve end user performance through expanding our global network.
	- The Data Center Engineering team is highly distributed and you will thrive in an environment of remote work and asynchronous communication. You're expected to have strong written communication skills and be able to develop working relationships with coworkers in locations around the globe.
	- As an engineer at GitHub you'll always be challenged to solve interesting and novel problems that have real impact on how the world builds software.
	- Responsibilities:
		* Design and implement global traffic management and DDoS mitigation systems with stringent availability requirements.
		* Build and maintain critical network systems spanning thousands of nodes across multiple regions to support GitHub’s global infrastructure.
		* Cultivate open source projects developed by GitHub and build things you are proud to share.
		* Work closely with networking and facilities teams to design and support our global data center presence.
	- Minimum Qualifications:
		* Experience building and managing large clusters of Linux servers with configuration management and infrastructure as code, such as Puppet, Chef, Ansible, or Salt and Terraform.
		* Standard web protocols and systems should be second nature to you, such as TCP, HTTP, TLS, DNS, CDNs, load balancers.
		* Proficiency in high-level languages such as Ruby, Python and Bash.
		* Experience diagnosing and resolving performance problems at the intersection of software and hardware.
		* You take a pragmatic approach to decision making and design choices.
	- Bonus Qualifications:
		* Familiarity with systems languages such as C/C++ or Go.
		* Experience with network technologies such as BGP, or work with network configuration on Arista EOS and/or Juniper Junos.
		* Experience operating services in physical data centers and the public cloud, or multiple public clouds.
		* Experience at a large content provider or content delivery network.
+ skill set:
	- GitHub helps companies, organizations, and groups of individuals succeed by allowing them to build better software, together. The engineering organization is looking for a Product Data Analyst who will report into our Data Science group and closely partner with the Product organization to provide best in class analysis and insight generation to help our product managers make better decisions, faster. You’ll also interface with our Analytics Engineering team to put your findings “into production” to ensure that our customers receive ongoing benefits from your work at scale.
	- GitHub is an exciting place to work joining a tight-knit environment of technical and business-minded individuals. This role is an individual contributor role with significant growth potential.
	- Responsibilities
		* Work with Product owners to assess metric needs and turn them into relevant, synthesized consumable outputs
		* Embed in and build business understanding across product domains leading to effective cross collaborative partnership
		* Partner with our Analytics engineering team to develop solutions for ongoing product performance reporting that scale and reduce effort to outcomes
		* Develop and automate reports and iteratively build dashboards to provide insights at scale, solving for on-going analytical needs
		* Leverage relevant product data to track and inform objectives and goals with product partners
	- Minimum Qualifications
		* A Bachelor’s Degree in statistics, math, engineering, computer science, economics, business, or a related technical field.
		* 2+ years prior relevant experience in an Analytics role covering product or engineering
		* Strong intellectual curiosity and desire to understand different parts of GitHub’s product
		* Experience translating requirements into analysis questions that can be directly actioned
		* Expertise in writing SQL queries and working with multiple data sets to develop analytical solutions for defined business problems
		* Experience with engineering practices around analytical rigor and the ability to make reproducible your analyses
		* Demonstrated ability to synthesize and communicate analysis into insights that inform business decision making
		* Demonstrated willingness to both teach others and learn new analytical problem solving techniques
		* Demonstrated effective written and verbal communication skills
		* Ability to lead without authority and a strong sense of responsibility
	- Preferred Qualifications
		* Experience conducting statistical analysis using Python / R (or equivalent)
		* Experience developing and maintaining ETLs (Airflow experience is a big plus)
+ skill set:
	- GitHub is seeking a research engineer in the area of code intelligence in the office of the CTO (OCTO). OCTO aims to be a meeting place within GitHub for experimentation with new ideas, and for setting the agenda for GitHub’s product several years in advance. OCTO has a small number of permanent research staff, and this position is part of the core OCTO team. The engineer will initially focus on exploring synthesis of code from documentation.
	- Here is some more detail on that initial project - it is just an example of more such projects in future. Recent advances in machine learning models for source code indicate that it is possible to synthesize code just from the signature and docstring of a function. Often better synthesis results are possible by also specifying an example to test synthesized candidates. We’d like to explore how to integrate this functionality into CodeSpaces, so that users can browse alternative solutions synthesized by the model. We’d also like to consider other user experiences for the same functionality, for example in an automated assistant for novice developers.
	- Responsibilities:
		* Design and build user interfaces as outlined above, and experiment with new ideas to embody the new code synthesis technology.
		* Collaborate with early adopters and machine learning experts on improving both the underlying technology and the way users interact with the synthesizer.
		* Participate in all activities of the OCTO at GitHub: organizing webinar series, evaluating project proposals, and disseminating research results.
	- Minimum Qualifications:
		* Ability to quickly create innovative user interfaces and new user experiences.
		* 5+ years experience in creating frontends in production
		* Inclination to prototype quickly and make fast decisions on experiment failure.
		* A creative mindset and good practical skills are more important than formal experience.
	- Preferred Qualifications:
		* Experience with user interface design, especially for developer tools.
		* Proven track record of working with early adopters to refine initial designs.
		* Ability to communicate complex ideas clearly, both in spoken and written form, for expert as well as novice audiences.
		* Interest in modern AI technologies and their use in developer tools.
+ skill set:
	- GitHub is seeking a research engineer in the area of code intelligence in the office of the CTO (OCTO), specifically for the experimentation with new and interesting user experiences. OCTO aims to be a meeting place within GitHub for experimentation with new ideas, and for setting the agenda for GitHub’s product several years in advance. OCTO has a small number of permanent research staff, and this position is part of the core OCTO team. The engineer will initially focus on user interfaces for code synthesis.
	- Here is some more detail on that initial project - it’s just an example of similar projects in future. To train machine learning models for program synthesis, we can use existing code bases and their unit tests: find a function that has good test coverage and documentation, mask out the body, synthesize an alternative implementation, and test it. Applied to all Python and JavaScript code on GitHub, this would be a huge training set. Full unit tests can however be slow to execute, and for effectively training machine learning models we need the tests to be as fast as possible. One way might be to distill the unit tests into ‘micro tests’ by recording just enough state and I/O behavior so we can replay previous behaviors.
	- Responsibilities:
		* Design and build a framework for creating fast functional correctness tests of Python and JavaScript code.
		* Collaborate with machine learning experts on applying this framework for reinforcement learning on program synthesis tasks.
		* Participate in all activities of the OCTO at GitHub: organizing webinar series, evaluating project proposals, and disseminating research results.
	- Minimum Qualifications:
		* Ability to do innovative research on one of the following topics: dynamic analysis, instrumentation, or runtime verification.
		* 5+ years experience building developer tools in production
		* Inclination to prototype quickly and make fast decisions on experiment failure.
		* A creative mindset and good practical skills are more important than formal experience.
	- Preferred Qualifications:
		* PhD in computer science or related field, or other evidence of the ability to do independent research.
		* Knowledge of Python or JavaScript and its ecosystem, or the ability to acquire such knowledge quickly.
		* Ability to communicate complex ideas clearly, both in spoken and written form, for expert as well as novice audiences.
		* Interest in modern AI technologies and program synthesis in particular.
+ skill set:
	- GitHub has changed the way software is built. While GitHub-the-product must deliver immediate value to software engineers, we also have a unique opportunity to look farther ahead and identify how to make software development faster, safer, easier, and more accessible.
	- This is the mission of GitHub’s Office of the CTO. We research the current state of software engineering to understand what can be improved, and illustrate the future through working prototypes. We’re looking for talented polymaths to join us!
	- You’ll work with a small team of researchers to explore the future of software development in order to guide GitHub’s product and engineering decision-making. Your north star is ensuring that GitHub remains at the heart of software development. Your secondary goal is to project GitHub’s technical prowess — our published work should be inspirational, insightful, and informative to developers everywhere.
	- Responsibilities:
		* Research Engineers conduct investigations and build prototypes. With few constraints on our solution space, our hardest task is scoping our research so that we are able to produce impactful results. We will have an order of magnitude more ideas than we are able to pursue; choosing wisely is part of the job.
		* The domains of exploration are varied and will require an ability to understand, investigate, and implement prototypes across a wide range of technologies.
		* We do not work with production GitHub systems; our focus is on innovation and velocity. If we do our jobs well, we provide a map of the territory that de-risks engineering projects. From time to time, we may be called upon to investigate specific, high-priority topics.
	- Minimum Qualifications:
		* These are the general qualities that candidates must possess in order to succeed in this role.
			+ Comfortable identifying and justifying research goals in situations of ambiguity, and executing towards those goals without explicit direction.
			+ Finds ways to build prototypes that clearly articulate a thesis to others. Able to prototype quickly and evaluate ideas strategically.
			+ Is an effective and inclusive communicator, comfortable with remote communication practices. OCTO’s currency is ideas; the health of our team, our execution, and our results rests on our ability to communicate well.
			+ Able to collaborate with members of OCTO and the broader GitHub Engineering community to identify fruitful areas of investigation, inform OCTO’s point of view on issues/opportunities, and define projects to enhance our understanding of these topics.
			+ Comfortable managing interactions with stakeholders around timelines and milestones. Proactive, consistent communications are key to our working relationships, and a good guardrail against rabbitholes.
			+ 5+ years of experience writing and shipping software. This is a senior engineering role! That said, we are not primarily looking for raw coding ability. Experience is about more than your ability to write code and debate the finer points of $LANGUAGE_FEATURE.
			+ Are a generalist with some areas of deeper knowledge. We will also consider candidates who have specialized in a relevant field.
	- Preferred Qualifications:
		* These are more specific abilities we’re looking for, but it is the rare human who possesses them all. Think of this as a descriptive sketch, not a checklist of requirements. Be comfortable applying even if you don’t have all of them.
			+ A deep understanding of GitHub’s industry and business context, and the ability to be articulate about topics related to our product and audience.
			+ Has held roles that deal with topics at the boundary of human knowledge regarding software development and developers.
			+ A demonstrated ability to ship software using a variety of technology stacks. You are not afraid to read source code. You are comfortable picking up new technology stacks in the normal course of work.
			+ Have significant experience with one or more frontend technologies. We currently default to Typescript and React for the web, but “whatever helps us ship” is the top concern.
			+ Have significant experience with one or more backend technologies: server-side environments, compute, datastores, networking, infrastructure, devops, security.
			+ Have significant experience with open-source software, communities, and the systems that these communities use to self-organize and ship software for others to use.
			+ Have significant experience operating production systems at a nontrivial scale, and are familiar with the common patterns and pitfalls of that work.
			+ Have significant experience in another area of computing that is relevant to our mission. Human-computer interaction, distributed systems, $YOURTHING.
+ skill set:
	- GitHub Security Telemetry is seeking a highly talented and motivated security engineer to drive security initiatives that affect the security of millions of developers around the world. The role involves designing, building, and supporting the security telemetry services and tools that allow GitHub to deliver the best developer experience to its internal employees and the rest of the world. The ideal candidate will share a passion for engineering solutions to complex security problems.
	- Development and implement appropriate and effective telemetry solutions to help mitigate threats and risks
	- Endpoint vulnerability management
	- Provide subject matter expertise on telemetry solutions
	- Provide technical leadership while working across the company on critical security initiatives
	- You have knowledge of telemetry systems/tools, like ELK, Splunk, Azure Data Explorer, and TICK stacks
	- You have operational experience with Nessus, Qualys or similar scanning tools
	- Familiarity with configuration management software such as Puppet, Chef, Ansible, or Salt
	- Experience using Linux day-to-day in a production environment
	- Working knowledge of security telemetry best practices and threat landscape
	- Experience working in a decentralized and geographically distributed environment
	- Experience working in or partnering with a threat detection or incident response teams
	- Excellent written and verbal communication skills
	- A proven track record of taking technical requirements, developing proof of concepts, and developing mature systems.
	- A passion and proven ability to drive security that is frictionless, collaborative and effective
	- Experience using software version control systems/Git and GitHub
	- Ability to engineer solutions using Python, Ruby or Go
+ skill set:
	- GitHub is seeking a highly experienced and detailed-oriented individual contributor with a technical bent to help maintain and expand GitHub’s Risk Management function.  GitHub is committed to doing right by our customers and developing a highly effective control environment where risk is managed in a meaningful and sensible way that aligns with our business.
		* Are you a fearless, autonomous yet social go-getter, prone to fits of root cause analysis, followed on by enthusiastic information sharing?
		* Do you like to test theories, and exult, rather than deflate, when the results return gaps or deficiencies because it means you have an opportunity to make something better?
		* Do you want to see The Big Picture, and find ways to collect and organize data to tell the story? Maybe have a strong forest-from-trees project management perspective?
		* Do you agree that the organic power of mutually respectful discourse and collaboration is what makes the world go round?
		* And last, but most certainly not least, have you already answered the question "Why are we here?" with the GRC Truth, "Because Customers”?
	- If so, you might be the person we are looking for!
	- As part of the Security-GRC team reporting to the Security-GRC Risk Manager, you will work closely with multiple groups including software engineering, infrastructure, product, security operations, application security, legal, privacy, finance, HR, sales, and audit to develop and execute sound risk management processes and technical controls to meet customer needs, satisfy external audit requirements, and address internal business objectives.
	- This is an excellent opportunity for a strong Individual Contributor to have a hand in elevating risk management and security as a business and sales enabler, and to integrate a deep understanding of product and business into the technical risk space. This is a team effort, so bringing your team members, leadership, and customers along for the ride is integral to your success. Central to the team's culture is that of inclusion, transparency, and teamwork - we lift each other up to be successful!
	- A large focus of this position will be:
		* Execution and management of the Risk Assessment lifecycle for GitHub products and operating environments, including reporting on, planning and tracking remediation/mitigation plans.
		* Engage with GitHub team members and GitHub and Azure Compliance partners in detailed research and analysis of technical and process centric requirements in support of new initiatives, continuous improvement, and remediation efforts.
		* Contribute to the development of controls and continuous testing, design remediation and risk mitigation solutions, and collaborate cross functionally to establishing high levels of automated testing and evidence collection.
		* Act as lead for your function area in development and tracking of risks and remediation project plans; assist in tracking successful completion of work, ensuring alignment with product roadmap.
		* Provide feedback to business stakeholders on regulatory/industry better practices with regard to establishment and operation of internal controls.
		* Represent GitHub’s culture, tone and spirit of partnership with our coworkers, technology partners, Microsoft peers.
		* Contribute to the development of tools, automation, and practices to better support ongoing Security-GRC services.
		* Above all, you'll be getting your hands deep into the work and identifying new ways to solve problems and provide services inside our company.
	- Our ideal candidate takes an extremely pragmatic approach to Risk Management, functions as part of a growing team, and is able to balance the needs of a very dynamic engineering culture with that of protecting the company and customer data.
	- This job is U.S. based and open nationwide, however, semi-frequent travel (<10%) to our San Francisco, CA headquarters, Portland, OR, or Seattle, WA, will be necessary for a remote worker. (NOTE: Due to current COVID-19 restrictions on travel, non-essential travel for GitHub employees has been suspended indefinitely)
	- Required experience:
		* 5+ years prior work experience in technical risk management, information security, audit and/or compliance efforts, with a focus in a technical capacity at a large SaaS provider.
		* 4+ years experience performing technology risk management lifecycle program work, including assessment, reporting and remediation planning and tracking activities.
		* 4+ years experience building complex project plans and tracking completion, negotiating commitments and escalating on blocking issues constructively.
		* Experience standing up and administering applications and tooling with a growth mindset for learning scripting and automating processes.
		* Proven success in developing and using metrics/KPIs to assess, report on and improve program performance.
		* Practical experience with NIST, AICPA TSP/SOC, PCI, FISMA/FedRAMP, COBIT, ISO, or other industry and regulatory frameworks.
		* CISA, CISSP, CRISC, CIA or other relevant independent certification, or equivalent education.
		* Proven communication skills and ability to understand the value and drivers behind adjusting style and tone for a given audience, including technical and non-technical peers across the company.
		* Strong independent motivation, high comfort level with asynchronous work environments, written communication, use of chat tools.
		* Must be legally authorized to work in the United States.
	- Preferred Attitude:
		* Lead From Any Chair - You model influence without control, bringing your team members, leadership, and customers along for the ride is integral to your success.
		* Loves the opportunity to Fix It, Build It, Understand It.
		* Confidence in ability to learn new things - has the ability to state: "I don't know, but I will find out and circle back!”
		* Very high comfort level working under ambiguous situations, with natural drive to bring clarity.
		* Compulsive about getting it down on "paper".
		* Creative mindset; a willingness to try a new approach, and challenge assumptions.
		* Highly team oriented personality.
		* An open, learning mindset.
+ skill set:
	- GitHub is changing the way the world builds secure software and we want you to help change the way we secure GitHub. We're looking for an experienced security engineer to drive the development of GitHub’s red team operations. GitHub’s Application Security team (AppSec) has historically been focused on collaborating with and supporting engineering teams during the software development lifecycle. We are looking for a fresh perspective to drive the identification and mitigation of security risks from an attacker’s point of view.
	- In this role you will define and implement how GitHub provides our engineers and security teams with broadly scoped and in depth security assessment of our services and infrastructure. You’ll have the freedom to define these engagements to best test the defensive security practices at GitHub. In this position, you will work closely with the AppSec team to leverage the team’s knowledge, skillset, and ongoing collaboration with engineers.
	- Communication and empathy is key in this role, and your collaboration with engineers is just as important as the vulnerabilities and security risks you identify. In this role you’ll not only need to be creative and thorough in the attacks you perform, but also in helping drive the remediation strategies with teams across the company.
	- Your responsibilities will include:
		* Defining processes and initiatives to perform attacks against GitHub’s services and infrastructure, while taking care to minimize impact to systems and data
		* Digesting complex application and service architectures to identify potential threats and avenues for exploitation
		* Engaging internal engineering and security teams to work with during red team operations
		* Collaborating with engineering teams and leadership to communicate identified risks and expectations for remediation
		* Developing a plan to scale the red team, its service offerings, and tooling
		* Mentoring other team members
	- The minimum qualifications are:
		* A passion for identifying and exploiting security vulnerabilities
		* 8+ years of experience performing penetration tests, security code reviews, and red team operations
		* Experience in security architecture review and threat modeling of complex systems
		* Experience developing security testing tooling and exploits
		* Experience with identifying and exploiting the unique security risks of cloud computing platforms including Azure and AWS
		* Excellent written and verbal communication skills targeting a broad range of audiences from engineers to leadership
		* Ability to empathize with a diverse range of engineers
	- Bonus points if you have:
		* Hands-on management experience in a personnel or team lead capacity
		* Experience with exploiting virtualization techniologies and container orchestration systems such as Kubernetes and Nomad
		* Practical software development skills with Ruby on Rails or Go
		* Experience using Git and GitHub
+ skill set:
	- We are looking for an experienced product security engineer to join our team that can help us to strategically push forward the state of product security throughout GitHub. The product security team is dedicated to identifying the most important application and product security risks and use our passion for building things to mitigate or eliminate those risks. To get specific, here are some things our team works on:
		* Account security - We work to ensure only legitimate users can access their accounts. Examples include:
			+ Two-factor authentication (2FA) and WebAuthn
			+ Verified device protection for non-2FA users
			+ Protecting accounts reusing passwords leaked in other services
		* Application security paved paths - We are passionate about projects where we can add defense in depth or secure by default security patterns. Examples include:
			+ Continually looking for modern web security standards we can leverage such as content security policy, samesite cookies, etc.
			+ Built/operate an internal cryptographic service used by other engineers and services throughout GitHub.
		* Application security architecture - We collaborate with engineers throughout GitHub to develop solutions to security obstacles that strike the best balance between security, usability, and convenience.
	- Responsibilities:
		* Identify the most important strategic product security focus areas for the team and GitHub itself
		* Help lead security architecture discussions with other engineering teams throughout GitHub
		* Stay current with emerging security standards and help to identify when and where they should be adopted at GitHub
		* Help lead the team’s technical/architectural decision making
		* Write robust, maintainable backend code
		* Review code and lead group discussions about the projects we’re working on
		* Develop systematic solutions to problems instead of focusing on one-off fixes
		* Mentor other engineers
	- Minimum Qualifications:
		* A passion for application security related problems
		* 8+ years building software applications at scale
		* 5+ years designing/architecting secure systems at scale
		* Working knowledge of web application vulnerabilities and mitigations
		* Known for being a great communicator and collaborator
		* Excellent written and verbal communication skills
	- Preferred Qualifications:
		* Practical software development skills with Ruby on Rails or Go
		* Working knowledge of applied cryptography
		* Working knowledge of modern web security standards
		* Experience mitigating account security risks
		* Experience using Git and GitHub
+ skill set:
	- GitHub is changing the way the world builds software, and we want you to help change the way we secure GitHub. We are looking for an experienced Threat Detection Manager to lead our remotely distributed detection engineering team focused on identifying and responding to security threats against GitHub and Azure DevOps(ADO).
	- Interested in leading efforts related to building and tuning scalable detection and enrichment systems, threat hunting, MITRE ATT&CK, or response automation?
	- As our Threat Detection Manager, you will work alongside other members of the GitHub Security and Engineering organizations to lead an awesome team of threat detection professionals. You will develop and mature a comprehensive threat detection program, plan new detection work according to company growth and threat intelligence trends, and foster effective, sustainable process development. A successful applicant will have a desire to lead and develop a healthy and inclusive team responsible for detecting and hunting a variety of adversaries in diverse environments at scale.
	- Threat Detection Manager Responsibilities
		* Lead and develop a dedicated team of threat detection professionals
		* Maintain a healthy team culture based in excellence and empathy
		* Plan, balance, and prioritize team activity in response to company growth and changing threat landscapes
		* Coordinate measurable threat detection and hunting activity across a complex technical environment at scale
		* Develop and mature threat detection process and integration with threat intelligence resources
		* Closely partner with dedicated corporate security and incident response resources to identify, investigate, and mitigate threats
		* Participate in an on-call rotation
	- Minimum Qualifications
		* Significant experience with the entire threat detection lifecycle and collaborating with incident response, corporate security, security engineering, and threat intelligence resources
		* Several years experience effectively managing and working with distributed and remote security teams
		* The ability to take a pragmatic, risk-based approach to decision making while applying practical security principles and practices
		* Exceptional written and verbal communication skills with a strong sense of empathy
		* Proven experience guiding risk-based strategic and tactical technical decision making and execution
		* Experience operating a threat detection program mapped to the MITRE ATT&CK framework
		* Experience supporting governance and compliance requirements
	- Preferred Qualifications
		* 5+ years or demonstrable proficiency in threat detection
		* General experience in the following disciplines with deep experience in one or more:
			+ Log analysis: Large scale analysis of standard and custom log types using client and server side log analysis tools such as Splunk, ELK, Kusto, and Sentinel
			+ Familiarity with file system, memory, or live response on MacOS, Linux, and Windows
			+ Network traffic analysis: Analyze network telemetry from intrusion detection systems and flow monitoring systems
			+ Detection development: Host and network level detection with tools such as osquery, yara, auditd, etc
			+ Threat intelligence: Collection, analysis, production, or consumption of threat data and finished intelligence
		* Experience using or securing Linux day-to-day in a production environment
		* Development experience with Python, Ruby, Bash, or Powershell
		* Experience working with git, GitHub, and Microsoft Azure
+ skill set:
	- In this role you will not only be a technical leader paving the pathway to success for GitHub's customers, but also the catalyst of positive transformation, applying GitHub's world class approaches founded on our Values. Furthermore, you will collaborate with internal teams at GitHub and help deliver world-class solutions to customers by bridging the gap between GitHub's customers and GitHub's engineering teams. You will understand GitHub customer goals and will work with your teams and customers to create tailored scalable solutions.
	- The team manager will apply Management Fundamentals to help the team learn and grow in their career, be a pillar of technical fortitude, and to provide our customers with amazing experiences.
	- Expectations
		* As a primary component of this role you will need to maintain an advanced expertise in git
		* It is a core expectation that you are comfortable in the topics and details of Pro Git
		* You will need to reach and maintain expert level knowledge of the GitHub API, knowing how to leverage the product to effectively address customer challenges and find solutions
		* While software development is not a core attribute of the role, the development of scripts, CI/CD pipelines, and GitHub Apps is a large component of the work
		* Knowledge of the Rest API is necessary for creating solutions
		* Knowledge of the GraphQL (v4) API is necessary for creating solutions
		* You will need to have the ability to troubleshoot virtual machines in various cloud environments
		* GitHub Enterprise Server is a core product that many of our customers use. You will need to learn and maintain expertise in the architecture and maintenance of the GitHub appliance to assist with troubleshooting
		* You will work with various architectures for the GitHub appliance, including clustering, and high availability
		* You will be a thought leader and operate with a proactive mindset to help deliver solutions beyond customer expectations
		* You will help customers understand and plan adoption of new GitHub Product features and updates, such as GitHub Enterprise Server major/minor releases, either through discussion or demonstration
		* You will learn new GitHub Product features, such as Actions, Pull Panda, Semmle
		* You will work very collaboratively with Solution Architects, Implementation Engineers, and internal product teams, as well as our customers to understand the customer needs and to deliver tailored solutions for customers
		* You will need the ability to weigh the tradeoffs of technology choices, and provide detailed actionable plans
		* You are expected to be an expert in the area of software delivery through modern practices
		* Your communications to our customers will be delivered in the context of a GitHub expert, with little to no ambiguity in solutioning and/or prescription, is in a tone that uses the GitHub Voice and Tone, and is technically consistent as if it were answered by any GitHub internal team (such as Sales, Support, Engineering, Product, etc)
		* You will collaborate with GitHub internal teams if you are unable or unsure of a proper answer that is either out of your technical expertise or in the scope of another team
		* You will work with the Engagement Manager on the how of the delivery, especially with more complex solutions and projects
		* You will work with the Engagement Manager to have detailed follow up describing what was accomplished
		* You may visit customers onsite per Statement of Work criteria during various stages of the customer lifecycle
	- Expectations for GitHub
		* You will understand and apply GitHub's Values and the guidelines in our Handbook
		* You will complete and provide a monthly engagement report in collaboration with the Solution Architect team manager for consumption by both our internal GitHub teams and by our customers
		* You will use our internal channels to continuously keep your customer's Sales and Solution Engineer team members up-to-date on status of the engagement
		* You will participate in conversations with the Professional Services team to progress technical and other learning knowledge in our team channels
		* You will be conscious of open sourcing and teaching about solutions delivered to your customers that can be adapted for other Professional Services provider engagements
		* You will actively participate in Professional Services team discussions and attend team meetings, reasonably considering your time zone, current travel, and OOO activities
		* You listen for opportunities to improve team operations, either technical or process oriented, and contribute where possible to iterate on these improvements
	- How Success Is Measured
		* It is important to note this also should include your own personal goals, career aspirations, and a focus on your health and sustainability. Always know you can reach out to your manager or another Hubber if you need help with achieving or aligning. We want you to feel supported, be happy and have a healthy/sustainable experience. We are excited to have you as part of the team, and want you to feel the same way.
		* Weekly 1:1s are held and used to chat about anything, and optionally everything! Notes are posted in the private repositories. We can also use the cadence to re-visit measurement of success. A great way to accomplish this can be asynchronously in 1:1 issue comments.
		* Success from the customer perspective: You accurately know and can articulate the pulse of the customer, and they have a satisfactory/exceptional view of their Services engagement
		* Success from GitHub's perspective: Our Sales team can quickly understand the status of the engagement(s) you are leading. Data exists or can be provided when a GitHub stakeholder would like a deeper understanding of the engagement
		* Success from the team manager's perspective: You are meeting or exceeding the expectations defined in this document and reach out for help when needed
			+ The team manager should provide a Product Owner perspective on team objectives, strategy, and provide resources and guidance on completing OKRs.
+ skill set:
	- GitHub is seeking a Security Solutions Architect for our Professional Services team. They focus on helping our customers improve the lives of developers working on the GitHub platform. As a Security Solutions Architect you will have a direct impact on the security of some of the world’s largest code bases and the most commonly used applications. You will be a trusted consultant to the world's leading companies to assist them in transforming how they approach security in their software delivery life cycle. You will shape how they integrate security throughout their software delivery lifecycle. You will create a vision for these customers on how they can improve, and work closely with their stakeholders and teams to implement these changes.
	- For this role, you can expect to spend about 60% of your time with customers on high-level details and driving Advanced Security adoption. The rest of the time is likely split between CodeQL and Advanced Security deployment.
	- Responsibilities
		* Be a trusted advisor for our customers on all aspects of GitHub Advanced Security
		* Share expertise on CodeQL, both from a language and deployment perspective
		* Serve as the primary owner of customer deliverables over long-term engagements
		* Provide technical contribution and facilitate development with the broader Services Advanced Security team
		* Participation in customer scoping calls throught the customer's journey, with ongoing, recurring collaboration with customers
		* Frequent calibration of customer success criteria and providing proactive, creative attention on their priorities
		* Help customers understand and quantify value from Advanced Security
		* Collaborate with team members across GitHub, providing valuable insights from the field on how we can improve our products
	- Qualifications
		* Demonstrated ability to connect with people, lead client projects, and help clients solve problems with GitHub
		* Strong ability to collaboratively and optimistically handle client expectations and project scope during all stages of a client engagement
		* Strong knowledge of secure coding practices and common types of vulnerability
		* Experience with common DevOps tools, CI/CD, builds, etc.
		* Experience of code analysis (static/dynamic), dependency scanning, or other security automation in a DevOps environment
		* Experience in mentoring other engineers and disseminating complex technical ideas and processes
		* Strong written and verbal communication skills
		* An ability to persuade customers to make hard, but worthwhile decisions
		* An ability to see the tradeoffs of technical solutions and make recommendations to customers
		* A desire to help others, and to collaborate with both customers and GitHub team members
		* A growth mentality, and a passion for discovering new technologies
+ skill set:
	- GitHub is seeking a Solution Architect for our Professional Services Delivery team. They focus on helping our customers improve the lives of developers working on the GitHub platform. As a Solution Architect you will impact the lives of developers by working with some of the largest companies in the world by crafting many aspects of software delivery. You will help our customers plan, prioritize, launch, and accelerate their initiatives in building on GitHub. This role will be based in the Central US region.
	- You will succeed in this role if you are a highly technical individual who feels as comfortable working with tech leaders to map out software delivery initiative roadmaps as you do writing code. You will work with customers from the planning phase through maintaining the system. You will be their primary technical contact at GitHub and establish relationships with admins and their tech leaders. This can be a remote position.
	- The Solution Architect will be responsible for the following:
		* Serve as the primary owner of customer deliverables over long-term engagements
		* Provide technical contribution and facilitate development with the broader Services Delivery team
		* Participation in customer pre- and post-sales scoping calls, and ongoing, recurring collaboration with customers
		* Frequent calibration of customer success criteria and providing proactive, creative attention on their priorities
	- Responsibilities:
		* Be the primary point of contact and trusted advisor in a technical capacity for customers
		* Help transform software delivery at some of the largest organizations through hands-on assistance
		* Demonstrate leadership in owning the development and delivery of adaptive solutions
		* Proactively seek out new GitHub enhancements and provide demonstrations/adaptive tooling
		* Managing customer success criteria, understand the pulse of the customer, and providing an exceptional experience with GitHub
		* Build customer business artifacts, such as company-specific roll-out plans and timelines
		* Work closely with the Engagement Manager to field customer questions and requests for services
		* Study reference customer cases for concepts to apply for specific customer scenarios
		* Track and share progress with GitHub and our customer to ensure expectations are clear and progress is being made
		* Discover issues that arise and create plans to solve their problems
		* Be on constant watch for process improvements
		* Seek out automation opportunities for repetitive tasks
	- Qualifications:
		* Deep experience with GitHub to deliver software
		* A strong understanding of IT infrastructure, governance, compliance and business process management
		* Interest in working creatively with customers to understand technical and business requirements
		* A demonstrable comfort in both facilitating and developing solutions
		* Aptitude to proactively engage customers with aspirational and recommended technical deliverables in a self-driven manner
		* Implement and test solutions based on requirements and customer feedback
		* An understanding of several of these methodologies and tools:Software development methods such as Agile, Scrum, Lean, Waterfall
			+Software project tools like JIRA, Pivotal Tracker, Trello, Asana, and MS Project
			+ Continuous integration and build automation with Jenkins, TeamCity, TFS, TravisCI, CircleCI
		* Experience configuring the following technologies:
			+ LDAP, ActiveDirectory, and other SAML/Single-Sign-on services
			+ VMware vSphere, ESXi, AWS, Azure, GCP, and other virtual infrastructure tools
		* Demonstrated ability to connect with people, lead client projects, and help clients solve problems with GitHub
		* Strong ability to cheerfully handle client expectations and project scope during all stages of a client engagement
		* Superb written and verbal communication skills
		* Self-motivation, energy, and enthusiasm
	- A more human note about this role:
		* This role is critical for our customers and GitHub. We would love your help to continue to assist customers in accomplishing their goals and making a positive impact in their company. We have seen how impactful a Solution Architect can be at GitHub. We hope you will join our team as we work with our customers to achieve their vision with the GitHub platform.
+ Maintaining awareness of internal GitHub initiatives, the direction of the Source Control Management (SCM) industry, and trends in global developer collaboration tools and techniques.
+ Knowledge of Source Control Management (SCM) tools and workflows
+ skill set:
	- The Internet Archive is a non-profit with a huge mission: "Universal Access to All Knowledge". Based in San Francisco, CA, with satellites around the world, Internet Archive staffers are building the digital library of the future - a place where anyone can go to learn and explore our shared human experience from books, web pages, audio, television and software. Forever.
	- The Internet Archive is seeking a Senior Software Engineer for its Archive-It Group. The Archive-It team is responsible for maintaining a web application which automates high quality captures of content from the web. An ideal candidate demonstrates independence and initiative, is a problem solver, works well autonomously, has deep experience on the Unix/Linux command line and broad experience in systems architecture. Additionally, the ideal candidate is open to helping advance the state of preserving web-published content, working on the platform which drives a large portion of global web capture.
	- The successful candidate will work in the Archive-It Group in support of building and maintaining high quality software for the collection, preservation, and accessibility of web content. The role will help design and implement the future of a toolset and APIs which automate web capture using open source technologies and platforms. An ideal candidate is interested in developing harvest techniques and tools to enable archival capture and re-rendering of rich media, streaming content, social media, as well as traditional web page content. This role contributes to defining deployment  architectures and workflows, managing data at scale, and monitoring production systems.
	- Essential Job Functions:
		* Contending with the complexity of a suite of tools that capture web content accurately at the micro and global scale with equal accuracy
		* Configuration, maintenance and improvement of web crawling tools
		* Contribute to the development of a distributed python-based database used for crawl material deduplication, analysis and reporting.
		* Demonstrated experience of delivering on commitments with deadlines and project time lines and working in a collaborative team of engineers and project/product managers.
	- Minimum Qualifications:
		* Strong experience in Unix shell scripting and Python coding required
		* Strong experience with python, bash, java, and C-based debugging tools strongly preferred
		* Solid experience in Internet protocols (HTTP is must.) Strong knowledge of HTML, JavaScript and Web technologies in general
		* Knowledge of building and deploying web applications, databases, web-host services, and Linux system administration
		* Ability to work in, and enjoy, a loosely structured work environment
	- Preferred Qualifications:
		* Cluster computing experience is preferred, especially familiarity with Hadoop and related technologies and tools
		* Experience working with Javascript and HTML in a large-scale application preferred
		* Experience or familiarity with Java preferred
		* Experience with applications designed to display archived web content
		* Experience with development environments and system monitoring/administration tools
		* Experience with open source practices, version control, and code review
		* Experience with Atlassian tool sets
		* Flexibility and a sense of humor are a plus
		* Bachelor's Degree in Computer Science or a related field, five years of progressively responsible experience in software development.
	- Reporting Structure: The Senior Software Engineer reports to the Engineering Manager for Archive-It and works closely with other departments. The position works alongside other web archiving engineers as well as program staff in Web Archiving & Data Services Group and with the broader Internet Archive infrastructure and engineering teams.
+ skill set:
	- Monitor stack health for issues with reliability, performance, durability, and security, maintaining our zero-downtime standard
	- Implement tooling across our AWS infrastructure and services to identify and remove bottlenecks
	- Develop our infrastructure-as-code initiative to ensure all environmental changes are tested, audited, and reproducible across environments and stacksImplement
	- Docker containers and container management to support out-of-the-box deployment of applications across environments
	- Manage CI and CD tools in coordination with the software engineers
	- Research and promote new DevOps tools to simplify processes and identify opportunities for improving existing processes or implementing new process automation
	- Handle production and non-production support issues as they arise
	- Participate in a 24/7 on-call rotation
	- Maintain and test Disaster Recovery procedures
	- Manage penetration testing, vulnerability testing, and web application scanning
	- Represent DevOps during design and development of software or extensive revisions to existing applications
	- Support the sales team in completion of security & architecture questionnaires
	- Organize, conduct and own follow-up action items for Root Cause Analysis meetings
	- Deep knowledge of AWS services, including ALB, CloudFormation, CodeBuild, CodePipeline, ECS, IAM, Lambda, RDS, Route53, S3, and SSM
	- Expertise with an automation framework such as CloudFormation, Ansible, Chef, Salt, or Puppet
	- Strong background in administering Linux, including Apache/Nginx web services
	- Strong scripting skills (Bash, Python) with the ability to develop ad hoc tools
	- Knowledge of networking concepts (Firewalls, Network ACLs, HTTP, DNS)
	- Experience with Infrastructure
	- Monitoring using tools such as Datadog, NewRelic, etc
	- Experience working with AWS CodeBuild, CodePipeline, Jenkins, Concourse or other build automation tools
	- 5+ years of relevant experience
	- Experience with Git and GitHub for version control
	- Strong interest in higher education, startups, and/or SaaS technology
+ skill set:
	- We are looking for a Senior Software Engineer to join our Data Science team and help further develop Deezer’s data-driven mindset.
	- We are part of the BI and Data Analytics team, whose mission is to find the correct levers within the product to further drive Deezer’s growth. Through our analysis and predictions tools, we ensure Deezer is fitting our users’ needs.
	- As a Senior Software Engineer in the Data Science team, you will be responsible for the engineering and implementation of scalable technical solutions around data science production. This solution will have significant impact to Deezer’s results in areas of fraud detection, churn, inactivty & conversion.
	- What you will do:
		* Develop a deep understanding of the business & product and their requirements to develop solutions to insure the fully adoption of our prediction modelling (visualisation, alerting, API).
		* Design, build, and maintain data pipelines between our Data science team & product, CRM and other relevant systems.
		* Help our Data Scientists implement and maintain those ML pipelines & data architecture related, supervise the GCP migration and deployment of real time modelling.
		* Improve and build solutions to address architectural gaps or technical debt.
		* Propose best technologies for data processing and data framework, test regularly new technologies that may ease team work (Skein, Meta Flow).
		* Mentor Data Scientists on their Engineering skills ; Drive enforcement of standards, tools and methodologies ; Ensure that the pipeline is fully tested.
		* Participate in story planning, standups and retrospectives.
		* Produce documentation and tutorials that enable other teams to use easily our pipeline.
		* Pro-active communication to users and management on issues.
	- What we are looking for:
		* At least 5 years of experience of software engineering/data engineering, with a degree in computer science.
		* Experience in micro services architecture
		* Experience with Docker, Kubernetes, REST API.
		* Fluent in at least one language in Python, Scala Java;
		* Experience of functional code.
		* Experience in designing, building and launching efficient & reliable data pipelines is preferred.
		* Experience with Hadoop/Hive, Spark, Cassandra and data warehouse technologies is preferred.
		* Passion for technology, industry research and enjoys solving business problems.
		* Experience in Agile Processes, Test Driven Development and Framework design.
		* Excellent verbal, written, communication, interpersonal and presentation skills - ability to clearly communicate data analyses results to end users.
	- Bonus Points.
		* Building and launching new data models that provide intuitive analytics for the analysts and customers.
		* Mathematical/machine learning background with the ability to understand & implement distributed algorithms.
+ skill set:
	- As a Network Engineer you will be responsible for the design, implementation, and support for the network within the OVHcloud environment.  You will be required to understand application and hardware points of failure, performance characteristics and have the ability to identify actionable items to maintain an acceptable service level for all associated environments and applications.  You will be required to participate in an on-call rotation and serve as top-level support for network related issues. 
	- Provide Tier I/II Technical Support for OVHCloud's global network infrastructure.
	- Execute or implement simple, automated and scripted changes or infrastructure requests.
	- Troubleshoot and provide customer support for technology and infrastructure issues.
	- Document and update incident technical details into ServiceNow/Jira ticketing system.
	- Escalate issues to Tier III support if unable to resolve through initial triage and troubleshooting.
	- Execution of standard operational processes which involve technology and client interfaces.
	- 1-2 years of hands on enterprise network operations support experience
	- CCNA certification required
	- Intermediate understanding of OSI model and troubleshooting of technology related issues
	- Intermediate understanding of network protocols (to include but not limited to): OSPF EIGRP BGP MPLS RSTP STP HSRP VRRP VRF VTP DHCP DNS CDP LLDP ARP FTP TFTP
	- CCNA level knowledge and experience (at least 1yr)
	- Able to work well in a fast-paced environment and be comfortable in stressful situations
	- Can effectively communicate with both management as well as non-technical personnel on any technology issue to ensure they understand the nature of the issue and current statue easily understood on any outage conference calls
	- Detail oriented self-motivated goal driven
	- Intermediate familiarity with Cisco IOS, Nexus NX-OS and IOS-XR
	- Knowledge of the following is preferred:
		* Network product: Arista
		* Virtualization network knowledge: VxLan
		* Scripting: Python, Perl
		* Devops: Linux, Github, bastion
		* Security knowledge: firewall, VPN
		* Load balancer
+ Knowledge of predictive analytics/statistical and mathematical modeling/data mining algorithms;
+ ***Publication in top-tier conferences and journals, such as NeurIPS, ICML, ICLR, CVPR, ICCV, ECCV, AAAI, ACL, STOC, IEEE TPAMI, IEEE TNNLS, IEEE TSP, IEEE TIP, Information Fusion, JAIR, IJRR, IJCV, and JMLR.***
+ Experience in using relational databases like MySQL, Redshift, ***Graph DB***.
+ Architect test methodologies applicable to a wide range of CPU and SoC designs for CPU memory sub-systems including Load-Store unit, various levels of caches, memory virtualization and industry standard bus protocols (e.g. AMBA and TileLink).
+ ***Perform initial sandbox verification***, and work with design verification team to create and execute thorough verification test plans.
+ ***Experience with designing an out-of-order system ( high-performance DDR controller or caches controllers on a hetro/homo-geneous multi core system is a plus.***
+ ***Architect, design and implement new features, performance improvements, and ISA extensions in RISC-V CPU core generators.***
+ skill set:
	- AI/ML or Heterogeneous computing infrastructure development
	- Parallel programming & optimization
	- Deep learning application/middleware integration
	- Open-source software development/ integration
	- Co-work with SW & HW members for performance exploring and tuning
	- 5+ years of experience on RTOS, Linux kernel development, especially on OS scheduler
	- 3+ years of experience with complex system performance tuning and debugging
	- Good understanding of both CPU and System Architecture
	- Basic understanding of Deep learning, MLIR, CUDA
	- Familiarity with TFRT/IREE/ONNX-runtime is plus
	- Open source upstreaming experience is plus
+ skill set:
	- You are in the process of receiving a Bachelor’s or Master’s degree in Human Computer Interaction, Interaction Design, Cognitive Psychology, Digital Media Design, and/or related fields
	- You are interested in prototyping, designing, testing, implementing, and evaluating user experiences for web based applications
	- You are familiar with usability heuristics and best practices in UX design
	- You have strong prototyping skills and are able to create wireframes and process flow diagrams
	- You are able to plan and administer usability tests
	- You have a portfolio of work or projects that includes case studies of design that highlight your process and your role on the project
	- Experience designing on multiple platforms (iOS, Android, Mobile web, Desktop, etc) is a bonus!
	- Excellent oral and written communication skills
	- Some experience with design tools (Figma, Sketch, Photoshop, Illustrator, etc.)
	- Some experience with interactive prototyping tools (Framer, Principle, Origami, Invision Studio, etc.)
	- Excellence in design craft
+ skill set:
	- Our team is at the forefront of the artificial intelligence revolution, enabling innovators from all industries and sectors to expand human potential with technology. What we do, really makes a difference.
	- As a Field AI Engineer, you will be working closely with Graphcore’s customers and partners to help them in understanding and getting the most from our Intelligence Processing Unit (IPU) technology. In your work you will support some of the world’s top machine learning innovators at deep learning research groups, at academic institutions, at innovative machine learning start-ups, at leading automotive companies, and at some of the world’s largest cloud and internet companies.
	- You will need to develop a deep understanding of the state-of-the-art in artificial intelligence & machine learning domains and work with our customers to develop new techniques which exploit the unique features of our IPU architecture.  We want you to become an industry thought leader on Graphcore technology and machine learning applications in the cloud, in automotive and in embedded applications. You should be interested and keen to present at industry conferences and will be able to back this up with written blogs and compelling content.
	- Develop strong technical relationships with researchers and engineers at our customers and partners and help them to develop new algorithms using Graphcore’s IPU technology and achieve breakthroughs in artificial intelligence
	- Support Sales teams as they engage new customers, understanding their AI challenges and describing how Graphcore’s technology can help
	- Become a thought leader on machine learning and advocate for Graphcore’s IPU technology
	- Work with the Product Management and Engineering to ensure a good flow of customer and market feedback that can be incorporated into future products
	- 4+ years of related experience ideally in Machine Learning, HPC or a math’s intensive engineering field
	- Bachelor’s in Engineering, Computer Science, Mathematics, Physics or similar field
	- Experience working with modern deep learning software architecture and frameworks including: Tensorflow, MxNet, Caffe, Caffe2, Torch, and/or PyTorch, or a strong mathematics background and a keen interest to learn about these exciting new techniques
	- Comfortable in a customer-facing environment and experience working with developers or researchers
	- Ability to multitask effectively in a fast-paced environment
	- Action-oriented with strong analytical and problem-solving skills
	- Strong time-management and organization skills for coordinating and prioritizing multiple projects and initiatives
	- Strong written and oral communications skills with the ability to effectively interface with management and engineering
	- Strong team-working and excellent interpersonal skills
	- Masters or PhD in related computationally intensive science or engineering field
	- Experience with C/C++, parallel programming and knowledge of computer architectures
	- Experience working with PCIe form-factor accelerators such as GPUs, DSPs or FPGAs
	- Experience in the cloud or automotive space
+ skill set:
	- The use of machine learning to reimagine software applications and service development is exploding.  Companies from every corner of the industry -- the biggest cloud service providers to corporate industrials to financial services to healthcare to retailers -- are exploring new ways of building products and services using data-centric learning models in place of traditional explicit programming.  The drive to deliver more timely and more accurate results is compelling an ever greater need for specialized computing power. GPUs have been hailed as the solution to those computing needs but the industry is actively searching for a better, more efficient solution.  Graphcore has that solution. 
	- Graphcore’s Intelligence Processing Units, or IPUs, are specifically designed for artificial intelligence and compute-dense graph applications.  These are not GPUs, Graphics Processing Units, but rather graph processors especially adept at the kinds of computations used in understanding relationships within a sea of data.  Architecturally, IPUs looking nothing like GPUs.  They offer performance, latency, and power efficiency advantages a GPU will be unable to match.  Graphcore offers support for popular industry ML frameworks and a full tool suite for developers to innovate both within and outside those frameworks. 
	- As a Machine Learning Engineer, you will work to port and optimize machine learning and artificial intelligence applications using Graphcore’s Poplar™ software and IPU processors, enabling breakthroughs in this rapidly moving field.
	- You will work on AI and ML applications, create application notes and blog content, and work closely with Graphcore’s field teams, customers and partners to help them in understanding and getting the most from our Intelligence Processing Unit (IPU) technology. Having access to world leading compute resources, you will develop applications that push the boundaries of what is possible with machine learning today. You will also act as a senior technical figure within our product support organization, debugging customer issues and providing concise summaries and recommended fixes to our core engineering teams.
	- In your work you will support some of the world’s top machine learning innovators at deep learning research groups, at academic institutions, at innovative machine learning start-ups, at leading automotive companies, and at some of the world’s largest cloud and internet companies. You will need to develop a deep understanding of the IPU architecture and the associated Poplar™ tools and become familiar with leading machine learning frameworks. 
	- You will need to develop a deep understanding of the state-of-the-art in artificial intelligence & machine learning domains and work with our customers to develop new techniques which exploit the unique features of our IPU architecture.  We want you to become an industry thought leader on Graphcore technology and machine learning applications in the cloud, in automotive and in embedded applications. You should be interested and keen to present at industry conferences and will be able to back this up with written blogs and compelling content.
	- Responsibilities
		* Develop strong technical relationships with researchers and engineers at our customers and partners and help them to develop new algorithms and achieve breakthroughs in artificial intelligence
		* Become a recognized expert on Graphcore’s IPU technology and Poplar™ tools and deliver compelling training to our customers and partners
		* Field & resolve challenging/complex customer support issues
		* Shepherd critical customer issues and provide timely advance warning of critical issues that need attention
		* Become a thought leader on machine learning and advocate for Graphcore’s IPU technology
		* Work with the Product Management and Engineering to ensure a good flow of customer feedback that can be incorporated into future products
	- Requirements
		* Demonstrable machine learning development experience or related experience writing and optimizing applications in HPC, scientific libraries, compilers, digital signal processors or GPUs.
		* Deep experience with C++ and in-depth knowledge of computer architectures, high performance programming and parallel programming
		* Ability to multitask effectively in a fast-paced environment
		* Action-oriented with strong analytical and problem-solving skills
		* Keen interest to learn about the exciting new field of AI
		* Comfortable in a customer-facing environment
		* Strong written and oral communications skills with the ability to effectively interface with management and engineering
		* Strong team-working and excellent interpersonal skills
	- Differentiators
		* Masters or PhD in related computationally intensive science or engineering field
		* Experience with C/C++, parallel programming and knowledge of computer architectures
		* Experience working with modern deep learning software architecture and frameworks including: Tensorflow, MxNet, Caffe and/or PyTorch
		* Excellent communication & presentations skills and comfortable in a customer-facing environment
		* Experience working with accelerators such as GPUs, DSPs or FPGAs
		* Experience in the AI/machine learning, cloud or automotive space
+ skill set:
	- Help the current effort of the AI research community, and contribute to cutting edge research in machine intelligence, starting from areas including Deep Learning, Generative Models, Reinforcement Learning, Evolutionary Computing, Sequence Modelling, Large-Scale Distributed Optimization and Low-Precision Numerical Formats.
	- Prototype efficient implementations for training of novel deep learning optimization algorithms and model architectures of increasing complexities.
	- Contribute to the design of efficient software implementation of the experimental setup required to evaluate novel machine learning algorithms and models at scale.
	- Participate to work to identify new directions of AI research, with the aim of contributing to new groundbreaking approaches to computational intelligence. The position will involve the possibility of attending the main research conferences in the field of machine intelligence.
	- Contribute to investigations in specific areas of fundamental and applied research, aiming at publishing the work for discussion within the wider AI research community.
	- Take responsibility for the software implementation of experimental setup critical for investigation of new research directions.
	- Collaborate with the rest of the team and with other groups within the company, to develop new ideas and identify research opportunities.
	- Interact and work with external institutions and research labs. 
	- MSc or PhD in Computer Science, Machine Learning, Mathematics, Physics, Electrical Engineering or related fields, with a strong basis in numerical methods and probability theory.
	- In-depth understanding of modern machine learning algorithms and deep learning architectures.
	- Strong software engineering and coding skills (Python, C/C++) and experience of algorithm implementation in modern machine learning frameworks (TensorFlow, PyTorch). 
	- Strong communication skills, and willingness to work in a collaborative environment.
	- Publications and/or open-source implementations in the area of machine intelligence will be a plus.
+ Experience with product/web analytics tools (Pendo, Heap, Hotjar, Google Analytics).
+ Python libraries:
	- dask
	- pandas
	- scikit-learn
+ file formats:
	- NetCDF 3\*
	- NetCDF 4\*
	- Zarr\*
	- GRIB\*
	- GeoTIFF\*
	- PythonPickle\*
	- HDF 4/5\*
	- Other image format: PNG, JPG, TIFF, etc.
	- video: MP4
	- database: MongoDB
	- Tensors: PyTorch, TensorFlow, NumPy
+ skill set:
	- We’re looking for an experienced Compiler Architect to help drive compiler improvements and hardware requirements.  
	- Analyze deep learning networks and develop compiler optimization algorithms for our hardware 
	- Performance tuning and analysis on different levels of the compiler  
	- Architect and implement compiler and optimization techniques for various neural networks  
	- Work closely with chip design team on hardware architecture 
	- Develop and maintain compiler tool chains 
	- Bachelors, Masters or Ph.D. or equivalent in Computer Science, Computer Engineering  
	- 3 to 5 years of relevant work in performance analysis and compiler optimization  
	- Experience with modern ML compiler technologies: MLIR, LLVM,  XLA, TVM, TensorRT 
	- Experience with graph algorithms, combinatorial optimization techniques, quantization of Deep Learning models, compilation for multi-core architectures (GPU, FPGA, or systolic arrays)  
	- Excellent C/C++ programming and Python software design skills  
	- Knowledge of deep learning frameworks (TensorFlow, PyTorch)  
	- Experience with developing and analyzing neural network models 
	- Experience with CUDA, cuDNN   
+ skill set:
	- We are seeking a candidate who is primarily responsible for design, optimization and layout of photonic devices. Some optical bench work is expected.
	- Optimize integrated photonic devices
	- Numerical electromagnetic simulation of photonic devices
	- Interact with photonic foundries to understand design environment and rules
	- Layout photonic devices with common EDA, such as Cadence or Mentor Graphics
	- Design optical bench experiments for device characterization
	- Collaborate with electronic and algorithm engineers on research and development efforts
	- PhD in electrical engineering, applied physics or material science
	- Expert knowledge of electromagnetic theory
	- 5+ years of experience in integrated photonics design, optimization, tape-out, and characterization
	- Proficiency in electromagnetic simulation with common tools, such as Lumerical, COMSOL or Photon Design.
	- Proficiency in photonic layout with Cadence or Mentor Graphics
	- Proficiency in optical bench experiments with tools such as parameter analyzer, optical spectrum analyzer, laser source, etc.
	- Experience in semiconductor processing is a plus
+ skill set:
	- If you would like to build computational machines that are solving problems in ways that have never been done, we are looking for software engineers with strong problem-solving skills to help us build an SDK for our optical hardware accelerators. 
	- This SDK converts a trained neural network into a binary we can run on our custom hardware. The SDK imports neural networks from popular frameworks (e.g., TensorFlow, PyTorch) and runs a series of transformations on those neural networks. These transformations include things like quantizing certain parts of the graph and partitioning subgraphs that can run on our device. The SDK also includes a compiler and runtime library to run the transformed neural network on both a simulator and our actual hardware. 
	- Create a customer portal to help keep track of bugs in the SDK 
	- Write documentation and literature for customers to learn how to use the SDK 
	- Debug and refactor parts of the SDK based on customer feedback  
	- Work with electrical engineers to update compiler and runtime libraries
	- Create profiling and debugging tools for both internal and customer use 
	- Bachelor’s degree in computer science or related fields 
	- 2+ years of experience writing industry standard code 
	- Proficient in at least one object-oriented programming language (i.e., Python, Java, C++) 
	- Familiarity with Python and C++ 
	- Experience with software testing and building robust software systems 
	- Strong debugging and problem-solving skills  
	- Experience with different build tools (e.g., CMake, Bazel)  
	- Familiarity with Protocol Buffers  
	- Highly proficient in deep learning frameworks (e.g., TensorFlow, PyTorch) 
	- Understanding of machine learning concepts like quantization, pruning, sparsity, etc. 
	- Strong skills with graph algorithms  
	- Experience with Jira, Azure Boards, and Sphinx 
	- Substantial experience with Python and C++ 
	- Proficient with Linux, Bash, and Git  
	- Experience publishing and maintaining open-source packages  
+ skill set:
	- We’re looking for an experienced RTL designer to help develop novel AI hardware.   
	- What you’ll do at Lightelligence:  
	- Collaborate with RTL, DV, PD, and system engineers to define and implement  DFT functions (scan/ATPG, MBIST, LBIST and more) and methodology  
	- Work across domains to develop a manufacturing test strategy for a heterogeneous high-speed electro-optical design
	- MS or PhD in a relevant discipline such as Computer Science, Electrical Engineering, or Computer Engineering with at least 10 years of relevant work or research experience
	- Proficiency in industry-standard DFT EDA tools to enable scan, ATPG, and related technologies 
	- Proficiency in SystemVerilog  
	- Strong scripting skills (Python, tcl, shell)  
	- Synthesis, STA, CDC, or P&R experience a plus 
	- Experience bringing-up silicon in wafer and packaged environments 
+ skill set:
	- We’re looking for a System Validation Engineer who can create tools and methodologies to aid in providing feedback to analog, photonics and digital design teams. 
	- Developing tools to perform lab measurements with Python and C++ 
	- Evaluating new silicon and analyzing performance of photonics processors 
	- Characterization of analog, digital and photonics test circuits 
	- Preparing products to enter manufacturing and customer deployment 
	- Prototyping, building and reworking systems 
	- Degree in engineering-related field 
	- 5+ years working as an engineer in a hands-on role 
	- Programming experience with Python and object-oriented environments 
	- Familiarity with instruments such as high-speed oscilloscopes, signal generators, network analyzers, optical sources, etc. 
	- Experience with high-speed digital interfaces such as PCIe 3.0, DDR4, or JESD204B is a plus 
	- Experience with photonics is a plus 
	- Aptitude for problem solving and opportunity exploration 
+ skill set:
	- We’re looking for an entry-level analog/mixed-signal engineer for support of custom analog/mixed-signal ASIC design. 
	- Analog/Mixed-Signal design support including, simulation, schematic capture, layout, silicon and/or discrete component evaluation/characterization 
	- Laboratory team support interfacing with standard test equipment, custom hardware, and software development to meet test requirements    
	- Team oriented with a desire for “hands-on” experience 
	- BS or MS in a relevant discipline such as Electrical Engineering with 1-2 years of relevant work or research experience  
	- Experience with analog circuit design including operational amplifiers, ADC and DAC circuits, regulators, and references 
	- Experience with FPGA and DSP design and implementation is a plus  
	- Experience with various EDA/Computing languages and tools, i.e. Spice, SystemVerilog, Verilog-AMS, Matlab, Python, C++, etc. 
	- Willingness to learn new skills and do the work necessary to succeed 
+ skill set:
	- We’re looking for an experienced computer architect.
	- Develop performance modeling of a hybrid digital, analog, and optical computing system
	- Optimize system performance and drive system architectural design for executing machine learning workloads
	- Codesign digital microarchitecture and perform model validation
	- A BS in Computer Science, Software Engineering, Electrical Engineering or Computer Engineering
	- Programming languages: C++, Python
	- Familiarity with common machine learning workloads in image recognition, object detection, language processing, or recommendation
	- Techniques for accelerating inference a plus: quantization, graph fusion, compression
+ Experience working with either a Map Reduce or a MPP system on any size/scale
+ skill set:
	- a Master’s degree in CS or equivalent,
	- experience with Functional Programming (e.g. OCaml, Erlang),
	- has worked on 2+ large scale commercial projects taken from inception to production,
	- experience with dynamically typed systems (e.g. Javascript, Erlang; Python is a must),
	- experience with C/C++ or other low-level languages with manual memory management,
	- experience with scalable microservice architecture,
	- the ability to work on any system, from code running in the browser to big data analytics dealing with terabytes of data,
	- excellent communications skills in English,
	- the opportunity to obtain a valid EU work permit.
	- Other things you should know are
		* we're currently working on Issuu’s Story Cloud both on web and mobile apps, machine learning for better understanding of our content, internal analytics and our famous reading experience to mention a few examples,
		* we currently use Python, OCaml, Javascript, Erlang and a bit of C++, and we’re extremely open to using new languages and/or technologies,
		* our architecture is microservice-oriented using AMQP,
		* we deploy multiple times a day on AWS and use Docker Swarm, MySQL, Redis, Node, etc.,
		* we strive to be agile (who doesn’t?), but we're not religious about Scrum, Kanban or any other methodology.
	- We believe you can help us succeed by
		* delivering results that create value for the end users, while we ensure a high-performance,  high-availability, robust product that scale with our traffic (10.000++ requests/second) and data-heavy platforms (100++ terabytes),
		* working across disciplines, and take a holistic, end-2-end approach to software development,
		* being at the forefront of development practices, Agile, Continuous Delivery, Software as Service, Cloud-based, Docker, React,
		* working equally well creating back-end and front-end solutions that can run in production at the scale of our traffic,
		* solving problems from just about every area of computer science, including search, information retrieval, artificial intelligence, natural language processing, distributed computing, large-scale system design, networking, security, data compression, big data and so on.
	- We are the right company for you, if you
		* want to work on a product that matters to a lot of people – We receive hundreds of visits per second and host over 50M+ documents,
		* consider yourself one of the best at what you do and you're looking for equally talented colleagues,
		* are self-driven and would never just want to take the next ticket,
		* are curious and never stopped learning and exploring new languages, technologies and solutions,
		* seek a culture where all voices matter when it comes to shaping the future of the product,
		* want to work with colleagues who have ‘here to help’ attitude, and absolutely want to help you succeed.
+ experience with Protobuf, Docker, Python, Mysql, and Rabbitmq is a plus,
+ we currently use Python, OCaml, Javascript (client and server side), Erlang/elixir, Kotlin, and a bit of C++, and we’re open to using new languages and/or technologies,
+ the ability to architect and build complex single page applications with Typescript and React/Redux,
+ Help developers, marketers, and product managers understand how to access, implement, and rigorously evaluate and optimise ML-based interventions.
+ You have data analytics skills with Hive, Scalding, or Spark.
+ skill set:
	- understanding of database systems (postgres, Cassandra, CockroachDB)
	- understanding of AWS (S3, SQS, etc), terraform + Kubernetes
	- Golang a must, C++ and Python a nice-to-have
	- CI/CD (Jenkins, docker/containers), GitHub, unix command line tools
	- What you’ll do:
		* add new features to existing services.
		* design and build new services that add customer value
		* improve stability and monitoring of existing workflows
		* work with services running in concert at large scale (tens of billions of documents, trillions of keys, millions of submissions daily, etc)
	- What we are looking for:
		* desire to solve complicated problems in elegant/graceful ways
		* strong work ethic, “self-starter”, endless improvement, never give up
		* easy to work with, good communicator, doesn’t take himself/herself too seriously, able to take feedback.
		* willing to jump into things are figure it out along the way
		* straight up, no-nonsense, no-politics
+ skill set:
	- We are looking for an experienced Data Engineer who thinks in clever ways to solve data problems of scale and load with elegant solutions. Our Data Engineering team supports several clusters of PostgreSQL databases of up to 2+TB each with hundreds of millions of rows, as well as many on prem and cloud data storage systems, such as Aurora, Redis, Redshift, CockroachDB, and Cassandra. As a senior member of this team, you will work closely with our DevOps, QA, Engineering, Business Unit and Project Management Teams to help us bring automation and stability to this architecture.
	- Our team is currently working remotely until our Oakland, CA office re-opens.
	- Key Responsibilities: 
		* Protect, tune, migrate, and administer On-premises and Cloud Datastores
		* Participate in a 24x7 on-call rotations
		* Always perform in a manner that guarantees the Protection, Availability, and Performance of our Global Datastores.
		* Be opinionated enough to speak up when you think we could be doing something better than we're doing it now - and tactful and empathetic enough to communicate this in a way that brings people along instead of distancing them.
	- Qualifications
		* Passion for datastores and a high sense of ownership while performing critical duties based on senior-level experience in Security, Disaster Recovery, and High Availability.
		* Ability to have a strong work ethic in a fast-paced environment with multiple priorities that may occasionally change.
		* Ability to work independently and perform under pressure.
		* Good interpersonal skills, friendly, and approachable.
		* Deep Linux experience.
		* Strong SQL skills.
		* Expert in PostgreSQL tuning and best practices.
		* AWS experience, including Terraform.
		* Bachelor's degree in Computer Science or equivalent experience.
		* Automated monitoring and alerting of On-premises and Cloud data technologies, such as Aurora, Redshift, Redis, CockroachDB, and Cassandra.
		* Kubernetes experience.
		* Working experience with configuration management tools, preferably Puppet and Terraform.
+ skill set for MLOps with Kubeflow:
	- Use Kubeflow (KF) as a coherent platform with end-to-end workflows across all KF services.
		* Kubeflow services:
			+ Notebooks
			+ Pipelines, Kubeflow Pipelines
			+ KFServing
	- Kubeflow components:
		* AutoML (Katib)
		* distributed training
		* HyperParameter Tuning (Katib)
		* Fairing
		* Feast
		* Kale
		* KFServing
		* Notebooks
		* MLMD
		* Seldon
		* TFServing
		* Visualization (Tensorboard)
	- deploy machine learning models into production that would deliver business value
	- steps in data science or applied machine learning workflows:
		* converting tuned models to model serving
		* connecting data pipelines to ML pipelines
		* data preprocessing and transformation
		* distributed training
		* feature engineering
		* hyperparameter tuning
		* notebook experimentation
		* manually building ML pipelines
		* model building
		* model serving
		* monitoring models
		* pipeline building
		* training models
	- checklist for MLOps, and data science or applied machine learning workflows:
		* automation
		* documentation
		* installation
		* portability
		* reproducibility
		* security
		* support
		* tutorials
	- storage classes
		* AWS EBS
		* AWS EFS
		* GCP Persistent Disk
		* Azure Disk
		* IBM
		* Arrikto Rok
		* Gluster
		* EMC
		* NetApp
		* Pure
		* Portworx
		* Rock (Ceph)
	- use Kubeflow tutorials from:
		* AgileStacks
		* AWS
		* Azure
		* Canonical
		* Cisco
		* GCP/Google
		* IBM
		* MiniKF/Arrikto
		* Patterson Consulting
	-IDEs:
		* OptionJupyterLab
		* PyCharm
		* RStudio
		* Virtual Studio Code, VSCode
	- ML frameworks & tools
		* Airflow
		* Caffe
		* Chainer
		* Keras
		* MLflow
		* MPI
		* MXNet
		* PyTorch
		* Tensorflow
		* Scikit-Learn
		* Spark
		* Theano
		* XGBoost
	- Progression of Kubeflow usage:
		* Have Kubeflow working in the lab
		* Have Kubeflow working in production
		* Use a Kubeflow cluster
		* Contributing to Kubeflow
		* Have Kubeflow
+ (applied) machine learning and data science skill set:
	- Google Cloud ML Engine
	- spaCy / Prodigy
	- scikit-learn
	- H2O
	- Amazon SageMaker
	- Azure ML Studio
	- RISELab Ray
	- OpenAI Gym
	- PyTorch
	- Spark NLP
	- BigDL and Analytics Zoo
	- TensorFlow
	- Keras
	- AllenNLP
	- Other cloud-based services
	- Other open source tools
	- AutoML tools/technologies:
		* Google Cloud AutoML
		* Azure AutoML
		* Amazon SageMaker
		* IBM Watson AutoAI
		* DataRobot
		* H2O
	- data versioning:
		* Weights & Biases
		* Pachyderm
		* DVC
		* Homegrown
	- model and experiment tracking:
		* Neptune
		* MLflow
		* Polyaxon
		* Replicate
		* Weights & Biases
		* Kubeflow
		* Comet
		* Homegrown
	- categories of ML tools to incorporate into ML workflows:
		* Automated model search and hyperparameter tuning
		* Model monitoring
		* Support for notebooks
		* Support for IDEs
		* Model visualization
		* Feature store
		* Data lineage or data catalog
	-  bottlenecks holding back further AI adoption:
		* Lack of data or data quality issues
		* Company culture doesn’t yet recognize the needs for AI
		* Lack of skilled people or difficulty hiring the required roles
		* Efficient tuning of hyperparameters
		* Difficulties in identifying appropriate business use cases
		* Legal concerns, risks, or compliance issues
		* Technical infrastructure challenges
		* Workflow reproducibility
	- skills gaps related to machine learning and AI adoption within your organization
		* Understanding and maintaining a set of business use cases
		* Data engineering
		* Compute infrastructure
		* ML modelers and data scientists
+ skill set:
	- ClickHouse columnar databases
	- Spring Boot
+ skill set:
	- You have a deep knowledge of ASR (Automatic Speech Recognition) technologies such as acoustic modeling, language modeling, neural networks, HMM, WFST, and feature extraction
	- You possess hands-on experience in ASR tool kits such as Sphinx, Kaldi, HTK, and Julius
	- You have experience with deep learning frameworks such as Caffe, TensorFlow, Torch, PyTorch, and MxNet
+ Experience with security technologies (SSO, SAML, Okta etc).
+ skill set:
	- C3.ai, Inc. (NYSE:AI) is a leading provider of Enterprise AI software for accelerating digital transformation. C3 AI delivers a family of fully integrated products: C3 AI® Suite, an end-to-end platform for developing, deploying, and operating large-scale AI applications; C3 AI Applications, a portfolio of industry-specific SaaS AI applications; C3 AI CRM, a suite of industry-specific CRM applications designed for AI and machine learning; and C3 AI Ex Machina, a no-code AI solution to apply data science to everyday business problems. The core of the C3 AI offering is an open, model-driven AI architecture that dramatically simplifies data science and application development. Learn more at: www.c3.ai
	- We are looking for a seasoned and motivated Software Engineers to build the next generation AI platform scaling to several petabyte level data volumes.
	- As a member of C3 AI's growing platform team, you will be responsible for the entire software engineering lifecyle, i.e design, document, build, test, maintain. As one of the core teams, this role is integral to the success of the company. A successful candidate will thrive in a fast-paced, highly collaborative environment and demonstrate an ability to execute precisely and quickly. The ideal candidate will have a passion for finding elegant solutions to complex problems.
	- Role Responsibilities:
		* Design and develop various features in the next generation C3 AI PaaS AI suite
		* Design and develop data pipelines that can handle petabyte level data scale and more
		* Develop core fundamental distibuted system components like distributed stream processing engine, distributed queueing, distributed batch processing, cluster management, etc.
		* Design and develop abstraction over existing datastores & cloud infrastructure in an innovative way E.g. Key value stores like cassandra / hbase, sql stores like postgres / mysql, file systems like s3 / azure blob store / hdfs, cloud infrastructure like AWS / Azure / GCP
		* Handle large data infrastructure platform and driving stability through automated monitoring, alerting, and actions.
		* Work closely with software engineering & product management teams to gather requirements and deliver a top quality product following the agile software development methodology
	- Minimum Qualifications
		* BS in Computer Science or related technical field, or equivalent industry experience
		* 2+ years of relevant experience 
		* Strong communication and interpersonal skills
		* Systematic problem-solving approach coupled with a strong sense of ownership and independence
		* Strong understanding of Computer Science fundamentals ( Algorithms, Data Structures)
		* Must be proficient in expert level programing in Java or Javascript or Python.
		* Experience with Aws / Azure / GCP Cloud Platform
		* Skilled in robust, highly available large-scale, distributed SaaS systems.
		* Familiarity with Big Data systems like Apache Spark / Hadoop / Distributed Systems
		* Experience with security technologies (SSO, SAML, Okta etc).
		* Proactive work ethic - self starter
	- Preferred Qualifications
		* Experience with modern container orchestration systems: e.g. Kubernetes, Mesos, DC/OS, Swarm
		* Experience with building scalable and reliable data pipelines
		* Experience with integration of data from multiple data sources
+ skill set:
	- As a Software Engineer on the CI/CD team, you will own the build/release pipeline operation of our production, staging and development systems. You will own and develop our CI/CD tooling and infrastructure, including high-compliance services on AWS/Azure, and help us roll out new services using Kubernetes on AWS/Azure or on-premise. You will lead the way in building tooling and automation to close the feedback gaps in the CI/CD pipeline, develop new integrations with third-party services and monitor the health of our build/deploy infrastructure. You will be responsible for the performance of our test suite and will be instrumental in creating a comfortable development environment for a growing team of software engineers. You will work in close cooperation with the Cloud team to achieve these goals. You will also get the opportunity to learn the fundamentals of distributed computing. You will get to work with infrastructure that handles massive amount of scale running tens of millions of tests per day across thousands of machines.
	- Requirements:
		* Bachelor’s degree in Computer Science, Electrical Engineering, or related field.
		* Software Engineer passionate about infrastructure and scale.
		* 3+ years of experience in a DevOps/SRE/Build-Release role, preferably using Kubernetes and Jenkins.
		* Experience with CI/CD principles, architecture and operations.
		* Experience setting up and working with Jenkins in a containerized environment.
		* Experience with Docker and container orchestration tools like Kubernetes, AWS ECS/EKS and (Azure) AKS.
		* Proficiency with a scripting language to develop integrations (Python, Javascript, Groovy).
		* Rigor in high code quality, automated testing, and other engineering best practices.
		* Thrive in a fast-paced, dynamic environment and value end-to-end ownership of projects.
		* Intellectually curious and open to challenges.
	- Preferred
		* Advanced degree in engineering, sciences or related field.
		* 2+ years of experience working with distributed systems.
		* 2+ years of experience with using and developing technologies like Cassandra, PostgreSQL, RedShift, DynamoDb, Elastic Beanstalk, Docker, and Amazon EMR.
		* Strong experience with Python, Bash, Jscript and automation tools such as Chef, Puppet, Ansible, etc.
		* Strong experience with container orchestration technologies such as Kubernetes, Docker Swarm, Mesos.
		* Proficiency in Linux administration, configuration, and automation tools.
		* Working knowledge of public Cloud platforms (AWS, Azure, Google Cloud Platform).
		* Knowledge of performance benchmarking and diagnostic tools.
		* Solid understanding and usage of observability solutions such as cAdvisor, Prometheus, Dynatrace, Splunk etc.
		* Experience with Java, Scala.
+ skill set:
	- Your Responsibilities:
		* Design and develop the core authentication and authorization system components of the C3 AI Suite
		* Research and apply identity and certificate management solutions to secure a distributed system deployed on Kubernetes (K8s)
		* Ensure that our core foundational system components including distributed stream processing engine, distributed queuing, distributed batch processing and cluster management are secure
		* Enable customers, partners and system integrators to securely integrate our platform into their infrastructure
		* Shrink the overall attack surface and keep it minimal throughout continuous integration and delivery
		* Work closely with our information security and operations teams to investigate and mitigate threats
	- Requirements:
		* Bachelor’s degree in Computer Science, Electrical Engineering, or related field.
		* 2+ years of relevant experience
		* Strong communication and interpersonal skills
		* Systematic problem-solving approach coupled with a strong sense of ownership and independence
		* Strong understanding of Computer Science fundamentals
		* Experience with security in Kubernetes (K8s) and the concept of a service mesh (Istio)
		* Proficiency with Java Cryptography infrastructure
		* Expert knowledge of SAML and OAuth authentication / authorization protocols
		* Proficiency in networking protocols, naming services and network trust
		* Demonstrated understanding of TLS certificate management
		* Demonstrated understanding of http protocol security (CORS, XSRF, etc.)
	- Preferred:
		* Master’s degree in Computer Science, Electrical Engineering, or related field.
		* Proficient in Python and JavaScript
+ skill set:
	- We are looking for a seasoned software engineer to build the next generation AI platform scaling to petabyte level data volumes.
	- As a member of C3.AI's platform engineering team, you will be responsible for the entire software engineering lifecyle, i.e design, document, build, test, maintain. As one of the core teams, this role is integral to the success of the company. A successful candidate will thrive in a fast-paced, highly collaborative environment and demonstrate an ability to execute precisely and quickly. The ideal candidate will have in-depth experience with Data Science workflows and built scalable machine learning systems.
		* Build systems and tools that enable data scientists to create machine learning applications using the C3 AI Platform.
		* Enable scalable, end-to-end machine learning pipelines in a distributed system.
		* Work with other platform engineering teams to enable streaming, batch, or ad-hoc data analysis.
		* Collaborate with and support data scientists to understand the utility of the C3.ai Platform and define new requirements.
		* Define and lead the development of longer-term C3 AI Platform capabilities.
		* Mentor junior members of the team.
	- Requirements:
		* Advanced degree in computer science, math, or similar field.
		* Excellent programming and algorithmic skills and a taste for DRY code.
		* In-depth understanding of supervised and unsupervised machine learning algorithms.
		* Proven track record of applying learning algorithms in a production system.
		* Strong programming skills in Java, Python and JavaScript.
		* Demonstrated end-to-end ownership of projects.
		* Stellar listening and explanation skills.
		* Thorough knowledge of data structures, algorithms, profiling/optimization, and Object-Oriented and Functional Programming.
		* A minimum of 3 years of work experience in a fast-paced software company.
+ skill set:
	- As a Data Scientist, you will participate in the definition of new analytics capabilities able to provide our customers with the information they need to make proper decisions to support our customers in operating the internet of things (IoT). In addition, you will help find the appropriate machine learning / data mining algorithms to answer these questions. Finally, you will be responsible for implementing this into the product and making it available to our customers.
		* Qualified candidates will have an in-depth knowledge of most common machine learning techniques and their application. You will also understand the limitations of these algorithms and how to tweak them or derive from them to achieve similar results at large-scale.
	- Your Responsibilities:
		* Driving adoption of Deep Learning systems into next-generation of C3 AI products.
		* Designing and deploying Machine Learning algorithms for industrial applications such as fraud detection and predictive maintenance.
		* Collaborating with data and subject matter experts from C3 AI and its customer teams to seek, understand, validate, interpret, and correctly use new data elements.
	- Requirements:
		* MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields.
		* Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning). 
		* Strong mathematical background (linear algebra, calculus, probability and statistics).
		* Experience with scalable ML (MapReduce, streaming).
		* Ability to drive a project and work both independently and in a team.
		* Smart, motivated, can do attitude, and seeks to make a difference.
		* Excellent verbal and written communication.
	- Preferred
		* Experience with JavaScript and prototyping languages such as Python and R. Experience with Java and Scala is a plus.
		* Knowledge in electrical engineering and cyber-physical systems is a plus.
		* A portfolio of projects (GitHub, papers, etc.) is a plus.
+ Strong understanding of machine learning algorithms & principles (regression analysis, time series, probabilistic models, supervised classification and unsupervised learning), and their application
+ skill set:
	- worked within standard GitOps workflow
		* branch and merge
		* pull requests or PRs
		* CI/CD systems
	- DevOps via CI/CD and Docker+K8S
	- scalable data pipelines
	- infrastructure configuration
		* IaC, such as Terraform
		* cluster parameter tuning
		* service parameter tuning
	- data discovery tooling
		* Amundsen
		* Atlas
	- determine optimal caching strategies and eviction policies
	- approximation algorithms for high-use statistics of interest, such as approximate nearest neighbor
	- determine approximate relaxations to deterministic compute where appropriate and leverage probabilistics data structures, such as bloom filters and count min sketch
+ data science modeling frameworks
	- statsmodels
	- scikit-learn
	- XGBoost
+ personalized data pipelines/models using tools like:
	- Hive
	- Airflow
	- Kafka
	- Spark
+ architect highly scalable microservices
+ skill set:
	- architect systems that deliver low latency experience in a high latency environment
	- develop long-lasting external API contracts with little obsoletion/obsolescence or sunsetting.
+ skill set:
	- strong programming skills in C++ with experience in developing latency-critical software
	- demonstrated ability to take neural network models from concept to production with in-depth knowledge in deep learning frameworks, such as TensorFlow
+ skill set:
	- management of E2E (enterprise-to-enterprise) ML pipeline development and automation, to enable developers and creators alike to have the ability to go from an ML idea to production in weeks of less
	- ML ecosystem tooling
	- As a Machine Learning Platform Engineer you will build the next generation of ML Ecosystem Tooling. You will have a direct impact to the state of the Roblox platform, and the industry, to the next level of managed E2E ML Pipeline Development and Automation—providing our developers and creators alike the ability to go from an ML idea to production in weeks or less. We are looking for talented ML and Systems Engineers to help build the next generation of ML Ecosystem Tooling. 
	- Passionate about pushing the technological envelope and venturing into the unknown.
	- Possessing a toolchest of system design experience upon which to draw to build scalable, reliable platforms for all of Roblox.
	- 3+ years of professional experience working with scalable, distributed systems.
	- Well versed with the Model Development Lifecycle from initial ad hoc analysis in notebooks to monitored services in production and back again.
	- Proficient with DevOps tooling such as Docker, K8S, CI/CD systems.
	- Strong understanding of best practices in developing Platform / Infrastructure APIs.
	- Someone who has built a model in a modern ML framework such as Tensoflow, PyTorch, ML Lib, etc.
	- Experienced with developing data pipelines in a common framework such as Beam / Spark / AirFlow / etc.
	- Understand best practices around Data and Model management
	- Have deployed and maintained an ML model in production
	- Understand the use cases for various data processing and storage technologies
	- Bachelor's degree in Computer Science, Computer Engineering, Data Science or a similar technical field.
	- Design and Implement the Developer and Creator facing API for declaring E2E ML Pipelines and Model Experimentation.
	- Develop the service APIs for various ML Infrastructure components--Serving Layer, Metadata Store, Model Registry, Feature Store, and Pipeline Orchestrator.
	- Work directly with the ML Infrastructure team to identify and leverage opportunities for further automation and optimization.
	- Partner across organizations to build tooling, interfaces, and visualizations that make the ML@Roblox a delight to use.
	- Have a direct impact to the state of the Roblox platform, and the industry, to the next level of managed E2E ML Pipeline Development and Automation
	- Provide our developers and creators alike the ability to go from an ML idea to production in weeks or less. 
	- Have a direct impact as a part of the team that is building a platform to handle the thousands of model experiments per day needed to support everything from ranking and recommendations, through content moderation and fraud prevention, to studio creative tooling.
+ experience working with common cloud technologies, such as:
	- Hashistack (Nomda, Terraform, Vault, etc)
	- Kubernetes
	- Docker
	- AWS
	- Azure 
+ skill set:
	- As a Senior Backend Web Engineer working on the Monetization team, you will be responsible for all things virtual economy at Roblox, from purchasing and selling virtual items to the real time bidding of advertising slots. The Monetization team maintains a virtual marketplace that handles over 4 million transactions a day. The team provides the infrastructure and statistics to empower developers to monetize their games, with our top developers earning millions of dollars each year.
	- Experienced with a Bachelor’s degree (or equivalent professional experience) in Computer Science or related engineering field with at least 5 years of hands-on experience.
	- A Solid programmer with demonstrable skills with compiled languages such as C#, Java, C++, or others.
	- Proven at scale: you’ve designed and implemented large-scale distributed microservices architectures and have experience with Memcached, Redis, or other caching technologies.
	- Proficient with Microsoft SQL Server, MySQL, PostgreSQL or other database technology at scale.
	- ***Practiced with noSQL technologies such as DynamoDB, MongoDB or others.***
	- ***Knowledgeable about search technologies such as Elasticsearch or Solr.***
	- ***Focused on writing clear, readable, testable, and monitored code.***
	- Have a direct impact on the future direction of the largest social platform for play, delivering groundbreaking solutions that will enable our development teams to localize Roblox for a global community of over 60 million monthly active players.
	- Develop services by which our community of creators on the platform can internationalize their games, whether manually, crowdsourced, or automatically via machine translation.
	- Build core internationalization and localization tools and infrastructure, which will be used by all engineering teams within Roblox.
	- Design and build backend services to handle real-time machine translation of user communication.
	- Serve as a tech lead for the team and mentor junior engineers.
	- Play an active role in recruiting future talent for the team.
+ skill set:
	- design and implement efficient ranking algorithm at high throughput and scalable search engine
	- analyze search and document data using SQL and Hive on Spark, S3, and ElasticSearch
	- understanding and experience for query expansion and rewrite techniques such as synonyms, auto complete, speel correction, query optimization, and query-to-query similarity
	- understanding of search ranking quality evaluation and experience with metric-driven search ranking tuning techniques
	- understanding of knowledge graphs for document understanding and ranking
		* experience with graph DB, such as Neo4j, ArangoDB, OrientDB
	- experienced working in a fast-paced environment in an agile/scrum environment with focus on robust design, architecture, TDD, rapid experimentation, A/B testing, and metrics
	- big data frameworks, such as map-reduce, Spark, Pig, Hive
+ experienced with Memcached and Redis
+ domain-driven design, and service-oriented architecture
+ App Engine cloud computing platform
+ apply diverse tools and technologies to solve existing problems, such as: C\#, Go, Rust, Docker, Hashistack's Consul, Vault, and Nomad.
+ skill set:
	- extensive experience in deep learning, classifiers, clustering algorithms, and anomaly detection
	- highly scalable security tools for exploit and bot detection
	- ML security projects
	- large-scale ML systems
+ GraphQL, Docker, Hashistack, Traefik, HUbot, InfluxDB
+ GPU APIs: OpenGL, DirectX, ...
+ skill set:
	- Familiarity with at least one of the following areas:
		* Deep learning for computer vision
		* Camera tracking (SLAM, VIO) and self-localization
		* Object detection and model-based tracking
		* 3D reconstruction and semantic scene understanding
+ skill set:
	- You will play a meaningful role in one of our agile teams - designing, building, deploying and maintaining the team's deliverables with respect to the full lifecycle of our new data analytics offerings. You will work closely in with other teams in their related journeys.
	- As an experienced engineer you will help to drive continuous improvement in practices and improve the team’s ability to take on bigger challenges.
	- You will gain exposure to a wide range of our software modules and the technologies backing them, e.g. cloud, microservices, database, data lakes, cloud warehouses, pipelines. Key technologies we currently use include: AWS, Kubernetes, Kafka, Snowflake, Java, Terraform, React, MongoDB, Oracle
	- What we’re looking for in you
		* Passion for writing and maintaining high-quality software
		* An understanding of how to build and support large scale distributed systems and handle issues that arise
		* Strong skills in data acquisition, pipeline and data storage/lake technologies
		* Cloud experience (we use AWS and Kubernetes)
		* Experience with at least two programming languages, e.g. Python, Scala, Java
	- The following would be beneficial:
		* Experience with DevOps and Infrastructure as code (e.g. Terraform)
		* Experience using lean and agile practices in a regulated environment
		* Experience with Tableau or similar BI tools such as PowerBI
		* Experience with Spark, Airflow or similar
	- What you’ll get in return
		* Working in a multi-functional, team-based environment, our culture is enabling and engaging
		* You’ll be exposed to a range of technologies with the opportunity to expand your experience and expertise
		* IDBS has the camaraderie of a small company, but the security of a global employer, we offer flexible career paths, exciting work, and the opportunity to both learn from others and share your experiences.
+ skill set:
	- What You’ll Be Doing:
		* Design,  implement  and deploy Automatic Speech Recognition (ASR) models to provide the best-possible experience for our customers in Zoom’s online meeting. 
		* Handle large-scale audio data to make ASR model best fit the online conference use case.
		* Adapt machine learning and neural network algorithms and architectures to best fit the real-time requirement
		* Partner closely with talented peers to research ASR and contribute to our long-term research efforts.
	- Qualifications: 
		* MS degree in EE, CS or related technical field or equivalent practical experience  or Mathematics with specialization in speech recognition, natural language processing, or machine learning.
		* 5+ years experience in building speech recognition, ASR or NLP (natural language processing) systems
		* Familiar with commonly used  deep learning and machine learning models like DNN-HMM, RNN-Transducer and Attention-based end to end models.
		* Familiar with one or more ASR toolkits (e.g. Kaldi, HTK,  Pykaldi, Tensorflow, CNTK)
		* Ability to run experiments scientifically and analyze results.
	- Bonus Qualifications:
		* Ph.D. degree in EE, CS or related technical field
		* Solid Machine Learning background and familiar with standard speech and machine learning techniques.
		* Scientific thinking and the ability to invent, a track record of thought leadership and contributions that have advanced the field.
		* Solid software development experience.
		* Strong publication record in top tier conferences such as ICASSP, INTERSPEECH, TASLP, etc.
+ skill set:
	- Zoomies help the world connect — and deliver happiness while doing it. We set out to build the best video conferencing product for the enterprise, and today help people communicate better with products like Zoom Phone, Zoom Rooms, Zoom Video Webinars, Zoom Apps, and OnZoom.
	- Our Data Science teams lie at the foundation of Zoom’s success. As a Data Science, Intern on the Customer Success team, you will play an important role in driving the growth of Zoom by surfacing, analyzing, and reporting on data that drives mission-critical business decisions. 
	- This paid internship is for a duration of approximately 10 - 12 weeks during the spring of 2021. The program offers cutting edge projects, as well as a mix of additional types of learning in areas of leadership and business acumen-- and is packed full of fun!
	- Responsibilities:
		* Assist with building and maintaining Zoom product features and services. 
		* Build, deploy and upgrade our real time compute infrastructure.
		* Design and implement features to improve our systems. 
		* Connect with customers to understand their goals and needs and translate those into solutions our team can deliver.
		* Configure tooling for systems scalability, ensure we have capacity for future growth.
		* Ensure our systems are continuously monitored and running efficiently with a consistent, unified experience across products, platforms, and devices.
		* Test current algorithms and write testing documents.
		* Collaborate with internal stakeholders across the business to drive the delivery of features, processes and happiness.
	- Requirements:
		* At least 18 years old, currently enrolled in a four year academic institution completing an undergrad, grad, or PhD degree in Business/Economics, Human-Computer Interaction, Computer Science or a related STEM field.
		* Legally authorized to work in the United States. Due to the limited duration of this program, sponsorship for employment visa status is not available for this position.
		* Availability to complete the full 10-12-week internship program during Spring 2021, with a time commitment of approximately 30-40 hours per week.
		* Must be highly proficient in SQL and Microsoft Excel
		* Minimum 4+ years of experience using data to facilitate decisions  
		* Strong understanding of growth principles, product development, and product go to market processes 
		* Self-starter, ability to envision solutions and take initiative to see the solution to the end despite challenges. 
		* Ability to crystallize vague concepts into concise plans with clear documentation and data driven decision making .
		* Detail oriented, organized, ethical, responsible, and self-motivated.
		* Team player, ability to work effectively in a matrix organization.
		* Consumer facing experience
		* Strong communication and problem solving skills and a desire to learn something new.
		* A passion for creating products that resonate emotionally with people.
		* A passion for Zoom’s mission, vision, values, and culture.  
+ skill set:
	- RDS Postgres, Snowflake, Airflow, AWS DMS, Spark on EMR, Python
	- data pipeline and workflow management tools:
		* Airflow
		* Luigi
	- Big Data tools:
		* Haddop
		* Hive
		* Spark
	- AWS cloud services:
		* EC2
		* EMR
		* RDS
		* Redshift
		* S3
	- Programming languages:
		* Python
		* Java
		* Scala
	- Linux
	- working knowledge of message queueing, stream processing, and highky-scalable Big Data stores.
	- expand and optimize data pipline architecture, and data flow and collection for cross functional teams
		* automating manual processes
		* ETL
		* re-designing infrastructure for greater scalability
		* improving relaiability & accuracy
	- support software initiatives tpo ensure optimal delivery architecture is consistent throughout ongoing projects
	- using appropriate tools to analyze the data pipeline and provide actional insights into operational efficiency, data accuracy, and other KPIs.
	- working knowledge of:
		* workload management
		* message queueing
		* stream processing
		* highly scalable big data stores
+ skill set:
	- support existing scientific workflows
	- set the vision for future data generation and collection efforts
		* Or, set data engineering vision
	- design, build, and maintain databases and data warehouses that underpin our scientific endeavors and accelerate the company's ability to ask new, sophisticated questions spanning multiple organisms, data modalities, and timescales.
	- understand common uses cases and data access needs
	- design strategies for data storage and integration across different data sources for multiple use cases
	- implement, document, and maintain processing pipelines, databases, and data warehouse and data lake infrastructure
	- build out core infrastructure, tooling, and software development processes
	- ETL tools and frameworks
		* Airflow
		* Luigi
	- Python data ecosystem
		* NumPy
		* pandas
		* Jupyter
	- SQL and relational database systems, such as:
		* PostgreSQL
		* MySQL
		* RESTFUL APIs
	- experience implementing RESTful APIs, GraphQL, and other programmatic interfaces to complex multi-dimensional data
	- experience deploying flexible and high-performance data backends and interfaces in the cloud with Google Cloud Platform, Amazon Web Services, or similar platforms
	- built backends for high-dimensional graph or network data
	- designed or worked with auditable data systems suitable for regulatory review
	- experience working with diverse and cutting-edge datasets:
		* RNASeq
		* metabolomics
		* high-content imaging
	- experience with on-prem high-performance computing clusters, such as SLURM
+ process structured and unstructured data
+ skill set:
	- experience using Web services, such as:
		* WCF
		* Spark
		* Rest
	- experience using a statistical process control system, such as Camline SPACE.
	- experience in Hadoop, Spark, and Impala for large-scale data manipulations.
	- software source code repository tools:
		* Git
		* Subversion
		* Azure DevOps Server, formerly known as MS TFS or Microsoft Team Foundation Server
	- VoC, voice of customer software tools
+ skill set:
	- As part of this initiative, we are looking for a Data Engineer and help us build a scalable petabyte scale data lake and Enterprise Data Warehouse (EDW) using modern tech stack from the ground up using open source technologies. Success in this role comes from marrying a strong data engineering background with product and business acumen to deliver scalable data pipelines and analytics solutions that can enable advanced analytics via a self-service user interface.
	- Experience building and supporting modern data lake and EDW technologies (Hadoop, Spark, Cloud, NoSQL etc.) and workflow technologies (eg. Airflow)
	- Solid understanding of Google Cloud Platform, Python, Hive, and Kafka
	- Experience with Tableau, Google Analytics and BigQuery (or any other Big data/Cloud equivalent) etc.
	- Experience working with and processing structured, unstructured, and semi-structured data
	- Experience building data systems at scale
+ skill set:
	- 3+ years of data scientist experience with proven industry experience in a large scale environment (PBs scale & globally distributed teams).
	- 2+ years experience with a fast-growing SaaS business based company is preferred.
	- Strong experience in scientific computing using Python, R, or Scala.
	- Experience with Spark, SQL, Tableau, Google Analytics, Hive and BigQuery (or any other Big data/Cloud equivalent) etc.
+ skill set:
	- Strong experience in scientific computing using Python, R, or Scala
	- Experience with Spark, SQL, Tableau, Google Analytics, Hive and BigQuery (or any other Big data/Cloud equivalent) etc.
	- Experience working with and processing structured, unstructured, and semi-structured data
	- Experience building data systems at scale
	- 5+ years of engineering experience with proven industry experience in big data engineering
	- 2+ years experience with a fast-growing SaaS business based company is preferred
	- Experience building big data systems required, experience building Machine Learning pipelines is a strong plus
+ skill set:
	- From https://meta.stackoverflow.com/questions/407253/review-our-languages-and-platforms-for-dev-survey-2021
	- Referene:
		* Stephanie, Ivar, Julien, bad_coder, Yatin Aditya Tekumalla, "Review our languages and platforms for Dev Survey 2021," Stack Exchange Inc., New York, NY, May 1, 2021. Available online from Stack Exchange Inc.: Stack Overflow: Questions at: https://meta.stackoverflow.com/q/407253/1531728 and https://meta.stackoverflow.com/questions/407253/review-our-languages-and-platforms-for-dev-survey-2021; May 4, 2021 was the last accessed date.
	- Programming, scripting, and markup language:
		* Assembly
		* Bash/Shell/PowerShell
		* C
		* C#
		* C++
		* Dart
		* Go
		* Haskell
		* HTML/CSS
		* Java
		* JavaScript
		* Julia
		* Kotlin
		* Objective-C
		* Perl
		* PHP
		* Python
		* R
		* Ruby
		* Rust
		* Scala
		* SQL
		* Swift
		* TypeScript
		* VBA
	- Database environments:
		* Cassandra
		* Couchbase
		* DynamoDB
		* Elasticsearch
		* Firebase
		* IBM DB2
		* MariaDB
		* Microsoft SQL Server
		* MongoDB
		* MySQL
		* Oracle
		* PostgreSQL
		* Redis
		* SQLite
	- Cloud Platforms:
		* AWS
		* DigitalOcean
		* Google Cloud Platform
		* Heroku
		* IBM Cloud or Watson
		* Microsoft Azure
		* Oracle Cloud Infrastructure
	- Web framework/libraries:
		* Angular
		* Angular.js
		* ASP.NET
		* ASP.NET Core
		* Django
		* Drupal
		* Express
		* Flask
		* Gatsby
		* jQuery
		* Laravel
		* React.js
		* Ruby on Rails
		* Spring
		* Symfony
		* Vue.js
	- Other frameworks, libraries:
		* .NET
		* .NET Core
		* Apache Spark
		* Cordova
		* Flutter
		* Hadoop
		* Keras
		* Pandas
		* React Native
		* TensorFlow
		* Torch/PyTorch
	- Tools:
		* Ansible
		* Chef
		* Puppet
		* Node.js
		* Terraform
		* Kubernetes
		* Docker
		* Unity 3D
		* Unity Engine
		* Xamarin
	- Development environments:
		* Visual Studio Code
		* Visual Studio
		* Notepad++
		* IntelliJ
		* Vim
		* Sublime Text
		* Android Studio
		* Eclipse
		* PyCharm
		* Atom
		* IPython/Jupyter
		* Xcode
		* PHPStorm
		* NetBeans
		* Emacs
		* RStudio
		* RubyMine
		* TextMate
	- Primary operating systems:
		* Linux-based
		* Windows
		* MacOS
		* BSD



