+ skill set:
	- TensorFlow, SpaCy, Scikit-Learn
	- cloud-based AI/ML services
		* Microsoft Azure Cognitive Services
		* Google Cloud
		* IBM Watson
	- Python, Django, and/or Flask
	- Linux
+ skill set:
	- SpaCy, NLTK, and comparable libraries
	- Python, Django, and/or Flask
	- Linux and/or working with cloud services with AWS, Azure, etc..
	- GitHub and Docker
+ workflow for embedded computer vision product development:
	- dataset sourcing
	- dataset curation
	- dataset annotation
	- algorithm design
	- algorithm implementation and optimization
	- identifying the right hardware platform for the embedded computer vision system
	- hardware design
	- software integration
	- product testing and validation
+ skill set:
	- data pipeline and workflow management teams:
		* Airflow
		* Luigi
	- Big Data tools:
		* Hadoop
		* Hive
		* Spark
	- AWS Cloud services:
		* EC2
		* EMR
		* RDS
		* Redshift
		* S3
	- languages:
		* Python
		* Java
		* Scala
	- Linux
	- expanding and optimizing data pipeline architecture, data flow and collection for cross-functional teams
		* ETL
		* re-designing infrastructure to improve scalability, reliability, and accuracy 
	- ensure optimal delivery architecture by supporting software engineering initiatives
	- use appropriate tools to analyze data pipeline, and provide actionable insights into operational efficiency, data accuracy, and other KPIs
	- experience with:
		* relational databases
		* data warehoouses
		* big data platforms
	- perform root cause analysis on external and internal data and processes to answer specific business questions and identify opportunities for improvement
	- improve processes to support data transformation, data structures, metadata, dependency, and workload management
	- working knowledge of:
		*  message queueing
		* stream processing
		* highly scalable big data stores
+ skill set:
	- Agile workflow practices and familiarity with Atlassian tools
		* Jira
		* Confluence
	- statistical methods
		* exploratory data analysis
		* hypothesis testing
		* regression techniques
	- techniques and best practices for data visualization
		* visualization libraries:
			+ Altair
			+ seaborn
			+ matplotlib
			+ Tableau
			+ ggplot2/shiny
		* storytelling with data, to support data-driven decisions using compelling visualizations
	- analytical toolkit
		* Python
		* pandas
		* R
	- SQL, JSON, and unstructured data
	- Amazon Web Services ecosystem
+ skill set:
	- project management skills to:
		* manage complexity
		* make informed trade-offs to quickly escape rabbit holes and make on-time deliveries
	- Agile workflow practices and familiarity with Atlassian tools
		* Jira
		* Confluence
	- statistical methods
		* exploratory data analysis
		* hypothesis testing
		* regression techniques
		* power analysis
		* generalized linear models
		* time series
		* survival analysis
	- machine learning techniques
		* supervised learning
		* unsupervised learning
		* general machine learning workflow
		* linear regression
		* logistic regression
		* decision trees
		* neural networks
		* clustering
	- techniques and best practices for data visualization
		* visualization libraries:
			+ Altair
			+ seaborn
			+ matplotlib
			+ Tableau
			+ ggplot2/shiny
		* storytelling with data, to support data-driven decisions using compelling visualizations
	- analytical toolkit
		* Python
		* pandas
		* scikit-learn
		* R
	- database management:
		* SQL
		* JSON
		* unstructured data
		* NoSQL data environments and tools:
			+ Hadoop
			+ Spark
			+ DynamoDB
	- Amazon Web Services ecosystem
	- software development practices:
		* story estimation
		* test-driven development
		* code review
		* version control with Git
+ skill set for Platform Software Engineer (BMC):
	- At Graphcore, we're optimistic for a future where people live healthier, more informed, more creative lives. Our team is at the forefront of the artificial intelligence revolution, enabling innovators from all industries and sectors to expand human potential with technology. We believe our IPU technology will become the worldwide standard for artificial intelligence, transforming whole industries and sectors whether you are a medical researcher, roboticist or building autonomous cars.
	- As a Platform Software Engineer, you will be working in the engineering team in Oslo developing the Graphcore M2000 platform with scale out technology for our Intelligence Processing Unit (IPU). You will work closely with our hardware and software engineering teams to develop the platform software that our other engineering teams depends on for the final product definition.
	- Your responsibilities:
		* Define and develop our generic platform applications
		* Configure operating system kernels and set up full distribution images
		* Bring up new systems in the lab together with the FPGA and Hardware teams
		* Board environmental monitoring, cooling/power regulation and fault handling  
	- What you will bring:
		* Proven experience in embedded Linux
		* Experience with yocto based projects, bitbake, systemd, OpenBMC
		* Experience with shell scripting, Python, C and understanding of C++
		* Experience in Linux kernel and system configuration, package management
		* Knowledge of low level peripheral interconnects, such as I2C, UART, SPI, PWM
		* Knowledge of Ethernet and IP networking standards
		* Demonstrable knowledge of computer security and authentication schemes
	- Good to have:
		* Knowledge of high availability (HA) systems, management
		* Familiarity of ILOM, BMC, IPMI, Redfish and OCP (Open Compute)
		* Familiarity with DMTF standards, Redfish and Server products
		* Experience in working with open source projects.
		* Experience in hands-on lab and bring-up activities, as well as knowledge of design for product and manufacturing
		* You like to work in a fast-paced environment using agile methods
+ skill set for Research Engineer
	- Responsibilities:
		* Perform and publish cutting-edge research in machine intelligence, with special focus on fundamental algorithms and applications for computer vision, language modelling, numerical formats and graph neural networks.
		* Exploit Graphcore’s hardware to develop and deliver models of unprecedented scale and performance.
		* Collaborate with both the research team and other groups within the company, to develop new ideas, identify research opportunities and provide machine learning expertise.
		* Follow the latest developments in the field by attending/presenting at journal clubs and travelling to relevant conferences.
		* Promote the IPU by developing and maintaining collaborations with external institutions and research labs.
	- Essential:
		* MSc or PhD in Machine Learning, Computer Science, Electrical Engineering, Physics, Mathematics or a related field.
		* In-depth understanding of modern machine learning algorithms, deep learning architectures and probability theory.
		* Experience using modern machine learning frameworks (e.g., TensorFlow, PyTorch, JAX).
		* Proficiency in Python and/or C++.
		* Strong communication skills and willingness to work in a collaborative environment.
	- Desirable:
		* Publications at top conference venues (e.g., NeurIPS, ICLR, ICML).
		* Contributions to open-source software projects in the area of machine intelligence.
		* Experience in using or designing low-precision numerical formats.
		* Kaggle competitions or other evidence of practical expertise.
+ skill set for Research Scientist:
	- Responsibilities:
		* Perform and publish cutting-edge research in machine intelligence, with special focus on fundamental algorithms and applications for computer vision, language modelling, numerical formats and graph neural networks.
		* Exploit Graphcore’s hardware to develop and deliver models of unprecedented scale and performance.
		* Collaborate with both the research team and other groups within the company, to develop new ideas, identify research opportunities and provide machine learning expertise.
		* Follow the latest developments in the field by attending/presenting at journal clubs and travelling to relevant conferences.
		* Promote the IPU by developing and maintaining collaborations with external institutions and research labs.
	- Essential:
		* MSc or PhD in Machine Learning, Computer Science, Electrical Engineering, Physics, Mathematics or a related field.
		* In-depth understanding of modern machine learning algorithms, deep learning architectures and probability theory.
		* Experience using modern machine learning frameworks (e.g., TensorFlow, PyTorch, JAX).
		* Proficiency in Python and/or C++.
		* Strong communication skills and willingness to work in a collaborative environment.
	- Desirable:
		* Publications at top conference venues (e.g., NeurIPS, ICLR, ICML).
		* Contributions to open-source software projects in the area of machine intelligence.
		* Experience in using or designing low-precision numerical formats.
		* Kaggle competitions or other evidence of practical expertise.
+ skill set:
	- Android
	- Zephyr
	- Linux
	- Renode
	- RISC-V
	- TensorFlow
	- Caffe
	- OpenCV
	- Singularity
	- KiCad
	- Docker
	- ROS
+ skill set:
	- continuous integration/delivery (CI/CD) methodologies and practices
	- develop open-source, scalable simulation and virtualization environments
	- contribute to open-source frameworks
	- design cloud infrastructure
	- distributed CI/CD constructions
	- cloud engineering:
		* virtualization
		* scalability
		* load balancing
		* failovers
		* distributed computing power
		* cloud deployments
		* monitoring
		* log processing
	- orchestration tools
+ skill set:
	- knowledge of:
		* AXI
		* AHB
		* APB
		* Wishbone
	- knowledge of comunication interfaces:
		* UART
		* I2C
		* SPI
		* TileLink
	- knowledge of fast comunication interfaces:
		* PCI
		* PCIe / PCI Expresss
		* USB
		* ChipLink
	- SoC FPGA:
		* Xilinx Zynq
		* Xilinx UltraScale+ MPSoC
		* Intel SoC FPGA
		* Microsemi SmartFusion
+ skill set:
	- develop edge AI tooling ecosystem
	- design deep learning-capable data processing devices
	- experience working with the following:
		* open-source machine learning framework TensorFlow
		* Caffe
		* neural network architectures
		* CUDA
		* OpenCL
		* OpenCV
	- design AI system architectures:
		* deep neural networks
		* machine learning algorithms
		* computer vision
			+ video processing
			+ object detection
			+ object tracking
		* speech recognition
		* text analysis
	- tasks include:
		* implementing, training, and testing AI algorithms with 3-D game engines, and optimizing them for given hardware
		* develop and improve a range of AI-oriented tools and frameworks
		* work with Linux and other open-source operating systems
		* automate workflow for validation vi auatomted testing/verification and continuous integration (CI) scripts
+ skill set for data engineering:
	- work with Scala-based core science and data platform
	- consumer-facing product layer in java and React
	- AWS-deployed software, using CI/CD with Kubernetes.
	- build, optimize, test, and improve REST and gRPC services
	- weight technical trade-offs and collaborate with coworkers to reach consensus about balancing practical necessities and ideological concerns
	- functional programming languages:
		* Scala
		* Haskell
		* Erlang
	- cloud computing tools
		* AWS
		* Docker
		* Kubernetes
		* Terraform
	- database systems:
		* schema design
		* query optimization
		* database tuning
		* migration tools
+ skill set:
	- experience with multi-imaging modalities
		* RGBN
		* multi-/hyper- spectral
		* thermal
		* LiDAR
		* radar
	- experience delveoping algorithms and methods for object detection, classification, and characterization
	





















































+ AI compiler design
	- Poplar framework for IPU architecture compiler.
+ AI compilers:
	- MLIR
	- TVM
	- Glow

