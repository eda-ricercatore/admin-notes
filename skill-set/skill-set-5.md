+ skill set:
	- TensorFlow, SpaCy, Scikit-Learn
	- cloud-based AI/ML services
		* Microsoft Azure Cognitive Services
		* Google Cloud
		* IBM Watson
	- Python, Django, and/or Flask
	- Linux
+ skill set:
	- SpaCy, NLTK, and comparable libraries
	- Python, Django, and/or Flask
	- Linux and/or working with cloud services with AWS, Azure, etc..
	- GitHub and Docker
+ workflow for embedded computer vision product development:
	- dataset sourcing
	- dataset curation
	- dataset annotation
	- algorithm design
	- algorithm implementation and optimization
	- identifying the right hardware platform for the embedded computer vision system
	- hardware design
	- software integration
	- product testing and validation
+ skill set:
	- data pipeline and workflow management teams:
		* Airflow
		* Luigi
	- Big Data tools:
		* Hadoop
		* Hive
		* Spark
	- AWS Cloud services:
		* EC2
		* EMR
		* RDS
		* Redshift
		* S3
	- languages:
		* Python
		* Java
		* Scala
	- Linux
	- expanding and optimizing data pipeline architecture, data flow and collection for cross-functional teams
		* ETL
		* re-designing infrastructure to improve scalability, reliability, and accuracy 
	- ensure optimal delivery architecture by supporting software engineering initiatives
	- use appropriate tools to analyze data pipeline, and provide actionable insights into operational efficiency, data accuracy, and other KPIs
	- experience with:
		* relational databases
		* data warehoouses
		* big data platforms
	- perform root cause analysis on external and internal data and processes to answer specific business questions and identify opportunities for improvement
	- improve processes to support data transformation, data structures, metadata, dependency, and workload management
	- working knowledge of:
		*  message queueing
		* stream processing
		* highly scalable big data stores
+ skill set:
	- Agile workflow practices and familiarity with Atlassian tools
		* Jira
		* Confluence
	- statistical methods
		* exploratory data analysis
		* hypothesis testing
		* regression techniques
	- techniques and best practices for data visualization
		* visualization libraries:
			+ Altair
			+ seaborn
			+ matplotlib
			+ Tableau
			+ ggplot2/shiny
		* storytelling with data, to support data-driven decisions using compelling visualizations
	- analytical toolkit
		* Python
		* pandas
		* R
	- SQL, JSON, and unstructured data
	- Amazon Web Services ecosystem
+ skill set:
	- project management skills to:
		* manage complexity
		* make informed trade-offs to quickly escape rabbit holes and make on-time deliveries
	- Agile workflow practices and familiarity with Atlassian tools
		* Jira
		* Confluence
	- statistical methods
		* exploratory data analysis
		* hypothesis testing
		* regression techniques
		* power analysis
		* generalized linear models
		* time series
		* survival analysis
	- machine learning techniques
		* supervised learning
		* unsupervised learning
		* general machine learning workflow
		* linear regression
		* logistic regression
		* decision trees
		* neural networks
		* clustering
	- techniques and best practices for data visualization
		* visualization libraries:
			+ Altair
			+ seaborn
			+ matplotlib
			+ Tableau
			+ ggplot2/shiny
		* storytelling with data, to support data-driven decisions using compelling visualizations
	- analytical toolkit
		* Python
		* pandas
		* scikit-learn
		* R
	- database management:
		* SQL
		* JSON
		* unstructured data
		* NoSQL data environments and tools:
			+ Hadoop
			+ Spark
			+ DynamoDB
	- Amazon Web Services ecosystem
	- software development practices:
		* story estimation
		* test-driven development
		* code review
		* version control with Git
+ skill set for Platform Software Engineer (BMC):
	- At Graphcore, we're optimistic for a future where people live healthier, more informed, more creative lives. Our team is at the forefront of the artificial intelligence revolution, enabling innovators from all industries and sectors to expand human potential with technology. We believe our IPU technology will become the worldwide standard for artificial intelligence, transforming whole industries and sectors whether you are a medical researcher, roboticist or building autonomous cars.
	- As a Platform Software Engineer, you will be working in the engineering team in Oslo developing the Graphcore M2000 platform with scale out technology for our Intelligence Processing Unit (IPU). You will work closely with our hardware and software engineering teams to develop the platform software that our other engineering teams depends on for the final product definition.
	- Your responsibilities:
		* Define and develop our generic platform applications
		* Configure operating system kernels and set up full distribution images
		* Bring up new systems in the lab together with the FPGA and Hardware teams
		* Board environmental monitoring, cooling/power regulation and fault handling  
	- What you will bring:
		* Proven experience in embedded Linux
		* Experience with yocto based projects, bitbake, systemd, OpenBMC
		* Experience with shell scripting, Python, C and understanding of C++
		* Experience in Linux kernel and system configuration, package management
		* Knowledge of low level peripheral interconnects, such as I2C, UART, SPI, PWM
		* Knowledge of Ethernet and IP networking standards
		* Demonstrable knowledge of computer security and authentication schemes
	- Good to have:
		* Knowledge of high availability (HA) systems, management
		* Familiarity of ILOM, BMC, IPMI, Redfish and OCP (Open Compute)
		* Familiarity with DMTF standards, Redfish and Server products
		* Experience in working with open source projects.
		* Experience in hands-on lab and bring-up activities, as well as knowledge of design for product and manufacturing
		* You like to work in a fast-paced environment using agile methods
+ skill set for Research Engineer
	- Responsibilities:
		* Perform and publish cutting-edge research in machine intelligence, with special focus on fundamental algorithms and applications for computer vision, language modelling, numerical formats and graph neural networks.
		* Exploit Graphcore’s hardware to develop and deliver models of unprecedented scale and performance.
		* Collaborate with both the research team and other groups within the company, to develop new ideas, identify research opportunities and provide machine learning expertise.
		* Follow the latest developments in the field by attending/presenting at journal clubs and travelling to relevant conferences.
		* Promote the IPU by developing and maintaining collaborations with external institutions and research labs.
	- Essential:
		* MSc or PhD in Machine Learning, Computer Science, Electrical Engineering, Physics, Mathematics or a related field.
		* In-depth understanding of modern machine learning algorithms, deep learning architectures and probability theory.
		* Experience using modern machine learning frameworks (e.g., TensorFlow, PyTorch, JAX).
		* Proficiency in Python and/or C++.
		* Strong communication skills and willingness to work in a collaborative environment.
	- Desirable:
		* Publications at top conference venues (e.g., NeurIPS, ICLR, ICML).
		* Contributions to open-source software projects in the area of machine intelligence.
		* Experience in using or designing low-precision numerical formats.
		* Kaggle competitions or other evidence of practical expertise.
+ skill set for Research Scientist:
	- Responsibilities:
		* Perform and publish cutting-edge research in machine intelligence, with special focus on fundamental algorithms and applications for computer vision, language modelling, numerical formats and graph neural networks.
		* Exploit Graphcore’s hardware to develop and deliver models of unprecedented scale and performance.
		* Collaborate with both the research team and other groups within the company, to develop new ideas, identify research opportunities and provide machine learning expertise.
		* Follow the latest developments in the field by attending/presenting at journal clubs and travelling to relevant conferences.
		* Promote the IPU by developing and maintaining collaborations with external institutions and research labs.
	- Essential:
		* MSc or PhD in Machine Learning, Computer Science, Electrical Engineering, Physics, Mathematics or a related field.
		* In-depth understanding of modern machine learning algorithms, deep learning architectures and probability theory.
		* Experience using modern machine learning frameworks (e.g., TensorFlow, PyTorch, JAX).
		* Proficiency in Python and/or C++.
		* Strong communication skills and willingness to work in a collaborative environment.
	- Desirable:
		* Publications at top conference venues (e.g., NeurIPS, ICLR, ICML).
		* Contributions to open-source software projects in the area of machine intelligence.
		* Experience in using or designing low-precision numerical formats.
		* Kaggle competitions or other evidence of practical expertise.
+ skill set:
	- Android
	- Zephyr
	- Linux
	- Renode
	- RISC-V
	- TensorFlow
	- Caffe
	- OpenCV
	- Singularity
	- KiCad
	- Docker
	- ROS
+ skill set:
	- continuous integration/delivery (CI/CD) methodologies and practices
	- develop open-source, scalable simulation and virtualization environments
	- contribute to open-source frameworks
	- design cloud infrastructure
	- distributed CI/CD constructions
	- cloud engineering:
		* virtualization
		* scalability
		* load balancing
		* failovers
		* distributed computing power
		* cloud deployments
		* monitoring
		* log processing
	- orchestration tools
+ skill set:
	- knowledge of:
		* AXI
		* AHB
		* APB
		* Wishbone
	- knowledge of comunication interfaces:
		* UART
		* I2C
		* SPI
		* TileLink
	- knowledge of fast comunication interfaces:
		* PCI
		* PCIe / PCI Expresss
		* USB
		* ChipLink
	- SoC FPGA:
		* Xilinx Zynq
		* Xilinx UltraScale+ MPSoC
		* Intel SoC FPGA
		* Microsemi SmartFusion
+ skill set:
	- develop edge AI tooling ecosystem
	- design deep learning-capable data processing devices
	- experience working with the following:
		* open-source machine learning framework TensorFlow
		* Caffe
		* neural network architectures
		* CUDA
		* OpenCL
		* OpenCV
	- design AI system architectures:
		* deep neural networks
		* machine learning algorithms
		* computer vision
			+ video processing
			+ object detection
			+ object tracking
		* speech recognition
		* text analysis
	- tasks include:
		* implementing, training, and testing AI algorithms with 3-D game engines, and optimizing them for given hardware
		* develop and improve a range of AI-oriented tools and frameworks
		* work with Linux and other open-source operating systems
		* automate workflow for validation vi auatomted testing/verification and continuous integration (CI) scripts
+ skill set for data engineering:
	- work with Scala-based core science and data platform
	- consumer-facing product layer in java and React
	- AWS-deployed software, using CI/CD with Kubernetes.
	- build, optimize, test, and improve REST and gRPC services
	- weight technical trade-offs and collaborate with coworkers to reach consensus about balancing practical necessities and ideological concerns
	- functional programming languages:
		* Scala
		* Haskell
		* Erlang
	- cloud computing tools
		* AWS
		* Docker
		* Kubernetes
		* Terraform
	- database systems:
		* schema design
		* query optimization
		* database tuning
		* migration tools
+ skill set:
	- experience with multi-imaging modalities
		* RGBN
		* multi-/hyper- spectral
		* thermal
		* LiDAR
		* radar
	- experience delveoping algorithms and methods for object detection, classification, and characterization
	- compiled production-class OO or FP programming language
		* Java
		* Scala
		* C++
		* C#
		* Haskell
		* ML
		* Erlang
		* Clojure
		* Rust
	- geospatial/GIS tools:
		* ArcGIS/QGIS
		* ENVI
		* ERDAS Imagine
	- ability to think broadly and creatively about real-world problems, and technical and scientific solutions that produce value for customers
	- experience with deep learning or machine learning methodologies
	- cloud-based implementation of software via:
		* AWS
		* Azure
		* GCP
	- Bayesian image analysis, Bayesian statistics, optimization methods
	- sensor and image fusion, multi-scale and multi-temporal data processing, video processing, 3-D scene reconstruction methods
+ skill set:
	- JavaScript technologies
		* React
		* Angular
		* Vue
		* high-quality, functional JavaScript
	- tools
		* Babel
		* Webpack/Rollup/Parcel
	- languages
		* Typescript
		* ES6+
	- Git
	- Node.js
	- Redux
	- MobX
+ skill set:
	- buildout of serverless AI platform, using a combination of Python and AWS technologies, such as:
		* Lambda
		* Kinesis
		* S3
		* EC2
		* Glue
		* Batch
		* EMR
		* CloudFormation
+ skill set:
	- Java/Scala
	- front-end Web development framework
		* React
		* Vue.js
		* Angular
		* Ember
	- leading end-to-end tech design and architecture activity
	- test driven development
	- GraphQL
	- gRPC
+ skill set:
	- Hadoop ecosystem
		* Hive
		* Pig
		* Presto
		* Spark
		* SQOOP
	- Columnstore DBs
		* Redshift
		* Vertica
	- Python
	- Scala
	- MS SQL server
	- Tableau
	- Amazon solutions
+ skill set:
	- SQL/NoSQL databases
		* MySQL
		* HBase
		* Redis
		* Presto/Trino
	- Kafka
	- Kubernetes
	- Zookeeper
	- Spark
	- Consul
	- Chef
	- Terraform
	- Rust
	- Java
	- Scala
	- monitoring tools
		* Prometheus
		* Grafana
	- building/retrofitting effective instrumentation or existing applications
	- Terraform, or CloudFormation
	- Orchestration
		* Kubernetes
		* Mesos
		* Swarm
+ skill set:
	- Windbg, LLDB, GDB debugging experience
	- SQLite, SQLCipher
	- PKI/CA certification
	- OpenSSL
	- gloox, libevent, curl
+ skill set:
	- develop software with good code quality
	- development experience with high performance, high stability, and high availability real-time server development
	- multithreading programming
	- STL4
	- TCP/IP, LAN, WAN, and P2P experience
	- unit testing and test framework like Gtest
+ skill set:
	- noise suppression, voice activity detection, and speacker recognition
	- deep learning model optimization, such as quantization, neural architecture search, pruning
+ skill set:
	- noise suppression, voice activity detection, and speacker recognition
	- audio processing algorithms:
		* acoustic noise cancellation
		* noise suppression
		* gain control
		* de-reverberation
		* microphone array processing
	- linear adaptive filtering
	- linear systems
	- audio data analysis
+ Publications in NeurIPS, ICASSP, INTERSPEECH, TASLP.
+ ZABBIX, Python, API, Ansible, Terraform, and AWS cloud.
+ system hardware tools:
	- MFT
	- Video Toolbox
	- MediaCodec
	- VA-API
+ network operations center, NOC.
+ skill set:
	- We are seeking an experienced and highly motivated DevOps Engineer who will play a key role in the setup, support, and maintenance of the deployment strategies for our services. In this role, you will be responsible for delivery by optimizing practices, improving communications and collaborations, and creating automation.
	- responsibilities:
		* Own the stability and automation of our deployment.
		* Setup, support, and maintain cloud infrastructure
		* Setup, support and maintain code management and CI/CD pipelines
		* Implement monitoring and security best practices.
		* Own the stability and automation of our deployment.
		* Guide and potentially assist API and ML engineers developing in Go and Python.
	- experience and qualifications
		* 3+ years of DevOps experience, preferably in a lead role
		* Experience with Go (Strongly Preferred), or JVM languages like Java or Scala, or C/C++
		* Proficient with HashiCorp Terraform, Vault, and Nomad
		* Advanced ability to craft clear and concise documentation
		* Understanding of deployment orchestration using Kubernetes.
		* Ability to design and manage CI / CD pipelines
+ skil set:
	- Familiarity with Go, Kubernetes, Docker, React, AWS/GCP
	- Experience with containers and resource managers (e.g., Kubernetes, Mesos, YARN, Linux package managers)
+ skill set:
	- Katana Graph is an enterprise graph computing system and storage engine. Our technology is the world’s fastest graph processing engine, providing compelling scalability and programmability advantages... Building on decades of experience in developing state-of-the-art distributed systems, Katana Graph is bringing together experts in hardware acceleration, cloud computing, storage systems, and high-performance computing to help create the platform of the future for data processing and analysis in this new world of specialized hardware and revitalized algorithms... Katana Graph recently completed a $28.5 million Series A financing round led by Intel Capital with participation from existing and new investors including WRVI Capital, Nepenthe Capital, Dell Technologies Capital, and Redline Capital.
	- Are you a talented software engineer that is interested in developing solutions for difficult problems? Do you love to code and be actively engaged in the work you do?
	- Roles:
		* Graph Engine GPU - Software Engineer
		* Graph Query Engine - Software Engineer
		* Graph Transaction Engine - Software Engineer
		* Evolving Graph Engine - Software Engineer
		* Graph Storage Engine - Software Engineer
	- Successful engineers at Katana Graph are familiar with GRAPH ALGORITHMS, comfortable working in C/C++, and are proficient PARALLEL PROGRAMMERS, in addition to experience in one of the following areas::
		* Compiler, runtime or query engine development
		* Relational and/or graph databases
		* Distributed systems and/or high-performance computing
		* CUDA or OpenCL
		* Python
+ Publication record in top AI conferences (ACL, CVPR, NAACL, ICML, etc.) is a plus.
+ Hands-on experience design and development of graph-based compilers and experience in LLVM, MLIR, GLOW, etc. is a plus.
+ skill set:
	- hands-on experience in configuring, maintaining, and building upon deployments of industry-standard tools (e.g., Jenkins, Docker, CMake, GitLab, Jira, etc.)
	- experience in software shipping cycles (dev, deploy/CD, release, CI,) and open-source software development.
+ experience working with OpenCV and FFMPEG libraries
+ skill set:
	- At ApertureData, we are on a mission to solve data infrastructure challenges for machine learning on big-visual-data. We are an angel and NSF grant backed, fast growing startup looking for a Sr. Software Engineer with experience building large scale infrastructure and developing low level systems software. If you enjoy the idiosyncrasies of C++, big data systems excite you, and being among the first five hires fires up your imagination on what all hats you get to wear, we are looking forward to hearing from you!
	- Minimum qualifications
		* While you get the freedom to define direction and build castles on-ground for now, it comes with some requirements so we can build fast and stay focused.
		* 5+ years of experience in Computer Science, or a related technical field
		* 2+ years of experience in C++
		* Understand concurrency well
		* Understand the effects of cache/memory/disk as they interplay with each other and processing
		* Systems level data structure and algorithm effects (kernel and driver level included)
		* Be comfortable with Linux, C++, and Python
		* Valid work status in the US
	- Additional qualifications
		* Good tools make engineering more fun and the more you know about scaling, the faster you can help us scale our product
		* Productivity, development, testing, and cluster management tools/frameworks/languages such as Gtest, git, Jupyter, shell scripting, OpenCV (to know how to handle some computer vision tasks), Kafka, Spark, Tensorflow/PyTorch/Caffe2, Docker, Kubernetes, Zookeeper, and just in general keep up with new technology to know when we should pay attention to something
		* Practical implementation knowledge of CAP theorem, distributed systems programming
		* Experience architecting a system to run as a service independent of the cloud vendor
		* Knowledge of how to interact with distributed file systems
+ skill set:
	- At ApertureData, we are on a mission to solve data infrastructure challenges for machine learning on big-visual-data through our unique visual database, ApertureDB. We are an angel and NSF grant backed, fast growing startup looking for a Computer Vision Systems Engineer because dealing with images and videos is challenging, particularly at scale. If you can easily tackle the likes of OpenCV and ffmpeg, dealing with large object caching excites you, and being among the first five hires fires up your imagination on what all hats you get to wear, we are looking forward to hearing from you!
	- Minimum qualifications
		* We are focused on making access to visual data simple and fast. That requires absorbing the comlexity of these data types within ApertureDB, therefore requiring certain qualifications
		* 5+ years of experience in Computer Science, or a related technical field
		* 2+ years of experience in C++
		* Understand different image and video formats and encodings
		* Experience working with OpenCV and FFMPEG libraries
		* Systems level data structure and algorithm effects (kernel and driver level included)
		* Data structure optimization techniques
		* Valid work status in the US
	- Additional qualifications
		* It would be great if you already came to us with a few more tricks up your sleeve.
		* Be comfortable with JSON, Python, Git, and Linux
		* Other visual processing libraries
		* Understand the effects of cache/memory/disk as they interplay with each other and processing
		* Efficient algorithms for visual transformations
+ skill set:
	- At ApertureData, we are on a mission to solve data infrastructure challenges for machine learning on big-visual-data through our unique visual database, ApertureDB. We are an angel and NSF grant backed, fast growing startup looking for a Database Architect with experience designing and building database internals. If you think locking and logging have a lot more to them than MVCC or redo, connected graph-like queries excite you, and being among the first five hires fires up your imagination on what all hats you get to wear, we are looking forward to hearing from you!
	- Minimum qualifications
		* Databases serve a vital purpose particularly as we get to define them for unstructured data. That requires a certain set of skills to even start off.
		* 5+ years of experience in Computer Science, or a related technical field
		* 2+ years of experience in C++
		* Understand concurrency and ACID implementations well
		* Systems level data structure and algorithm effects (kernel and driver level included)
		* Data structure and query optimization techniques
		* Different consistency models
		* Valid work status in the US
	- Additional qualifications
		* It would be great if you already came to us with a few more tricks up your sleeve.
		* Be comfortable with JSON, Python, Git, and Linux
		* Object mapper interfaces
		* Indexing vector data types
		* Understand the effects of cache/memory/disk as they interplay with each other and processing
		* Experience architecting a system to run as a service independent of the cloud vendor








































+ AI compiler design
	- Poplar framework for IPU architecture compiler.
+ AI compilers:
	- MLIR
	- TVM
	- Glow

