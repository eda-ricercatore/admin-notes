








+ skill set:
	- Kiwibot is looking for a Senior Machine Learning Engineer role and it could be a great opportunity to join us. You should have the right technical knowledge and understanding of common and novel computer vision, and machine learning techniques to support and develop new algorithms, and create solutions. You should also have proven experience designing, developing and deploying machine learning solutions on real world applications.
	- As a Machine Learning Engineer : You will report directly to our Head of AI & Robotics.
	- Implement, train and iterate vision based deep learning models.
	- Train models on Cloud on single and multiple GPUs. 
	- Design and implement data pipelines for storing and processing thousands of images and videos.
	- Design and integrate with third party labeling company API for upload and ingestion of data and labels. 
	- Design and implementation of data harvesting from current fleet operations. 
	- Create data visualization tools for data analysis and debugging. 
	- Evaluate the quality of labeling of data.
	- Design and iterate labeling instructions that produce high quality labels.
	- Implement, design and manage databases of images, videos and metadata associated with them.
	- Optimize models for performance on constrained environments.
	- Deploy trained models on-premise integrated with the rest of the robot’s software stack.
	- Report of training procedures, error analysis, data review.
	- Offline database analysis for getting insights, generating labels automatically, doing anonymization, etc. 
	- You have knowledge of Python and scripting (advanced) 
	- Git (intermediate/advanced) 
	- Docker, docker-compose (advanced) 
	- Scrum and agile methodologies 
	- Vast experience with deep learning frameworks like pytorch/tensorflow 
	- Experience with one or more cloud providers (advanced), GCP is a plus 
	- Deep understanding of DL techniques like CNN, LSTM, RNN, Transformers
	- Hands on with semantic segmentation algorithms, object detection or depth estimation.
	- Experience using and implementing RESTFULs services 
	- Terraform/pulumi knowledge for deploying solutions 
	- Experience with some MLOps, MLFlow is a plus 
	- SQL and no SQL databases (advanced). BigQuery is a plus 
	- ROS or ROS2 (basic) is a plus 
	- C++ (intermediate) is a plus 
	- Experience with sensor technologies is a plus (Lidars 2D, 3D, Stereo Cameras, Cameras, IMU, GPS) 
	- Strong English level, both written and spoken.
+ skill set:
	- We are looking for Machine Learning Interns to \#JoinTheBand and help drive a data-first culture across Spotify.  You will work on a variety of problems such as content recommendation, personalization, optimization, user intelligence, and content classification. You will work with a team to come up with new and interesting hypotheses, test them, and scale them up to huge data sets with hundreds of billions of data points. Above all, your work will impact the way the world experiences music.
	- Apply machine learning, collaborative filtering, NLP, and deep learning methods to massive data sets
	- Prototype new algorithms, evaluate with small scale experiments, and later productionize solutions at scale to our 140 million active users
	- Collaborate with a cross functional agile team of software engineers, data engineers, ML experts, and others to build new product features
	- Help drive optimization, testing and tooling to improve data quality
	- Iterate on recommendation quality through continuous A/B testing
	- You are pursuing a Ph.D. or Master's degree in Machine Learning, Statistics or related field preferred
	- You have a graduation date of 2022 or 2023
	- You currently have valid work authorization to work in the country in which this role is based that will extend from June to August 2022
	- You have experience implementing machine learning systems at scale in Java, Scala, Python or similar (not just R or Matlab)
	- You have a strong mathematical background in statistics and machine learning
	- You care about agile software processes, data-driven development, reliability, and responsible experimentation
	- You preferably have experience with data processing and storage frameworks like Hadoop, Scalding, Spark, Storm, Cassandra, Kafka, etc.
	- You preferably have machine learning publications or work on open source to share with us
	- We are a distributed workforce enabling our band members to find a work mode that is best for them!
	- Where in the world? For this role, it can be within the Americas region in which we have a work location.
	- Prefer an office to work from home instead? Not a problem! We have plenty of options for your working preferences. Find more information about our Work From Anywhere options here.
	- Working hours? We operate within the Eastern Standard time zone for collaboration.
+ skill set:
	- We are looking for a Financial Systems Engineering Intern who is organized, passionate, and excited to learn. You will join our Financial Systems team in NYC responsible for the support and growth of a suite of financial SaaS tools. In this role, you will primarily help support the daily operations of our NetSuite, Concur, Coupa, and Blackline systems. Above all, your work will impact the way the world experiences music.
	- Provide front-line support across a suite of financial systems, learning along the way.  
	- Troubleshoot process, application, and functional issues, and manage these through to resolution. 
	- Identify areas of opportunity for process optimization and system automation to enable rapid growth in the Financial Systems end-user base. 
	- Support major system upgrades in NetSuite, Coupa, and Blackline. 
	- Support testing of ongoing enhancements. 
	- Engage with stakeholders across the entire Spotify organization. 
	- Work from our office in New York or remotely anywhere in the US, collaborating with our partner team based in Stockholm. 
	- A current undergraduate or graduate student pursuing a degree in Computer Science, Engineering, Finance, or Accounting, and planning to graduate in 2023. 
	- You currently have valid work authorization to work in the country in which this role is based that will extend from June to August 2022. 
	- You know how to balance multiple tasks, problem solve in new contexts and communicate clearly. 
	- You are experienced in system development and/or accounting. 
	- You care about optimizing systems and processes and have a keen eye for detail. 
	- You have experiences with system development and accounting processes that you can tell us about.
+ skill set:
	- We are looking for a Data Analyst Intern to \#JoinTheBand and support our Tech Learning team. As a part of our Collaborative Learning Product Area, The Tech Learning team creates peer-to-peer learning experiences that upskill and reskill Spotify employees in technical domains. We are looking for a Data Analyst Intern to consume, understand, and interpret data across our programs and create tools to better understand topics like customer demand and customer learner journeys.
	- Perform analyses on large sets of data to extract practical insights that will help drive decisions across the business
	- Build dashboards and recurring reporting results, empowering creative growth and business decisions
	- Communicate data-driven insights and recommendations to key collaborators
	- Work closely with the Tech Learning team, Data Scientists, and other key stakeholders across disciplines
	- You are pursuing a Bachelor’s, Master’s degree, or bootcamp certification in Data Science, Computer Science, Statistics, Economics, Mathematics, or a similar quantitative subject area
	- You have a graduation date of 2023 or later
	- You currently have valid work authorization to work in the country in which this role is based that will extend from June to August 2022
	- You harbor a passion for numbers and the use of data to make decisions
	- You have the technical competence to perform more analytics in one or more of the following areas:Coding skills (such as Python, Java, or Scala)Analytics tools experience (such as Bigquery, SQL, or Tableau)
	- Experience and passion for performing analysis with large datasets
+ skill set:
	- Spotify is looking for Data Engineering Interns to join us this Summer. You will build data driven solutions to bring audio and digital media experiences to our millions of active users and artists either by working directly on product features, publishing and insight tools for artists, or by improving the quality of our data tools and large scale data infrastructure. You will take on complex data-related problems using some of the most diverse datasets available — user behaviors, acoustical analysis, revenue streams, cultural and contextual data, and other signals across our broad range of mobile and connected platforms. Above all, your work will impact the way the world experiences audio.
	- Build large-scale batch and real-time data pipelines with data processing frameworks like Scalding, Scio, Storm, Spark and the Google Cloud Platform.
	- Use best practices in continuous integration and delivery.
	- Help drive optimization, testing and tooling to improve data quality.
	- Collaborate with other engineers, ML experts and collaborators, taking learning opportunities that will arise every single day.
	- Work in multi-functional agile teams to continuously experiment, iterate and deliver on new product objectives.
	- You are pursuing a Bachelor's or Master's degree or a bootcamp certification in Computer Science or Computer Engineering or a related field of study.
	- You currently have valid work authorization to work in the country in which this role is based that will extend from June to August 2022
	- You are a current sophomore, junior or senior in undergrad or a first or final year Master's student
	- You've dabbled in high volume data, preferably with distributed systems such as Hadoop, BigTable, and Cassandra.
	- You know how to write distributed, high-volume services in Java, Scala and Python.
	- You've had exposure to data modeling, data access, and data storage techniques.
	- You have an interest in agile software processes, data-driven development, reliability, and responsible experimentation.
	- You understand the value of collaboration within teams.
+ skill set:
	- We are looking for Machine Learning Engineering Interns to help drive a data-led culture across Spotify. You will apply machine learning methods to extensive data sets to extend improve Spotify’s means of understanding and engaging users across various contexts and modalities. You will build upon Spotify’s deep understanding of our content, users, and artists to develop rich analytics, engagement, and business applications. Above all, your work will impact the way the world experiences audio.
	- Contribute to designing, building, evaluating, shipping, and refining Spotify’s product by hands-on ML development
	- Collaborate with a cross functional agile team spanning user research, design, data science, product management, and engineering to build new product features that advance our mission to connect artists and fans in personalized and relevant ways
	- Assist in prototyping new approaches and product-ionize solutions at scale for our hundreds of millions of active users
	- Help drive optimization, testing, and tooling to improve quality
	- Be part of an active group of machine learning practitioners across Spotify) collaborating with one another
	- You are pursuing a Bachelor’s or Master’s degree in Machine Learning, Computer Science, Computer Engineering or a related field of study
	- You have dabbled in ML engineering practices via prior internships, coursework, and/or projects
	- You have experience in working with Scala and/or PythonYou have an understanding of system design, data structures, and algorithms
	- You care about quality and you know what it means to ship high-quality code
	- You are currently in your final or penultimate year of your studies
+ skill set:
	- We are looking for a Research Scientist Intern to join our growing Trust & Safety Research & Algorithmic Impact team. Spotify’s Algorithmic Responsibility effort focuses on empowering Spotify teams to assess the algorithmic impact of their products on audio culture, avoid algorithmic harms and unintended side effects, and better serve worldwide audiences and creators. As an Algorithmic Impact research intern, you will help to define, research, and communicate how we assess our impact as a platform and our recommendations across podcasts, music, and user-generated content. We help ensure that Spotify is a safe platform that’s true to our values.
	- Be part of an interdisciplinary team focused on understanding Spotify’s impact as a platform, and practical implementation and operationalization of Responsible ML activities such as algorithmic impact assessments. 
	- Contribute to the wider research community by publishing. 
	- Develop and iterate policy and auditing processes related to tech responsibility, algorithmic fairness and representation in the music and podcast industry. 
	- Apply your scientific knowledge to develop strategy around cultural equity in audio and algorithmic systems, including application-oriented problems in search, recommendation and Machine Learning settings. 
	- Provide consultative support, guidance on methods, and research-based input for products. For instance, this can include algorithmic audits, or analyzing & tracking global and local trends around online abuse, hate content, misinformation, etc., with a particular focus on algorithmic amplification. 
	- Work closely with our team and internal partners to develop, refine, and launch processes that help ensure Spotify is a safe and positive experience. 
	- Be a valued member of an autonomous, multi-functional team working in collaboration with other scientists, engineers, product managers, policy experts, designers, user researchers, and analysts across Spotify to design creative solutions to exciting problems.
	- You are pursuing a PhD in Social Science, HCI, Computer Science, Information Science, Data Science, Technology Policy, or related areas with a strong computational focus.
	- You have publications in communities such as the Web Conference, AIES, FAccT, CSCW, SIGIR, CHI, ACL, NeurIPS, WSDM, EMNLP, RecSys, KDD, ICWSM, ISMIR or related venues.
	- You are curious about how interaction design, data collection strategies, and people’s perceptions affect Machine Learning outcomes.
	- You are a creative problem-solver who is passionate about digging into complex problems and devising innovative ways to reach results.
	- You have experience with the complexities of real-world data, and understand the value of both in-depth, qualitative and web-scale, quantitative data working together to build a deep understanding of people’s interaction with technology.
	- Knowledge or experience working in emerging markets is a plus.
	- You have strong communication skills, both written and verbal. Able to provide concise advice and translate complex challenges clearly. Willing to apply academic knowledge and frameworks into product and practice.
	- You must be comfortable reviewing or being exposed to sensitive content and topics, and having related conversations with teams.
+ skill set:
	- We are looking for Data Scientist Interns to #JoinTheBand and help drive a data-first culture across Spotify. Our Data Scientist mission is to turn terabytes of data into insights and get a deep understanding of music and listeners so we can impact the strategy and direction of Spotify. You will study user behavior, critical initiatives, markets, content, and new features and bring data and insights into every decision we make. Above all, your work will impact the way the world experiences audio. 
	- Perform analyses on large sets of data to extract concrete insights that will help drive decisions across the business
	- Build dashboards and recurring reporting results, empowering creative growth and business decisions.
	- Communicate data-driven insights and recommendations to key collaborators
	- Work closely with cross-functional teams of analysts, product owners, marketers, designers, and others across the company who are passionate about Spotify’s success
	- You are pursuing a Bachelor’s, Master’s degree or bootcamp certification in Science, Computer Science, Statistics, Economics, Mathematics, or similar quantitative field
	- You are a sophomore, junior or senior in undergrad or a first or final year in a Master's program
	- You have harbor a passion for numbers and the use of data to make decisions
	- You have have technical competence to perform more analytics in one or more of the following areas:
	- Coding skills (such as Python, Java, or Scala)
	- Analytics tools experience (such as Pandas, R, SPSS, SQL or Tableau)
	- Experience performing analysis with large datasets
+ Experience with RxJS or other event-based/observer framework
+ skill set:
	- Master’s degree in software development, computer science, algorithm design, artificial intelligence, or machine learning or equivalent experience
	- 5 years of experience as a machine learning engineer and using libraries, such as Scikit-learn, TensorFlow, Caffe, Keras, etc.
	- Experience with Microsoft Azure platform – Azure ML Services, Databricks, AKS, etc.
	- Experience with the Hadoop ecosystem (e.g., Apache Hive, Pig, HBase and Kafka)
	- Experience with distributed computing platforms, such as Spark, and user interface frameworks, such as Angular or React
	- Ph.D. in software development, computer science, algorithm design, artificial intelligence, or machine learning or equivalent experience
	- Strong object-oriented programming skills, including proficiency in Java, Scala, C/C++ or Python
	- Strong SQL skills
	- Proficiency in the Microsoft Office suite
	- The Machine Learning Engineer designs and develops the platform and frameworks that facilitate automated data-driven decision-making, gathers data, and determines statistical algorithms and models that a system can use to learn from experience, predict outcomes and make decisions.
	- Collaborate with data scientists to develop algorithms and tools for training and running simulations
	- Build services to interact with machine learning models through simulations
	- Participate in code reviews to ensure code quality and share best practices
	- Develop services that host the trained models and work with other application teams to integrate them into business processes
	- Gather and analyze large datasets and develop data model pipelines
	- Develop algorithms that drive automated data-driven decision-making
	- Build the tools for monitoring the performance of machine learning applications
+ skill set:
	- Our core cultural values are manifested in our practices and processes every day. We highly value transparency and fairness in everything we do. We look for people who like to move quickly, are ambitious yet humble and have a great sense of humour. If you have a mischievous spark of fun, that’s even better.
	- What you will be doing
		* We’re looking for an experienced DevOps Engineer to join a team of talented engineers to develop high quality products which are scalable, testable, extensible, and provide high value to our customers.
		* As a key member of the server and infrastructure team, you will work closely with the various development teams to provide operational support. This support will help them gain insight into their systems, improve reliability, and increase developer productivity.
		* This is an individual contributor role where you will be reporting to a Team Lead. This role can be based in Vancouver or Toronto, with benefits from a flexible hybrid work model of remote + in office collaboration.
	- Responsibilities
		* The ultimate tasks for a DevOps Engineer can vary from company to company, but the base responsibilities are usually similar. Monitoring and improving infrastructure and processes will be part of the job at Later just as it would be anywhere else. That being said, there are some things that we are particularly keen on at Later.
		* Ability to work with different engineering teams, back end, web front end, and mobile teams.
		* Bringing your wealth of knowledge and experiences (good and bad) to Later and improving our processes and technology.
		* Educating product and stakeholders on the trade-offs of different paths to a given milestone to enable them to make educated decisions for our roadmap.
		* Writing documentation by hand or via automation.
		* Holding other developers, in particular other Senior Developers, to high coding standards through PR reviews.
		* Constantly learning and staying up-to-date through use of dedicated unstructured dev time for you to: making open-source contributions, writing technical blog articles, creating internal tools for non-feature work, as well as self-education on relevant topics.
		* Knowing when good is good enough.
		* Knowing when good just isn’t going to cut it.
		* Joining the on call rotation.
		* Writing documentation, did we mention that?
		* Taking ownership of pieces of code, infrastructure, and processes and then caring enough to improve them.
		* Knowing how to scale workloads while managing the various resources used by them.
		* Owning and improving deployment processes for the different apps and services
		* Supporting CI/CD pipelines for the various development teams
		* Maintaining documentation and runbooks for the services and infrastructure
		* Owning and scheduling maintenance for dependencies, i.e., databases and cache stores
		* Owning and improving infrastructure monitoring and alarming
		* Improving and optimizing the use of our AWS infrastructure
		* Automation of common task that allow you to be removed from the process
	- Supported Tech... in our tech stack:
		* A moderately sized Ruby on Rails monolith
		* Dockerized services written Node, Ruby, and Elixir
		* Node/Express/Typescript API
		* Postgres, Redis, and DynamoDB datastores
		* Deployments in Heroku and AWS (ECS, EKS, and Lambda)
		* CircleCI based CI pipeline
	- What we are looking for
		* 3+ years of experience working on a team and shipping code and services in production environments
		* Minimum 2+ years devops experience
		* Strong experience managing AWS based deployments, K8s preferred
		* Experience working with Dockerized services (micro or other)
		* Experience with infrastructure-as-code
		* Experience CI/CD pipelines across multiple domains
		* Familiarity with Postgres (or other relational DBs)
		* Familiarity with cloud based security best practices
		* Familiarity with Agile process
		* We believe that good DevOps people have the ability to pick up new processes and technologies quickly, but some of the following will help you hit the ground running in one area or another.
		* Experience working on Ruby on Rails applications
		* Experience working with Typescript/Express applications
		* Experience with AWS based DevSecOps
		* Experience with processing images at scale
	- Culture/Benefits
		* We are passionate about learning and development, providing opportunities through lunch and learns, training and workshops. We also provide each employee with a $3000 per year Education & Conference budget.
		* We provide our employees with a monthly Wellness Spending Account, to help cover costs related to fitness equipment, personal training, gym memberships or health and wellness practitioners.
		* We provide our team with a generous technology bonus and provide the tools you need to succeed in your role.
		* We offer a comprehensive benefits package including health, dental, vision, and an Employee and Family Assistance Program to support the wellbeing of you and your family.
		* We offer flexible working hours & schedules so you can work around school and home commitments.
		* We offer parental leave top-ups, family forming support and a life-transitions program to ensure you and your family are well supported when returning to work
		* We provide a variety of workshops, meditation and yoga at our monthly Wellness Wednesday events to help our team perform at their best.
		* All departments have quarterly department team building activities
		* We fly all employees in or out to join us at our fun filled annual company retreat.
		* Later values diversity of thought; we are committed to creating a diverse environment and are proud to be an equal opportunity employer. All applications will receive consideration for employment without regard to race, colour, religion, gender, gender identity or expression, national origin, disability, or age.
+ skill set:
	- We’re looking for an experienced Senior Software Developer (back end) to join a team of talented engineers to develop high quality products which are scalable, testable, extensible, and provide high value to our customers.
	- As a key member of the development team, you will work closely with designers, product managers, and other key stakeholders to define and execute on both our short term critical missions and long term vision.
	- This is an individual contributor role where you will be reporting to a Team Lead. This role can be based in Vancouver or Toronto, with benefits from a flexible hybrid work model of remote + in office collaboration.
	- The base responsibilities for a Senior Developer are the same across most companies. Critical thinking, designing and implementing well structured and robust solutions, writing tests, mentoring junior developers will be part of the job at Later just as it would be anywhere else. That being said, there are some things that we are particularly keen on at Later.
	- Bringing your wealth of knowledge and experiences (good and bad) to Later and improving our processes and technology.
	- Educating product and stakeholders on the trade-offs of different paths to a given milestone to enable them to make educated decisions for our roadmap.
	- Writing documentation by hand or via automation.
	- Holding other developers, in particular other Senior Developers, to high coding standards through PR reviews.
	- Constantly learning and staying up-to-date through use of dedicated unstructured dev time for you to: making open-source contributions, writing technical blog articles, planning developer events, preparing conference talks, creating internal tools for non-feature work, as well as self-education on relevant topics.
	- Knowing when good is good enough.
	- Knowing when good just isn’t going to cut it.
	- Joining the on call rotation.
	- Writing documentation, did we mention that?
	- Taking ownership of pieces of code, infrastructure, and processes and then caring enough to improve them.
	- Knowing how to scale workloads while managing the various resources used by them.
	- Here is an abridged list of of things you can find in our tech stack:
		* A moderately sized Ruby on Rails monolith
		* Dockerized Node services deployed to AWS ECS
		* Node/Express/Typescript API
		* A pure Ruby analytics collector application
		* Postgres, Redis, and DynamoDB datastores
		* Microservices written in Elixir
	- What we are looking for
		* 5+ years of experience working on a team and shipping code in production environments
		* Minimum 5+ years software development experience
		* Minimum 2+ years solid web app development experience
		* Experience providing technical leadership and guidance
		* Experience architecting and implementing complex services from design to deployment and through maintenance
		* Ability to mentor junior developers
		* Experience writing test suites and CI/CD pipelines
		* Proficiency in Postgres (or other relational DBs)
		* Familiarity with OWASP best practices
		* Familiarity with Agile process
		* Experience working on Ruby on Rails applications
		* Experience working with Typescript/Express applications
		* Experience working with Dockerized services (micro or other)
		* Experience with AWS based DevSecOps
		* Experience with processing images at scale
	- Multiple company-wide Hackweeks each year
	- PTO awarded for being part of the on call rotation
	- Regular Unstructured Development Time to investigate new technologies that would benefit you and your team
	- Working with the latest versions of Ruby and Rails. No legacy Ruby 2.3 or Rails 4.2 apps here.
+ ***OpenCV Ceres, ROS, PyTorch***
+ skill set:
	- GrAI Matter Labs is a young and vibrant high-tech company, which aims to revolutionize artificial intelligence for everyone. Our unique machine learning technology will drive the next generation of computer chips to power many future products. This way, we contribute to making robots, cameras, and transportation smart, safe, and power-efficient. GML is an international company, with highly motivated teams in offices in France (Paris), Netherlands (Eindhoven), and USA (San Jose).
	- At GML, we develop new technologies for efficient low-latency and low-power processing of neural networks, for training neural networks, and for neuromorphic computing. And we are looking for talented MSc candidates to help us in this research.
	- If you are an MSc candidate with a background in electrical engineering, computer science, or computer architecture, and you are looking for a cutting-edge environment to perform your MSc thesis project, then you should certainly consider applying at GML!
	- You will be embedded in a team of highly trained and highly motivated architects, scientists, and engineers. In your assignment, you will work with experts in the fields of processor architecture, computer architecture, compiler construction, neural network and neuromorphic processing. These are some of the topics we are currently working on:
		* Retraining neural networks for imposed temporal sparsity;
		* Improving input signal sparsity;
		* Mixed-precision training;
		* LIDAR-based neural network applications;
		* Bayesian machine learning on neuromorphic architectures;
		* Neural-networks mapper algorithms for massive-multicore Systems;
		* Auto-tuners for efficient neural-network mapping for massive multicore systems;
		* NoC architectures for neuromorphic massive multicore systems;
		* Low-power techniques for neuromorphic massive multicore systems.
		* AI solutions for [ANDANTE project](https://www.andante-ai.eu/) use cases, together with partners such as ST Microelectronics, Philips, Boeing, Thales, Valeo, CEA, and Fraunhofer.
		* AI solutions for medical sensor systems in the [pAvIs project](https://penta-eureka.eu/project-overview/penta-call-5/pavis/), together with partners such as Philips, Cochlear, and InBrain.
	- Responsibilities:
		* Determining the scientific contributions of your project, and advancing the state-of-the-art in neural network processing;
		* Providing GML with new technologies for neural network processing and neuromorphic design;
		* Defining your project goals, deliverables, and plans, to fit the timeframe of your assignment;
		* Running and managing your project, together with your GML advisors, university supervisors, colleagues, and co-students;
		* Delivering a final report for your MSc graduation.
	- Requirements:
		* Master student with a background in Electrical of
		* Strong mathematics, computer science, and/or computer architecture background
		* Strong machine-learning background, and hands-on experience with neural network frameworks, such as Tensorflow
		* Strong programming skills (e.g. Python, C, C++)
		* "Can-do" mentality, excellent problem-solving skills
	- GrAI Matter Labs is a dynamic organization which employs some of the brightest minds in the industry and is known for the great care we take with clients and employees alike. We believe we will win as a close-knit team that converts a strong vision into products that solve use cases which our customers truly value. We also hold to the highest standards of inclusion, team spirit, and cooperation. This position is based at GrAI Matter Labs offices at the High Tech Campus in Eindhoven, The Netherlands. The High Tech Campus houses 160 companies, employing a total of 11,000 entrepreneurs and R&D employees. To our interns, we offer a nice compensation, in line with what is customary around the Eindhoven area.
+ skill set:
	- Work on exciting Proof of Concept projects with using GrAI VIP
	- Train Deep Learning models that work on Real-World Scenarios.
	- Develop and optimize AI training pipelines.
	- Use different sensors to acquire data.
	- Create applications using AI and robotics.
	- You will work closely with the Customer’s Solutions Architect Team to deliver contents that drive results.
	- You are in your last year of your engineering School.
	- Pursuing a master's degree program in Computer Science, or related technical field.
	- Programming experience in Python. Experience in C/C++ is a plus.
	- Good Understanding of Deep Learning fundamentals.
	- Experience using one or more of the Machine Learning Libraries (TensorFlow, Keras, PyTorch).
	- Experience working in Linux environments.
	- Team Player.
	- Problem-solver keen to find innovative solutions in any situation.
	- Super enthusiastic, and you like to be challenged!
	- Fluent in English and willingness to work in an international context.
+ skill set:
	- GrAI Matter Labs is looking for a talented Senior AI Processor Architect to help us shape the next generation of our GrAI Core Architecture and its pre- and post-processing peripherals (such as image processing, FFT, IFFT...). As a Senior Core Architect you will own the specifications of one or more components of our core architecture. You will analyse the performance of our processors for selected applications, and propose, quantify and specify architectural features and optimisations to improve the performance, cost and power consumption of our next generation GrAI Core.
	- You are expected to play a key role in innovation, working with partners on benchmarking and optimizing architectural features to match the needs of the application and efficiently mapping and prototyping them on the company’s architecture, as well as adapting such concepts to work in production-grade systems.
	- Our ideal architect is creative, curious, knowledgeable, and not afraid to get their hands dirty by helping the hardware and tools teams with implementation tasks when necessary. The right candidate knows how to find solutions that are both theoretically sound and provide the best cost-performance trade-offs, while also considering all the practical constraints created by the development process.
	- As part of the architecture team your main responsibilities are:
		* to carry out analysis of the performance and cost of the existing core architecture;
		* to propose and evaluate new architectural features in collaboration with the other members of the architecture team;
		* to draft and own specifications of features in the next generations of the GrAI Core;
		* to provide guidance and assistance to hardware and tools engineers;
		* to contribute to the long-term technological direction of the company.
		* You will be working on exciting and emerging topics, finding new techniques and silicon technologies to exploit sparsity and event-driven processing of neural networks to enable new applications on the Edge.
	- Master or PhD in Electrical engineering, Computer Engineering or Computer Science;
	- 5+ years of experience in designing chips and hardware;
	- Excellent theoretical knowledge and practical experience in computer architecture and hardware design, including network-on-chip, datapath, memory hierarchy;
	- Excellent skills and experience as a hardware designer;
	- Knowledge of VLSI process technology and backend is a big plus;
	- Knowledge of compilers, simulators and other software development tools is a plus.
	- Knowledge of machine learning, deep learning and AI applications is a plus.
+ skill set:
	- The machine learning engineer’s primary role is to support the research team in developing commercial applications for BrainChip’s Akida Neuromorphic System-on-Chip (NSoC). Some of the target applications include work in computer vision (object classification/detection and face recognition), audio processing (keyword spotting), and sensor fusion. Additionally, this team member will support the research team’s algorithm development for the next version of the Akida NSoC.
	- B.S. in Computer Science or equivalent
	- Course work in machine learning and computer vision
	- Strong programming skills in Python
	- 3 years’ experience developing ML applications in either TensorFlow/Keras and/or PyTorch
	- Excellent communication skills
	- The ability to read, understand, and implement algorithms from technical ML journals
	- Master’s in computer science of equivalent
	- 4+ years experience developing ML applications in TensorFlow/Keras and PyTorch
	- Multi-project experience in object classification, object detection, face recognition, and/or keyword spotting
	- Knowledge of deep learning quantization techniques
	- Experience with Docker and Git
	- Experience with Scrum/Agile software development (e.g. Jira)
+ skill set:
	- The junior machine learning engineer’s primary role is to support the research team in developing commercial applications for BrainChip’s Akida Neuromorphic System-on-Chip (NSoC). Some of the target applications include work in computer vision (object classification/detection and face recognition), audio processing (keyword spotting), and sensor fusion. Additionally, this team member will support the research team’s algorithm development for the next version of the Akida NSoC.
	- B.S. in Computer Science or equivalent
	- Course work in machine learning and computer vision
	- Strong programming skills in Python
	- 1 year experience developing ML applications in either TensorFlow/Keras and/or PyTorch
	- Excellent communication skills
	- The ability to read, understand, and implement algorithms from technical ML journals
	- 2+ years experience developing ML applications in TensorFlow/Keras and PyTorch
	- Multi-project experience in object classification, object detection, face recognition, and/or keyword spotting
	- Knowledge of deep learning quantization techniques
	- Experience with Docker and Git
	- Experience with Scrum/Agile software development (e.g. Jira)
+ skill set:
	- At Brainchip, we are revolutionizing Artificial Intelligence at the edge with our AkidaTM Hardware and Software products. Akida™ hardware and software products are the result of over a decade of fundamental R&D by BrainChip engineers and data scientists. Akida AI IP, AI SoC, and development environment help customers create ultra-low-power solutions with the ability to incrementally learn on-chip without the need to retrain in the cloud.
	- We are looking for a HW Design Engineering Summer Intern (May-August 2022) with a strong background in Digital Design and excellent Verilog/System Verilog coding and scripting skills.
	- As a HW Design Engineering Intern, you will work on our latest AI Chip and/or IP design. You will work closely with the HW Engineering team using Industry standard tools and flows for RTL design, verification, automation and debug. The position requires willingness and ability to learn quickly and excellent communication skills.
	- GPA 3.0 and above
	- Currently enrolled in a Bachelors/Masters program in Electrical Engineering and/or Computer Science with a graduation date of Dec 2022 or later.
	- Candidate should be local to Southern California since this position does not provide relocation assistance.
	- Currently pursuing a Bachelors or Masters in Electrical Engineering and/or Computer Architecture with emphasis on Digital Design, Verification or Computer Architecture
	- Familiarity with Digital design using Verilog/System Verilog
	- Proficient in scripting languages like Python, PERL, or Shell scripting
	- Strong analytical and problem-solving skills
+ skill set:
	- The machine learning research scientist’s primary role is to work with other R&D team members to imagine, define, and develop BrainChip’s spiking neural network technology. This research takes place at the interface between machine learning algorithms, event-based algorithms, and neuromorphic hardware. The research scientist will also be involved in developing commercial applications for BrainChip’s Akida Neuromorphic System-on-Chip (NSoC). Target commercial application topics include computer vision (object classification/detection and face recognition), audio processing (keyword spotting), and sensor fusion. Additionally, the team member will support the research team’s algorithm development for the next version of the Akida NSoC.
	- Ph.D. in computer science (or equivalent) or MS in computer science with +5 years of machine learning experience
	- 3+ years of machine learning experience using Python
	- Experience with supervised, unsupervised, and reinforcement learning
	- Experience in popular Deep Learning/Machine Learning frameworks (Keras, Tensorflow, PyTorch, Scikit-learn, etc.)
	- Experience in one or more of the following application fields: Image Processing/Computer Vision, ADAS, Anomaly Detection, Audio/Speech Processing, or Sensor Fusion.
	- Experience in Neuromorphic Engineering and/or Spiking Neural Networks
	- Experience with event-based algorithms
	- Experience with Git version control system
+ skill set for Research Scientist, Sculpting Evolution:
	- The Sculpting Evolution Group seeks to a research scientist to supervise and assist research projects focused on advancing biotechnology safely. Ideal candidates will be committed to glimpsing the best possibilities of the future and making them real.
	- On a practical level, we’re looking for people who:
		* Enjoy hands-on work with a wide variety of experimental systems and biology-relevant laboratory techniques,
		* Love continually learning, developing, applying, and teaching new methods and techniques,
		* Are happy to be asked for help, to lend a hand when it’s possible, and to say no when it’s not,
		* Have strong written and oral communication skills,
		* Do their best to contribute to a supportive team atmosphere with explicit proactive communication,
		* Are enthusiastic about mentorship and committed to building an outstanding research team.
	- Broader views are also important. Particularly strong candidates might be those who:
		* Aim to ensure that biotechnology benefits as many morally relevant beings as possible,
		* Recognize the importance of mitigating catastrophic risks,
		* Care more about long-term impact than conventional metrics,
		* Gladly seize upon a small chance of achieving a tremendously impactful outcome.
	- The group’s overt research interests have shifted over the past few years. We retain a focus on understanding and controlling evolution, including but not limited to our PRANCE system for high-throughput robotic directed evolution, and adding machine learning and in silico directed evolution to our repertoire. However, we now focus more on engineering mammalian systems, not just in developing novel genome editing approaches relevant to ecological engineering, but also with relevance to biosecurity and mitigating catastrophic risks, for some of the reasons outlined here. Example ongoing projects in this area include SecureDNA and the Nucleic Acid Observatory; we also work on receptor decoys and other broad-spectrum or rapidly scalable defenses against exponentially spreading agents. As these projects span an impressively large number of fields, we seek generalists with expertise covering several of them.
	- On a day-to-day level, the position will involve designing and performing experiments, supervising diverse research projects in the group, training and mentoring new arrivals, helping manage key collaborations, writing publications and grant proposals, and optionally engaging in science communication to general audiences or to policymakers. Given the breadth of research methods that we employ, willingness to learn new skills and techniques is a must.
	- REQUIRED:
		* PhD in Biology, Chemisty, Physics, Bioinformatics, MechE, or Computer Science or related field;
		* Skilled at troubleshooting experiments involving complex systems;
		* Specialized expertise in multiple fields supporting our primary areas of interest:
		* Examples of valuable skill sets include but are not limited to:
			+ Genome, cell, and organism editing – applied to biosecurity, ecological engineering, and animal well-being
			+ Cell culture, virus propagation, genome editing, flow cytometry, animal husbandry
			+ Technology development – catalytic tools for beneficial applications in diverse settings
			+ Microbiology, chemical biology, evolutionary biology, robotics, bioinformatics, machine learning.
			+ Support for a major collaboration focused on developing wastewater and environmental metagenomic sequencing as an early warning system, including expertise in experimental design for sensitivity testing, sampling techniques, sequencing, and data processing, analysis, and storage.
	- PREFERRED:
		* One year of postdoctoral experience;
		* Ideally some level of skill in several of these, and willingness to pick up others:
		* Library construction, NGS sample preparation, sequencing, and data analysis
		* Mammalian cell culture and engineering
		* Experience with computational biology algorithms, including bioinformatics, computational structural biology, statistical machine learning, and deep learning
		* Experience with high-performance and cloud computing, especially AWS, as well as with Github and Docker
		* Basic familiarity with circuits, hardware, 3D printing, and/or robotics, or willingness to learn the basics
		* Strong written and oral communication skills
		* Enthusiastic about mentorship and helping others learn.
+ skill set:
	- As a member of our Compiler team, you will work with leaders from industry and academia to develop entirely new solutions for the toughest problems in AI compute. 
	- As deep neural network architectures evolve, they are becoming enormously parallel, and distributed. Compilers are needed to optimize the mappings of computation graphs to compute nodes. In this position, you will build the tools that generate distributed memory code from evolving intermediate representations. 
	- Design and devise graph semantics, intermediate representations, and abstraction layers between high-level definitions (like TensorFlow and Pytorch) and low-level distributed code 
	- Use state-of-the-art parallelization and partitioning techniques to automate generation, exploiting hand-written distributed kernels
	- Identify and implement novel program analysis and optimization techniques for compilers targeting linear algebra applications on distributed memory architectures 
	- Leverage open-source tools and compiler toolchains such as ISL, MLIR and LLVM to build domain specific language and compiler for programming Cerebras Wafer Scale Engine
	- Develop and optimize the LLVM backend target for various generations of Cerebras architecture
	- Bachelor’s, Master’s, PhD, or foreign equivalents in computer science, engineering, or related field 
	- Familiarity with high-level parallel program analysis and optimization 
	- Compiler experience; experience in code generation and optimization for distributed systems
	- Strong proficiency in C/C++ or other language for designing large, performant systems
	- Familiarity with Python or other scripting language. 
	- Familiarity with multi-thread and multi-process programming models
	- MLIR & LLVM compiler toolchain internals 
	- Polyhedral models, Integer Set Library (ISL) 
	- Familiarity with HPC kernels and their optimization 
	- IEEE floating point representations 
	- Familiarity with machine learning frameworks such as TensorFlow and Pytorch 
	- Knowledge of ML application areas and state-of-the-art networks in various application areas 
+ skill set:
	- As a member of our Compiler team, you will work with leaders from industry and academia to develop entirely new solutions for the toughest problems in AI compute. 
	- As deep neural network architectures evolve, they are becoming enormously parallel, and distributed. The Cerebras compiler efficiently maps this computation onto hundreds of thousands of compute nodes, leveraging novel hardware architecture features to maximize performance while maintaining correctness. LLVM is a critical component in the compilation process, not only performing low-level optimization and efficient mapping to hardware instructions, but also ensuring effective use of novel hardware features. 
	- Work with hardware architects to ensure future hardware designs maximize the performance accessible via automatic compilation while minimizing compiler complexity
	- Develop effective representations of Cerebras’ novel architectural features in LLVM IR
	- Extend the LLVM backend to target new hardware architectures, designing and implementing performant and correct mappings from LLVM IR to Cerebras’ novel hardware
	- Design and implement LLVM IR and backend optimizations, maximizing performance on deep learning and HPC workloads
	- Mentor junior engineers on development best practices and LLVM internals
	- Collaborate closely with teams developing related software components to ensure compatibility, robustness, quality, and performance
	- Contribute to the design of higher-level intermediate representations and domain specific languages and their mapping to LLVM IR
	- Maintain our production compiler in use by customers in both the ML and HPC domains
	- Bachelor’s or foreign equivalents in computer science, engineering, or related field 
	- 5+ years of experience developing optimizing compilers using the LLVM tool chain 
	- Strong C++ development skills
	- Excellent verbal and written communication skills
	- Able to collaborate effectively in a distributed team 
	- Master’s, PhD, or foreign equivalents in computer science, engineering, or related field 
	- Production compiler development experience, particularly developing LLVM target backends
	- Experience in the design and implementation of DSLs
	- Familiarity with machine learning frameworks and intermediate representations 
	- Experience with parallel programming techniques and optimizations
+ skill set:
	- Cerebras’ Wafer Scale Engine (WSE) was designed to provide significant reduction of training times for deep neural networks. Our goal is to provide customers with the computational power needed to iterate faster so that they can develop the most accurate models possible. 
	- As an applied machine learning engineer, you will work on adapting state of the art deep learning (DL) models to run on our wafer scale system. This includes both functional validation and performance tuning of a variety of core models for applications like Natural Language Processing (NLP), Computer Vision (CV), Graph Neural Networks (GNN), Recurrent Neural Networks (RNN), and Recommendation models. 
	- As a member of the Cerebras engineering team you will be implementing models in popular DL frameworks like TensorFlow and PyTorch and using insights into our hardware architecture to unlock to full potential of our chip.  You will work on all aspects of the DL model pipeline including: 
		* Dataloader implementation and performance optimization 
		* Reference model implementation and functional validation 
		* Model convergence tuning 
		* Model performance optimization 
		* Model customization to meet customer needs 
	- This role will allow you to work closely with partner companies at the forefront of their fields across many industries. You will get to see how deep learning is being applied to some of the world’s most difficult problems today and help ML researchers in these fields to innovate more rapidly and in ways that are not currently possible on other hardware systems. 
	- Analyze, implement, and optimize DL models for the WSE 
	- Functional and convergence of models on the WSE 
	- Work with engineering teams to optimize models for the Cerebras stack 
	- Support engineering teams in functional and performance scoping new models and layers 
	- Work with customers to optimize their models for the Cerebras stack 
	- Bachelor's degree in engineering, science, or related field 
	- Experience programming in modern language like Python or C++ 
	- In-depth understanding of DL learning methods and model architectures 
	- Experience with DL frameworks like PyTorch and TensorFlow 
	- A deep passion for cutting edge artificial intelligence techniques 
	- Master's or PhD in engineering, science or related field 
	- Understanding of hardware architecture 
	- Experience programming accelerators like GPUs and FPGAs
+ skill set:
	- Cerebras' fully-integrated system is built from the ground up with a singular focus on AI. To explore new techniques and algorithms at the frontier of machine learning uniquely enabled by our revolutionary technology, our experienced team of Machine Learning engineers and researchers work in collaboration with other experts in the company, giving insight and access to every level of our system stack.   
	- This is an applied research position with a focus on working with state-of-the-art research and developing novel models and algorithms on top of our core technology. We are interested in a wide range of machine learning algorithms and application domains with a focus on exploring new ideas that hold the potential to substantially reduce computational constraints limiting today's machine learning research.
	- Develop algorithms for training and inference in sparse neural networks
	- Develop novel optimizers and learning algorithms such as local learning rules and layer-parallel training
	- Develop novel network architectures and layers such as, normalization, activation functions, and parameter layers
	- Publish and present research at leading machine learning conferences
	- Experience with machine learning frameworks, such as TensorFlow, Caffe/2, and PyTorch.
	- Fluency in a programming language, such as Python and C
	- Strong grasp of linear algebra and statistics
	- Strong track record of relevant research success in roles at the level of doctoral, postdoctoral in academia or in industrial R&D
	- Strong track record of relevant publications/patents
	- Familiarity with HPC kernels and their optimization 
	- IEEE floating point representations 
	- Familiarity with machine learning frameworks such as TensorFlow and Pytorch 
	- Knowledge of ML application areas and state-of-the-art networks in various application areas 
+ ***Knowledge of industry standards, e.g. ETSI, ASTM, NEBS, IEC, UL, CSA, ISTA, etc.***
+ skill set:
	- As an ML Engineer on our team, you will work with leaders from industry and academia at the intersection of hardware and software to develop state-of-the-art solutions for emerging problems in AI compute.
	- The Cerebras software platform is designed to be targeted by today’s most relevant machine learning frameworks such as TensorFlow, PyTorch, and JAX. Our ML software engineers are responsible for integrating these frameworks to work with our own highly optimized software stack. Fundamentally, you will be enabling ML researchers to use the software tools and workflows of today to unlock the advanced hardware capabilities of tomorrow.  
	- In this role, you will create tools and design workflows that enable the development, training, and deployment of machine learning models on our new hardware system. The workflow covers from a small to an extremely large models with trillion of parameters. Furthermore, you will be lowering abstract computations expressed via third-party ML frameworks into representations that can be compiled into highly optimized executables that target the Cerebras system, and help us design a general backend that can accommodate most advance deep learning models. You will also have the opportunity to participate and contribute to open-source projects that we depend on. 
	- Work on the end-to-end training, eval, and inference workflow with customer-facing API
	- Distributed training both via data and model parallelism
	- Scale and optimize the data pipeline
	- Lower Deep Learning framework graph presentation into our internal IR and add any missing OPs
	- Compiler optimization such as graph rewrite, constant folding, common expression elimination, and canonization
	- Lower high-level OPs to low-level OPs such as affine dialect
	- Handle both static and dynamic computational graph
	- Bachelor’s, Master’s, or foreign equivalent in Computer Science, Engineering, or related
	- 5+ years software development experience
	- Understanding of state-of-the-art deep learning model architectures and training protocols
	- Strong Python and C++ development skills
	- Direct experience with at least one Deep Learning framework internals is strongly preferred
	- Contributed to a deep learning framework
	- Experience with distributed training algorithm
	- Familiar with deep learning model architecture
	- Experience with MLIR, LLVM, or TVM
+ ***Experience working with large data sets and distributed computing tools (e.g. Redshift, Presto)***
+ Take end to end ownership of machine learning systems - data pipelines, candidate extraction, feature engineering, model training, as well as integration into our production systems
+ ***TensorRT, Deepstream Projects in video, speech, or NLP***
+ skill set:
	- At Cleanlab you’ll get to
		* Spend 100% of your time writing open-source ML, with guidance from MIT PhDs who are prominent in ML research. Get paid a Silicon Valley engineer salary but have the ability to work remotely from wherever you want. And the cherry on top? You get to work with a modern tech stack (the latest tooling and ML models) at a dynamic startup to pioneer the rapidly growing field of data-centric AI.
	- What we’re looking for
		* First and foremost, strong software engineering skills and experience productionizing your code. You should be comfortable with large software systems and love building applications.
		* Contributed to the open-source community for more than 4 years, either via your own open-source package or via substantial contributions to existing open-source repositories, written blog posts, and tutorials.
		* Experience working in ML: processing data, deploying models, etc. We do not require deep theoretical ML expertise, but practical experience in ML projects is desired.
	- Responsibilities
		* Develop and contribute novel data-centric AI algorithms to Cleanlab’s open-source projects, via high quality implementations and maintaining the highest coding standards.
		* Be a good member of the open-source community (address Github issues and queries, review PRs, write crisp documentation/tutorials, help integrate with other packages).
		* Work on applied ML projects with Cleanlab enterprise customers.
		* Collaborate with other engineers to build large-scale systems and help establish a strong engineering culture across the company.
	- Qualifications
		* We select candidates based on strengths, not on weaknesses. Experience with the following is highly recommended, but not required:
			+ Python, NumPy
			+ pandas, scikit-learn
			+ ***PyTorch/PyTorch Lightning or TensorFlow + Keras***
		* Bonus:
			+ ***MLOps Experience with model deployment and monitoring (MLflow, Sagemaker, etc.)***
			+ Databases and ETL (Postgres, etc.)
			+ Cleanlab or other data-centric AI tools
			+ ***AutoGluon, H2O, or other AutoML tools***
			+ ***Tableau, DataBricks, Alteryx, Trifacta***
			+ ***Hugging Face, Snorkel, Weights and Biases, Gradio, Streamlit***
	- Working at Cleanlab is awesome! Beyond the opportunity to work at a well-funded (backed by Bain Capital Ventures) early stage AI tech company with an incredible, friendly founding team of MIT, Stanford, and Harvard graduates, all full-time employees receive the following:
		* $9,000 per year travel benefit
		* Travel enhances our empathy with different cultures and enables us to work together more effectively. It’s how we grow and learn: traveling is an essential part of what makes us human. At Cleanlab, every two months you will receive a $1500 reimbursable travel benefit (resets on Jan 1, March 1, May 1, July 1, Sep 1, Nov 1). This is a unique benefit that lets you work from Paris for a week in February, then take a backpacking trip in the Andes for a weekend in March. Cleanlab will cover the flight for your partner or friend, too, as long as you attend and its within the $1500 / two-month period. For remote employees, you can use this benefit to come work with us in Boston/SF from time to time (encouraged, but not required).
		* Premium health insurance
			+ We provide a fantastic $4 (we cover the rest) health insurance option. We also provide a $0 deductible 100% coverage premium health care option for those who prefer the best health insurance.
		* Stipend for attending conferences to keep up with the latest innovations in ML and software.
		* Competitive salary (+ equity offering for certain roles), with regular opportunities for a raise if things are going well.
	- Cleanlab is focused on data-centric AI (DCAI), providing algorithms/interfaces to help companies (across all industries) improve the quality of their datasets and diagnose/fix various issues in them. We develop next-generation DCAI algorithms that are publicly contributed via open-source (github.com/cleanlab), as well as SaaS enterprise products with interfaces for data scientists/engineers to effectively improve their data quality and produce more reliable ML models.
	- Founded by 3 ML PhDs from MIT and engineers/scientists from Stanford & Harvard, Cleanlab is a well-funded early-stage startup that is rapidly growing to transform the future of DCAI. Some of Cleanlab’s early work (while the company was still in stealth-mode) has been featured in various media such as: Wired, MIT Technology Review, and VentureBeat.
	- While many companies can help store/manage data or develop ML models, there exist few solutions today to improve the quality of existing data, which is the core asset of the modern enterprise. This is where you come in. At Cleanlab, you’ll be able to take ownership of critical projects that pioneer the future of data-centric AI.
	- We are a remote-first company, with roughly half of our team located near Boston, MA (EST time) and the other half located near San Francisco, CA (PST time).
+ skill set:
	- Work on cutting-edge MLOps with guidance from MIT PhDs who are prominent in ML research.
	- Develop large-scale web applications for data-centric AI. Our tools enable data scientists/engineers (across all industries) to effectively diagnose/fix issues in their datasets thus improving the quality of their business’s core asset.
	- Work on interesting challenges (model deployment/monitoring, managing massive datasets, rapidly scaling cloud deployments, etc.) at a dynamic startup operating in one of the fastest growing subfields of data science & AI.
	- As a Cleanlab software engineer, you will be responsible for Cleanlab Pro, a user-friendly web app built on our ML algorithms. You’ll orchestrate cloud infrastructure for data ingestion, model training, and data analysis, and you’ll optimize the reliability of our web app, model deployments, and data management systems.
	- We encourage applications from software engineers with DevOps/backend/cloud experience who have some familiarity with machine learning and are interested in furthering their MLOps skills. Your contributions to our SaaS tool will be used by data scientists/engineers across all industries to improve the quality of their data and reliability of ML models produced from this data. Come help us build the next generation of data-centric AI!
	- Orchestrate cloud infrastructure to reliably support a SaaS data and machine learning pipeline.
	- Design, develop, test, deploy, maintain, and improve software, using a modern tech stack.
	- Contribute cloud/container integrations and other deployment/monitoring solutions to Cleanlab’s open-source library.
	- Collaborate with other engineers to build and maintain large-scale systems and establish a strong engineering culture across the company.
	- We select candidates based on strengths, not based on weaknesses. Candidates should have at leat 3+ years experience developing web apps using a modern tech stack and shipping code to production.
		* Linux
		* Python
		* Shell
		* Java/C++
		* AWS
		* Docker + Kubernetes
		* Git
		* CI/Testing, e.g. Jenkins
		* Bonus:
			+ AWS DevOps Stack (https://aws.amazon.com/devops/)
			+ AWS Sagemaker
			+ MLSys/MLOps experience
			+ IaC, e.g. Ansible, Terraform
+ ***Infrastructure as Code (IaC)***:
	- ***Ansible***
	- ***Terraform***
	- https://en.wikipedia.org/wiki/Infrastructure_as_code
+ skill set:
	- Contribute to open-source with guidance from MIT PhDs who are prominent in ML research.
	- Develop large-scale web applications for data-centric AI. Our tools enable data scientists/engineers (across all industries) to effectively diagnose/fix issues in their datasets thus improving the quality of their business’s core asset.
	- Get paid a Silicon Valley engineer salary but have the ability to work remotely with flexible hours.
	- Work on interesting challenges (massive datasets, scaling systems, security/privacy, novel interfaces for data editing, etc.) using modern tech stack at a dynamic startup operating in one of the fastest growing subfields of data science & AI.
	- As a Cleanlab software engineer, you will be responsible for building Cleanlab Pro, a user-friendly web app built on our ML algorithms. You’ll work on scalable backend code for data ingestion, model training, and data analysis, and you’ll help design beautiful and easy-to-use interfaces for data visualization, interpretation, and correction.
	- We encourage applications from full-stack software engineers who have some familiarity with machine learning and are interested in furthering their skills in building MLOps applications. Your contributions to our SaaS tool will be used by data scientists/engineers across all industries to improve the quality of their data and reliability of ML models produced from this data. Come help us build the next generation of data-centric AI!
	- Developing a SaaS data and machine learning pipeline.
	- Design, develop, test, deploy, maintain, and improve software, using a modern tech stack.
	- Write server and client-side code for web applications, optimizing for speed, scale, and ease-of-use.
	- Collaborate with other engineers to build large-scale systems and help establish a strong engineering culture across the company.
	- We select candidates based on strengths, not based on weaknesses. Candidates should have at leat 3+ years experience developing web apps using a modern tech stack and shipping code to production.
	- Experience with the following is recommended (but not necessarily required):
		* Python, Flask
		* Relational databases (e.g. PostgreSQL)
		* JavaScript + React, HTML, CSS (and SCSS)
		* AWS (or other similar cloud tools like Azure, GCP)
	- Bonus points if you have experience with some of the following:
		* Docker, Kubernetes
sklearn, pandas
		* Distributed computing (Ray, Spark, etc.)
		* Model serving, deployment, sharing (Sagemaker, Triton, gradio, etc.)
+ skill set:
	- JavaScript/TypeScript
	- React.js/Next.js
	- HTML
	- CSS + some CSS Framework (Chakra UI, Tailwind, Bootstrap)
	- Module bundlers, e.g. Webpack
	- Visualization libraries, e.g. D3.js
	- React testing libraries, e.g. Jest
	- Desktop app frameworks, e.g. Electron
