+ skill set:
	- Familiarity with IPv4/IPv6 with standard OSI stack.
	- Familiarity with security vulnerabilities, patching third party software.
	- Familiarity with security compliance standards such as STIG, Common Criteria a plus.
+ skill set:
	- Experience in multiple virtualization environments such as VMware, KVM, OpenStack, AWS, Azure, GCP, and OCI.
	- Experience with Cassandra, MongoDB, Kafka, Elasticsearch, JavaScript, React, Node.js, AWS, Git, Linux and Python are all valuable pluses
	- Understanding of, or background using, high-speed networking devices such as firewalls, intrusion detection systems, intrusion prevention systems, or deep packet inspection (DPI) systems
+ skill set:
	- Experience working with Columnar Database (e.g. Vertica) with exposure to SQL and high-volume data loading
	- Elements (xNodeB, MME, SGW, AMF, SMF etc.), Interfaces (N1, S1-MME, S5/S8, etc.) and Protocols (GTP, SIP, Diameter etc.)
	- Experience with Atlassian toolset e.g. Jira, Confluence, Bitbucket
	- Any previous experience with reporting frameworks like MicroStrategy or similar is a plus
	- Knowledge SCM tools (e.g. Git), make and build automation (e.g. Jenkins), code testing (Junit/Mockito) with experience working in a Continuous Integration environment
	- Experience and knowledge of 4G LTE and 5G Networks is a plus for this role: experience working with some Network Elements (xNodeB, MME, SGW, AMF, SMF etc.), Interfaces (N1, S1-MME, S5/S8, etc.) and Protocols (GTP, SIP, Diameter etc.)
+ skill set:
	- Position Summary: Work with security and DDoS experts on the ASERT team to explore and analyze a vast array of data to extract trends, apply machine learning, and create user-friendly visibility into the data set.
	- Leverage data analysis and coding skills to extrapolate value from a data set that spans the globe and gives unique insight into adversary activity in the DDoS Threat Landscape.
	- Use multiple query languages to explore large data sets
	- Apply data science and machine learning to a decades worth of collection
	- Pursue a deeper study and correlation of internet routing/topology.
	- Synthesize the analysis into dashboards or some form of reporting mechanism.
+ skill set:
	- To learn about the latest trends in hiring, technology, software development practices, data science workflows, machine learning workflows, and research
+ skill set:
	- databases:
		* DynamoDB
		* Elasticsearch
		* Cassandra
		* Redis
		* IBM DB2
		* Couchbase
		* PostgreSQL
		* Microsoft SQL Server
		* SQLite
		* Oracle
		* MariaDB
		* MongoDB
		* MySQL
		* Firebase
	- platforms:
		* AWS
		* Microsoft Azure
		* Google Cloud Platform
		* IBM Cloud or Watson
		* Oracle Cloud Infrastructure
		* DigitalOcean
		* Heroku
	- Web frameworks:
		* Ruby on Rails
		* Svelte
		* ASP.NET Core
		* Gatsby
		* React.js
		* ASP.NET
		* Flask
		* FastAPI
		* Spring
		* Drupal
		* Vue.js
		* Angular.js
		* Angular
		* Express
		* jQuery
		* Symfony
		* Django
		* Laravel
	- frameworks and libraries:
		* Apache Spark
		* .NET Core / .NET 5
		* Hadoop
		* .NET Framework
		* NumPy
		* Pandas
		* Torch/PyTorch
		* Qt
		* TensorFlow
		* Keras
		* React Native
		* Cordova
		* Flutter
	- tools:
		* Pulumi
		* Terraform
		* Chef
		* Puppet
		* Kubernetes
		* Ansible
		* Deno
		* Docker
		* Yarn
		* Git
		* Flow
		* Xamarin
		* Unreal Engine
		* Unity 3D
	- Collaboration Tools:
		* TextMate
		* Emacs
		* RubyMine
		* Rider
		* Vim
		* Neovim
		* IntelliJ
		* Xcode
		* Visual Studio
		* RStudio
		* Visual Studio Code
		* IPython/Jupyter
		* PyCharm
		* Notepad++
		* Webstorm
		* Sublime Text
		* Atom
		* Eclipse
		* PHPStorm
		* Android Studio
		* NetBeans
+ skill set:
	- Bachelor’s or Master’s degree in computer science or related engineering fields
	- 8+ years of software development with C and C++ languages in a U-Boot/UEFI and Linux in an embedded or server environment
	- Hands-on programming experience with the Linux kernel internals, device drivers for multi-core SoCs, Linux networking and PCIe sub-systems
	- UEFI BIOS/EDK2.1 experience and low-level embedded firmware development experience
	- Hands-on experience with the GNU/LLVM tool chain and debuggers like GDB
	- Hands-on programming and debugging experience with board bring-up and BSP delivery
	- Experience in performance optimization at the firmware, bios, kernel and application layers including hardware accelerators
	- Ability to work independently and across geographies with hardware, SQA and product management teams
	- Excellent problem-solving and debugging skills and good English communications skills, both verbal and writing
	- Practical experence in two or more of the following: U-Boot, UEFI, Linux, Virtualization, Hypervisor, KVM, QEMU, Device Drivers, PCI-E, Ethernet, USB, DPDK, NFV, Network Programming
	- Good understanding of CPU architecture, ARM or X86
	- Knowledge of Linux power management, Linux Reliability-Availability-Serviceability (RAS) framework, DPDK, Control Plane, SMART NIC, Networking Fast Path and the Linux Storage stack will be an added plus
	- Development experience with Virtualization and Hypervisors including KVM and QEMU
	- Experience working in multi-core, multi-process/thread environment
	- Knowledge of open source Linux, source code upstreaming, git repository maintenance and source code management and kernel.org flow understanding
	- Understanding of AL/ML frameworks like TensorFlow will be an added plus
+ skill set:
	- Tenstorrent is looking for an experienced Machine Learning engineer to support our growing customer base as they build Deep Learning models on Tenstorrent hardware. If you're enthusiastic about Machine Learning, are a competent software engineer, and enjoy working with other people, this is your opportunity to be at the bleeding edge of AI processing. You'll get exposure to a broad array of problem types from different industries and be at the forefront of our customer engagements.
	- Work with the customer-facing team to support clients with their ML models on Tenstorrent hardware
	- Designing and developing demonstration machine learning and deep learning systems
	- ***Model benchmarking***
	- Running machine learning tests and experiments on behalf of customers
	- Implementing appropriate ML algorithms
	- Select appropriate datasets and data representation methods
	- ***Run machine learning tests and experiments***
	- ***Perform statistical analysis and fine-tuning using test results***
	- ***Train and retrain systems when necessary***
	- ***Extend existing ML libraries and frameworks***
	- ***Develop novel ML models and primitives that take advantage of Tenstorrent’s breakthrough architecture to deliver orders of magnitude performance & efficiency improvements***
	- Student in Electrical/Computer Engineering, Computer Science, Machine Intelligence, Engineering Science, or Math;
	- 5 years of experience as a Machine Learning Engineer or similar role (a fleshed out GitHub repo a plus)
	- Experience with algorithms, data structures, and software development in Python and C/C++.
	- Deep knowledge of math, probability, statistics and algorithms
	- Experience in solving business problems with Machine Learning models
	- Familiarity with and passion for any of the following -- machine learning, compilers, parallel programming, high-performance and massively parallel systems, processor and computer architecture -- is a plus
	- Travel at 15% to 25% will be required.
+ skill set:
	- Tenstorrent is seeking a High-Performance Computing (HPC) Systems Engineer to support Accelerated ML Storage platforms. You will focus on delivery of ML storage services with an emphasis of multi-tenant cloud storage requirements. Duties include administrating both high-speed and archiving cloud storage services. You will also be responsible for understanding workload bottlenecks and work with all necessary teams to drive resolution.
	- Build and maintain high-performance storage environments designed for multi-tenant HPC cloud
	- Work closely with other AI/ML Engineers and Data Engineering Subject Matter Experts
	- Work with Central IT, Cybersecurity, and Engineering teams for both on-premises and cloud deployments
	- Ensure user and technical issues are promptly prioritized and resolved
	- Effectively communicating with cloud tenants as required
	- Monitor resource usage and planning for increased capacity
	- Additional responsibilities assigned from time to time
	- Bachelor’s Degree in a related discipline or equivalent experience, with 3 years of professional experience
	- Ceph Certified Specialist or equivalent experience
	- Strong sense of urgency, client-oriented and ability to maintain positive partnerships
	- ***Experience with Ceph, Swift, Luster, NFS, S3, and/or high-performance storage***
	- Experience with performance measuring/modelling of high-performance storage
	- ***Experience with OpenStack***
	- ***Automation using tools such as Ansible, Puppet, BASH and Python Scripting***
	- Willing to roll up your sleeves and help out with hardware and software issues
	- ***Experience with Luster, Weka, Vast, and/or Spectrum Scale***
	- ***Familiarity with Container Storage, including Container Storage Interfaces (CSI) and Persistent Volumes***
	- ***Familiarity with Infrastructure Automation***
	- ***Familiarity of Data Center design, including server hardware, rack diagrams, power, and cooling requirements***
	- ***Knowledge of Monitoring and Performance, such as Prometheus, Grafana, Dynatrace, Sysdig***
+ skill set:
	- Tenstorrent is seeking a High-Performance Computing (HPC) Systems Architect for OpenStack multi-tenant cloud deployments. You will have the chance to architect multiple clusters, ensure all data is managed and secure, and deploy and support changing requirements. The ideal candidate will be proficient in cluster administration, network administration, relevant virtualization, and relationship to storage. You will support an environment with guarantees of no data leakage, rapid recovery process from VM snapshots, and support substantial cluster service scale and growth.
	- ***Architect and evolve our Tenstorrent OpenStack environment***
	- Linux system configuration, and administration
	- Understand cluster requirements with evolving customer needs. Design and implement solution meeting requirements
	- Work across teams to provide feedback and guidance in the evolution of the platform support and maintenance practices
	- Build process and procedures through comprehensive testing resulting in published documentation
	- Define support team for all cloud tenants
	- Effectively communicate with cloud tenants as required
	- Additional responsibilities assigned from time to time
	- Bachelor’s Degree in a related discipline or equivalent experience, with 6+ years of professional experience
	- 4+ years of experience of architecture experience in an OpenStack environment
	- 5+ years of experience with Linux configuration, and administration
	- Strong client service orientation and ability to maintain positive partnerships
	- Certified OpenStack Administrator or equivalent experience
	- Detailed knowledge of one of the public clouds
	- Experience with Containers
	- ***Automation using tools such as Ansible, Puppet, BASH and Python Scripting***
	- Provide product training through webinars and workshops
	- Excellent planning and problem-solving skills
	- Organized and track record of managing complex projects
	- Ability to work with internal developers to collect feedback, prioritize tasks, and manage the engineering backlog
	- Willing to roll up your sleeves and help out with hardware and software issues
	- ***Experience with Ceph/Swift***
	- ***Membership and extensive interaction with the OpenStack community and active participation in the core projects***
	- ***Familiarity with Infrastructure Automation***
	- ***Familiarity with Kubernetes***
	- ***Familiarity of Data Center design, including server hardware, rack diagrams, power, and cooling requirements***
	- ***Knowledge of Canonical’s OpenStack***
	- ***Knowledge of Monitoring and Performance, such as Prometheus, Grafana***
	- ***Knowledge of Container Security, such as Falco, Sysdig Secure, Aqua, or Anchore***
	- ***Knowledge of Image Registries, such as Quay, Harbor, Docker Registry***
	- ***Knowledge of ML/AI Orchestration, such as Kubeflow, OpenDataHub.io, or Domino***
+ skill set:
	- Implementation of Tenstorrent IP and SOC RTL logic in Verilog
	- Architecture exploration and modeling
	- ***Occasional verification of Tenstorrent's IP and SOC logic, using advanced verification methodologies –UVM, FPGA prototyping, and emulation***
	- Performance and power verification and validation of Tenstorrent's IP and SOC
	- Runtime firmware and low-level software implementation
	- Benchmark and analyze performance optimizations for key machine learning algorithms across Tenstorrent hardware and software stack
	- Development of frameworks for automating post-silicon verification, data analysis and debug
	- Support board/system design and debug
	- Knowledge of Hardware Description Languages (Verilog/VHDL)
	- Interest and knowledge of processor/computer architecture
	- Interest and knowledge of the full ASIC design flow, including design, verification, synthesis, P&R
	- C/C++ as well as scripting languages (C, C++, Python, Perl, tcl)
	- Experience with high frequency logic design, scalar and vector processor architecture, GPU architecture and programming models, digital signal processing hardware, SoC architecture, memory sub system architecture, real time hardware/firmware systems and PCB design is very beneficial
	- Understanding of deep learning concepts and familiarity with popular machine learning frameworks and models
	- Strong analytical and problem-solving skills
+ skill set:
	- Position is ASIC Test Engineer for industry leading AI/ML ASICs. The person coming into this role will conduct post-silicon characterization and testing to verify the functionality and timing of internal blocks and interfaces in our ASICs, and collaborate with DV and DFT teams to develop test requirements and test patterns. The work is done alongside a group of highly experienced engineers across various domains of the AI ASIC.
	- Track test execution to confirm all features are validated.
	- Convert design specifications into characterization and test plans.
	- Translate patterns and sequences into tester format to run on ATE and SLT.
	- ***Help develop ATE load boards, SLT interface boards, and sockets.***
	- Prepare for first silicon arrival with prioritized test plans that includes enablement of IP and critical features.
	- Work with test systems, tools, and lab equipment to debug ASIC faults.
	- Leverage lessons from current products to drive continuous improvements into future products.
	- BS/MS/PhD in EE/ECE/CE/CS with at least 5 years of industry experience in advanced testing techniques.
	- ***Experience with SLT, ATE, and new product introduction.***
	- ***Proficiency with test equipment such as oscilloscopes, protocol/logic/network analyzers and signal generators.***
	- Successful track record debugging SOC and board-level faults.
	- ***Experience testing CPUs, high speed SERDES, PCIe, DDR, and PLLs is desirable.***
	- ***Solid understanding of DFx features and standards including scan, ASST, MBIST, IEEE 1149.6, JTAG, and IJTAG, and fluency in RTL coding for DFx logic a plus.***
	- Good understanding of PCB fabrication, server-class compliance standards, signal and power integrity (SI/PI) methods, thermal and mechanical analysis tools.
	- Strong scripting skills in C/C++, Python, Perl, Java, Bugzilla, TCL, or Ruby.
+ skill set:
	- Position is Hardware Test Engineer for industry leading AI/ML ASICs. The person coming into this role will conduct post-silicon characterization and testing to verify the functionality and timing of internal blocks and interfaces in our ASICs, and collaborate with DV and DFT teams to develop test requirements and test patterns. The work is done alongside a group of highly experienced engineers across various domains of the AI ASIC.
	- Work closely with the Design for Test and Design Verification teams on test vectors, coverage, and diagnostics.
	- Track test execution to confirm all features are validated.
	- Convert design specifications into characterization and test plans.
	- Translate patterns and sequences into tester format to run on ATE and SLT.
	- Help develop ATE load boards, SLT interface boards, and sockets.
	- Prepare for first silicon arrival with prioritized test plans that includes enablement of IP and critical features.
	- Work with test systems, tools, and lab equipment to analyze ASIC faults.
	- Collect and analyze volume fault data for root cause identification.
	- Debug issues found during bring-up, characterization, validation, and production.
	- ***Generate voltage/frequency shmoos.***
	- Leverage lessons from current products to drive continuous improvements into future products.
	- BS/MS/PhD in EE/ECE/CE/CS with at least 5 years of industry experience in advanced testing techniques.
	- Experience with SLT, ATE, new product introduction, and high-volume production enablement.
	- Experience interfacing with OSATs and delivering converted ATE patterns for production runs.
	- Proficiency with test equipment such as oscilloscopes, protocol/logic/network analyzers and signal generators.
	- Expertise with processor characterization, speed path testing, frequency/power sort using ATE, and guard-banding for volume shipping.
	- Successful track record debugging SOC and board-level faults.
	- ***Experience testing CPUs, high speed SERDES, PCIe, DDR, and PLLs is desirable.***
	- Good fundamentals in digital ASIC design, CMOS, and reliability.
	- Strong scripting skills in C/C++, Python, Perl, Java, TCL, and/or Ruby.
	- Experience with Bugzilla, LoadRunner, and Apache Maven.
	- ***Solid understanding of DFx features and standards including scan, ASST, MBIST, IEEE 1149.6, IEEE 1687, and IEEE 1500.***
	- Fluency in RTL coding for DFx logic is a plus.
	- Basic understanding of DFT fault models.
	- Good understanding of PCB fabrication, server-class compliance standards, signal and power integrity (SI/PI) methods, thermal and mechanical analysis tools.
+ skill set:
	- Position is ASIC Production Test Engineer for industry leading AI/ML ASICs. The person coming into this role will enable and conduct high-volume production testing of ASICs in preparation for shipping. The work is done alongside a group of highly experienced engineers across various domains of the AI ASIC.
	- Assist in initial silicon bring-up and debug, and provide feedback for changes needed for volume production.
	- Assist in requirements and inputs for ATE load boards, SLT interface boards, and sockets.
	- Collect and analyze volume fault data for root cause identification and yield improvement opportunities.
	- Track and help improve production yield.
	- Debug issues found during validation and production.
	- Generate voltage/frequency shmoos.
	- Determine characterization test needs and requirements for ASICs for volume production.
	- Leverage lessons from current products to drive continuous improvements into future products.
	- BS/MS/PhD in EE/ECE/CE/CS with at least 5 years of industry experience in advanced testing techniques.
	- Experience with SLT, ATE, new product introduction, and high-volume production enablement.
	- Experience interfacing with OSATs and delivering ATE patterns for production runs.
	- Expertise with processor characterization, speed path testing, frequency/power sort using ATE, and guard-banding for volume shipping.
	- Experience testing CPUs, high speed SERDES, PCIe, DDR, and PLLs is desirable.
	- Basic understanding of DFT fault models.
	- Good understanding of PCB fabrication, server-class compliance standards, signal and power integrity (SI/PI) methods, thermal and mechanical analysis tools.
	- Good understanding of diagnostic and yield enhancement tools.
	- Strong scripting skills in C/C++, Python, Perl, Java, Bugzilla, TCL, or Ruby.
+ skill set:
	- Tenstorrent is growing and we are looking for an IT Systems & Support Administrator for our Austin office. You will be our Austin IT Lead to support daily activities and work on cross site projects.
	- Deployment, maintenance, support and monitoring of our infrastructure in the Austin office
	- Be the onsite IT presence, therefore support and troubleshoot local technical issues from laptops to AV equipment, Administration of local and in part of entire network wide CentOS and Ubuntu Linux systems; systems security tasks including security scanning, patching and systems hardening
	- Configure, add and maintain laptop, server, and network inventory
	- Partnership across sites on various IT projects
	- Other task and duties as determined from time to time
	- This role will have a physical as well as remote administration and support aspect.
	- Degree/diploma in Computer Science or demonstrated combination of education and experience
	- 2 plus years of Systems Administration experience in a small to mid-size company using Linux (CentOS/Redhat) with a Linux+ certification
	- 2 plus years of installation and maintenance of enterprise level hardware, small deployments count provided its standard equipment
	- Network management, both physical infrastructure cabling and switches/firewall - 1 year experience is preferable
	- Experience with Veeam Back-ups or similar tools, managing backup & restoration implementation and testing
	- Proficient with SNMP/Nagios/Managed Engine based Monitoring, ElasticSearch, Jamf and Grafana
	- Worked with firewalls (Fortinet) and Linux based firewall (IPTABLES/IPCHAINS)
	- Strong documentation abilities necessary to ensure timely problem resolution
	- Experience with container orchestration systems (such as Kubernetes, Docker, Amazon ECS, EKS, Rancher)
	- Skilled at managing cloud-based environments in AWS and Azure
	- Proven ability to work autonomously with limited direction and oversight
	- Network Administration with CCNA certification
	- Strong technical problem-solving skills and experience in IP networking and static routing FTP, SSH, SMTP, DNS, HTTP/S, DHCP
	- Python and other scripting languages such as bash, Ruby etc (Nice to have)
	- Intermediate knowledge of TCP/IP including the usage of stateful and stateless firewalls, access control lists, packet capture and logging, network design, Subnetting, IP routing, IPSEC virtual private networks, and intrusion detection and prevention
	- Worked with automation/configuration management tools using Ansible, Chef or an equivalent an asset
	- Mac support and experience with Jamf is preferable
+ skill set:
	- Position is Design for Test and Design for Debug (DFT/DFD or DFx) engineer for high-performance designs going into industry leading AI/ML architecture. The person coming into this role will be involved in all aspects of implementation and verification of advanced DFx techniques for various IPs. High level challenges include reducing test cost while attaining high coverage, and facilitating debug and yield learnings while minimizing design intrusions. The work is done alongside with a group of highly experienced engineers across various domains of the AI ASIC.
	- ATPG and test coverage analysis using industry standard tools.
	- ***JTAG, Scan Compression, and ASST implementation.***
	- Gate level simulation using Synopsys VCS and Verdi.
	- Support silicon bring-up and debug.
	- MBIST planning, implementation, and verification.
	- Support Test Engineering on planning, patterns, and debug.
	- Develop efficient DFx flows and methodology compatible with front end and physical design flows.
	- BS/MS/PhD in EE/ECE/CE/CS with at least 5 years of industry experience in advanced DFx techniques.
	- DFx experience implementing in finFET technologies.
	- Experience with industry standard ATPG and DFx insertion CAD tools.
	- Familiarity with System Verilog and UVM.
	- ***Fluent in RTL coding for DFx logic including lock-up latches, clock gates, and scan anchors.***
	- Understanding of low-power design flows such as power gating, multi-Vt and voltage scaling.
	- Good understanding of high-performance, low-power design fundamentals.
	- ***Knowledge of fault models including Stuck-at, Transition, Gate-Exhaustive, Path Delay, IDDQ, and Cell Aware.***
	- Exposure to post-silicon testing and tester pattern debug are major assets.
	- Experience with Fault Campaigns a plus.
	- Strong problem solving and debug skills across various levels of design hierarchies.
+ skill set:
	- SOC Fabric Architect
	- ***Software 2.0 is redefining the computing paradigm.*** The new paradigm computation demand is incommensurable with the existing software and hardware criteria. The solutions require unifying the innovations on the software programming model, compiler technology, heterogenous computation platform, networking technology, and semiconductor process and packaging technology. Do you want to join a dynamic team of hardware and software architects building the leading hardware platform for Machine Learning and Artificial Intelligence?
	- ***Collaborate with the software team and platform architecture team to understand fabric bandwidth and latency requirements and real-time constraints for AI accelerator, CPU, security, and networking traffic. Devise QoS and ordering rules among the CPU, accelerator, and IO coherent/non-coherent traffics.***
	- Identify representative traffic patterns for the software applications. Perform data-driven analysis to evaluate fabric topology, QoS, memory architecture, and u-architecture solutions to improve performance, power efficiency, or reduce hardware.
	- Create directory-based cache coherency specification to satisfy performance requirements of coherent multiple-cluster CPU system and accelerator. Make tradeoff protocol complexity and performance requirements.
	- Set SOC fabric architecture direction based on the data analysis and work with a cross-functional team to achieve the best hardware/software solutions to meet PPA goals.
	- Develop an SoC cycle-accurate performance model that includes memory sub-systems, directory-based coherent cache controllers, fabric interconnects, and fabric switches that describe the microarchitecture and use it to evaluate new features.
	- Collaborate with RTL and Physical design engineers to make power, performance, and area tradeoffs.
	- Drive analysis and correlation of performance feature both pre and post-silicon.
	- BS/MS/PhD in EE/ECE/CE/CS
	- ***Strong grasp of NoC topologies, routing algorithms, and QoS***
	- ***Expertise in cache coherency protocols (AMBA CHI/AXI protocol), DDR/LPDDR/GDDR memory technology, and IO technology (PCIe/CCIX/CXL).***
	- Prior experience or a strong understanding of traffic patterns for ML/AI algorithms in a heterogeneous computation system is a plus.
	- ***Prior experience on formal verification of cache coherency protocol is a plus.***
	- Proficient in C/C++ programming. Experience in the development of highly efficient C/C++ CPU models.
+ skill set:
	- Develop physical design flow for high-performance designs going into industry leading AI/ML architecture. The person coming into this role will be involved in all aspects of optimizing flows from synthesis to tape-out for various IPs on the chip. The work is done alongside a group of highly experienced engineers across various domains of the AI chip.
	- Work closely with physical design team and tool vendors to define flow requirements
	- Flow tasks may include enabling targets such as floor-planning, synthesis, PnR, timing and phyv closure
	- Optimize and support PnR flow to ensure quality results on schedule
	- Discussions with vendor tool providers, foundry partners and design services
	- End to end tasks from flow development to sign-off
	- Deploy innovative techniques for improving power, performance and area of the design, drive experiments with PD, and evaluate PnR, timing and power results
	- BS/MS/PhD in EE/ECE/CE/CS with at least 5 years of industry experience
	- Hands-on experience with synthesis, block and chip level implementation with industry standard PnR flows and tools
	- Strong experience in SOC/ASIC/GPU/CPU design flows on taped out designs, expertise in timing closure at block/chip levels and ECO flows
	- Experience with back-end design tools such as Primetime, Innovus, RedHawk, etc.
	- ***Knowledge of low-power design flows such as power gating, multi-Vt and voltage scaling***
	- Strong programming skills in Tcl/Perl/Shell/Python
	- Excellent understanding of logic design fundamentals and gate/transistor level implementation
	- Exposure to DFT is an asset
	- Prior experience working on high performance technology nodes and understanding of deep sub-micron design problems/solutions
	- Strong problem solving and debug skills across various levels of design hierarchies
+ skill set:
	- Software Runtime Principal Engineer (CA, TX or ON)
	- Provide technical guidance and direction to junior staff member
	- Work closely across teams to discover the hardware and software requirements of current and future machine learning applications
	- Develop performance analysis and debug tools
	- Develop firmware for Tenstorrent hardware
	- Develop highly optimized kernels in C++ and assembly to implement complex ML operations
	- Analyze, optimize, and fine-tune performance of key machine learning applications on various configurations of Tenstorrent hardware
	- Extensive working experience with one or more: firmware, low-level programming, optimizing kernels, hardware debug
	- Close familiarity with computer architecture, comfortable working with hardware
	- 7+ years of experience working with algorithms, data structures, and software development
	- C/C++, Python
	- Bachelors in Computer Science or Electrical/Computer Engineering or Engineering Science
	- Excellent verbal and written communication skills
	- Ability to work across multiple teams
	- 2+ years of experience as a technical lead, developing and mentoring a team
	- Masters/PhD in Computer Science or Electrical/Computer Engineering or Engineering Science
+ skill set:
	- Hardware and system knowledge including bare metal compute, colocation centers, and cloud
	- ML frameworks and workloads
+ skill set:
	- Design and development of scalable verification infrastructure for high performance CPUs going into industry leading AI/ML architecture. The person coming into this role will help define DV methodology and create tools and flows that will enable a multi-discipline and multi-site team to execute flawlessly. The person in this role will collaborate with a group of highly experienced engineers across various domains of the AI chip.
	- Architecture and hands-on development of scalable solutions that are leveraged for DV testbenches, architectural tools, RTL development and performance modelling across CPU, compute engines and SOCs
	- Development of automation systems for the entire design team
	- Engage with leading industry vendors and 3rd party IP providers, drive integration of external tools and IPs in the design flow
	- Experience with open-source tool-flows and deployment of applicable tools and infrastructure in the design flow; drive tool decisions for build vs leverage vs buy
	- Own regular block/chip/emulation regressions
	- Experience with development of DV tools and infrastructure and large-scale regression environments is required, extensive debug of automation workflows
	- Knowledge of EDA tools, strong understanding of simulators. Hands-on experience working with emulation environment and tools is a plus
	- Expertise developing tools for revision control, prior experience with git preferred
	- Very strong programming skills in C/C++, scripting skills in Python, Tcl, Perl
	- Knowledge of multiple testbench methodologies, proficiency in UVM is a plus
	- Strong problem solving and debug skills across various levels of design hierarchies
	- BS/MS/PhD in EE/ECE/CE/CS with at least 5 years of industry experience
+ skill set:
	- As an FPGA design engineer in our System Engineering team, you will be focusing on architecture and design of interconnect solutions for multi-processor systems, as well as FPGA emulation of Tenstorrent’s AI processors.
	- Participation in next generation deep learning system architecture – a “full stack” effort spanning software, processor and system architecture teams
	- High speed digital design of new components targeting state of the art Xilinx and Intel FPGAs
	- Conversion of ASIC designs to FPGA for emulation purposes
	- Participation in PCB architecture and simulation
	- Bring up, debug, validation
	- Bachelor or Master’s in Electrical or Computer Engineering
	- Expert knowledge of hardware description languages (Verilog/VHDL)
	- Superior analytical and problem-solving skills
	- Excellent understanding of computer architecture and logic design
	- Strong understanding of high-speed serial interfaces
	- Solid programming skills (C, C++, Python, Perl)
	- Experience using lab equipment: high speed oscilloscopes, logic and protocol analyzers, spectrum analyzers, etc.
	- Interest in and understanding of machine learning
	- Superior verbal and written communication skills
+ skill set:
	- As a ML processor bring-up and validation engineer in our System Engineering team, you will have a unique opportunity to work at the intersection of machine learning and systems engineering: performing combined tuning of model + system parameters, studying sparsity and data statistics vs. power/temperature; debugging performance and power bottlenecks for modern machine learning models. Additionally, the successful candidate will gain experience with state-of-the art ML processor architecture, embedded firmware development, FPGA and board design and debug.
	- Development of post-silicon test and characterization/tuning plans
	- ML processor bring-up and validation
	- Firmware development in C++
	- Architecture and development of frameworks for automating post-silicon verification, data analysis and debug
	- RTL development for FPGAs
	- Power/performance/speed characterization, data analysis and product definition
	- Bachelor or Master’s in Electrical or Computer Engineering
	- Superior analytical and problem-solving skills
	- Excellent programming skills (C, C++, Python, Perl)
	- Strong understanding of computer architecture and logic design
	- Good understanding of circuit design, power regulation, high speed signal propagation
	- Understanding of machine learning concepts and familiarity with popular machine learning frameworks and models
	- Experience using lab equipment: high speed oscilloscopes, logic and protocol analyzers, spectrum analyzers, etc.
	- Interest in and understanding of machine learning
	- Superior verbal and written communication skills
	- Ability to work cross functionally and drive issues to closure
+ skill set:
	- Principal Engineer, Compilers
	- In partnership with the leadership team, create and define the product roadmap and co-design of Tenstorrent's hardware and software stack
	- ***Develop machine learning graph compiler***
	- ***Be the subject matter expert across one or more areas: scheduling, parallelization, memory allocation, data flow optimizations, optimizing kernels***
	- ***Define the benchmark, analyze, and optimize performance of key machine learning applications across Tenstorrent's hardware and software stack***
	- ***Develop performance analysis and estimation infrastructure that feeds into Tenstorrent compiler***
	- ***Integrate the Tenstorrent software into leading machine learning frameworks***
	- Provide technical guidance and direction to junior staff member
	- Work closely across teams to discover the hardware and software requirements of current and future machine learning applications
	- ***Deep understanding of IR and machine level compiler optimization techniques.***
	- ***Extensive working experience with one or more: scheduling, parallelization, memory allocation, data flow optimizations, optimizing kernels***
	- 7+ years of experience working with algorithms, data structures, and software development
	- C++, Python
	- Bachelors in Computer Science or Electrical/Computer Engineering or Engineering Science
	- Excellent verbal and written communication skills
	- Ability to work across multiple teams
	- 2+ years of experience as a technical lead, developing and mentoring a team
	- Experience contributing to open-source projects, and demonstrated influence in the open community.
	- Masters/PhD in Computer Science or Electrical/Computer Engineering or Engineering Science
	- Software development in Python
+ skill set:
	- In this role, you will learn Functional verification of high-performance CPUs going into industry leading AI/ML architecture. You will be mentored by and work alongside a group of highly experienced engineers across various domains of the AI chip.
	- Develop and execute DV testplans for ISA and microarchitecture
	- Understand and debug RTL code for the CPU and help make changes to the design
	- Help with development of architectural tools for ISA level verification
	- Write C/assembly based stimulus that scales from pre-silicon to emulation and post-silicon domain
	- Help with infrastructure and tool development for RTL, Performance and DV environments
	- Support development and integration of testbench components such as microarchitectural models, checkers and coverage
	- Senior year BS/MS or PhD candidate in EE/ECE/CE/CS with a strong GPA
	- Prior academic work in the field of computer architecture, internship experience preferred
	- Academic projects in C++ / SV / UVM as well knowledge of scripting languages
	- Understanding of assembly level programming
	- Knowledge of hardware description languages (Verilog, VHDL)
	- Strong academic skills or internship experience in verification methodologies and techniques – Simulation/debug, TB development, stimulus, checking, coverage
	- Strong problem solving and analytical skills
+ skill set:
	- Collaborate with the software team and platform architecture team to understand CPU hardware requirements for AI accelerator compiler, OS, video/image/voice processing, security, networking, and virtualization technology. Identify the application performance bottlenecks.
	- Identify representative benchmarks for the software applications. Use the benchmarks and the performance model to perform data-driven analysis to evaluate software, architecture, and u-architecture solutions to improve performance, power efficiency, or reduce hardware.
	- Set CPU architecture direction based on the data analysis and work with a cross-functional team to achieve the best hardware/software solutions to meet PPA goals.
	- Develop a cycle-accurate CPU model that describes the microarchitecture, use it for evaluation of new features.
	- Collaborate with RTL and Physical design engineers to make power, performance, and area trade-offs.
	- Drive analysis and correlation of performance feature both pre and post-silicon.
	- BS/MS/PhD in EE/ECE/CE/CS
	- Strong background in CPU ISA's, u-architecture research, and performance benchmarks.
	- Understanding SOC fabric, coherency protocols, memory technology, and accelerator technology is a plus.
	- Prior experience or strong understanding of ML/AI algorithms, compiler, and OS kernel is a plus.
	- Proficient in C/C++ programming. Experience in the development of highly efficient C/C++ CPU models.
+ skill set:
	- Develop DV testplans for ISA and microarchitecture and execute on them
	- Design and develop component, block and core level testbenches including stimulus engines, microarchitectural models, checkers and coverage models
	- Build architectural tools for ISA level verification
	- Develop stimulus generators that scale from pre-silicon to emulation and post-silicon domain
	- Develop DV environment, tools and infrastructure to enable functional verification for pre-silicon, emulation and post-silicon
	- BS/MS/PhD in EE/ECE/CE/CS with a strong GPA
	- Knowledge of computer architecture/system components/network/fabric, prior internship working in these domains preferred
	- Strong academic skills or internship experience in verification methodologies and techniques – Simulation/debug, TB development, stimulus, checking, coverage
	- Academic projects in C++ / SV / UVM as well knowledge of scripting languages
	- Understanding of assembly level programming
	- Knowledge of hardware description languages (Verilog, VHDL)
	- Strong problem solving and debug skills across various levels of design hierarchies
	- Understanding of deep learning concepts and familiarity with popular machine learning frameworks and models is a plus
+ skill set:
	- Architecture of Tenstorrent's IP blocks including aggressive optimization for performance, power, and area
	- Implementation of Tenstorrent IP RTL logic in Verilog
	- Contribution to verification of Tenstorrent's IP and SOC logic
	- Performance and power verification and validation of Tenstorrent's IP and SOC
	- Versatility, independent thinking, and general ability to get things done!
	- 15+ years of experience working on high performance IP and ASIC designs
	- Bachelor/Masters/PhD in Electrical/Computer Engineering/Engineering Science
	- Expert knowledge of Hardware Description Languages (Verilog/VHDL)
	- Comfortable with C++
	- Deep and broad understanding of processor/computer architecture
	- Knowledge and understanding of the full ASIC design flow
	- ***Experience with any of high frequency logic design, scalar and vector processor architecture, GPU architecture and programming models, digital signal processing hardware, SoC architecture, memory sub system architecture, real time hardware/firmware systems or deep learning is very beneficial***
+ skill set:
	- Functional verification of high-performance CPUs going into industry leading AI/ML architecture. The person coming into this role will help define DV strategies and execute on them while working alongside with a group of highly experienced engineers across various domains of the AI chip.
	- Define DV requirements for design changes resulting from rapidly evolving AI/ML models; work with engineers across domains to understand real world use cases
	- Develop DV testplans for ISA and microarchitecture and execute on them
	- Design and develop component, block and core level testbenches including stimulus engines, microarchitectural models, checkers
	- Build architectural tools for ISA level verification
	- Develop stimulus generators that scale from pre-silicon to emulation and post-silicon domain
	- Evaluate and integrate open-source toolchains into the DV flow
	- Develop DV environment, tools and infrastructure to enable functional verification for pre-silicon, emulation and post-silicon
	- BS/MS/PhD in EE/ECE/CE/CS with at least 5 years of experience
	- Experience with computer architecture/system components/network/fabric as a part of a CPU, ASIC or SOC design team
	- Verification methodologies and techniques – Simulation/debug, TB development, stimulus, checking, coverage, infrastructure, tools
	- Experience with C++ / SV / UVM as well as scripting languages
	- Experience with assembly level programming
	- Experience with hardware description languages (Verilog, VHDL) and simulators (VCS, NC, Verilator)
	- Strong problem solving and debug skills across various levels of design hierarchies
+ skill set:
	- Architecture of Tenstorrent's IP blocks including aggressive optimization for performance, power as well as area
	- Implementation of Tenstorrent IP and SOC RTL logic in Verilog
	- Occasional verification of Tenstorrent's IP and SOC logic, using advanced verification methodologies - UVM, FPGA prototyping, and emulation
	- Performance and power verification and validation of Tenstorrent's IP and SOC
	- Bachelor/Master in Electrical/Computer Engineering/Engineering Science
	- Expert knowledge of Hardware Description Languages (Verilog/VHDL)
	- Deep and broad understanding of processor/computer architecture
	- Knowledge and understanding of the full ASIC design flow, including synthesis, P&R
	- Excellent programming skills. C/C++ as well as scripting languages (Perl, tcl)
	- Experience with high frequency logic design, scalar and vector processor architecture, GPU architecture and programming models, digital signal processing hardware, SoC architecture, memory sub system architecture, real time hardware/firmware systems or deep learning is very beneficial
+ skill set:
	- Verification of Tenstorrent's digital IP and SOC logic, using advanced verification methodologies - UVM, FPGA prototyping, emulation
	- Creation of test plans
	- Writing testbenches, checkers and tests, models, assertions and irritators
	- Creating functional coverage points
	- Reviewing verification results and metrics and driving the verification convergence towards tape-out
	- Performance and power verification and validation of Tenstorrent's IP and SOC
	- Bachelor/Master in Electrical/Computer Engineering/Engineering Science
	- Expert in hardware verification languages (SystemVerilog, SystemC)
	- Experience with UVM and coverage driven constrained random verification
	- Experience with Low power verification techniques
	- Excellent programming skills. C/C++ as well as scripting languages (Perl, tcl)
	- Deep interest in computer architecture, under-the-hood details of machine learning frameworks, GPU programming and methods for efficient parallelization of deep learning execution
+ skill set:
	- Development, testing, analysis, and documentation of Linux device drivers
	- Development of new features and programs, as well as, enhancements, modifications, and corrections to existing software.
	- Experience in Linux driver development (I2C/SPI/UAR/PCI/USB)
	- Experience in software optimization code development within the Linux environment
	- Strong C/C++ experience
	- Knowledge of Git
+ skill set:
	- ***Develop machine learning graph compiler***
	- Participate in the co-design of Tenstorrent's hardware and software stack
	- ***Benchmark, analyze, and optimize performance of key machine learning applications across Tenstorrent's hardware and software stack***
	- ***Develop performance analysis and estimation infrastructure that feeds into Tenstorrent compiler***
	- ***Develop high-performance run-time engine***
	- ***Integrate the Tenstorrent software into leading machine learning frameworks***
	- Work closely with machine learning engineers to discover the hardware and software requirements of current and future machine learning applications
	- BSc, MSc or PhD in Electrical/Computer Engineering or Computer Science;
	- Experience with algorithms, data structures, and software development in C/C++. Python expertise is welcome as well
	- ***Familiarity with and passion for any of the following -- machine learning, compilers, parallel programming, high-performance and massively parallel systems, processor and computer architecture -- is a plus***
+ skill set:
	- AI Silicon Design – RTL/Architecture Engineer:
	- RTL design and microarchitecture definition of high-performance microprocessors going into industry leading AI/ML architecture. The person coming into this role will define new features and code the RTL across multiple areas of our processor Core. The work is done alongside with a group of highly experienced engineers across various domains of the AI chip.
	- ***Define architecture and logic design requirements by understanding rapidly evolving AI/ML models; work with engineers across domains to understand real world use cases***
	- RTL coding in Verilog leveraging on both industry tools as well as open-source infrastructure
	- Drive trade-offs for your logic by working closely with performance, DV and physical design engineers to craft optimal solutions that meet the design goals
	- ***Deploy innovative techniques for improving power, performance and area of the design, drive experiments with RTL and evaluate synthesis, timing and power results***
	- ***Debug RTL/logic issues across various hierarchies (ex: core, chip) in both pre-silicon and post-silicon environment***
	- BS/MS/PhD in EE/ECE/CE/CS with at least 5 years of experience
	- ***Experience with computer architecture/system components/network/fabrics as a part of a CPU, ASIC or SOC design team***
	- Expertise in logic design and ability to evaluate functional, performance, timing and power for you design
	- Strong experience with hardware description languages (Verilog, VHDL) and simulators (VCS, NC, Verilator)
	- ***Expertise in microarchitecture definition and specification development***
	- ***Prior experience in industry standard ISAs – ARM, RISC-V, X86 preferred***
	- ***Strong problem solving and debug skills across various levels of design hierarchies***
+ skill set:
	- Physical design for high-performance designs going into industry leading AI/ML architecture. The person coming into this role will be involved in all implementation aspects from synthesis to tapeout for various IPs on the chip. The work is done alongside with a group of highly experienced engineers across various domains of the AI chip.
	- Define PD requirements by working closely with the front-end team, understand the chip architecture and drive physical aspects early in the design cycle
	- Physical design tasks including such as synthesis, PnR, timing closure, area improvement, floorplanning, clocking, I/O planning and power optimization
	- Discussions with 3rd party IP providers, foundry partners and design services
	- End to end tasks from flow development to sign-off
	- Deploy innovative techniques for improving power, performance and area of the design, drive experiments with RTL, and evaluate synthesis, timing and power results
	- BS/MS/PhD in EE/ECE/CE/CS with at least 5 years of industry experience
	- Hands-on experience with synthesis, block and chip level implementation with industry standard PnR flows and tools
	- Strong experience in SOC/ASIC/GPU/CPU design flows on taped out designs, expertise in timing closure at block/chip levels and ECO flows
	- Experience with back-end design tools such as Primetime, Innovus, RedHawk, etc.
	- Knowledge of low-power design flows such as power gating, multi-Vt and voltage scaling
	- Strong programming skills in Tcl/Perl/Shell/Python
	- Excellent understanding of logic design fundamentals and gate/transistor level implementation
	- Exposure to DFT is an asset
	- Prior experience working on high performance technology nodes and understanding of deep sub-micron design problems/solutions
	- Strong problem solving and debug skills across various levels of design hierarchies
+ FastAPI and SQLAlchemy
+ gRPC, open-source remote procedure call system
+ infrastructure reliability, corporate production systems, user-facing services, production serving or DevOps
+ skill set:
	- RLlib is an open-source library for reinforcement learning that offers both high scalability and a unified API for a variety of applications. We're looking for software engineers with existing machine learning experience that are interested in continuing to improve RLlib.
	- We are looking for senior hires as well as less experienced but motivated individuals.
	- About the ML Ecosystem team:
		* The ML Ecosystem team’s mission is to make it really easy to do distributed machine learning on Ray and Anyscale.Specifically, our team maintains and develops features for a broad number of libraries — including RaySGD (distributed deep learning), Ray Tune (distributed hyperparameter tuning), RLlib (reinforcement learning), and XGBoost-on-Ray.Our team is the most user-facing engineering team on the open source side, collaborating with ML engineering teams at organizations like Shopify, Uber, and Bytedance.
	- As part of this role, you will:
		* Develop high quality open source software to simplify reinforcement learning (RLlib)
		* Identify, implement, and evaluate promising new RL algorithms from the literature
		* Improve the testing process for RLlib to make releases as smooth as possible
		* Communicate your work to a broader audience through talks, tutorials, and blog posts
	- We'd love to hear from you if you:
		* Have relevant experience using RLlib or developing RL algorithms
		* Have strong proficiency in Python and Tensorflow or Pytorch
		* Are excited about working with customers who are applying RL to their own use cases
		* Are excited about working on open source and broadcasting new features to the community
	- About Anyscale:
		* Anyscale provides an application development platform for developers to build distributed applications. We’re commercializing a popular open source project called Ray, which is a framework for distributed computing as well as an ecosystem of libraries for scalable machine learning. Our goal is to build a standardized platform for distributed computing. Ray was developed at UC Berkeley by Robert Nishihara and Philipp Moritz, under the guidance of Ion Stoica and Michael Jordan, and the four of them have co-founded Anyscale. The company raised a $20.6M Series A and a $40M Series B funding from Andreessen Horowitz (a16z), NEA, Foundation Capital, Intel Capital, Ant Financial, Amplify Partners, 11.2 Capital, and The House Fund.
		* With Ray, we're making it easy to program at any scale (from your laptop to the datacenter) by providing easy-to-use, general-purpose, and high-performance tools. In addition, we are building a rich ecosystem of libraries (for reinforcement learning, hyperparameter search, experiment management, machine learning training, prediction serving, and more) on top of the core distributed system so that users can rapidly build sophisticated applications. Help us build the future of software development.
+ skill set:
	- Anyscale is looking to hire strong individuals to develop open source machine learning libraries.
	- The software industry largely operates on a messy zoo of specialized distributed systems such as Spark, Horovod, and TensorFlow Serving. These systems cannot easily be composed together and used as elements of a larger application. On the Machine Learning Ecosystem team at Anyscale, we are developing a rich ecosystem that will allow developers to import powerful distributed libraries and compose them together to build new applications.
	- Part of this work will be open source as part of Ray, which is a distributed Python execution engine as well as an ecosystem of libraries for scalable machine learning.
	- The ML Ecosystem team’s mission is to make it really easy to do distributed machine learning on Ray and Anyscale. Specifically, our team maintains and develops features for a broad number of libraries — including RaySGD (distributed deep learning), Ray Tune (distributed hyperparameter tuning), RLlib (reinforcement learning), and XGBoost-on-Ray.
	- Our team is the most user-facing engineering team on the open source side, collaborating with ML engineering teams at organizations like Shopify, Uber, and Bytedance.
	- Build elastic, scalable, fault-tolerant distributed machine learning libraries that power the next generation of machine learning platforms around the world
	- Benchmark and improve performance and scalability of different machine learning libraries
	- Work closely with other engineers developing Ray to build core abstractions and simplify machine learning services for open source users
	- Work closely with the open source community (with ML researchers, ML engineers, data scientists) to scope and build new abstractions for scalable machine learning
	- Solid background in algorithms, data structures, system design
	- Experience with machine learning frameworks and libraries (PyTorch, Tensorflow)
	- At least 1 year of relevant work experience (new grads should apply to a separate job posting)
	- Experience working with a cloud technology stack (AWS, GCP, Kubernetes)
	- Experience building machine learning training pipelines or inference services in a production setting
	- Experience with big data tools (Spark, Flink, Hadoop)
	- Experience in building scalable and fault-tolerant distributed systems
+ skill set:
	- We are looking for a Machine Learning Engineer with expertise in NLP who can join our AI research and development efforts with a direct impact on our core platform. You will work with both engineering and business teams to best understand design requirements. Then, your role is to design and build practical high performance machine learning solutions.
	- In this role, you will work on some of the latest cutting edge applications of machine learning applied to critical problems that affect businesses, governments and society. You will directly work with top management and key stakeholders to define solutions to critical problems that will have immediate impact and value at the platform and client levels. If you are passionate to work on massive, unstructured problems that can be solved using data, we are looking for you.
	- Contribute to research and development focusing on the following areas: information extraction, multilingual NLP, automated summarization and graph network analysis.
	- Manage the collection and annotation of large custom datasets for text classification, unsupervised pre-training, translation, tagging, and other related problems.
	- Capable of understanding and implementing state-of-the-art methods based on research papers and/or open source libraries, and push beyond the state-of-the-art.
	- Experience with implementing efficient and scalable software systems in Python.
	- Ability to integrate implemented software components into a fully functional software pipeline, and provide verification and validation against requirements.
	- Knowledge of machine learning evaluation techniques, failure modes, and limitations.
	- Requirements
		* Minimum 2 years of professional experience working in Natural Language Processing or closely related field, with demonstration of successful delivery of novel research and/or product offerings.
		* Masters degree or PhD from an accredited college/university in Computer Science, Computational Linguistics, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields (strong mathematical/static background with ability to understand algorithms and methods from a mathematical and intuitive viewpoint). Some exceptions can be made depending on exceptional past accomplishments/references.
		* Experience with command-line scripting, data structures and algorithms, and the ability to work in a Linux environment, processing large amounts of data in a cloud environment.
		* Highly skilled in Python development, as well as: Tensorflow, Pytorch, Keras and Scikit-Learn.
		* Able to communicate scientific concepts to both technical and non-technical audiences.
	- Nice to Have:
		* Working knowledge of AWS and other cloud services.
		* Experience creating novel datasets for scientific analysis or benchmarking.
		* Capability to contribute at the system architecture level to enhance scalability, testability, robustness.
		* Experience with generative models of fake text or images.
		* Experience and top performances in online competitions / hackathons, such as, kaggle.
		* Published research in areas related to machine learning, NLP, or its applications.
		* Record of contributions to open-source machine learning projects, or related endeavors.
		* Experience writing detailed documentation of machine learning systems.
+ skill set:
	- Target-independent optimization techniques
	- Optimized code-generation for scalar and vector DSPs
	- Definition and implementation of dedicated C/C++ language extensions
	- Architecture definition and enhancements
	- Benchmark and performance optimization
	- B.Sc Computer science, or similar degree from a known University.
	- Experience and knowledge of C/C++ – An advantage
	- Team player with excellent communication skills.
	- Experience in Python scripting – advantage
+ skill set:
	- Target-independent optimization techniques
	- Optimized code-generation for scalar and vector DSPs
	- Definition and implementation of dedicated C/C++ language extensions
	- Architecture definition and enhancements
	- Benchmark and performance optimizations
	- B.Sc Computer science, or similar degree that provides strong knowledge of computer science theory along with practical software devolvement skills
	- 3+ years software development experience with excellent knowledge of C/C++.
	- Team player with excellent communication skills.
	- Experience with LLVM Compilers – advantage
	- Experience in Python scripting – advantage
+ Ability to follow a design flow (RTL, testbench, code coverage, synthesis, formal verification, gate level simulation).
+ skill set:
	- Are you ready to be challenged, right from the interview process?  Are you looking to work with a highly intelligent but humble team? Do you want to work on cutting-edge cyber security problems and have the background to do it? Well then, this role may be for you.  
	- GrammaTech is looking for a number of software engineers at varying levels of experience to perform advanced software development. Build new components and extend existing tooling to meet project needs. Implement both exploratory research prototypes and high-quality products. Possess significant experience contributing to large projects, developing software, with focus on C++ and Python.
	- GrammaTech employees must be fully vaccinated against COVID-19.
	- Location: Our R&D center is in Ithaca, NY, but we will consider remote employees with a strong match of skills and experience.
	- Responsibilities of a research-oriented software engineer is expected to:
		* Study and implement approaches drawn from academic literature or in-house design
		* Evaluate the resulting prototype implementation to test its value in addressing the research goals
		* Report results to the PI and respond by adapting the prototype to better address research goals
		* Contribute to presentations and written reports to keep research sponsors up to date on project progress
		* Prepare prototypes for demonstrations and evaluations by research sponsors
		* Transition prototypes into deployable products
	- Required Qualifications.
		* BS in Computer Science or equivalent with a minimum of 3+ years demonstrated experience working in software development in C++ and Python. Knowledge of other languages is a plus.
		* Experience in development activities on large code bases with software designed, built, and tested from scratch; familiarity with common software architectures and design patterns
		* Experience with modern software -development life cycle practices including effectively using revision control systems (git), continuous integration and deployment (CI/CD), container and orchestration technology (docker, Kubernetes, etc.)
		* Knowledge of fundamentals of software security and bug/vulnerability finding 
	- Preferred Qualifications.
		* MS or PhD in computer science or closely related field
		* Knowledge of machine code, such as x86, ARM, or MIPS
		* Background in static analysis for binaries and/or source code
		* Experience with fuzzing or symbolic execution
		* Experience with vulnerability research/demonstration or penetration testing (e.g., Metasploit)
		* Compiler design, compiler front-end integration, C/C++ parsers
		* Dynamic analysis, program instrumentation, and profiling
		* System-administration experience, especially related to security
		* Malware-analysis techniques
		* Experience in using Machine Learning Frameworks like scikit-learn, TensorFlow, Keras, etc.
	- Innovation is at the heart of GrammaTech. We are constantly pushing the boundaries of software research and development – from software assurance and software integrity to cyber-security threat mitigation and autonomic computing. 
	- GrammaTech was founded over 30 years ago, with a firmly-grounded purpose to help organizations develop tomorrow’s software.  Given the ever-increasing dependence of software in today’s connected world, our staff is able to focus on the most challenging software issues through a constant stream of highly innovative research and commercial development programs – focused on the evolving cyber-security landscape, software hardening and intelligent systems.  Within these projects, GrammaTech employees have the opportunity to work with industry, academic, and government experts, significantly advancing their skills in engineering, research, marketing, or sales.
+ skill set:
	- GrammaTech’s Common Lisp Software internship program offers students the opportunity to gain real experience in a friendly, open, and supportive environment. We choose projects based on real needs, and interns work closely with engineers to make sure that projects are completed successfully.  Current COMMON LISP IS REQURED FOR THIS ROLE.
	- GrammaTech will conduct a series of programming tests and screening interviews in Common Lisp as part of our process. (Please do not apply if you do not have experience with Lisp, unfortunately, we cannot train for this role.)  
	- GrammaTech employees must be fully vaccinated against COVID-19.
	- Location:  Remote (must be in USA Only) with a possibility of being located in our Ithaca, NY office for the summer.  (COVID Restrictions will be considered as we get closer to the summer.)
	- Responsibilities
		* Research projects at GrammaTech can take on a wide variety of topics and challenges. Projects focus on software assurance, software protection, reverse engineering, and software transformation. We do both static and dynamic analysis on both source and object code, in order to tackle serious problems with practical solutions.
		* Potential projects include:
			+ Apply compiler optimizations to binaries. Develop some classic compiler optimizations on top of our Binary IR (https://grammatech.github.io/gtirb/)
			+ Develop source-code program transformations for refactoring, optimization, and diversification on top of our Software Evolution Library (https://grammatech.github.io/sel)
			+ Design and run large-scale experiments evaluating automated software modification and automated software engineering tools
	- Required Qualifications
		* Currently enrolled in a BS, MS, or PhD program
		* Excellent programming skills with Common LISP (required)
	- Preferred Qualifications
		* Enrollment in a Computer Science PhD program
+ skill set:
	- The primary responsibility is leading efforts to design and implement research prototypes, based on ideas drawn from academic literature and original research. Team size varies from project to project. On small projects, a scientist may implement a significant portion of the prototype, while on larger projects they will lead a team of engineers. Our scientists are expected to:
		* Generate ideas for innovative solutions (original or drawn from the literature) that address needs identified by research sponsors
		* Translate research ideas into working prototypes
		* Manage researchers and engineers implementing research prototypes: identify risks, plan work, monitor progress, review designs and code used in prototypes, as well as adapt plans as we learn more about the sponsor’s needs and the benefits/deficiencies of the prototype
		* Write proposals for research contracts
		* Build and maintain relationships with research sponsors
		* Document research results in written reports. Present results in-person at meetings with research sponsors
		* Work with research sponsors to ensure success of any demonstrations or evaluations of the research prototype
		* Promote research results in blogs, external presentations, and publications
		* Collaborate with product and marketing teams to identify a strategy to turn the research prototype into a marketable product
		* Ph.D. in Computer Science, Computer Engineering, or Software Engineering and a minimum of three years of industry or post-doctoral academic experience
		* Experience leading research projects and managing/supervising a research team, as Principal Investigator (PI) or equivalent
		* Research experience in compilers, static analysis, language-based security, or another field aligned with GrammaTech's research activities. Maybe your area of expertise is reverse engineering, or vulnerability detection, or code transformation. Expertise in machine learning or statistical techniques with applications to software development or security is highly relevant, as well. On the other hand, maybe you will be adding a new area of expertise to our team
		* Lots of languages: C, C++, Java, machine code, etc. It's not just about our own code, it's about taking other people's software apart and showing them what makes it tick
+ skill set for Sr. SW Engineer - HW Security Analysis:
	- Reporting to the VP of Engineering, the Sr. SW Engineer – HW Security Analysis will be responsible for developing innovative solutions that shape the way the emerging process of HW security verification and analysis is performed.
	- Bachelor’s degree in Computer Science/Engineering (MS or PhD preferred)
	- Expert level engineer with a minimum of 10 years of proficiency in algorithms and data structures for digital logic in the domains of Simulation, Synthesis or Formal Verification or similar products
	- Deep knowledge in design and architecture of efficient, scalable software systems and data structures to support compilation of billion gate designs
	- Experience in multi-threading, multi-tasking and job distribution to support analysis and netlist transformations to minimize runtime and memory footprint
	- Expert programming and debug skills in C/C++.
	- Ability to operate in a small team and be an effective communicator.
	- This position can be based anywhere in the continental USA. Some travel may be required with return to normal business from COVID.
	- Preferred qualifications
		* Experience in the development and support of commercial EDA software
		* Experience in the implementation and verification of SoC designs
		* A background in Computer Security or familiarity with Computer Security topics
+ skill set:
	- We are looking for a Research Scientist Intern to join our growing Trust & Safety Research & Algorithmic Impact team. Spotify’s Algorithmic Responsibility effort focuses on empowering Spotify teams to assess the algorithmic impact of their products on audio culture, avoid algorithmic harms and unintended side effects, and better serve worldwide audiences and creators. As an Algorithmic Impact research intern, you will help to define, research, and communicate how we assess our impact as a platform and our recommendations across podcasts, music, and user-generated content. We help ensure that Spotify is a safe platform that’s true to our values.
	- Be part of an interdisciplinary team focused on understanding Spotify’s impact as a platform, and practical implementation and operationalization of Responsible ML activities such as algorithmic impact assessments. 
	- Contribute to the wider research community by publishing. 
	- Develop and iterate policy and auditing processes related to tech responsibility, algorithmic fairness and representation in the music and podcast industry. 
	- Apply your scientific knowledge to develop strategy around cultural equity in audio and algorithmic systems, including application-oriented problems in search, recommendation and Machine Learning settings. 
	- Provide consultative support, guidance on methods, and research-based input for products. For instance, this can include algorithmic audits, or analyzing & tracking global and local trends around online abuse, hate content, misinformation, etc., with a particular focus on algorithmic amplification. 
	- Work closely with our team and internal partners to develop, refine, and launch processes that help ensure Spotify is a safe and positive experience. 
	- Be a valued member of an autonomous, multi-functional team working in collaboration with other scientists, engineers, product managers, policy experts, designers, user researchers, and analysts across Spotify to design creative solutions to exciting problems.
	- You are pursuing a PhD in Social Science, HCI, Computer Science, Information Science, Data Science, Technology Policy, or related areas with a strong computational focus.
	- ***You have publications in communities such as the Web Conference, AIES, FAccT, CSCW, SIGIR, CHI, ACL, NeurIPS, WSDM, EMNLP, RecSys, KDD, ICWSM, ISMIR or related venues.***
	- You are curious about how interaction design, data collection strategies, and people’s perceptions affect Machine Learning outcomes.
	- You are a creative problem-solver who is passionate about digging into complex problems and devising innovative ways to reach results.
	- You have experience with the complexities of real-world data, and understand the value of both in-depth, qualitative and web-scale, quantitative data working together to build a deep understanding of people’s interaction with technology.
	- Knowledge or experience working in emerging markets is a plus.
	- You have strong communication skills, both written and verbal. Able to provide concise advice and translate complex challenges clearly. Willing to apply academic knowledge and frameworks into product and practice.
	- You must be comfortable reviewing or being exposed to sensitive content and topics, and having related conversations with teams.
+ skill set:
	- We are looking for Data Scientist Interns to \#JoinTheBand and help drive a data-first culture across Spotify. Our Data Scientist mission is to turn terabytes of data into insights and get a deep understanding of music and listeners so that we can impact the strategy and direction of Spotify. You will study user behavior, critical initiatives, markets, content, and new features and bring data and insights into every decision we make. Above all, your work will affect the way the world experiences audio. 
	- Perform analyses on large sets of data to extract practical insights that will help drive decisions across the business
	- Build dashboards and recurring reporting results, empowering creative growth and business decisions
	- Communicate data-driven insights and recommendations to key collaborators
	- Work closely with cross-functional teams of analysts, product owners, marketers, designers, and others across the company who are passionate about Spotify’s success
	- You are pursuing a Bachelor’s, Master’s degree, or bootcamp certification in Science, Computer Science, Statistics, Economics, Mathematics, or a similar quantitative subject area
	- You have a graduation date of 2022 or 2023
	- You currently have valid work authorization to work in the country in which this role is based that will extend from June to August 2022
	- You harbor a passion for numbers and the use of data to make decisions
	- You have the technical competence to perform more analytics in one or more of the following areas:
		* Coding skills (such as Python, Java, or Scala)
		* Analytics tools experience (such as Pandas, R, SPSS, SQL, or Tableau)
		* Experience performing analysis with large datasets
+ skill set:
	- Facebook is seeking a Research Scientist to join our AI Research Team, a research organization focused on making significant progress in AI. Individuals in this role are expected to be recognized experts in identified research areas such as artificial intelligence, machine learning, computational statistics, and applied mathematics, particularly including areas such as deep learning, graphical models, reinforcement learning, computer perception, natural language processing and data representation. The ideal candidate will have a keen interest in producing new science to understand intelligence and technology to make computers more intelligent. To learn more about our research, visit https://ai.facebook.com/.
	- Lead research to advance the science and technology of intelligent machines
	- Lead research that enables learning the semantics of data (images, video, text, audio, speech and other modalities)
	- Devise better data-driven models of human behavior
	- Work towards long-term ambitious research goals, while identifying intermediate milestones
	- Influence progress of relevant research communities by producing publications
	- Contribute research that can be applied to Facebook product development
	- Lead and collaborate on research projects within a globally based team
	- Experience holding a faculty, industry, or government researcher position
	- Ph.D. and publications in machine learning, AI, computer science, statistics, applied mathematics, data science, or related technical fields
	- Experience leading a team in solving modeling problems using AI/ML approaches
	- Experience in theoretical and empirical research and for addressing research problems
	- Experience communicating research for public audiences of peers
	- Knowledge in a programming language
	- Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment
	- 1+ year(s) of work experience in a university, industry, or government lab(s), in a role with primary emphasis on AI research
	- Experience driving original scholarship in collaboration with a team
	- First-author publications at peer-reviewed AI conferences (e.g. NeurIPS, CVPR, ICML, ICLR, ICCV, and ACL)
	- Experience in developing and debugging in C/C++, Python, or C#
+ Experience framework such as MLflow, Kubeflow, Airflow, Seldon Core, TFServing etc
+ skill set for Senior Research Scientist, Design Automation:
	- NVIDIA Research is seeking leading researchers in the areas of VLSI electronic design automation (EDA) to contribute to the development of future high-performance and mobile computing systems. You should have a strong track record of research excellence; systems-building experience; a broad perspective across areas including EDA algorithms and software, machine learning, and VLSI chip design methodology. Specific areas of research interest include but are not limited to applications of supervised learning, unsupervised learning, reinforcement learning and GPU acceleration to EDA algorithms.
	- Apply machine learning and GPU acceleration to EDA software and ASIC and VLSI design tool flows.
	- Research and develop creative and innovative EDA software and algorithms.
	- Collaborate with circuits, VLSI, and architecture team members in research and product teams.
	- Publish and present your original research, speak at conferences and events
	- Collaborate with external researchers and a diverse set of internal product teams.
	- PhD or equivalent experience in Electrical Engineering, Computer Engineering or related field (or equivalent experience).
	- 3+ years of relevant research experience with a strong research record, well-referenced publications and/or patents.
	- You should display a strong background in EDA algorithms and software development, machine learning, along with knowledge of VLSI, circuits, IC design, and/or computer micro-architecture fundamentals.
	- Experience with C, C++, Python, and scripting languages.
	- Background with commonly used machine learning frameworks (PyTorch, Tensorflow).
	- Experience with CUDA and GPU computing
	- Strong communication skills needed. Being a creative and dynamic presenter is a huge advantage.
+ skill set for Research Scientist, Design Automation - New College Grad.
	- We are now looking for a Research Scientist – Design Automation
	- NVIDIA’s invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined modern computer graphics, and revolutionized parallel computing. More recently, GPU deep learning ignited modern AI — the next era of computing — with the GPU acting as the brain of computers, robots, and self-driving cars that can perceive and understand the world. Today, we are increasingly known as “the AI computing company.” We're looking to grow our company, and build our teams with the smartest people in the world. Would you like to join us at the forefront of technological advancement?
	- NVIDIA Research is seeking leading researchers in the areas of VLSI electronic design automation (EDA) to contribute to the development of future high-performance and mobile computing systems. You should have a strong track record of research excellence; systems-building experience; a broad perspective across areas including EDA algorithms and software, machine learning, and VLSI chip design methodology. Specific areas of research interest include but are not limited to applications of supervised learning, unsupervised learning, reinforcement learning and GPU acceleration to EDA algorithms.
	- Apply machine learning and GPU acceleration to EDA software and ASIC and VLSI design tool flows.
	- Research and develop creative and innovative EDA software and algorithms.
	- Collaborate with circuits, VLSI, and architecture team members in research and product teams.
	- Publish and present your original research, speak at conferences and events
	- Collaborate with external researchers and a diverse set of internal product teams.
	- Pursuing Ph.D in EE or related with a strong research record, well referenced publications and / or patents.
	- You should display a strong background in EDA algorithms and software development, machine learning, along with knowledge of VLSI, circuits, IC design, and/or computer micro-architecture fundamentals.
	- Experience with C, C++, Python, and scripting languages.
	- Background with commonly used machine learning frameworks (PyTorch, Tensorflow).
	- Experience with CUDA and GPU computing
	- Strong communication skills needed. Being a creative and dynamic presenter is a huge advantage.
+ skill set:
	- We are now looking for Sr. Research Scientist, Computational Chemistry!
	- NVIDIA is using the power of GPU computing and computational chemistry to accelerate digital biology. We are seeking hardworking individuals to help us realize our mission. As a Sr. Computational Chemistry Researcher, you will join a team passionate about research and development using molecular simulation and machine learning. Together, we will advance NVIDIA's capacity to build digital biology solutions.
	- You’ll build large scale molecular dynamics simulations
	- Collaborate with multiple AI research, high performance computing, and digital biology teams
	- Drive the testing and maintenance of the algorithms and software modules
	- Develop tools to assist data processing, data quality control, algorithm development, and algorithm testing
	- 8+ years of relevant experience
	- Advanced degree in a quantitative field such as Computational Chemistry, Computational Biophysics, Physics, Computer Science, Mathematics, or equivalent work experience
	- Experience with molecular dynamics-based modeling, enhanced sampling or free-energy calculations, or statistical approaches for analyzing large datasets
	- Background with C++ and/or python
	- Recognized for technical leadership contributions, capable of self-direction, and ability to learn from and teach others
	- You should display strong communication skills, be organized and self-motivated, and play well with others (be a phenomenal teammate)
	- Ways To Stand Out From The Crowd
		* Ability to use structural biology and experimental data to inform computational approaches
		* Experience applying molecular dynamics or machine learning to drug discovery, biochemical and biophysical assay development, or target analysis and selection
		* Background with CUDA programming
		* Experience with deep learning
+ skill set for Senior Research Scientist, Autonomous Vehicle Research:
	- We are now recruiting top Research Scientists in Autonomous Vehicle Research.
	- AI-powered autonomous vehicles that can learn, reason, and interact with people are no longer science fiction. Self-driving cars, autonomous delivery vehicles, and autonomous construction vehicles, among others, are getting increasingly close to widespread deployment. However, fundamental research questions still need to be addressed in order to achieve full vehicle autonomy. For instance, how can we: Remove the traditional barriers among perception, prediction, and planning in order to improve overall system performance? Equip autonomous vehicles with online and offline assurances that meet the standards for safety-critical systems? Ensure that autonomous vehicles work seamlessly in new places?
	- These are some of the exciting questions that the newly-established NVIDIA Autonomous Vehicle Research Lab will be tackling. The lab will bring together a diverse, interdisciplinary research team working on core topics in vehicle autonomy, ranging from perception and prediction to planning and control, as well as critical related areas such as decision making under uncertainty, deep learning, reinforcement learning, and the verification and validation of safety-critical AI systems. The lab will focus on basic research; lab members will be encouraged to publish their work and open-source code. NVIDIA is well known for its team culture, and lab researchers will be able to closely interact with others within the company who are experts in perception systems, machine learning, and robotics. There is an opportunity to make a strong impact on products, while having the freedom and bandwidth to conduct ground-breaking publishable research.
	- Designing and implementing cutting-edge techniques in the field of vehicle autonomy, having an opportunity to define your own research.
	- Publishing your original research and speaking at conferences and events.
	- Collaborating with other research team members, a diverse set of internal product teams, and external researchers.
	- Transferring technology you've developed to relevant product groups.
	- PhD or equivalent experience in Robotics, Computer Science, Computer Engineering or related field.
	- 4+ years of relevant research experience in the field of vehicle / robot autonomy.
	- Strong knowledge of theory and practice of vehicle / robot autonomy, or a related area with a strong interest in connecting your work to autonomous vehicles.
	- A track record of research excellence with your work published in top conferences and journals such as RSS, ICRA, IJRR, NeurIPS, ICML, CVPR, TAC, etc., and other research artifacts such as software projects.
	- Exceptional programming skills in Python; C++ and parallel programming (e.g., CUDA) are a plus.
	- Knowledge of common machine learning frameworks such as PyTorch and Tensorflow.
	- Strong communication and interpersonal skills are required along with the ability to work in a dynamic, research-focused team. Experience with mentoring junior engineers and interns is a huge plus.
+ skill set:
	- We are now recruiting top Research Scientists in Autonomous Vehicle Research.
	- AI-powered autonomous vehicles that can learn, reason, and interact with people are no longer science fiction. Self-driving cars, autonomous delivery vehicles, and autonomous construction vehicles, among others, are getting increasingly close to widespread deployment. However, fundamental research questions still need to be addressed in order to achieve full vehicle autonomy. For instance, how can we: Remove the traditional barriers among perception, prediction, and planning in order to improve overall system performance? Equip autonomous vehicles with online and offline assurances that meet the standards for safety-critical systems? Ensure that autonomous vehicles work seamlessly in new places?
	- These are some of the exciting questions that the newly-established NVIDIA Autonomous Vehicle Research Lab will be tackling. The lab will bring together a diverse, interdisciplinary research team working on core topics in vehicle autonomy, ranging from perception and prediction to planning and control, as well as critical related areas such as decision making under uncertainty, deep learning, reinforcement learning, and the verification and validation of safety-critical AI systems. The lab will focus on basic research; lab members will be encouraged to publish their work and open-source code. NVIDIA is well known for its team culture, and lab researchers will be able to closely interact with others within the company who are experts in perception systems, machine learning, and robotics. There is an opportunity to make a strong impact on products, while having the freedom and bandwidth to conduct ground-breaking publishable research.
	- Designing and implementing cutting-edge techniques in the field of vehicle autonomy, having an opportunity to define your own research.
	- Publishing your original research and speaking at conferences and events.
	- Collaborating with other research team members, a diverse set of internal product teams, and external researchers.
	- Transferring technology you've developed to relevant product groups.
	- Pursuing PhD or equivalent experience in Robotics, Computer Science, Computer Engineering or related field.
	- 4+ years of relevant research experience in the field of vehicle / robot autonomy.
	- Strong knowledge of theory and practice of vehicle / robot autonomy, or a related area with a strong interest in connecting your work to autonomous vehicles.
	- A track record of research excellence with your work published in top conferences and journals such as ***RSS, ICRA, IJRR, NeurIPS, ICML, CVPR, TAC***, etc., and other research artifacts such as software projects.
	- Exceptional programming skills in Python; C++ and parallel programming (e.g., CUDA) are a plus.
	- Knowledge of common machine learning frameworks such as PyTorch and Tensorflow.
	- Strong communication and interpersonal skills are required along with the ability to work in a dynamic, research-focused team. Experience with mentoring junior engineers and interns is a huge plus.
+ skill set:
	- NVIDIA Research is seeking extraordinary networking innovators to join our NVResearch team. In this role, you will contribute to the development of future high-performance and embedded computing systems. You will need a great background of research excellence in building systems and a deep understanding and broad perspective across the fields of computer architecture and communication systems for distributed computation. NVIDIA has pioneered programmable GPUs and the CUDA language, and this visionary Research team will take those technologies to the next level with its creative ideas and new inventions. This position offers you the opportunity to have a real impact while working with some of the most creative and forward-thinking people in the world who are here at this dynamic, technology-focused company.
	- This role requires the person to conduct creative and innovative research in networking and associated technologies. Positive impact to NVIDIA’s business is the key measure of success. This requires:
	- Working with product teams and other financial sponsors to identify areas that could benefit from research
	- Creating and inventing novel solutions to solve those problems
	- Communicating those results internally through documentation and presentations
	- Identifying patentable ideas and filing ISFs
	- Publishing key research results to ensure NVIDIA maintains a right to use and contributes to the NVIDIA research brand.
	- Much of NVIDIA’s networking research is funded by external sources (e.g. DOE, DoD). You are expected to work towards the contractual obligations, including the work areas, and assist in preparing deliverables such as reports and presentations.
	- Ph.D. in CE/CS/EE plus publications history and excellent accomplishments in research or equivalent experience. 2+ years of relevant postgrad research work.
	- Strong background in computer architecture, networking, VLSI, circuits, parallel processing, high-performance computing, and/or mobile computing
	- Demonstrated ability to innovate and implement
	- Experience with experimental computer architecture development and evaluation
	- Experience with C, C++, and scripting languages
	- Deep understanding of technology and passionate about what you do
+ skill set for Senior Research Scientist, Quantum Computing:
	- NVIDIA Research is seeking leading researchers in the area of quantum computing. You should have a strong track record of research excellence, software systems building experience, and interest in advancing the state-of-the-art in applications of GPUs to the quantum computing ecosystem. Specific areas of research interest include but are not limited to quantum circuit simulation, tensor network methods, applications of machine learning to quantum circuit simulation, quantum algorithms and programming systems, and hybrid classical/quantum computations.
	- Research and develop creative and innovative algorithms and software systems for the quantum computing ecosystem.
	- Collaborate with research and product teams in the areas of machine learning, programming systems, and quantum computing.
	- Publish and present your original research, speak at conferences and events.
	- Collaborate with external quantum computing researchers.
	- Run large-scale experiments on large clusters of GPUs to advance the state-of-the-art in quantum computing simulation.
	- Ph.D. in Computer Science, Physics, Chemistry, Mathematics or related fields with a strong research record supported by well-referenced publications and / or patents. (or equivalent experience)
	- 2 or more years of industrial research or postdoc research experience in quantum computing field
	- Strong basis in linear algebra and expertise in math for quantum computing and tensor algebraic methods.
	- Experience with C, C++, CUDA, and Python.
	- Background with commonly used machine learning frameworks (PyTorch, Tensorflow, JAX).
	- Strong communication and teamwork skills needed. Being a creative and dynamic presenter is a huge advantage.
+ skill set:
	- NVIDIA Research is seeking leading researchers in the area of quantum computing. You should have a strong track record of research excellence, software systems building experience, and interest in advancing the state-of-the-art in applications of GPUs to the quantum computing ecosystem. Specific areas of research interest include but are not limited to quantum circuit simulation, tensor network methods, applications of machine learning to quantum circuit simulation, quantum algorithms and programming systems, and hybrid classical/quantum computations.
	- Research and develop creative and innovative algorithms and software systems for the quantum computing ecosystem.
	- Collaborate with research and product teams in the areas of machine learning, programming systems, and quantum computing.
	- Publish and present your original research, speak at conferences and events.
	- Collaborate with external quantum computing researchers.
	- Run large-scale experiments on large clusters of GPUs to advance the state-of-the-art in quantum computing simulation.
	- Ph.D. in Computer Science, Physics, Chemistry, Mathematics or related fields with a strong research record supported by well-referenced publications and / or patents. (or equivalent experience)
	- Strong basis in linear algebra and expertise in math for quantum computing and tensor algebraic methods.
	- Experience with C, C++, CUDA, and Python.
	- Background with commonly used machine learning frameworks (PyTorch, Tensorflow, JAX).
	- Strong communication and teamwork skills needed. Being a creative and dynamic presenter is a huge advantage.
+ skill set for Senior Research Scientist, Hyperscale Graphics Systems:
	- NVIDIA is searching for outstanding senior researchers for the reinvention of interactive 3D systems for games, virtual film production, and beyond, using new ideas in cloud/distributed computing, ray tracing, and machine learning. The ideal candidate is an established thought leader in academic or industry with deep experience creating technology for 3D environments, publishing and presenting at industry and academic conferences, and hands-on implementation. This role requires high-level knowledge of multiple areas within production workflow and tools, physical simulation, networking, rendering, and character animation and AI. Datacenter experience with liveops, multiuser environments, and user created content is highly valued. Come join a diverse research group that works on hard and meaningful problems; that consistently publishes at top venues in graphics, computer vision, and artificial intelligence; and that values real impact on NVIDIA products and the industry at large.
	- Work independently on research projects and lead small teams as a principal investigator
	- Select and solve complex problems in a multi-year research agenda
	- Mentor graduate interns
	- Implement experiments and research prototypes in C++, Python, CUDA, and other domain-appropriate tools
	- Influence research initiatives across the company and in the field
	- Protect strategic inventions with patents
	- Publish and present findings in top-tier venues
	- Collaborate with leading experts outside of the company
	- Work with product groups to identify future research needs and transfer technology
	- Participate in top-tier conference and journals as reviewer, session chair, program committee member, or editor/chairperson 
	- A Ph.D. or comparable research experience or equivalent experience in Computer Science/Engineering or a related field.
	- 5+ years of relevant work experience.
	- Excellent knowledge of theory and practice in computer graphics, cloud/distributed computing, ray tracing, and machine learning
	- Expertise with programming systems such as C++, Python, CUDA, and deep learning frameworks such as TensorFlow and PyTorch. Very strong programming skills.
	- A track record of research excellence demonstrated in publications at leading conferences and journals and other research artifacts such as software projects
	- Great presentation and interpersonal skills.
+ skill set:
	- NVIDIA Research’s "Hyperscale Graphics Systems" research team is looking for a graphics software engineer. Our team's mission is to reinvent interactive 3D systems for a world where the graphics system is not one GPU, but the entire data center. We aim to reimagine metaverse simulations, virtual film production, game engines, and beyond using new ideas in cloud/distributed computing, ray tracing, and artificial intelligence. That innovation happens on top of rendering algorithms and software, AI frameworks, cloud and web development stacks, and NVIDIA's Omniverse platform. We need a skilled, creative, and self-starting graphics software engineer to help us build that future. Come join a diverse research group that works on hard and meaningful problems; that consistently publishes at top venues in graphics, computer vision, and artificial intelligence; and that values real impact on NVIDIA products and the industry at large.
	- Build research infrastructure on top of open-source rendering frameworks such as NVIDIA's Falcor, a physically-based rendering system and collection of software modules designed to maximize graphics R&D productivity
	- Help integrate research infrastructure, such as Falcor and hyperscale research systems, into NVIDIA Omniverse
	- Collaborate with researchers, product engineers, and architects across the company working on aspects of hyperscale graphics
	- Help implement and maintain modern full-stack cloud systems, working with technologies from GPU containerization to WebRTC
	- Participate in tech transfer with engineers around NVIDIA as ideas "graduate" from research to product
	- Extend and maintain continuous integration, nightly testing, and other professional software development systems to ensure robust and dependable infrastructure
	- B.S., M.S. or Ph.D. in computer science or equivalent experience
	- Strong programming skills in C++, Python, and HLSL/GLSL
	- 3+ years of experience with 3D graphics development
	- Experience with parallel programming on both CPUs and GPUs
	- Understanding of and experience with modern graphics APIs: Direct3D, Vulkan, and/or OptiX
	- A demonstrated passion for participating in collaborative interdisciplinary research teams.
+ skill set:
	- NVIDIA is searching for outstanding applied research manager to spearhead our Computer Vision efforts. Computer Vision is a core component of NVIDIAs platforms from Drive AV to Isaac autonomous Robotics to Clara for Healthcare to Maxine streaming and broadcast and beyond. The ideal candidate is an established thought leader in academic or industry with deep experience in vision, human understanding, publishing and presenting at industry and academic conferences, and hands-on implementation. This role requires high-level knowledge of multiple areas within production workflow and tools, Deep Learning, network optimization, and vision systems. Come join a diverse applied research group that works on hard and meaningful problems; that consistently publishes at top venues in graphics, computer vision, and artificial intelligence; and that values real impact on NVIDIA products and the industry at large.
	- Start an applied research team focused on Computer Vision specifically targeted on Video Understanding
	- Recruit, build and lead a small applied research team with diverse skills across research, high performance computing, hardware acceleration, and system software
	- Define and execute a multi-year applied research agenda
	- Work with product groups to identify short and medium term technology gaps, transfer technology
	- Identify and close gaps between research and product teams
	- Prove out potential in existing research for use in product. Improve robustness and performance
	- Implement experiments and research prototypes in C++, Python, CUDA, and other domain-appropriate tools
	- Influence research initiatives across the company and in the field
	- Protect strategic inventions with patents
	- Publish and present findings in top-tier venues
	- A Ph.D. or comparable research experience or equivalent experience in Computer Science/Engineering or a related field
	- 10+ years of relevant work experience
	- 3+ years of experience leading a team
	- Excellent knowledge of theory and practice in computer graphics, cloud/distributed computing, ray tracing, and machine learning
	- Expertise with programming systems such as C++, Python, CUDA, and deep learning frameworks such as TensorFlow and PyTorch
	- Demonstrated team/management leadership in research, applied research, or product teams
	- A track record of research excellence demonstrated in publications at leading conferences and journals and other research artifacts such as software projects
	- Great presentation and interpersonal skills
+ skill set:
	- NVIDIA's technology is at the heart of AI revolution, touching people across the planet by powering everything from self-driving cars, robotics, and voice-powered intelligent assistants. We work on new models for speech recognition, speech synthesis, and natural language processing. Our team crafted Jasper, QuartzNet, Talknet and other state-of-the-art neural models for ASR and text-to-speech, and we've also developed new algorithms to accelerate training large models on our GPU cloud.
	- Be a part of the team that's released new models as part of NeMo - open-source toolkit for Conversational AI and whose models are used by world class companies for applications such as customer service, smart voice assistants, etc. This exciting opportunity will have you collaborating with internal research and product teams, as well as researchers from top machine learning labs, and we are looking for someone who's curious, tenacious, and passionate to join our applied research team to influence and build the next generation of Conversational AI systems!
	- Develop new deep learning models and training algorithms for speech recognition, speech synthesis, information retrieval, machine translation, etc.
	- Transfer your technology to NVIDIA’s software product teams.
	- Publish your research at conferences (NeurIPS, Interspeech, ICASSP).
	- Partner with Deep Learning & AI researchers in leading universities and industrial research labs.
	- Master’s degree (or equivalent experience) or PhD in Computer Science, Electrical Engineering, Artificial Intelligence, or Applied Math.
	- 4+ years of practical experience.
	- Advanced understanding of Deep Learning with applications in Speech Processing and NLP, and a record of publications or significant product contributions in these areas.
	- Strong Python programming skills and experience with deep learning frameworks such as PyTorch or TensorFlow.
	- Expert mathematical background, especially in optimization theory, stochastic algorithms, and/or numerical methods.
	- Excellent communication and interpersonal skills are required along with the ability to work in a dynamic, product oriented and global team. Your history of mentoring other engineers and interns is a great bonus.
	- Strong C++ programming skills.
	- Systems software engineering knowledge and expertise in optimizing software for computational performance.
	- Contribution to open source software projects.
+ skill set:
	- We are looking for a Research Scientist, Robotics - New College Graduate:
	- NVIDIA’s invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined modern computer graphics, and revolutionized parallel computing. More recently, GPU deep learning ignited modern AI — the next era of computing. With the GPU acting as the primary computing device, robots can now perceive and understand the world around them. Today, NVIDIA has transformed into “the AI computing company.” We're looking to grow our company, and build our teams with the smartest people in the world working on diverse aspects of AI. Join us at the frontier of technological advancement!
	- Robotics is an increasingly exciting field, influenced heavily by recent advances in hardware acceleration through devices such as the modern GPU. These advances have enabled tremendous progress in several areas of robotics, including manipulation, visual recognition, real-time tracking, and learning-based control. Robots are getting increasingly proficient at building 3D maps of their environments, detecting and tracking objects and people as they move through the world, learning controllers from realistic simulation, and understanding commands provided via gestures and natural language.
	- While our ultimate goal is to reach human-level dexterity, perception, and adaptability, we still have a long way to go. To enable the next generation of robots that can robustly operate in the physical world and interact with people in a natural way, progress is still needed in multiple domains: perception, planning, learning, and control. Moreover, even more importantly, the integration of these individual contributions into complete robot systems opens new challenges.
	- Toward this goal, the NVIDIA Robotics Research Lab brings together a diverse, interdisciplinary research team working on core robotics topics ranging from control, perception, machine learning, common sense reasoning, task planning, human-robot collaboration, and critical related areas such as deep learning for computer vision, natural language processing and decision making.
	- The lab focuses on fundamental research questions in robotics and lab members are encouraged to publish their research and open source their code. The lab hosts numerous internships every year to foster education and communication, and the team is encouraged to collaborate broadly with institutions outside of NVIDIA, both academic and industrial. NVIDIA is well known for its team culture, and lab researchers are able to closely interact with others within the company who are experts in broad subtopics such as computer vision, computer graphics, GPU computing, AI and Deep Learning, self-driving cars, and physics-based simulation.
	- Robot manipulation, robot control, reinforcement learning, computer vision, human-robot interaction, deep learning, physics-based simulation, neuro symbolic reasoning, and natural language processing.
	- Pursuing PhD in Robotics, Computer Science, Engineering or related field.
	- 3+ years of relevant research or work experience
	- Knowledge of theory and practice of robotics, or a related area with a strong interest in connecting your work to robotics scenarios.
	- A track record of research excellence with your work published in top conferences and journals such as Robotics (RSS, ICRA, IROS, CoRL, T-RO, IJRR), Machine Learning (NeurIPS, ICML, ICLR, AAAI, JMLR), Computer Vision (CVPR, ICCV, ECCV, TPAMI) and Language (ACL, EMNLP, NAACL).
	- Exceptional programming skills in Python, and deep learning frameworks such as Tensorflow and Pytorch. Fluency in C/C++; CUDA and robotics frameworks such as ROS is a plus.
	- Strong communication and interpersonal skills are required along with the ability to work in a dynamic, research focused team. A demonstrated history of mentoring junior engineers and interns is a huge plus.
	- Are you dedicated, upbeat and dynamic with excellent analytical ability? Are you a researcher or an engineer passionate and highly motivated about solving complex problems? If so, you may be a perfect fit for NVIDIA!
+ skill set:
	- We are now looking for a Research Scientist with a focus in Platform Architecture to contribute to the development of future scalable multi-GPU platforms. Scalable systems in a post-Moore world require co-optimization of architecture, runtime systems, operating systems, and compilers, to achieve high throughput while improving energy efficiency. We are seeking candidates with a proven track record of research excellence, systems-building experience, a broad perspective across the field of computer architecture and virtualization or security of accelerators. NVIDIA has pioneered programmable GPUs and the CUDA language, and is a world leader in high-performance and mobile computing technology, with ambitious plans for future processors. This position offers you the opportunity to have a real impact in a multifacited, technology-focused company.
	- Develop novel architectures and system software implementations to enable scalable multi-GPU platforms.
	- Understand and analyze the interplay between operating systems, and virtualized CPU and GPU architectures.
	- Collaborate with a diverse set of teams across the company, spanning software, research, hardware engineering, and product groups.
	- Publish original research and speak at conferences and events.
	- You have a Ph.D. in CE/CS/EE or equivalent experience with a strong background.
	- 2+ years of work experience in computer architecture, operating systems, compilers, and/or HPC. A strong publication, patent, and research collaboration history is a huge advantage.
	- Demonstrated expertise in one specific area with the ability to become the go-to resource within a team from differing backgrounds.
	- Background with experimental computer architecture development and evaluation.
	- Experience with C, C++, Python, and scripting languages.
	- Strong interpersonal skills are needed and being a creative and dynamic presenter is a huge advantage.
+ skill set:
	- NVIDIA is searching for a world-class Research Scientist to join our growing research team. The ideal candidate will be conducting cutting-edge research at the intersection of Machine Learning, Computer Vision and Computer Graphics, and working alongside top experts in these fields. With incredible resources in AI, graphics and robotics, you will be able to impact, contribute and advance these exciting domains. Topics include but are not limited to AI for simulation, 3D Deep Learning, DL for animation, content generation, transfer learning, domain adaptation, computer vision, and medical imaging. With its unique open culture, NVIDIA is one of the best industry labs to do AI research.
	- Apply deep learning techniques to the simulation of complex physical phenomena such as fluid dynamics, fracture of materials, combustion, audio synthesis and propagation, and more.
	- Work on improving realism and immersive qualities of VR environments and interactions, including intelligent characters, behavior of crowds and traffic, and human-machine interface problems.
	- Participate in numerous projects to conduct Deep Learning research and publish papers to well known conferences (ex. ICCV)
	- Product development for technology in Games, Virtual Reality, Education and other applications.
	- Completion of a PhD or equivalent experience in Computer Science or a related field (or equivalent experience)
	- Expertise in computer graphics, simulation or game development.
	- 2+ years of experience with C++/C, CUDA, DX, or OpenGL.
	- Dedication to producing high quality and creative results in a collaborative environment
	- Excellent work ethic and problem-solving skills
	- Strong publication record
	- Ways to stand out from the crowd:
	- A great communicator who is self-motivated towards the team goal
	- Take pride in helping others and welcome mentoring others around you
	- Sharp mathematics skills
	- Image recognition and speech recognition — GPU deep learning has provided the foundation for machines to learn, perceive, reason and solve problems. The GPU started out as the engine for simulating human imagination, conjuring up the amazing virtual worlds of video games and Hollywood films. Now, Nvidia’s GPU runs deep learning algorithms, simulating human intelligence, and acts as the brain of computers, robots and self-driving cars that can perceive and understand the world. Just as human imagination and intelligence are linked, computer graphics and artificial intelligence come together in our architecture. Two modes of the human brain, two modes of the GPU. This may explain why Nvidia GPUs are used broadly for deep learning, and NVIDIA is increasingly known as “the AI computing company.”
+ skill set:
	- NVIDIA is seeking an outstanding researcher to join our programming systems research team. If you would like to help build the future of computing by equipping programmers with the tools they need to use parallel computing systems, this team will be a great fit for you! We seek to invent innovative parallel algorithm techniques, expressive parallel programming models/languages, powerful code analysis & generation tools, and scalable runtime environments that can help accelerate a broad range of real-world applications. After developing novel solutions and building prototype software that demonstrates their promise, you will work with product teams to help integrate your ideas into NVIDIA's accelerated computing platform.
	- Develop innovative parallel computing technologies and craft these technologies into prototype implementations.
	- Collaborate with other researchers and engineers at NVIDIA to deliver your innovations in high-quality software systems.
	- Engage with the research community by publishing work that advances the state of the art.
	- A Doctoral degree (Ph.D.) or equivalent experience in a computational subject area such as computer science, computer engineering, or scientific computing. 3+ years of relevant research experience.
	- Expertise in parallel programming and algorithmic techniques.
	- Creativity in developing innovative solutions to the problems faced by parallel programmers and the skill to implement them in software.
	- Experience developing software in languages, such as C++ and Python, commonly used by the developer community.
	- An existing track record of research excellence and publications that demonstrate your body of work.
	- Expertise in applying programming system insights and techniques to problems in machine learning, data science, and/or distributed computing.
	- Ability to implement ideas in the CUDA programming model
	- Experience building software systems used by other developers to solve their own problems.
+ skill set for Research Scientist, Circuits - New College Grad:
	- We are now looking for a Research Scientist for Circuits.
	- Advanced circuit design is critically important in the post-Moore’s Law age. Without the ability to scale process to increase performance and reduce power, we must rely more and more on creative architectural and underlying circuit solutions to provide continuing advancement from generation to generation.
	- NVIDIA Research is seeking world-class circuit researchers to contribute to the exploration of future high-performance, low-power circuit technologies and development of prototype circuits. If you have a strong circuits background, desire to collaborate with elite researchers on critical problems, and a vision about how to advance the state-of-the-art, the team will be a great fit for you. NVIDIA has an ambitious circuit research agenda that involves taking circuit technology to the next level. This position offers an opportunity to have a real impact in a fast-moving technology-focused company.
	- Explore circuit approaches to optimizing processor computation and interconnect performance and power
	- Design and implement circuit approaches in prototype systems
	- Collaborate with external researchers and a diverse set of internal product teams across research and product roles
	- Transfer technology to product groups
	- Publish original research and speak at conferences and events
	- Pursuing PhD or equivalent experience in Electrical Engineering, Computer Science/Engineering, or related field. A strong publication, patent, and research collaboration history is a huge advantage.
	- Excellent knowledge and broad background of theory and practice of circuit design
	- Depth in one or more areas of high-performance circuit design (PLLs and clocking, SerDes and high-speed signaling, photonics, SRAMs, power delivery/regulation, security circuits, and high-speed logic)
	- Track record of research excellence or significant product development
	- Excellent communication and collaboration skills
+ skill set for Research Scientist, ASIC & VLSI:
	- NVIDIA Research is seeking leading researchers in the areas of ASIC & VLSI design and verification to contribute to the development of future high-performance and mobile computing systems. You should have a strong track record of research excellence and systems-building experience. Ideal candidates will have a broad perspective across areas including RTL and logic design and verification, machine learning, processor micro-architecture, VLSI implementation, and Electronic Design Automation (EDA) algorithms. Specific areas of research interest include but are not limited to machine learning accelerators, high-productivity VLSI design and verification methodologies, hardware/software co-design, on-chip networks and interconnect, and applications of machine learning and GPU acceleration to EDA. Applicants with specific expertise and research interest in any of these areas will be considered.
	- Research and develop creative and innovative EDA software and algorithms, ASIC and VLSI design techniques, machine learning accelerator approaches, and/or novel digital VLSI circuits.
	- Contribute to novel research advancing the state-of-the-art in machine learning accelerator design.
	- Collaborate on the development of research prototype testchips.
	- Develop and apply machine learning and GPU acceleration to EDA software and ASIC and VLSI design tool flows.
	- Collaborate with circuits and architecture team members in research and product teams.
	- Publish and present your original research, speak at conferences and events
	- Collaborate with external researchers and a diverse set of internal product teams.
	- Ph.D. or equivalent experienc in EE or related with a strong research record, well referenced publications and / or patents is required.
	- Recent PhD graduates (Research Scientist) or candidates with more years of relevant work or research experience (Senior Research Scientists) will be considered for the open position.
	- You should display a strong background in VLSI, circuits, IC design, computer micro-architecture fundamentals, machine learning, EDA algorithms and software development.
	- Experience with C, C++, Python, and scripting languages required; experience with machine learning frameworks such as PyTorch or Tensorflow preferred.
	- Strong interpersonal skills needed. Being a creative and dynamic presenter is a huge advantage.
+ skill set for Research Scientist, Computer Architecture:
	- NVIDIA is seeking extraordinary hardware and architecture researchers to contribute to the development of future high-performance and mobile computing systems. We are seeking candidates with a consistent track record of research excellence, systems-building experience, a broad perspective across the field of computer architecture, and depth in one or more of these areas of computer architecture: GPU architectures, multi-processor and memory system architectures microarchitecture/compilers, resilience and safety, architectures for security, and domain specific architectures such as machine learning. NVIDIA has pioneered programmable GPUs and the CUDA language, and is a world leader in high performance and mobile computing technology, with bold plans for future processors. This position offers the opportunity to have real impact in a fast paced, technology-focused company.
	- Develop innovative computer architectures to address the emerging demands high performance and energy efficient computing systems.
	- Understand and analyze the interplay between hardware, software, and efficient algorithm designs.
	- Collaborate with a diverse set of teams across the company, spanning software, research, hardware engineering, and product groups.
	- Publish original research and speak at conferences and events.
	- You have a Ph.D. or equivalent experience in CE/CS/EE with a strong background in computer architecture, compilers, and/or high-performance computing with at least 2+ years of relevant research experience. A strong publication, patent, and research collaboration history is a huge advantage.
	- Demonstrated expertise in one specific area with the ability to become the go-to resource within a team having varied backgrounds.
	- Experience with experimental computer architecture development and evaluation.
	- Background with C, C++, Python, and scripting languages.
	- Strong interpersonal skills along with dynamic presentation skills.
+ skill set for Research Scientist, Computer Architecture - New College Grad:
	- NVIDIA is seeking extraordinary hardware and architecture researchers to contribute to the development of future high-performance and mobile computing systems. We are seeking candidates with a consistent track record of research excellence, systems-building experience, a broad perspective across the field of computer architecture, and depth in one or more of these areas of computer architecture: GPU architectures, multi-processor and memory system architectures microarchitecture/compilers, resilience and safety, architectures for security, and domain specific architectures such as machine learning. NVIDIA has pioneered programmable GPUs and the CUDA language, and is a world leader in high performance and mobile computing technology, with bold plans for future processors. This position offers the opportunity to have real impact in a fast paced, technology-focused company.
	- Develop innovative computer architectures to address the emerging demands high performance and energy efficient computing systems.
	- Understand and analyze the interplay between hardware, software, and efficient algorithm designs.
	- Collaborate with a diverse set of teams across the company, spanning software, research, hardware engineering, and product groups.
	- Publish original research and speak at conferences and events.
	- You have a Ph.D. or equivalent experience in CE/CS/EE with a strong background in computer architecture, compilers, and/or high-performance computing. A strong publication, patent, and research collaboration history is a huge advantage.
	- Demonstrated expertise in one specific area with the ability to become the go-to resource within a team having varied backgrounds.
	- Experience with experimental computer architecture development and evaluation.
	- Background with C, C++, Python, and scripting languages.
	- Strong interpersonal skills along with dynamic presentation skills.
+ skill set for Research Scientist, ASIC & VLSI - New College Grad:
	- NVIDIA Research is seeking leading researchers in the areas of ASIC & VLSI design and verification to contribute to the development of future high-performance and mobile computing systems. You should have a strong track record of research excellence and systems-building experience. Ideal candidates will have a broad perspective across areas including RTL and logic design and verification, machine learning, processor micro-architecture, VLSI implementation, and Electronic Design Automation (EDA) algorithms. Specific areas of research interest include but are not limited to machine learning accelerators, high-productivity VLSI design and verification methodologies, hardware/software co-design, on-chip networks and interconnect, and applications of machine learning and GPU acceleration to EDA. Applicants with specific expertise and research interest in any of these areas will be considered.
	- Research and develop creative and innovative EDA software and algorithms, ASIC and VLSI design techniques, machine learning accelerator approaches, and/or novel digital VLSI circuits.
	- Contribute to novel research advancing the state-of-the-art in machine learning accelerator design.
	- Collaborate on the development of research prototype testchips.
	- Develop and apply machine learning and GPU acceleration to EDA software and ASIC and VLSI design tool flows.
	- Collaborate with circuits and architecture team members in research and product teams.
	- Publish and present your original research, speak at conferences and events
	- Collaborate with external researchers and a diverse set of internal product teams.
	- Ph.D. or equivalent experience in EE or related with a strong research record, well referenced publications and / or patents is required.
	- Recent PhD graduates (Research Scientist) or candidates with more years of relevant work or research experience (Senior Research Scientists) will be considered for the open position.
	- You should display a strong background in VLSI, circuits, IC design, computer micro-architecture fundamentals, machine learning, EDA algorithms and software development.
	- Experience with C, C++, Python, and scripting languages required; experience with machine learning frameworks such as PyTorch or Tensorflow preferred.
	- Strong interpersonal skills needed. Being a creative and dynamic presenter is a huge advantage.
+ skill set for Research Scientist, SysArch and Software - New College Grad:
	- We are now looking for a Research Scientist with a focus in Platform Architecture and Runtime System to contribute to the development of future scalable multi-GPU platforms. Scalable systems in a post-Moore world require co-optimization of architecture, runtime systems, operating systems, and compilers, to achieve high throughput while improving energy efficiency. We are seeking candidates with a proven track record of research excellence, systems-building experience, a broad perspective across the field of computer architecture, and depth in data parallel architectures or operating and runtime systems. NVIDIA has pioneered programmable GPUs and the CUDA language, and is a world leader in high-performance and mobile computing technology, with ambitious plans for future processors. This position offers you the opportunity to have a real impact in a multifacited, technology-focused company.
	- Develop novel architectures and system software implementations to enable scalable multi-GPU platforms.
	- Understand and analyze the interplay between operating systems, CPU and GPU architectures, and efficient algorithm designs.
	- Collaborate with a diverse set of teams across the company, spanning software, research, hardware engineering, and product groups.
	- Publish original research and speak at conferences and events.
	- You are pursuing a Ph.D. in CE/CS/EE with a strong background in computer architecture, operating systems, compilers, and/or HPC. A strong publication, patent, and research collaboration history is a huge advantage.
	- Demonstrated expertise in one specific area with the ability to become the go-to resource within a team from differing backgrounds.
	- Experience with experimental computer architecture development and evaluation.
	- Experience with C, C++, Python, and scripting languages.
	- Strong interpersonal skills are needed and being a creative and dynamic presenter is a huge advantage.
+ skill set for Research Scientist - Platform Architecture and Runtime Systems:
	- We are now looking for a Research Scientist with a focus in Platform Architecture and Runtime System to contribute to the development of future scalable multi-GPU platforms. Scalable systems in a post-Moore world require co-optimization of architecture, runtime systems, operating systems, and compilers, to achieve high throughput while improving energy efficiency. We are seeking candidates with a proven track record of research excellence, systems-building experience, a broad perspective across the field of computer architecture, and depth in data parallel architectures or operating and runtime systems. NVIDIA has pioneered programmable GPUs and the CUDA language, and is a world leader in high-performance and mobile computing technology, with ambitious plans for future processors. This position offers you the opportunity to have a real impact in a multifacited, technology-focused company.
	- Develop novel architectures and system software implementations to enable scalable multi-GPU platforms.
	- Understand and analyze the interplay between operating systems, CPU and GPU architectures, and efficient algorithm designs.
	- Collaborate with a diverse set of teams across the company, spanning software, research, hardware engineering, and product groups.
	- Publish original research and speak at conferences and events.
	- You have a Ph.D. in CE/CS/EE or equivalent experience with a strong background and work experience in computer architecture, operating systems, compilers, and/or HPC. A strong publication, patent, and research collaboration history is a huge advantage.
	- Demonstrated expertise in one specific area with the ability to become the go-to resource within a team from differing backgrounds.
	- Experience with experimental computer architecture development and evaluation.
	- Experience with C, C++, Python, and scripting languages.
	- Strong interpersonal skills are needed and being a creative and dynamic presenter is a huge advantage.
+ skill set:
	- We're looking for outstanding interns to apply their parallel programming skills to accelerate NVIDIA's open source software suite for data science, RAPIDS. RAPIDS combines the performance of modern GPUs with the ease of use of Python and Scala APIs. It builds on a highly-optimized computational core, written in C++ and CUDA, that leverages the parallel nature of GPUs to accelerate fundamental data operations from load and parsing, to joins, aggregations, and more. Previous interns have made significant contributions to these core libraries, and we hope you’ll be the next major contributor!
	- Developing novel, parallel algorithms to accelerate core problems in data processing
	- Implementing solutions in C++ and CUDA
	- Contributing to open source RAPIDS projects, such as cuDF
	- Benchmarking, profiling, and optimizing code
	- Working closely with mentors and some of the world’s top experts in GPU optimization
	- Pursuing a PhD, MS, or BS in computer science, engineering, or a related field
	- You have strong Modern C++ programming skills
	- Familiar with at least one parallel programming framework, such as CUDA, OpenACC, OpenMP, etc.
	- You care deeply about robust, readable, high-performance code
	- Excited to learn, explore new problem areas, and apply your creativity to some of the most challenging and rewarding problems we have
+ skill set:
	- We are looking for software engineering interns for our cuSPARSE and cuSOLVER team which are a key part of high-performance computing and deep learning software stacks. The main purpose of these libraries is to provide the fastest computing primitives for sparse and dense linear algebra, like Cholesky decomposition and sparse matrix products among many others. We see strong interest in optimization of such key functionalities from various industrial and research organizations - from Gaming and Machine Learning to autonomous driving and chip modeling. Some of these kernels spend several milliseconds while others involve hundreds of GPUs and spend hours. All of them need to be optimized for current and future GPUs that involve mathematical changes of algorithms. Does the idea of being at the heart of these projects and apply your knowledge to develop and optimize algorithms which make an impact around world excite you? If yes, then come and join our team!
	- During your internship, you will work with senior software engineers in the libraries team who will provide mentorship and guide you in developing highly optimized algorithms. Projects will involve implementing new numerical algorithms, defining APIs, analyzing performance, finding appropriate solutions for difficult numerical corner cases, and other general software engineering work.
	- Prototype and develop numerical algorithms for high-performance math libraries in the areas of dense and sparse linear algebra for single node and multi GPU clusters
	- Analyze the performance of GPU or CPU implementations and find opportunities for improvements.
	- Collaborate with team members to understand software use cases and requirements
	- Studying towards a degree in Computer Science, Applied Math, Engineering, or related field.
	- Strong C++ programming, debugging, performance analysis, and test design skills.
	- Strong algorithms and numerical methods fundamentals.
	- Ability to work independently.
	- Good teamwork, communication, and documentation habits.
	- Parallel programming experience using multi-threading or MPI.
	- GPU programming experience (CUDA or OpenCL).
	- Experience developing and optimizing numerical software.
	- Experience with sparse or dense algebra optimizations.
	- Exposure to floating-point arithmetic and numerical error analysis.
	- A scripting language, preferably Python.
+ skill set:
	- We are now hiring interns for our DriveIX team, with a preferred start in August or September. Join our DriveIX team and help build the real-time, cost-effective computing platform driving our success in this exciting and quickly growing field. Intelligent machines powered by AI computers that can learn, reason and interact with people are no longer science fiction. Today, a self-driving car powered by AI can meander through a country road at night and find its way. An AI-powered robot can learn motor skills through trial and error. This is truly an extraordinary time. The era of AI has begun.
	- As a Software Intern on our Copilot team, you will be working on research, design and implementation of software features in the DriveIX and intelligent assistant. You will use machine learning, deep learning and computer vision techniques combined with rules-based domain specification to provide monitoring, communication/interaction and external perception capabilities using multiple different type of sensors and inputs on embedded platforms.
	- Pursuing BS/MS degree in Computer Science/EE or related
	- You have strong fundamentals in embedded systems, programming and SW design
	- Strong knowledge of ML/DL techniques, algorithms and tools with exposure to memory networks, CNN, RNN and LSTM and/or Computer Vision
	- Have shown ability to harness existing data, acquiring and labeling of new data and managing related work flows.
	- Excellent fluency with C/C++ and Python
	- You strongly believe that prototyping is the right way to prove the idea
	- Image, sentiment and object classification experience is highly desired
	- Experience with one of the following: dialog systems and conversational platforms, computer vision, signal processing
	- A familiarity with GPU computing (CUDA, OpenCL, OpenACC)
	- Background with Dockers and Kubernetes
	- Familiarity with TensorRT
	- Worked with variety of vision, depth and audio sensors
	- Worked on programming automotive CAN bus
+ Proficiency in C#.net or Python/Selenium for automation development.
+ skill set:
	- NVIDIA is searching for world-class researchers in deep learning, focused on large-scale and high-precision medical imaging analysis, federated learning to join our applied research team. We believe that Deep Learning accelerated AI will completely reshape life sciences, medicine, and healthcare as an industry. To foster that transformation, NVIDIA is democratizing deep learning by providing an end-to-end AI computing platform crafted for the healthcare community.
	- GPU-accelerated deep learning solutions can be used to craft more sophisticated neural networks for healthcare and medical research applications: from real-time pathology assessment to point-of-care interventions to predictive analytics for clinical decision-making. Innovations in AI are advancing the future of precision medicine and population health management in spectacular ways. We are passionate about applying deep learning to healthcare applications for high-performance preventive/precision medicine, and knowledge mining from very large-scale clinical datasets and resources, to facilitate effective clinical workflows, built upon NVIDIA’s hardware/software AI platform. After building prototypes that demonstrate the promise of your research, you will collaborate with software engineering team to integrate your work into products.
	- Craft DL approaches to solving medical imaging analysis, federated learning problems.
	- Construct and curate large problem datasets.
	- Design and implement medical imaging, computer vision, machine learning, federated learning techniques sought at solving specific problems.
	- Keep up with the latest DL research and collaborate with diverse teams, including DL researchers, physicians, hardware architects, and software engineers, etc.
	- Generate high-quality patents and top-tier technical or clinical publications, transfer technology into products.
	- Pursuing a PhD in Electrical Engineering, Computer Science/Engineering, or related field.
	- Relevant work experience in computer vision, medical imaging, deep learning, statistical learning, federated learning.
	- You've produced a track record of research (publication) excellence and/or significant product development. IE 4+ pieces of tier-one publications with substantial deep learning for healthcare applications.
	- Excellent rapid prototyping skills with medical applications using Python.
	- Excellent knowledge and development experience of common deep learning frameworks and packages (Caffe, Tensorflow, PyTorch, etc.).
	- Excellent communications skills.
	- Prior experience working with physicians to identify (novel) important problems and assessing possible DL solutions is a plus.
+ skill set:
	- Data Processing Unit’s (DPU’s) are the new class of programmable processor’s igniting unprecedented innovation for modern data centers by offloading and accelerating networking, storage, compute and security services. As we work to advance and implement these technologies into our future offerings, our Compiler team is growing and seeking a top-tier Compiler Engineer Intern who wants an exciting and fun role as they help lead the charge to even greater accomplishments within a world-class organization. Come join us and to be part of the team in making a difference!
	- We are hiring a Compiler Engineer Intern for a minimum 12-week, full-time (40 hours/week) internship for the Summer 2022 term!
	- Design and implementation of significant parts of the compiler
	- Work on performance analysis and design/implementation of new optimizations
	- Partnering and collaborating with global compiler and network software teams to coordinate improvements and problem resolutions
	- You are pursuing your BS/MS/PhD in Computer Science or Computer Engineering (MS/PhD strongly preferred) or equivalent
	- Some work or research experience in performance analysis, compiler optimizations, code generation
	- Knowledge of network programming, network protocols and layers
	- Strong C/C++ and Python programming and software design skills, including debugging, performance analysis, and test design
	- Solid interpersonal skills are required along with the ability to work in a dynamic product-oriented team
	- Ability to collaborate well with others in an energizing environment
	- Proven ability to design/architect compiler frameworks
	- Experience with open source compilers and contributions to code base
	- Background with data plane programming or Linux networking stack and hardware packet processing pipelines
+ skill set:
	- We are looking for an extraordinary Deep Learning Software Intern to develop NVIDIA's deep learning solutions in autonomous driving vehicles. As a member of our Solution Engineering-Automotive Machine Learning team, you will utilize ground breaking NVIDIA deep learning model training/inference software libraries for deployment on NVIDIA's hardware architecture. You will develop new deep learning architectures, deploy deep learning models in low precision, and compile and optimize DNN graphs. As a part of this role, you will be building a close technical relationship with our internal automotive/framework teams during product development and coordinate with the architecture and software teams to develop the best solution on our platforms.
	- Train, fine-tune, optimize and customize perception DNNs in low precision (FP16/INT8)
	- Apply low precision inference, quantization, and compression of DNNs
	- Design and develop robust inferencing software that can be scaled to multiple platforms for functionality and performance
	- Performance analysis, optimization and tuning
	- You'll collaborate across the company to guide the direction of machine learning inferencing, working with software, research and product teams
	- Pursuing MS or PhD degree from a leading University in a relevant field, e.g. engineering, computer science, or computer engineering or equivalent
	- 2+ years of relevant software development experience
	- Excellent C/C++ programming and software design skills, including debugging, performance analysis, and test design
	- You should display a real passion for artificial intelligence and computer vision, and knowledge of the latest developments in DL and AI
	- Experience working with deep learning frameworks like Caffe, TensorFlow and PyTorch
	- Dedicated and able to work without supervision
	- Experience with low precision inference, quantization, compression of DNNs
	- Experience with NVIDIA software libraries such as CUDA and TensorRT
	- Open source project ownership or contribution, healthy GitHub repositories, guiding and/or mentoring experience
+ skill set:
	- We are currently seeking a software engineer intern with strong Computer Vision, Graphics and Deep Learning fundamentals and solid implementation skills to contribute to the development of NVIDIA Maxine - a comprehensive suite of SDKs with state-of-the-art AI features for virtual collaboration and content creation.
	- You will work alongside brilliant engineers on core technologies to solve challenging computer graphics, vision, and deep learning problems. You will work collaboratively with research and production teams on new groundbreaking approaches that transform the industry.
	- Gain first-hand experience and grow your technical expertise in one or multiple areas of:
		* 3D human face/body/gaze tracking
		* Avatar 3D modeling and animation
		* Hand pose prediction and recognition
		* Video artifact removal, super resolution and style transfer
		* 3D reconstruction and scene understanding
	- Pursuing BS, MS, or PhD in Computer Science or related field
	- Hands on experience with building, training and debugging neural networks
	- Hands on expertise with one or more Deep Learning frameworks (Caffe, tensorflow, keras etc)
	- Strong software engineering background, Proficiency in C++ programming or Python.
	- Self-motivated, fast to act and eager to learn
	- Experience of using deep learning in computer vision and graphics
	- Background with CUDA programming, and a real passion for optimizing system performance.
	- Background with SDK development
	- Experience of building platforms to deploy computer vision and deep learning technologies.
+ skill set for ***Machine Learning Compiler Research Intern***:
	- NVIDIA is hiring software engineer interns for its GPU-accelerated Deep Learning team. Academic and commercial groups around the world are using GPUs to power a revolution in deep learning, enabling breakthroughs in problems from image classification to speech recognition to natural language processing and artificial intelligence. Join NVIDIA's team building software which will be used by the entire deep learning research community.
	- In this role, you will be responsible for developing highly optimized solutions for deep learning algorithms. You’ll collaborate with members of the open source deep learning software engineering community to define and implement the features needed to accelerate the next generation of deep learning software frameworks. The scope of these efforts ranges from defining public APIs, performance tuning and analysis, crafting and implementing compiler and optimization techniques for neural networks, and other general software engineering work.
	- Pursuing Master's (or equivalent experience) or PhD degree in CS or related field or equivalent.
	- Excellent C/C++ programming and software design skills, including debugging, performance analysis, and test design.
	- Knowledge of CPU and/or GPU architecture. CUDA or OpenCL programming experience desired but not required.
	- Experience with the following technologies: deep learning models and algorithms, deep learning framework design, high performance compiler design, or EDA synthesis and optimization algorithms.
	- You have a history of mentoring others.
+ skill set:
	- NVIDIA is seeking deep learning research / engineering interns to join the AV perception research team. The team consists of a group of dynamic AI applied researchers and engineers and is committed to build industry-grade deep learning to take autonomous vehicle (AV) perception into production, we work on fundamental advances in scientific methods to enabling scaling-up the entire perception for the autonomous driving stack. We are looking for highly motivated individuals to work in the areas of deep learning, optimization and computer vision. Our interns have the unique opportunity to make algorithmic contributions to core products and apply their ideas at a very large scale. As an intern, you will conduct applied research related to one of the meaningful research topics mainly related to perception for autonomous driving. You may also have the opportunity to publish in premier conferences in the fields of Machine Learning and perception.
	- In order to scale-up current AI-algorithms, we need to learn from datasets orders of magnitude larger than existing ones which is a very challenging task. Our team at NVIDIA is dedicated to developing new algorithms to explore the vast amount of collected data to improve AI-based applications such as AV.
	- Efficient data selection to improve learning and scaling-up training sets including active learning and mining strategies.
	- Network interpretability to predict network failures and to design novel algorithms to continuously learn from data and from failures.
	- Efficient training and inference to minimize training time and enable inference in embedded platforms.
	- Synthetic to real domain adaptation.
	- To learn more about our high-level goals visit: https://atscaleconference.com/videos/scale-2018-keynote-inside-nvidias-ai-infrastructure-for-self-driving-cars/
	- You will be responsible for conducting applied research to advance the performance of our codebase applied to perception for autonomous vehicles. Research is done in areas related to large scale learning including semi-supervised deep learning, active learning, deep network architecture search, parameter optimization and modeling, domain adaptation, or life-long learning. You may have opportunities to influence the progress of the field by producing publications.
	- Contribute to integrating novel algorithms into core applications to enable a better generation of autonomous vehicles, coding in Tensorflow to facilitate the integration into our codebase.
	- Collaborate and increase the performance of existing perception-based systems for AV.
	- Pursuing BS, MS, or Ph.D. in Computer Science, with a focus in Deep Learning, Artificial Intelligence or related fields.
	- Expertise in Computer Vision and Deep Learning.
	- Strong mathematical background and ability to analyze results.
	- Excellent Tensorflow and python programming skills to bring ideas into production systems.
	- A dedication to bring your work to completion and see your work having a worldwide impact.
	- A self-motivated and good teammate with good communication and social skills.
	- Publication or experience in fields related to machine learning, analytics, large-scale systems, statistics, and mathematics.
	- Currently enrolled in a Ph.D. program in CS or Math.
	- First author publications in top-tier peer-reviewed conferences such as NeurIPS, ECCV, ICML, CVPR, ICCV.
	- Research or software engineering experience confirmed via internships, relevant work experience or code competitions.
+ skill set:
	- The Thermal Engineering Design Team at NVIDIA is seeking a Thermal Engineering Intern who will contribute to thermal designs, testing, characterization, and prototyping activities as related to NVIDIA’s GeForce (gaming), Quadro (workstation), TESLA (High performance compute), and possibly server products. Be an integral member of a collaborative team which defines and develops thermal solutions from concept through production working with multi-functional Product Development teams and overseas partners. Your proven communication skills, strong thermal and validation engineering technical background with product development knowledge including thermal engineering and related manufacturing processes, are important.
	- As a team, we support all products NVIDIA develops. Your contribution will be towards the development, specifications, design, and manufacturing implementation from package to board level thermal solutions through complete systems including implications focusing on GeForce, Quadro, and TESLA products including development of thermal technologies.
	- Part of your responsibility is the investigation of relevant product design concepts, perform analysis and trade-offs aligned with product goals, and contributing to thermal solution product design from beginning to end (i.e. conceptualization to production).
	- We build physical prototype assemblies and instrument those assemblies for testing. We carry out testing, summarize and correlate data, modify, and improve our systems.
	- One of the team's responsibilities is to build test reports and summaries, and generally detail your efforts to broaden the knowledge of your team and the company.
	- Working towards a BS or MS or equivalent experience in Engineering (ME, Mechanical Systems, Physics or similar with emphasis on heat transfer and design).
	- Experience in visualizing and clarifying product/solution needs from fundamental concepts through system considerations to ensure optimized designs.
	- Experience with FEA/CFD theory, and general analysis of heat transfer tools including excellent knowledge of at least one thermal analysis SW would be very beneficial.
	- Hands-on experience and proficiency in thermal evaluation of computer hardware to provide relevant and data driven product design suggestions (i.e. thermocouple placement, acquiring readings using automated data acquisition, assembly and tear downs) are required.
	- Experience with CFD tools including IcePak, Fluent, or FloTHERM.
	- Experience using a flow bench for characterizing heat sinks, fans, and systems.
	- Background in a thermal laboratory environment and tools related to making accurate thermal measurements and related data collection for electronics (i.e. temperature, power, voltages, multimeters, and more).
	- Familiar with NVIDIA's GPU and SOC products.
+ skill set for Energy Solution Architect Intern:
	- NVIDIA is building the world’s leading AI company and we need Solution Architects to help our customers adopt GPU Deep Learning, accelerated data analytics, and other AI and HPC technologies. As an intern you will team up with experienced solution architects as you work as part of an NVIDIA account team supporting customers building solutions with our latest technology.
	- You will be supporting customers in their journey to optimize code for the GPU while working to complete a special project that will be agreed upon before you join. In the process you should become familiar with our Tesla data center products for AI and HPC including the DGX-1 deep learning supercomputer, our Quadro line of professional visualization solutions, and our Tegra embedded solutions for intelligent video analytics and IoT. At the end of your internship, after being exposed to a broad scope of our technologies, you will have insight into a role as a regular solution architect at NVIDIA.
	- The ideal candidate will have a solid computer architecture and software foundation, with some GPU-based visual or compute experience, and will be comfortable working in a fast-paced environment with changing requirements. Excellent communication skills and ability to work both independently and with a team are essential. Experience with GPU deep learning and data sciences is desirable, as is the ability to quickly learn new technologies.
	- Working at the convergence of HPC + AI developing domain specific Deep Learning, Machine Learning, and SimNet-based solutions
	- Coordinate the setup of experiments, tests, equipment, and otherwise facilitate evaluations that help solve customer problems using GPU deep learning and other NVIDIA technologies
	- Work closely with the NVIDIA Solution Architect and customer account team to secure design wins through customer proof-of-concept evaluations
	- Facilitate rapid resolution of customer issues and promote the highest levels of customer satisfaction
	- Work to complete a special project involving key NVIDIA technologies
	- Pursuing MS or higher in EE, CS, Math, Physics or related technical field
	- Data sciences coursework
	- Programming skills in 1 or more high level languages (C, C++, Python, etc.)
	- Linux command line and system administration skills are helpful
+ skill set for Compiler DevOps, Software Intern:
	- Do you want to help drive the progress of compiler development for cutting-edge technologies? Are you excited to learn new tools and develop infrastructure applications to assist developers? Are you passionate about improving software development workflows?
	- We are building the next generation of compiler technologies to accelerate graphics, compute and deep learning applications. We are looking for an intern to work on infrastructure projects to accelerate compiler development & testing.
	- In this role you will work closely with our build, release and productivity engineering teams to develop full-stack applications.
	- Pursuing a BS in Computer Science, Computer/Electrical Engineering or related field.
	- You are familiar with modern web UI frameworks such as React, Angular, or others.
	- Experience with Docker containers, Jenkins, Artifactory and Kubernetes.
	- You are skilled in wide variety of programming languages including Python and JavaScript.
	- Background with MySQL or equivalent and exposure to NoSQL databases.
	- Experience working across teams and converting designs to visual elements.
	- Excellent communication, problem solving and analytical skills to decompose complex issues and present them clearly and simply.
	- Background with agile software development methodology and practices.
	- Experience designing and deploying large-scale and distributed system software in cloud environments.
	- Experience with one or more version control systems, such as git or Perforce.
	- Experience with Linux configuration and installation of apps. Networking is a plus.
	- Interest in ground breaking technologies and the ability to take initiatives and drive them across multiple functional teams.
+ skill set for Architecture Energy Modeling Intern:
	- At NVIDIA, we pride ourselves in having energy efficient products. We believe that continuing to maintain our products' energy efficiency compared to competition is key to our continued success. Our team is responsible for researching, developing, and deploying methodologies to help NVIDIA's products become more energy efficient; and is responsible for building energy models that integrate into architectural simulators, RTL simulation, and emulation platforms.
	- As a member of the Power Modeling, Methodology and Analysis Team, you will collaborate with Architects, Performance Engineers, Software Engineers, ASIC Design Engineers, and Physical Design teams to study and implement energy modeling techniques for NVIDIA's next generation GPUs and Tegra SOCs. Your contributions will help us gain early insight into energy consumption of graphics and artificial intelligence workloads, and will allow us to influence architectural, design, and power management improvements.
	- Work with architects and performance architects to develop an energy-efficient GPU.
	- Develop methodologies and work flows to select and run a wide variety of workloads to train models using ML and/or statistical techniques.
	- Develop methodologies to improve the accuracy of energy models under various constraints, such as, process, timing, floorplan and layout.
	- Correlate the predicted energy from models created at different stages of the design cycle, with the goal of bridging early estimates to silicon.
	- Develop tools to debug energy inefficiencies observed in various workloads run on silicon, RTL and architectural simulators. Work with architects to fix the identified energy inefficiencies.
	- Work with performance, verification and emulation methodology and infrastructure development teams to integrate energy models into their platforms.
	- Prototype new architectural features, create an energy model, and analyze the system impact.
	- You are pursuing a BS/MS/PhD in related fields.
	- Strong coding skills, preferably in Python, C++.
	- Background in machine learning, AI, and/or statistical modeling.
	- Interest in computer architecture and energy efficient GPU designs.
	- Familiarity with Verilog and ASIC design principles is a plus.
	- Ability to formulate and analyze algorithms, and comment on their runtime and memory complexities.
	- Desire to bring quantitative decision-making and analytics to improve the energy efficiency of our products.
	- Good verbal/written English and interpersonal skills.
+ skill set:
	- NVIDIA is in search of Summer 2022 intern candidates with interests in computer architecture to join our memory system architecture team!  This team drives memory system architecture in products tailored to NVIDIA’s world changing SOCs for autonomous vehicles, mobile systems, server systems, deep-learning, and gaming.
	- Developing architecture and micro-architecture to improve the state-of-the-art in memory system optimizing along the axes of performance, power efficiency, complexity, area, effort, and schedule.
	- Performance modeling and simulation of features to improve memory system efficiency.
	- Implementing and maintaining high-level functional and performance models.
	- Analyzing benchmarks, application workloads, and performance simulation results to identify tradeoffs in areas of micro-architectural optimizations.
	- Debugging performance and functional issues with high-level models, RTL simulation, and silicon.
	- Enrollment in a BS, MS, or PhD program in CS/CE/EE or related field.
	- Minimum GPA: 3.5
	- You have an impeccable hardware engineering background with a concentration in VLSI and/or Computer Architecture.
	- Exposure/coursework related to Digital systems and VLSI design, Computer Architecture, C/C++ programming languages.
	- Deep understanding of memory subsystems – caches and coherence protocols, DDR and memory controller architecture, on-chip interconnects, address translation.
	- Strong communication and interpersonal skills are required along with the ability to work in a dynamic, product oriented, distributed team.
	- Strengths in C++, Perl or Python. Verilog or SV/UVM are a big plus.
+ skill set for Deep Learning Architect Intern:
	- NVIDIA is seeking computer architecture interns to help design processor and system architectures that will enable compelling Deep Learning performance, architecture and efficiency improvements. This role offers the opportunity to directly impact the future hardware and software roadmap in a fast-growing technology company that leads the AI revolution. If you are obsessed with improving deep learning performance beyond anything possible with today’s hardware and software, this is the place to be.
	- Understand, analyze, profile, and optimize deep learning training workloads on state-of-the-art hardware and software platforms.
	- Guide development of future generations of deep learning processors and computing platforms.
	- Develop detailed performance models and simulators for computing systems accelerating DL training.
	- Collaborate across the company to guide the direction of machine learning at NVIDIA; spanning teams from hardware to software and research to production.
	- Drive HW/SW co-design of NVIDIA’s full deep learning platform stack, from silicon to DL frameworks.
	- You are pursuing a PhD or MS in CS, EE or CSEE.
	- Strong background in computer architecture, preferably with focus on high-performance parallel processors.
	- Background in machine learning and neural networks, in particular training.
	- Experience analyzing and tuning application performance.
	- Experience with processor and system-level performance modelling.
	- Programming skills in C++ and Python.
	- Familiarity with GPU computing (CUDA, OpenCL).
+ Experience with MongoDB and/or ELK
+ Experience with at least one of the job schedulers such as LSF, SLURM, Mesos/Marathon, Kubernetes, Docker Swarm
+ Experience with containers – Docker, Clear Containers, rkt
+ Knowledge of OS/driver software stacks, e.g., Linux/QNX.
+ Some experience working with and implementing DevOps solutions including but not limited to Python, Ansible, Docker/Containers, Kubernetes and datacenter deployments
+ skill set:
	- Experience with Jamf Pro and Google MDM and software management tools.
	- Experience in designing/delivering modern workflow methodologies (DEP/VPP/ABM).
	- Experience with implementing open-source tools into an MDM product: Munki, autopkg, and osquery.
+ skill set:
	- computational science, especially computational physics/chemistry/biology for statistical mechanics, biophysics, fluid mechanics, and molecular dynamics.
	- statistical methodology, modeling, and inference
	- numerical methods for solving PDEs, PDE solvers
	- high-performance computing and software libraries
	- signal and image processing for neurophysiology and structural biology
	- machine learning for scientific applications
	- mathematics, algorithms, and optimization for deep neural networks
+ skill set:
	- Kiwibot is looking for a Senior Machine Learning Engineer role and it could be a great opportunity to join us. You should have the right technical knowledge and understanding of common and novel computer vision, and machine learning techniques to support and develop new algorithms, and create solutions. You should also have proven experience designing, developing and deploying machine learning solutions on real world applications.
	- As a Machine Learning Engineer : You will report directly to our Head of AI & Robotics.
	- Implement, train and iterate vision based deep learning models.
	- Train models on Cloud on single and multiple GPUs. 
	- Design and implement data pipelines for storing and processing thousands of images and videos.
	- Design and integrate with third party labeling company API for upload and ingestion of data and labels. 
	- Design and implementation of data harvesting from current fleet operations. 
	- Create data visualization tools for data analysis and debugging. 
	- Evaluate the quality of labeling of data.
	- Design and iterate labeling instructions that produce high quality labels.
	- Implement, design and manage databases of images, videos and metadata associated with them.
	- Optimize models for performance on constrained environments.
	- Deploy trained models on-premise integrated with the rest of the robot’s software stack.
	- Report of training procedures, error analysis, data review.
	- Offline database analysis for getting insights, generating labels automatically, doing anonymization, etc. 
	- You have knowledge of Python and scripting (advanced) 
	- Git (intermediate/advanced) 
	- Docker, docker-compose (advanced) 
	- Scrum and agile methodologies 
	- Vast experience with deep learning frameworks like pytorch/tensorflow 
	- Experience with one or more cloud providers (advanced), GCP is a plus 
	- Deep understanding of DL techniques like CNN, LSTM, RNN, Transformers
	- Hands on with semantic segmentation algorithms, object detection or depth estimation.
	- Experience using and implementing RESTFULs services 
	- Terraform/pulumi knowledge for deploying solutions 
	- Experience with some MLOps, MLFlow is a plus 
	- SQL and no SQL databases (advanced). BigQuery is a plus 
	- ROS or ROS2 (basic) is a plus 
	- C++ (intermediate) is a plus 
	- Experience with sensor technologies is a plus (Lidars 2D, 3D, Stereo Cameras, Cameras, IMU, GPS) 
	- Strong English level, both written and spoken.
+ skill set:
	- We are looking for Machine Learning Interns to \#JoinTheBand and help drive a data-first culture across Spotify.  You will work on a variety of problems such as content recommendation, personalization, optimization, user intelligence, and content classification. You will work with a team to come up with new and interesting hypotheses, test them, and scale them up to huge data sets with hundreds of billions of data points. Above all, your work will impact the way the world experiences music.
	- Apply machine learning, collaborative filtering, NLP, and deep learning methods to massive data sets
	- Prototype new algorithms, evaluate with small scale experiments, and later productionize solutions at scale to our 140 million active users
	- Collaborate with a cross functional agile team of software engineers, data engineers, ML experts, and others to build new product features
	- Help drive optimization, testing and tooling to improve data quality
	- Iterate on recommendation quality through continuous A/B testing
	- You are pursuing a Ph.D. or Master's degree in Machine Learning, Statistics or related field preferred
	- You have a graduation date of 2022 or 2023
	- You currently have valid work authorization to work in the country in which this role is based that will extend from June to August 2022
	- You have experience implementing machine learning systems at scale in Java, Scala, Python or similar (not just R or Matlab)
	- You have a strong mathematical background in statistics and machine learning
	- You care about agile software processes, data-driven development, reliability, and responsible experimentation
	- You preferably have experience with data processing and storage frameworks like Hadoop, Scalding, Spark, Storm, Cassandra, Kafka, etc.
	- You preferably have machine learning publications or work on open source to share with us
	- We are a distributed workforce enabling our band members to find a work mode that is best for them!
	- Where in the world? For this role, it can be within the Americas region in which we have a work location.
	- Prefer an office to work from home instead? Not a problem! We have plenty of options for your working preferences. Find more information about our Work From Anywhere options here.
	- Working hours? We operate within the Eastern Standard time zone for collaboration.
+ skill set:
	- We are looking for a Financial Systems Engineering Intern who is organized, passionate, and excited to learn. You will join our Financial Systems team in NYC responsible for the support and growth of a suite of financial SaaS tools. In this role, you will primarily help support the daily operations of our NetSuite, Concur, Coupa, and Blackline systems. Above all, your work will impact the way the world experiences music.
	- Provide front-line support across a suite of financial systems, learning along the way.  
	- Troubleshoot process, application, and functional issues, and manage these through to resolution. 
	- Identify areas of opportunity for process optimization and system automation to enable rapid growth in the Financial Systems end-user base. 
	- Support major system upgrades in NetSuite, Coupa, and Blackline. 
	- Support testing of ongoing enhancements. 
	- Engage with stakeholders across the entire Spotify organization. 
	- Work from our office in New York or remotely anywhere in the US, collaborating with our partner team based in Stockholm. 
	- A current undergraduate or graduate student pursuing a degree in Computer Science, Engineering, Finance, or Accounting, and planning to graduate in 2023. 
	- You currently have valid work authorization to work in the country in which this role is based that will extend from June to August 2022. 
	- You know how to balance multiple tasks, problem solve in new contexts and communicate clearly. 
	- You are experienced in system development and/or accounting. 
	- You care about optimizing systems and processes and have a keen eye for detail. 
	- You have experiences with system development and accounting processes that you can tell us about.
+ skill set:
	- We are looking for a Data Analyst Intern to \#JoinTheBand and support our Tech Learning team. As a part of our Collaborative Learning Product Area, The Tech Learning team creates peer-to-peer learning experiences that upskill and reskill Spotify employees in technical domains. We are looking for a Data Analyst Intern to consume, understand, and interpret data across our programs and create tools to better understand topics like customer demand and customer learner journeys.
	- Perform analyses on large sets of data to extract practical insights that will help drive decisions across the business
	- Build dashboards and recurring reporting results, empowering creative growth and business decisions
	- Communicate data-driven insights and recommendations to key collaborators
	- Work closely with the Tech Learning team, Data Scientists, and other key stakeholders across disciplines
	- You are pursuing a Bachelor’s, Master’s degree, or bootcamp certification in Data Science, Computer Science, Statistics, Economics, Mathematics, or a similar quantitative subject area
	- You have a graduation date of 2023 or later
	- You currently have valid work authorization to work in the country in which this role is based that will extend from June to August 2022
	- You harbor a passion for numbers and the use of data to make decisions
	- You have the technical competence to perform more analytics in one or more of the following areas:Coding skills (such as Python, Java, or Scala)Analytics tools experience (such as Bigquery, SQL, or Tableau)
	- Experience and passion for performing analysis with large datasets
+ skill set:
	- Spotify is looking for Data Engineering Interns to join us this Summer. You will build data driven solutions to bring audio and digital media experiences to our millions of active users and artists either by working directly on product features, publishing and insight tools for artists, or by improving the quality of our data tools and large scale data infrastructure. You will take on complex data-related problems using some of the most diverse datasets available — user behaviors, acoustical analysis, revenue streams, cultural and contextual data, and other signals across our broad range of mobile and connected platforms. Above all, your work will impact the way the world experiences audio.
	- Build large-scale batch and real-time data pipelines with data processing frameworks like Scalding, Scio, Storm, Spark and the Google Cloud Platform.
	- Use best practices in continuous integration and delivery.
	- Help drive optimization, testing and tooling to improve data quality.
	- Collaborate with other engineers, ML experts and collaborators, taking learning opportunities that will arise every single day.
	- Work in multi-functional agile teams to continuously experiment, iterate and deliver on new product objectives.
	- You are pursuing a Bachelor's or Master's degree or a bootcamp certification in Computer Science or Computer Engineering or a related field of study.
	- You currently have valid work authorization to work in the country in which this role is based that will extend from June to August 2022
	- You are a current sophomore, junior or senior in undergrad or a first or final year Master's student
	- You've dabbled in high volume data, preferably with distributed systems such as Hadoop, BigTable, and Cassandra.
	- You know how to write distributed, high-volume services in Java, Scala and Python.
	- You've had exposure to data modeling, data access, and data storage techniques.
	- You have an interest in agile software processes, data-driven development, reliability, and responsible experimentation.
	- You understand the value of collaboration within teams.
+ skill set:
	- We are looking for Machine Learning Engineering Interns to help drive a data-led culture across Spotify. You will apply machine learning methods to extensive data sets to extend improve Spotify’s means of understanding and engaging users across various contexts and modalities. You will build upon Spotify’s deep understanding of our content, users, and artists to develop rich analytics, engagement, and business applications. Above all, your work will impact the way the world experiences audio.
	- Contribute to designing, building, evaluating, shipping, and refining Spotify’s product by hands-on ML development
	- Collaborate with a cross functional agile team spanning user research, design, data science, product management, and engineering to build new product features that advance our mission to connect artists and fans in personalized and relevant ways
	- Assist in prototyping new approaches and product-ionize solutions at scale for our hundreds of millions of active users
	- Help drive optimization, testing, and tooling to improve quality
	- Be part of an active group of machine learning practitioners across Spotify) collaborating with one another
	- You are pursuing a Bachelor’s or Master’s degree in Machine Learning, Computer Science, Computer Engineering or a related field of study
	- You have dabbled in ML engineering practices via prior internships, coursework, and/or projects
	- You have experience in working with Scala and/or PythonYou have an understanding of system design, data structures, and algorithms
	- You care about quality and you know what it means to ship high-quality code
	- You are currently in your final or penultimate year of your studies
+ skill set:
	- We are looking for a Research Scientist Intern to join our growing Trust & Safety Research & Algorithmic Impact team. Spotify’s Algorithmic Responsibility effort focuses on empowering Spotify teams to assess the algorithmic impact of their products on audio culture, avoid algorithmic harms and unintended side effects, and better serve worldwide audiences and creators. As an Algorithmic Impact research intern, you will help to define, research, and communicate how we assess our impact as a platform and our recommendations across podcasts, music, and user-generated content. We help ensure that Spotify is a safe platform that’s true to our values.
	- Be part of an interdisciplinary team focused on understanding Spotify’s impact as a platform, and practical implementation and operationalization of Responsible ML activities such as algorithmic impact assessments. 
	- Contribute to the wider research community by publishing. 
	- Develop and iterate policy and auditing processes related to tech responsibility, algorithmic fairness and representation in the music and podcast industry. 
	- Apply your scientific knowledge to develop strategy around cultural equity in audio and algorithmic systems, including application-oriented problems in search, recommendation and Machine Learning settings. 
	- Provide consultative support, guidance on methods, and research-based input for products. For instance, this can include algorithmic audits, or analyzing & tracking global and local trends around online abuse, hate content, misinformation, etc., with a particular focus on algorithmic amplification. 
	- Work closely with our team and internal partners to develop, refine, and launch processes that help ensure Spotify is a safe and positive experience. 
	- Be a valued member of an autonomous, multi-functional team working in collaboration with other scientists, engineers, product managers, policy experts, designers, user researchers, and analysts across Spotify to design creative solutions to exciting problems.
	- You are pursuing a PhD in Social Science, HCI, Computer Science, Information Science, Data Science, Technology Policy, or related areas with a strong computational focus.
	- You have publications in communities such as the Web Conference, AIES, FAccT, CSCW, SIGIR, CHI, ACL, NeurIPS, WSDM, EMNLP, RecSys, KDD, ICWSM, ISMIR or related venues.
	- You are curious about how interaction design, data collection strategies, and people’s perceptions affect Machine Learning outcomes.
	- You are a creative problem-solver who is passionate about digging into complex problems and devising innovative ways to reach results.
	- You have experience with the complexities of real-world data, and understand the value of both in-depth, qualitative and web-scale, quantitative data working together to build a deep understanding of people’s interaction with technology.
	- Knowledge or experience working in emerging markets is a plus.
	- You have strong communication skills, both written and verbal. Able to provide concise advice and translate complex challenges clearly. Willing to apply academic knowledge and frameworks into product and practice.
	- You must be comfortable reviewing or being exposed to sensitive content and topics, and having related conversations with teams.
+ skill set:
	- We are looking for Data Scientist Interns to #JoinTheBand and help drive a data-first culture across Spotify. Our Data Scientist mission is to turn terabytes of data into insights and get a deep understanding of music and listeners so we can impact the strategy and direction of Spotify. You will study user behavior, critical initiatives, markets, content, and new features and bring data and insights into every decision we make. Above all, your work will impact the way the world experiences audio. 
	- Perform analyses on large sets of data to extract concrete insights that will help drive decisions across the business
	- Build dashboards and recurring reporting results, empowering creative growth and business decisions.
	- Communicate data-driven insights and recommendations to key collaborators
	- Work closely with cross-functional teams of analysts, product owners, marketers, designers, and others across the company who are passionate about Spotify’s success
	- You are pursuing a Bachelor’s, Master’s degree or bootcamp certification in Science, Computer Science, Statistics, Economics, Mathematics, or similar quantitative field
	- You are a sophomore, junior or senior in undergrad or a first or final year in a Master's program
	- You have harbor a passion for numbers and the use of data to make decisions
	- You have have technical competence to perform more analytics in one or more of the following areas:
	- Coding skills (such as Python, Java, or Scala)
	- Analytics tools experience (such as Pandas, R, SPSS, SQL or Tableau)
	- Experience performing analysis with large datasets
+ Experience with RxJS or other event-based/observer framework
+ skill set:
	- Master’s degree in software development, computer science, algorithm design, artificial intelligence, or machine learning or equivalent experience
	- 5 years of experience as a machine learning engineer and using libraries, such as Scikit-learn, TensorFlow, Caffe, Keras, etc.
	- Experience with Microsoft Azure platform – Azure ML Services, Databricks, AKS, etc.
	- Experience with the Hadoop ecosystem (e.g., Apache Hive, Pig, HBase and Kafka)
	- Experience with distributed computing platforms, such as Spark, and user interface frameworks, such as Angular or React
	- Ph.D. in software development, computer science, algorithm design, artificial intelligence, or machine learning or equivalent experience
	- Strong object-oriented programming skills, including proficiency in Java, Scala, C/C++ or Python
	- Strong SQL skills
	- Proficiency in the Microsoft Office suite
	- The Machine Learning Engineer designs and develops the platform and frameworks that facilitate automated data-driven decision-making, gathers data, and determines statistical algorithms and models that a system can use to learn from experience, predict outcomes and make decisions.
	- Collaborate with data scientists to develop algorithms and tools for training and running simulations
	- Build services to interact with machine learning models through simulations
	- Participate in code reviews to ensure code quality and share best practices
	- Develop services that host the trained models and work with other application teams to integrate them into business processes
	- Gather and analyze large datasets and develop data model pipelines
	- Develop algorithms that drive automated data-driven decision-making
	- Build the tools for monitoring the performance of machine learning applications
+ skill set:
	- Our core cultural values are manifested in our practices and processes every day. We highly value transparency and fairness in everything we do. We look for people who like to move quickly, are ambitious yet humble and have a great sense of humour. If you have a mischievous spark of fun, that’s even better.
	- What you will be doing
		* We’re looking for an experienced DevOps Engineer to join a team of talented engineers to develop high quality products which are scalable, testable, extensible, and provide high value to our customers.
		* As a key member of the server and infrastructure team, you will work closely with the various development teams to provide operational support. This support will help them gain insight into their systems, improve reliability, and increase developer productivity.
		* This is an individual contributor role where you will be reporting to a Team Lead. This role can be based in Vancouver or Toronto, with benefits from a flexible hybrid work model of remote + in office collaboration.
	- Responsibilities
		* The ultimate tasks for a DevOps Engineer can vary from company to company, but the base responsibilities are usually similar. Monitoring and improving infrastructure and processes will be part of the job at Later just as it would be anywhere else. That being said, there are some things that we are particularly keen on at Later.
		* Ability to work with different engineering teams, back end, web front end, and mobile teams.
		* Bringing your wealth of knowledge and experiences (good and bad) to Later and improving our processes and technology.
		* Educating product and stakeholders on the trade-offs of different paths to a given milestone to enable them to make educated decisions for our roadmap.
		* Writing documentation by hand or via automation.
		* Holding other developers, in particular other Senior Developers, to high coding standards through PR reviews.
		* Constantly learning and staying up-to-date through use of dedicated unstructured dev time for you to: making open-source contributions, writing technical blog articles, creating internal tools for non-feature work, as well as self-education on relevant topics.
		* Knowing when good is good enough.
		* Knowing when good just isn’t going to cut it.
		* Joining the on call rotation.
		* Writing documentation, did we mention that?
		* Taking ownership of pieces of code, infrastructure, and processes and then caring enough to improve them.
		* Knowing how to scale workloads while managing the various resources used by them.
		* Owning and improving deployment processes for the different apps and services
		* Supporting CI/CD pipelines for the various development teams
		* Maintaining documentation and runbooks for the services and infrastructure
		* Owning and scheduling maintenance for dependencies, i.e., databases and cache stores
		* Owning and improving infrastructure monitoring and alarming
		* Improving and optimizing the use of our AWS infrastructure
		* Automation of common task that allow you to be removed from the process
	- Supported Tech... in our tech stack:
		* A moderately sized Ruby on Rails monolith
		* Dockerized services written Node, Ruby, and Elixir
		* Node/Express/Typescript API
		* Postgres, Redis, and DynamoDB datastores
		* Deployments in Heroku and AWS (ECS, EKS, and Lambda)
		* CircleCI based CI pipeline
	- What we are looking for
		* 3+ years of experience working on a team and shipping code and services in production environments
		* Minimum 2+ years devops experience
		* Strong experience managing AWS based deployments, K8s preferred
		* Experience working with Dockerized services (micro or other)
		* Experience with infrastructure-as-code
		* Experience CI/CD pipelines across multiple domains
		* Familiarity with Postgres (or other relational DBs)
		* Familiarity with cloud based security best practices
		* Familiarity with Agile process
		* We believe that good DevOps people have the ability to pick up new processes and technologies quickly, but some of the following will help you hit the ground running in one area or another.
		* Experience working on Ruby on Rails applications
		* Experience working with Typescript/Express applications
		* Experience with AWS based DevSecOps
		* Experience with processing images at scale
	- Culture/Benefits
		* We are passionate about learning and development, providing opportunities through lunch and learns, training and workshops. We also provide each employee with a $3000 per year Education & Conference budget.
		* We provide our employees with a monthly Wellness Spending Account, to help cover costs related to fitness equipment, personal training, gym memberships or health and wellness practitioners.
		* We provide our team with a generous technology bonus and provide the tools you need to succeed in your role.
		* We offer a comprehensive benefits package including health, dental, vision, and an Employee and Family Assistance Program to support the wellbeing of you and your family.
		* We offer flexible working hours & schedules so you can work around school and home commitments.
		* We offer parental leave top-ups, family forming support and a life-transitions program to ensure you and your family are well supported when returning to work
		* We provide a variety of workshops, meditation and yoga at our monthly Wellness Wednesday events to help our team perform at their best.
		* All departments have quarterly department team building activities
		* We fly all employees in or out to join us at our fun filled annual company retreat.
		* Later values diversity of thought; we are committed to creating a diverse environment and are proud to be an equal opportunity employer. All applications will receive consideration for employment without regard to race, colour, religion, gender, gender identity or expression, national origin, disability, or age.
+ skill set:
	- We’re looking for an experienced Senior Software Developer (back end) to join a team of talented engineers to develop high quality products which are scalable, testable, extensible, and provide high value to our customers.
	- As a key member of the development team, you will work closely with designers, product managers, and other key stakeholders to define and execute on both our short term critical missions and long term vision.
	- This is an individual contributor role where you will be reporting to a Team Lead. This role can be based in Vancouver or Toronto, with benefits from a flexible hybrid work model of remote + in office collaboration.
	- The base responsibilities for a Senior Developer are the same across most companies. Critical thinking, designing and implementing well structured and robust solutions, writing tests, mentoring junior developers will be part of the job at Later just as it would be anywhere else. That being said, there are some things that we are particularly keen on at Later.
	- Bringing your wealth of knowledge and experiences (good and bad) to Later and improving our processes and technology.
	- Educating product and stakeholders on the trade-offs of different paths to a given milestone to enable them to make educated decisions for our roadmap.
	- Writing documentation by hand or via automation.
	- Holding other developers, in particular other Senior Developers, to high coding standards through PR reviews.
	- Constantly learning and staying up-to-date through use of dedicated unstructured dev time for you to: making open-source contributions, writing technical blog articles, planning developer events, preparing conference talks, creating internal tools for non-feature work, as well as self-education on relevant topics.
	- Knowing when good is good enough.
	- Knowing when good just isn’t going to cut it.
	- Joining the on call rotation.
	- Writing documentation, did we mention that?
	- Taking ownership of pieces of code, infrastructure, and processes and then caring enough to improve them.
	- Knowing how to scale workloads while managing the various resources used by them.
	- Here is an abridged list of of things you can find in our tech stack:
		* A moderately sized Ruby on Rails monolith
		* Dockerized Node services deployed to AWS ECS
		* Node/Express/Typescript API
		* A pure Ruby analytics collector application
		* Postgres, Redis, and DynamoDB datastores
		* Microservices written in Elixir
	- What we are looking for
		* 5+ years of experience working on a team and shipping code in production environments
		* Minimum 5+ years software development experience
		* Minimum 2+ years solid web app development experience
		* Experience providing technical leadership and guidance
		* Experience architecting and implementing complex services from design to deployment and through maintenance
		* Ability to mentor junior developers
		* Experience writing test suites and CI/CD pipelines
		* Proficiency in Postgres (or other relational DBs)
		* Familiarity with OWASP best practices
		* Familiarity with Agile process
		* Experience working on Ruby on Rails applications
		* Experience working with Typescript/Express applications
		* Experience working with Dockerized services (micro or other)
		* Experience with AWS based DevSecOps
		* Experience with processing images at scale
	- Multiple company-wide Hackweeks each year
	- PTO awarded for being part of the on call rotation
	- Regular Unstructured Development Time to investigate new technologies that would benefit you and your team
	- Working with the latest versions of Ruby and Rails. No legacy Ruby 2.3 or Rails 4.2 apps here.
+ ***OpenCV Ceres, ROS, PyTorch***
+ skill set:
	- GrAI Matter Labs is a young and vibrant high-tech company, which aims to revolutionize artificial intelligence for everyone. Our unique machine learning technology will drive the next generation of computer chips to power many future products. This way, we contribute to making robots, cameras, and transportation smart, safe, and power-efficient. GML is an international company, with highly motivated teams in offices in France (Paris), Netherlands (Eindhoven), and USA (San Jose).
	- At GML, we develop new technologies for efficient low-latency and low-power processing of neural networks, for training neural networks, and for neuromorphic computing. And we are looking for talented MSc candidates to help us in this research.
	- If you are an MSc candidate with a background in electrical engineering, computer science, or computer architecture, and you are looking for a cutting-edge environment to perform your MSc thesis project, then you should certainly consider applying at GML!
	- You will be embedded in a team of highly trained and highly motivated architects, scientists, and engineers. In your assignment, you will work with experts in the fields of processor architecture, computer architecture, compiler construction, neural network and neuromorphic processing. These are some of the topics we are currently working on:
		* Retraining neural networks for imposed temporal sparsity;
		* Improving input signal sparsity;
		* Mixed-precision training;
		* LIDAR-based neural network applications;
		* Bayesian machine learning on neuromorphic architectures;
		* Neural-networks mapper algorithms for massive-multicore Systems;
		* Auto-tuners for efficient neural-network mapping for massive multicore systems;
		* NoC architectures for neuromorphic massive multicore systems;
		* Low-power techniques for neuromorphic massive multicore systems.
		* AI solutions for [ANDANTE project](https://www.andante-ai.eu/) use cases, together with partners such as ST Microelectronics, Philips, Boeing, Thales, Valeo, CEA, and Fraunhofer.
		* AI solutions for medical sensor systems in the [pAvIs project](https://penta-eureka.eu/project-overview/penta-call-5/pavis/), together with partners such as Philips, Cochlear, and InBrain.
	- Responsibilities:
		* Determining the scientific contributions of your project, and advancing the state-of-the-art in neural network processing;
		* Providing GML with new technologies for neural network processing and neuromorphic design;
		* Defining your project goals, deliverables, and plans, to fit the timeframe of your assignment;
		* Running and managing your project, together with your GML advisors, university supervisors, colleagues, and co-students;
		* Delivering a final report for your MSc graduation.
	- Requirements:
		* Master student with a background in Electrical of
		* Strong mathematics, computer science, and/or computer architecture background
		* Strong machine-learning background, and hands-on experience with neural network frameworks, such as Tensorflow
		* Strong programming skills (e.g. Python, C, C++)
		* "Can-do" mentality, excellent problem-solving skills
	- GrAI Matter Labs is a dynamic organization which employs some of the brightest minds in the industry and is known for the great care we take with clients and employees alike. We believe we will win as a close-knit team that converts a strong vision into products that solve use cases which our customers truly value. We also hold to the highest standards of inclusion, team spirit, and cooperation. This position is based at GrAI Matter Labs offices at the High Tech Campus in Eindhoven, The Netherlands. The High Tech Campus houses 160 companies, employing a total of 11,000 entrepreneurs and R&D employees. To our interns, we offer a nice compensation, in line with what is customary around the Eindhoven area.
+ skill set:
	- Work on exciting Proof of Concept projects with using GrAI VIP
	- Train Deep Learning models that work on Real-World Scenarios.
	- Develop and optimize AI training pipelines.
	- Use different sensors to acquire data.
	- Create applications using AI and robotics.
	- You will work closely with the Customer’s Solutions Architect Team to deliver contents that drive results.
	- You are in your last year of your engineering School.
	- Pursuing a master's degree program in Computer Science, or related technical field.
	- Programming experience in Python. Experience in C/C++ is a plus.
	- Good Understanding of Deep Learning fundamentals.
	- Experience using one or more of the Machine Learning Libraries (TensorFlow, Keras, PyTorch).
	- Experience working in Linux environments.
	- Team Player.
	- Problem-solver keen to find innovative solutions in any situation.
	- Super enthusiastic, and you like to be challenged!
	- Fluent in English and willingness to work in an international context.
+ skill set:
	- GrAI Matter Labs is looking for a talented Senior AI Processor Architect to help us shape the next generation of our GrAI Core Architecture and its pre- and post-processing peripherals (such as image processing, FFT, IFFT...). As a Senior Core Architect you will own the specifications of one or more components of our core architecture. You will analyse the performance of our processors for selected applications, and propose, quantify and specify architectural features and optimisations to improve the performance, cost and power consumption of our next generation GrAI Core.
	- You are expected to play a key role in innovation, working with partners on benchmarking and optimizing architectural features to match the needs of the application and efficiently mapping and prototyping them on the company’s architecture, as well as adapting such concepts to work in production-grade systems.
	- Our ideal architect is creative, curious, knowledgeable, and not afraid to get their hands dirty by helping the hardware and tools teams with implementation tasks when necessary. The right candidate knows how to find solutions that are both theoretically sound and provide the best cost-performance trade-offs, while also considering all the practical constraints created by the development process.
	- As part of the architecture team your main responsibilities are:
		* to carry out analysis of the performance and cost of the existing core architecture;
		* to propose and evaluate new architectural features in collaboration with the other members of the architecture team;
		* to draft and own specifications of features in the next generations of the GrAI Core;
		* to provide guidance and assistance to hardware and tools engineers;
		* to contribute to the long-term technological direction of the company.
		* You will be working on exciting and emerging topics, finding new techniques and silicon technologies to exploit sparsity and event-driven processing of neural networks to enable new applications on the Edge.
	- Master or PhD in Electrical engineering, Computer Engineering or Computer Science;
	- 5+ years of experience in designing chips and hardware;
	- Excellent theoretical knowledge and practical experience in computer architecture and hardware design, including network-on-chip, datapath, memory hierarchy;
	- Excellent skills and experience as a hardware designer;
	- Knowledge of VLSI process technology and backend is a big plus;
	- Knowledge of compilers, simulators and other software development tools is a plus.
	- Knowledge of machine learning, deep learning and AI applications is a plus.
+ skill set:
	- The machine learning engineer’s primary role is to support the research team in developing commercial applications for BrainChip’s Akida Neuromorphic System-on-Chip (NSoC). Some of the target applications include work in computer vision (object classification/detection and face recognition), audio processing (keyword spotting), and sensor fusion. Additionally, this team member will support the research team’s algorithm development for the next version of the Akida NSoC.
	- B.S. in Computer Science or equivalent
	- Course work in machine learning and computer vision
	- Strong programming skills in Python
	- 3 years’ experience developing ML applications in either TensorFlow/Keras and/or PyTorch
	- Excellent communication skills
	- The ability to read, understand, and implement algorithms from technical ML journals
	- Master’s in computer science of equivalent
	- 4+ years experience developing ML applications in TensorFlow/Keras and PyTorch
	- Multi-project experience in object classification, object detection, face recognition, and/or keyword spotting
	- Knowledge of deep learning quantization techniques
	- Experience with Docker and Git
	- Experience with Scrum/Agile software development (e.g. Jira)
+ skill set:
	- The junior machine learning engineer’s primary role is to support the research team in developing commercial applications for BrainChip’s Akida Neuromorphic System-on-Chip (NSoC). Some of the target applications include work in computer vision (object classification/detection and face recognition), audio processing (keyword spotting), and sensor fusion. Additionally, this team member will support the research team’s algorithm development for the next version of the Akida NSoC.
	- B.S. in Computer Science or equivalent
	- Course work in machine learning and computer vision
	- Strong programming skills in Python
	- 1 year experience developing ML applications in either TensorFlow/Keras and/or PyTorch
	- Excellent communication skills
	- The ability to read, understand, and implement algorithms from technical ML journals
	- 2+ years experience developing ML applications in TensorFlow/Keras and PyTorch
	- Multi-project experience in object classification, object detection, face recognition, and/or keyword spotting
	- Knowledge of deep learning quantization techniques
	- Experience with Docker and Git
	- Experience with Scrum/Agile software development (e.g. Jira)
+ skill set:
	- At Brainchip, we are revolutionizing Artificial Intelligence at the edge with our AkidaTM Hardware and Software products. Akida™ hardware and software products are the result of over a decade of fundamental R&D by BrainChip engineers and data scientists. Akida AI IP, AI SoC, and development environment help customers create ultra-low-power solutions with the ability to incrementally learn on-chip without the need to retrain in the cloud.
	- We are looking for a HW Design Engineering Summer Intern (May-August 2022) with a strong background in Digital Design and excellent Verilog/System Verilog coding and scripting skills.
	- As a HW Design Engineering Intern, you will work on our latest AI Chip and/or IP design. You will work closely with the HW Engineering team using Industry standard tools and flows for RTL design, verification, automation and debug. The position requires willingness and ability to learn quickly and excellent communication skills.
	- GPA 3.0 and above
	- Currently enrolled in a Bachelors/Masters program in Electrical Engineering and/or Computer Science with a graduation date of Dec 2022 or later.
	- Candidate should be local to Southern California since this position does not provide relocation assistance.
	- Currently pursuing a Bachelors or Masters in Electrical Engineering and/or Computer Architecture with emphasis on Digital Design, Verification or Computer Architecture
	- Familiarity with Digital design using Verilog/System Verilog
	- Proficient in scripting languages like Python, PERL, or Shell scripting
	- Strong analytical and problem-solving skills
+ skill set:
	- The machine learning research scientist’s primary role is to work with other R&D team members to imagine, define, and develop BrainChip’s spiking neural network technology. This research takes place at the interface between machine learning algorithms, event-based algorithms, and neuromorphic hardware. The research scientist will also be involved in developing commercial applications for BrainChip’s Akida Neuromorphic System-on-Chip (NSoC). Target commercial application topics include computer vision (object classification/detection and face recognition), audio processing (keyword spotting), and sensor fusion. Additionally, the team member will support the research team’s algorithm development for the next version of the Akida NSoC.
	- Ph.D. in computer science (or equivalent) or MS in computer science with +5 years of machine learning experience
	- 3+ years of machine learning experience using Python
	- Experience with supervised, unsupervised, and reinforcement learning
	- Experience in popular Deep Learning/Machine Learning frameworks (Keras, Tensorflow, PyTorch, Scikit-learn, etc.)
	- Experience in one or more of the following application fields: Image Processing/Computer Vision, ADAS, Anomaly Detection, Audio/Speech Processing, or Sensor Fusion.
	- Experience in Neuromorphic Engineering and/or Spiking Neural Networks
	- Experience with event-based algorithms
	- Experience with Git version control system
+ skill set for Research Scientist, Sculpting Evolution:
	- The Sculpting Evolution Group seeks to a research scientist to supervise and assist research projects focused on advancing biotechnology safely. Ideal candidates will be committed to glimpsing the best possibilities of the future and making them real.
	- On a practical level, we’re looking for people who:
		* Enjoy hands-on work with a wide variety of experimental systems and biology-relevant laboratory techniques,
		* Love continually learning, developing, applying, and teaching new methods and techniques,
		* Are happy to be asked for help, to lend a hand when it’s possible, and to say no when it’s not,
		* Have strong written and oral communication skills,
		* Do their best to contribute to a supportive team atmosphere with explicit proactive communication,
		* Are enthusiastic about mentorship and committed to building an outstanding research team.
	- Broader views are also important. Particularly strong candidates might be those who:
		* Aim to ensure that biotechnology benefits as many morally relevant beings as possible,
		* Recognize the importance of mitigating catastrophic risks,
		* Care more about long-term impact than conventional metrics,
		* Gladly seize upon a small chance of achieving a tremendously impactful outcome.
	- The group’s overt research interests have shifted over the past few years. We retain a focus on understanding and controlling evolution, including but not limited to our PRANCE system for high-throughput robotic directed evolution, and adding machine learning and in silico directed evolution to our repertoire. However, we now focus more on engineering mammalian systems, not just in developing novel genome editing approaches relevant to ecological engineering, but also with relevance to biosecurity and mitigating catastrophic risks, for some of the reasons outlined here. Example ongoing projects in this area include SecureDNA and the Nucleic Acid Observatory; we also work on receptor decoys and other broad-spectrum or rapidly scalable defenses against exponentially spreading agents. As these projects span an impressively large number of fields, we seek generalists with expertise covering several of them.
	- On a day-to-day level, the position will involve designing and performing experiments, supervising diverse research projects in the group, training and mentoring new arrivals, helping manage key collaborations, writing publications and grant proposals, and optionally engaging in science communication to general audiences or to policymakers. Given the breadth of research methods that we employ, willingness to learn new skills and techniques is a must.
	- REQUIRED:
		* PhD in Biology, Chemisty, Physics, Bioinformatics, MechE, or Computer Science or related field;
		* Skilled at troubleshooting experiments involving complex systems;
		* Specialized expertise in multiple fields supporting our primary areas of interest:
		* Examples of valuable skill sets include but are not limited to:
			+ Genome, cell, and organism editing – applied to biosecurity, ecological engineering, and animal well-being
			+ Cell culture, virus propagation, genome editing, flow cytometry, animal husbandry
			+ Technology development – catalytic tools for beneficial applications in diverse settings
			+ Microbiology, chemical biology, evolutionary biology, robotics, bioinformatics, machine learning.
			+ Support for a major collaboration focused on developing wastewater and environmental metagenomic sequencing as an early warning system, including expertise in experimental design for sensitivity testing, sampling techniques, sequencing, and data processing, analysis, and storage.
	- PREFERRED:
		* One year of postdoctoral experience;
		* Ideally some level of skill in several of these, and willingness to pick up others:
		* Library construction, NGS sample preparation, sequencing, and data analysis
		* Mammalian cell culture and engineering
		* Experience with computational biology algorithms, including bioinformatics, computational structural biology, statistical machine learning, and deep learning
		* Experience with high-performance and cloud computing, especially AWS, as well as with Github and Docker
		* Basic familiarity with circuits, hardware, 3D printing, and/or robotics, or willingness to learn the basics
		* Strong written and oral communication skills
		* Enthusiastic about mentorship and helping others learn.
+ skill set:
	- As a member of our Compiler team, you will work with leaders from industry and academia to develop entirely new solutions for the toughest problems in AI compute. 
	- As deep neural network architectures evolve, they are becoming enormously parallel, and distributed. Compilers are needed to optimize the mappings of computation graphs to compute nodes. In this position, you will build the tools that generate distributed memory code from evolving intermediate representations. 
	- Design and devise graph semantics, intermediate representations, and abstraction layers between high-level definitions (like TensorFlow and Pytorch) and low-level distributed code 
	- Use state-of-the-art parallelization and partitioning techniques to automate generation, exploiting hand-written distributed kernels
	- Identify and implement novel program analysis and optimization techniques for compilers targeting linear algebra applications on distributed memory architectures 
	- Leverage open-source tools and compiler toolchains such as ISL, MLIR and LLVM to build domain specific language and compiler for programming Cerebras Wafer Scale Engine
	- Develop and optimize the LLVM backend target for various generations of Cerebras architecture
	- Bachelor’s, Master’s, PhD, or foreign equivalents in computer science, engineering, or related field 
	- Familiarity with high-level parallel program analysis and optimization 
	- Compiler experience; experience in code generation and optimization for distributed systems
	- Strong proficiency in C/C++ or other language for designing large, performant systems
	- Familiarity with Python or other scripting language. 
	- Familiarity with multi-thread and multi-process programming models
	- MLIR & LLVM compiler toolchain internals 
	- Polyhedral models, Integer Set Library (ISL) 
	- Familiarity with HPC kernels and their optimization 
	- IEEE floating point representations 
	- Familiarity with machine learning frameworks such as TensorFlow and Pytorch 
	- Knowledge of ML application areas and state-of-the-art networks in various application areas 
+ skill set:
	- As a member of our Compiler team, you will work with leaders from industry and academia to develop entirely new solutions for the toughest problems in AI compute. 
	- As deep neural network architectures evolve, they are becoming enormously parallel, and distributed. The Cerebras compiler efficiently maps this computation onto hundreds of thousands of compute nodes, leveraging novel hardware architecture features to maximize performance while maintaining correctness. LLVM is a critical component in the compilation process, not only performing low-level optimization and efficient mapping to hardware instructions, but also ensuring effective use of novel hardware features. 
	- Work with hardware architects to ensure future hardware designs maximize the performance accessible via automatic compilation while minimizing compiler complexity
	- Develop effective representations of Cerebras’ novel architectural features in LLVM IR
	- Extend the LLVM backend to target new hardware architectures, designing and implementing performant and correct mappings from LLVM IR to Cerebras’ novel hardware
	- Design and implement LLVM IR and backend optimizations, maximizing performance on deep learning and HPC workloads
	- Mentor junior engineers on development best practices and LLVM internals
	- Collaborate closely with teams developing related software components to ensure compatibility, robustness, quality, and performance
	- Contribute to the design of higher-level intermediate representations and domain specific languages and their mapping to LLVM IR
	- Maintain our production compiler in use by customers in both the ML and HPC domains
	- Bachelor’s or foreign equivalents in computer science, engineering, or related field 
	- 5+ years of experience developing optimizing compilers using the LLVM tool chain 
	- Strong C++ development skills
	- Excellent verbal and written communication skills
	- Able to collaborate effectively in a distributed team 
	- Master’s, PhD, or foreign equivalents in computer science, engineering, or related field 
	- Production compiler development experience, particularly developing LLVM target backends
	- Experience in the design and implementation of DSLs
	- Familiarity with machine learning frameworks and intermediate representations 
	- Experience with parallel programming techniques and optimizations
+ skill set:
	- Cerebras’ Wafer Scale Engine (WSE) was designed to provide significant reduction of training times for deep neural networks. Our goal is to provide customers with the computational power needed to iterate faster so that they can develop the most accurate models possible. 
	- As an applied machine learning engineer, you will work on adapting state of the art deep learning (DL) models to run on our wafer scale system. This includes both functional validation and performance tuning of a variety of core models for applications like Natural Language Processing (NLP), Computer Vision (CV), Graph Neural Networks (GNN), Recurrent Neural Networks (RNN), and Recommendation models. 
	- As a member of the Cerebras engineering team you will be implementing models in popular DL frameworks like TensorFlow and PyTorch and using insights into our hardware architecture to unlock to full potential of our chip.  You will work on all aspects of the DL model pipeline including: 
		* Dataloader implementation and performance optimization 
		* Reference model implementation and functional validation 
		* Model convergence tuning 
		* Model performance optimization 
		* Model customization to meet customer needs 
	- This role will allow you to work closely with partner companies at the forefront of their fields across many industries. You will get to see how deep learning is being applied to some of the world’s most difficult problems today and help ML researchers in these fields to innovate more rapidly and in ways that are not currently possible on other hardware systems. 
	- Analyze, implement, and optimize DL models for the WSE 
	- Functional and convergence of models on the WSE 
	- Work with engineering teams to optimize models for the Cerebras stack 
	- Support engineering teams in functional and performance scoping new models and layers 
	- Work with customers to optimize their models for the Cerebras stack 
	- Bachelor's degree in engineering, science, or related field 
	- Experience programming in modern language like Python or C++ 
	- In-depth understanding of DL learning methods and model architectures 
	- Experience with DL frameworks like PyTorch and TensorFlow 
	- A deep passion for cutting edge artificial intelligence techniques 
	- Master's or PhD in engineering, science or related field 
	- Understanding of hardware architecture 
	- Experience programming accelerators like GPUs and FPGAs
+ skill set:
	- Cerebras' fully-integrated system is built from the ground up with a singular focus on AI. To explore new techniques and algorithms at the frontier of machine learning uniquely enabled by our revolutionary technology, our experienced team of Machine Learning engineers and researchers work in collaboration with other experts in the company, giving insight and access to every level of our system stack.   
	- This is an applied research position with a focus on working with state-of-the-art research and developing novel models and algorithms on top of our core technology. We are interested in a wide range of machine learning algorithms and application domains with a focus on exploring new ideas that hold the potential to substantially reduce computational constraints limiting today's machine learning research.
	- Develop algorithms for training and inference in sparse neural networks
	- Develop novel optimizers and learning algorithms such as local learning rules and layer-parallel training
	- Develop novel network architectures and layers such as, normalization, activation functions, and parameter layers
	- Publish and present research at leading machine learning conferences
	- Experience with machine learning frameworks, such as TensorFlow, Caffe/2, and PyTorch.
	- Fluency in a programming language, such as Python and C
	- Strong grasp of linear algebra and statistics
	- Strong track record of relevant research success in roles at the level of doctoral, postdoctoral in academia or in industrial R&D
	- Strong track record of relevant publications/patents
	- Familiarity with HPC kernels and their optimization 
	- IEEE floating point representations 
	- Familiarity with machine learning frameworks such as TensorFlow and Pytorch 
	- Knowledge of ML application areas and state-of-the-art networks in various application areas 
+ ***Knowledge of industry standards, e.g. ETSI, ASTM, NEBS, IEC, UL, CSA, ISTA, etc.***
+ skill set:
	- As an ML Engineer on our team, you will work with leaders from industry and academia at the intersection of hardware and software to develop state-of-the-art solutions for emerging problems in AI compute.
	- The Cerebras software platform is designed to be targeted by today’s most relevant machine learning frameworks such as TensorFlow, PyTorch, and JAX. Our ML software engineers are responsible for integrating these frameworks to work with our own highly optimized software stack. Fundamentally, you will be enabling ML researchers to use the software tools and workflows of today to unlock the advanced hardware capabilities of tomorrow.  
	- In this role, you will create tools and design workflows that enable the development, training, and deployment of machine learning models on our new hardware system. The workflow covers from a small to an extremely large models with trillion of parameters. Furthermore, you will be lowering abstract computations expressed via third-party ML frameworks into representations that can be compiled into highly optimized executables that target the Cerebras system, and help us design a general backend that can accommodate most advance deep learning models. You will also have the opportunity to participate and contribute to open-source projects that we depend on. 
	- Work on the end-to-end training, eval, and inference workflow with customer-facing API
	- Distributed training both via data and model parallelism
	- Scale and optimize the data pipeline
	- Lower Deep Learning framework graph presentation into our internal IR and add any missing OPs
	- Compiler optimization such as graph rewrite, constant folding, common expression elimination, and canonization
	- Lower high-level OPs to low-level OPs such as affine dialect
	- Handle both static and dynamic computational graph
	- Bachelor’s, Master’s, or foreign equivalent in Computer Science, Engineering, or related
	- 5+ years software development experience
	- Understanding of state-of-the-art deep learning model architectures and training protocols
	- Strong Python and C++ development skills
	- Direct experience with at least one Deep Learning framework internals is strongly preferred
	- Contributed to a deep learning framework
	- Experience with distributed training algorithm
	- Familiar with deep learning model architecture
	- Experience with MLIR, LLVM, or TVM
+ ***Experience working with large data sets and distributed computing tools (e.g. Redshift, Presto)***
+ Take end to end ownership of machine learning systems - data pipelines, candidate extraction, feature engineering, model training, as well as integration into our production systems
+ ***TensorRT, Deepstream Projects in video, speech, or NLP***
+ skill set:
	- At Cleanlab you’ll get to
		* Spend 100% of your time writing open-source ML, with guidance from MIT PhDs who are prominent in ML research. Get paid a Silicon Valley engineer salary but have the ability to work remotely from wherever you want. And the cherry on top? You get to work with a modern tech stack (the latest tooling and ML models) at a dynamic startup to pioneer the rapidly growing field of data-centric AI.
	- What we’re looking for
		* First and foremost, strong software engineering skills and experience productionizing your code. You should be comfortable with large software systems and love building applications.
		* Contributed to the open-source community for more than 4 years, either via your own open-source package or via substantial contributions to existing open-source repositories, written blog posts, and tutorials.
		* Experience working in ML: processing data, deploying models, etc. We do not require deep theoretical ML expertise, but practical experience in ML projects is desired.
	- Responsibilities
		* Develop and contribute novel data-centric AI algorithms to Cleanlab’s open-source projects, via high quality implementations and maintaining the highest coding standards.
		* Be a good member of the open-source community (address Github issues and queries, review PRs, write crisp documentation/tutorials, help integrate with other packages).
		* Work on applied ML projects with Cleanlab enterprise customers.
		* Collaborate with other engineers to build large-scale systems and help establish a strong engineering culture across the company.
	- Qualifications
		* We select candidates based on strengths, not on weaknesses. Experience with the following is highly recommended, but not required:
			+ Python, NumPy
			+ pandas, scikit-learn
			+ ***PyTorch/PyTorch Lightning or TensorFlow + Keras***
		* Bonus:
			+ ***MLOps Experience with model deployment and monitoring (MLflow, Sagemaker, etc.)***
			+ Databases and ETL (Postgres, etc.)
			+ Cleanlab or other data-centric AI tools
			+ ***AutoGluon, H2O, or other AutoML tools***
			+ ***Tableau, DataBricks, Alteryx, Trifacta***
			+ ***Hugging Face, Snorkel, Weights and Biases, Gradio, Streamlit***
	- Working at Cleanlab is awesome! Beyond the opportunity to work at a well-funded (backed by Bain Capital Ventures) early stage AI tech company with an incredible, friendly founding team of MIT, Stanford, and Harvard graduates, all full-time employees receive the following:
		* $9,000 per year travel benefit
		* Travel enhances our empathy with different cultures and enables us to work together more effectively. It’s how we grow and learn: traveling is an essential part of what makes us human. At Cleanlab, every two months you will receive a $1500 reimbursable travel benefit (resets on Jan 1, March 1, May 1, July 1, Sep 1, Nov 1). This is a unique benefit that lets you work from Paris for a week in February, then take a backpacking trip in the Andes for a weekend in March. Cleanlab will cover the flight for your partner or friend, too, as long as you attend and its within the $1500 / two-month period. For remote employees, you can use this benefit to come work with us in Boston/SF from time to time (encouraged, but not required).
		* Premium health insurance
			+ We provide a fantastic $4 (we cover the rest) health insurance option. We also provide a $0 deductible 100% coverage premium health care option for those who prefer the best health insurance.
		* Stipend for attending conferences to keep up with the latest innovations in ML and software.
		* Competitive salary (+ equity offering for certain roles), with regular opportunities for a raise if things are going well.
	- Cleanlab is focused on data-centric AI (DCAI), providing algorithms/interfaces to help companies (across all industries) improve the quality of their datasets and diagnose/fix various issues in them. We develop next-generation DCAI algorithms that are publicly contributed via open-source (github.com/cleanlab), as well as SaaS enterprise products with interfaces for data scientists/engineers to effectively improve their data quality and produce more reliable ML models.
	- Founded by 3 ML PhDs from MIT and engineers/scientists from Stanford & Harvard, Cleanlab is a well-funded early-stage startup that is rapidly growing to transform the future of DCAI. Some of Cleanlab’s early work (while the company was still in stealth-mode) has been featured in various media such as: Wired, MIT Technology Review, and VentureBeat.
	- While many companies can help store/manage data or develop ML models, there exist few solutions today to improve the quality of existing data, which is the core asset of the modern enterprise. This is where you come in. At Cleanlab, you’ll be able to take ownership of critical projects that pioneer the future of data-centric AI.
	- We are a remote-first company, with roughly half of our team located near Boston, MA (EST time) and the other half located near San Francisco, CA (PST time).
+ skill set:
	- Work on cutting-edge MLOps with guidance from MIT PhDs who are prominent in ML research.
	- Develop large-scale web applications for data-centric AI. Our tools enable data scientists/engineers (across all industries) to effectively diagnose/fix issues in their datasets thus improving the quality of their business’s core asset.
	- Work on interesting challenges (model deployment/monitoring, managing massive datasets, rapidly scaling cloud deployments, etc.) at a dynamic startup operating in one of the fastest growing subfields of data science & AI.
	- As a Cleanlab software engineer, you will be responsible for Cleanlab Pro, a user-friendly web app built on our ML algorithms. You’ll orchestrate cloud infrastructure for data ingestion, model training, and data analysis, and you’ll optimize the reliability of our web app, model deployments, and data management systems.
	- We encourage applications from software engineers with DevOps/backend/cloud experience who have some familiarity with machine learning and are interested in furthering their MLOps skills. Your contributions to our SaaS tool will be used by data scientists/engineers across all industries to improve the quality of their data and reliability of ML models produced from this data. Come help us build the next generation of data-centric AI!
	- Orchestrate cloud infrastructure to reliably support a SaaS data and machine learning pipeline.
	- Design, develop, test, deploy, maintain, and improve software, using a modern tech stack.
	- Contribute cloud/container integrations and other deployment/monitoring solutions to Cleanlab’s open-source library.
	- Collaborate with other engineers to build and maintain large-scale systems and establish a strong engineering culture across the company.
	- We select candidates based on strengths, not based on weaknesses. Candidates should have at leat 3+ years experience developing web apps using a modern tech stack and shipping code to production.
		* Linux
		* Python
		* Shell
		* Java/C++
		* AWS
		* Docker + Kubernetes
		* Git
		* CI/Testing, e.g. Jenkins
		* Bonus:
			+ AWS DevOps Stack (https://aws.amazon.com/devops/)
			+ AWS Sagemaker
			+ MLSys/MLOps experience
			+ IaC, e.g. Ansible, Terraform
+ ***Infrastructure as Code (IaC)***:
	- ***Ansible***
	- ***Terraform***
	- https://en.wikipedia.org/wiki/Infrastructure_as_code
+ skill set:
	- Contribute to open-source with guidance from MIT PhDs who are prominent in ML research.
	- Develop large-scale web applications for data-centric AI. Our tools enable data scientists/engineers (across all industries) to effectively diagnose/fix issues in their datasets thus improving the quality of their business’s core asset.
	- Get paid a Silicon Valley engineer salary but have the ability to work remotely with flexible hours.
	- Work on interesting challenges (massive datasets, scaling systems, security/privacy, novel interfaces for data editing, etc.) using modern tech stack at a dynamic startup operating in one of the fastest growing subfields of data science & AI.
	- As a Cleanlab software engineer, you will be responsible for building Cleanlab Pro, a user-friendly web app built on our ML algorithms. You’ll work on scalable backend code for data ingestion, model training, and data analysis, and you’ll help design beautiful and easy-to-use interfaces for data visualization, interpretation, and correction.
	- We encourage applications from full-stack software engineers who have some familiarity with machine learning and are interested in furthering their skills in building MLOps applications. Your contributions to our SaaS tool will be used by data scientists/engineers across all industries to improve the quality of their data and reliability of ML models produced from this data. Come help us build the next generation of data-centric AI!
	- Developing a SaaS data and machine learning pipeline.
	- Design, develop, test, deploy, maintain, and improve software, using a modern tech stack.
	- Write server and client-side code for web applications, optimizing for speed, scale, and ease-of-use.
	- Collaborate with other engineers to build large-scale systems and help establish a strong engineering culture across the company.
	- We select candidates based on strengths, not based on weaknesses. Candidates should have at leat 3+ years experience developing web apps using a modern tech stack and shipping code to production.
	- Experience with the following is recommended (but not necessarily required):
		* Python, Flask
		* Relational databases (e.g. PostgreSQL)
		* JavaScript + React, HTML, CSS (and SCSS)
		* AWS (or other similar cloud tools like Azure, GCP)
	- Bonus points if you have experience with some of the following:
		* Docker, Kubernetes
sklearn, pandas
		* Distributed computing (Ray, Spark, etc.)
		* Model serving, deployment, sharing (Sagemaker, Triton, gradio, etc.)
+ skill set:
	- JavaScript/TypeScript
	- React.js/Next.js
	- HTML
	- CSS + some CSS Framework (Chakra UI, Tailwind, Bootstrap)
	- Module bundlers, e.g. Webpack
	- Visualization libraries, e.g. D3.js
	- React testing libraries, e.g. Jest
	- Desktop app frameworks, e.g. Electron
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.
+ skill set:
	- BLAH.


















+ AI compiler design
	- Poplar framework for IPU architecture compiler.
+ AI compilers:
	- MLIR
	- TVM
	- Glow




To use mathematical notations in Web browsers, try:
+ MathJax
+ MathML
+ OpenMath
+ KaTeX
+ AsciiMath
	- Or, AsciiMathML
	- ASCIIMathML.js
	- ASCIIMathML
	- LaTeXMathML
+ Lout